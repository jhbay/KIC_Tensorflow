{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.8.0\n",
      "training :  0  accuracy =   0.0600  loss =  230.683\n",
      "testing  :  0  accuracy =   0.0974  loss =  230.38\n",
      "training :  1  accuracy =   0.0900  loss =  230.331\n",
      "testing  :  1  accuracy =   0.0974  loss =  230.339\n",
      "training :  2  accuracy =   0.1100  loss =  230.319\n",
      "testing  :  2  accuracy =   0.0974  loss =  230.285\n",
      "training :  3  accuracy =   0.1000  loss =  230.226\n",
      "testing  :  3  accuracy =   0.1032  loss =  230.249\n",
      "training :  4  accuracy =   0.0700  loss =  231.275\n",
      "testing  :  4  accuracy =   0.1032  loss =  230.215\n",
      "training :  5  accuracy =   0.0600  loss =  230.734\n",
      "testing  :  5  accuracy =   0.1032  loss =  230.166\n",
      "training :  6  accuracy =   0.2100  loss =  229.887\n",
      "testing  :  6  accuracy =   0.2000  loss =  230.106\n",
      "training :  7  accuracy =   0.1500  loss =  229.707\n",
      "testing  :  7  accuracy =   0.1135  loss =  230.059\n",
      "training :  8  accuracy =   0.1100  loss =  229.841\n",
      "testing  :  8  accuracy =   0.1135  loss =  230.019\n",
      "training :  9  accuracy =   0.0700  loss =  230.984\n",
      "testing  :  9  accuracy =   0.1135  loss =  229.988\n",
      "training :  10  accuracy =   0.1200  loss =  229.908\n",
      "testing  :  10  accuracy =   0.1135  loss =  229.959\n",
      "training :  11  accuracy =   0.0900  loss =  230.307\n",
      "testing  :  11  accuracy =   0.1135  loss =  229.93\n",
      "training :  12  accuracy =   0.1300  loss =  229.689\n",
      "testing  :  12  accuracy =   0.1135  loss =  229.901\n",
      "training :  13  accuracy =   0.1200  loss =  229.517\n",
      "testing  :  13  accuracy =   0.1135  loss =  229.865\n",
      "training :  14  accuracy =   0.0800  loss =  230.394\n",
      "testing  :  14  accuracy =   0.1135  loss =  229.826\n",
      "training :  15  accuracy =   0.1000  loss =  229.481\n",
      "testing  :  15  accuracy =   0.1135  loss =  229.78\n",
      "training :  16  accuracy =   0.0900  loss =  230.548\n",
      "testing  :  16  accuracy =   0.1135  loss =  229.73\n",
      "training :  17  accuracy =   0.0900  loss =  228.957\n",
      "testing  :  17  accuracy =   0.1135  loss =  229.67\n",
      "training :  18  accuracy =   0.0600  loss =  229.62\n",
      "testing  :  18  accuracy =   0.1135  loss =  229.605\n",
      "training :  19  accuracy =   0.0800  loss =  229.979\n",
      "testing  :  19  accuracy =   0.1135  loss =  229.543\n",
      "training :  20  accuracy =   0.0500  loss =  230.418\n",
      "testing  :  20  accuracy =   0.1233  loss =  229.475\n",
      "training :  21  accuracy =   0.2100  loss =  230.457\n",
      "testing  :  21  accuracy =   0.2654  loss =  229.401\n",
      "training :  22  accuracy =   0.3400  loss =  228.573\n",
      "testing  :  22  accuracy =   0.2725  loss =  229.31\n",
      "training :  23  accuracy =   0.2800  loss =  228.43\n",
      "testing  :  23  accuracy =   0.2639  loss =  229.212\n",
      "training :  24  accuracy =   0.3200  loss =  229.13\n",
      "testing  :  24  accuracy =   0.2816  loss =  229.097\n",
      "training :  25  accuracy =   0.2900  loss =  229.575\n",
      "testing  :  25  accuracy =   0.2942  loss =  228.968\n",
      "training :  26  accuracy =   0.2000  loss =  230.228\n",
      "testing  :  26  accuracy =   0.2949  loss =  228.824\n",
      "training :  27  accuracy =   0.2900  loss =  229.092\n",
      "testing  :  27  accuracy =   0.2955  loss =  228.666\n",
      "training :  28  accuracy =   0.2500  loss =  228.773\n",
      "testing  :  28  accuracy =   0.2925  loss =  228.499\n",
      "training :  29  accuracy =   0.3000  loss =  228.489\n",
      "testing  :  29  accuracy =   0.2915  loss =  228.32\n",
      "training :  30  accuracy =   0.2200  loss =  229.462\n",
      "testing  :  30  accuracy =   0.2957  loss =  228.123\n",
      "training :  31  accuracy =   0.3400  loss =  228.145\n",
      "testing  :  31  accuracy =   0.3051  loss =  227.915\n",
      "training :  32  accuracy =   0.3400  loss =  227.743\n",
      "testing  :  32  accuracy =   0.3292  loss =  227.689\n",
      "training :  33  accuracy =   0.3500  loss =  227.983\n",
      "testing  :  33  accuracy =   0.3499  loss =  227.446\n",
      "training :  34  accuracy =   0.3100  loss =  227.976\n",
      "testing  :  34  accuracy =   0.3760  loss =  227.18\n",
      "training :  35  accuracy =   0.3800  loss =  227.061\n",
      "testing  :  35  accuracy =   0.3766  loss =  226.898\n",
      "training :  36  accuracy =   0.4000  loss =  226.335\n",
      "testing  :  36  accuracy =   0.3652  loss =  226.599\n",
      "training :  37  accuracy =   0.3500  loss =  226.092\n",
      "testing  :  37  accuracy =   0.3485  loss =  226.28\n",
      "training :  38  accuracy =   0.3200  loss =  226.354\n",
      "testing  :  38  accuracy =   0.3365  loss =  225.938\n",
      "training :  39  accuracy =   0.3300  loss =  225.752\n",
      "testing  :  39  accuracy =   0.3246  loss =  225.594\n",
      "training :  40  accuracy =   0.3300  loss =  224.518\n",
      "testing  :  40  accuracy =   0.3187  loss =  225.232\n",
      "training :  41  accuracy =   0.3500  loss =  225.36\n",
      "testing  :  41  accuracy =   0.3287  loss =  224.84\n",
      "training :  42  accuracy =   0.4000  loss =  223.606\n",
      "testing  :  42  accuracy =   0.3640  loss =  224.422\n",
      "training :  43  accuracy =   0.3900  loss =  224.233\n",
      "testing  :  43  accuracy =   0.3835  loss =  223.992\n",
      "training :  44  accuracy =   0.4400  loss =  223.375\n",
      "testing  :  44  accuracy =   0.4083  loss =  223.545\n",
      "training :  45  accuracy =   0.4000  loss =  223.361\n",
      "testing  :  45  accuracy =   0.4240  loss =  223.078\n",
      "training :  46  accuracy =   0.4700  loss =  222.277\n",
      "testing  :  46  accuracy =   0.4985  loss =  222.604\n",
      "training :  47  accuracy =   0.4500  loss =  222.992\n",
      "testing  :  47  accuracy =   0.5105  loss =  222.117\n",
      "training :  48  accuracy =   0.5700  loss =  220.849\n",
      "testing  :  48  accuracy =   0.5169  loss =  221.634\n",
      "training :  49  accuracy =   0.5300  loss =  221.491\n",
      "testing  :  49  accuracy =   0.5102  loss =  221.116\n",
      "training :  50  accuracy =   0.5800  loss =  220.041\n",
      "testing  :  50  accuracy =   0.5040  loss =  220.55\n",
      "training :  51  accuracy =   0.4600  loss =  220.033\n",
      "testing  :  51  accuracy =   0.4951  loss =  219.958\n",
      "training :  52  accuracy =   0.4200  loss =  220.008\n",
      "testing  :  52  accuracy =   0.4892  loss =  219.391\n",
      "training :  53  accuracy =   0.4700  loss =  218.402\n",
      "testing  :  53  accuracy =   0.4872  loss =  218.845\n",
      "training :  54  accuracy =   0.4900  loss =  218.056\n",
      "testing  :  54  accuracy =   0.4837  loss =  218.287\n",
      "training :  55  accuracy =   0.5000  loss =  217.862\n",
      "testing  :  55  accuracy =   0.4871  loss =  217.71\n",
      "training :  56  accuracy =   0.5300  loss =  217.432\n",
      "testing  :  56  accuracy =   0.4996  loss =  217.074\n",
      "training :  57  accuracy =   0.5000  loss =  216.769\n",
      "testing  :  57  accuracy =   0.5159  loss =  216.426\n",
      "training :  58  accuracy =   0.5900  loss =  215.268\n",
      "testing  :  58  accuracy =   0.5294  loss =  215.791\n",
      "training :  59  accuracy =   0.5300  loss =  215.713\n",
      "testing  :  59  accuracy =   0.5351  loss =  215.209\n",
      "training :  60  accuracy =   0.5100  loss =  215.537\n",
      "testing  :  60  accuracy =   0.5345  loss =  214.625\n",
      "training :  61  accuracy =   0.5500  loss =  214.357\n",
      "testing  :  61  accuracy =   0.5443  loss =  213.985\n",
      "training :  62  accuracy =   0.5100  loss =  214.092\n",
      "testing  :  62  accuracy =   0.5616  loss =  213.294\n",
      "training :  63  accuracy =   0.5600  loss =  212.656\n",
      "testing  :  63  accuracy =   0.5744  loss =  212.644\n",
      "training :  64  accuracy =   0.6500  loss =  212.482\n",
      "testing  :  64  accuracy =   0.5735  loss =  212.037\n",
      "training :  65  accuracy =   0.5600  loss =  211.114\n",
      "testing  :  65  accuracy =   0.5690  loss =  211.453\n",
      "training :  66  accuracy =   0.5600  loss =  211.085\n",
      "testing  :  66  accuracy =   0.5667  loss =  210.865\n",
      "training :  67  accuracy =   0.5900  loss =  209.724\n",
      "testing  :  67  accuracy =   0.5683  loss =  210.235\n",
      "training :  68  accuracy =   0.6100  loss =  209.636\n",
      "testing  :  68  accuracy =   0.5739  loss =  209.53\n",
      "training :  69  accuracy =   0.5200  loss =  209.201\n",
      "testing  :  69  accuracy =   0.5803  loss =  208.845\n",
      "training :  70  accuracy =   0.6200  loss =  208.089\n",
      "testing  :  70  accuracy =   0.5849  loss =  208.236\n",
      "training :  71  accuracy =   0.5900  loss =  206.7\n",
      "testing  :  71  accuracy =   0.5861  loss =  207.687\n",
      "training :  72  accuracy =   0.6200  loss =  206.722\n",
      "testing  :  72  accuracy =   0.5863  loss =  207.108\n",
      "training :  73  accuracy =   0.6400  loss =  205.573\n",
      "testing  :  73  accuracy =   0.5859  loss =  206.451\n",
      "training :  74  accuracy =   0.5400  loss =  204.963\n",
      "testing  :  74  accuracy =   0.5853  loss =  205.776\n",
      "training :  75  accuracy =   0.5600  loss =  206.394\n",
      "testing  :  75  accuracy =   0.5845  loss =  205.155\n",
      "training :  76  accuracy =   0.6600  loss =  204.388\n",
      "testing  :  76  accuracy =   0.5880  loss =  204.58\n",
      "training :  77  accuracy =   0.5700  loss =  204.195\n",
      "testing  :  77  accuracy =   0.5876  loss =  204.104\n",
      "training :  78  accuracy =   0.5300  loss =  203.526\n",
      "testing  :  78  accuracy =   0.5893  loss =  203.632\n",
      "training :  79  accuracy =   0.5100  loss =  203.49\n",
      "testing  :  79  accuracy =   0.5916  loss =  203.127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  80  accuracy =   0.6200  loss =  202.679\n",
      "testing  :  80  accuracy =   0.5950  loss =  202.52\n",
      "training :  81  accuracy =   0.6300  loss =  201.99\n",
      "testing  :  81  accuracy =   0.5981  loss =  201.859\n",
      "training :  82  accuracy =   0.5700  loss =  201.34\n",
      "testing  :  82  accuracy =   0.5973  loss =  201.255\n",
      "training :  83  accuracy =   0.6000  loss =  200.72\n",
      "testing  :  83  accuracy =   0.5954  loss =  200.723\n",
      "training :  84  accuracy =   0.5300  loss =  202.147\n",
      "testing  :  84  accuracy =   0.5981  loss =  200.258\n",
      "training :  85  accuracy =   0.5700  loss =  200.464\n",
      "testing  :  85  accuracy =   0.6032  loss =  199.826\n",
      "training :  86  accuracy =   0.6500  loss =  199.429\n",
      "testing  :  86  accuracy =   0.6103  loss =  199.471\n",
      "training :  87  accuracy =   0.6800  loss =  196.653\n",
      "testing  :  87  accuracy =   0.6151  loss =  199.101\n",
      "training :  88  accuracy =   0.6300  loss =  198.082\n",
      "testing  :  88  accuracy =   0.6190  loss =  198.707\n",
      "training :  89  accuracy =   0.6900  loss =  197.601\n",
      "testing  :  89  accuracy =   0.6252  loss =  198.184\n",
      "training :  90  accuracy =   0.7200  loss =  196.595\n",
      "testing  :  90  accuracy =   0.6327  loss =  197.575\n",
      "training :  91  accuracy =   0.6800  loss =  196.59\n",
      "testing  :  91  accuracy =   0.6425  loss =  197.048\n",
      "training :  92  accuracy =   0.6900  loss =  196.52\n",
      "testing  :  92  accuracy =   0.6521  loss =  196.7\n",
      "training :  93  accuracy =   0.6800  loss =  195.797\n",
      "testing  :  93  accuracy =   0.6589  loss =  196.295\n",
      "training :  94  accuracy =   0.6800  loss =  194.569\n",
      "testing  :  94  accuracy =   0.6641  loss =  195.848\n",
      "training :  95  accuracy =   0.6300  loss =  195.195\n",
      "testing  :  95  accuracy =   0.6687  loss =  195.475\n",
      "training :  96  accuracy =   0.6400  loss =  196.956\n",
      "testing  :  96  accuracy =   0.6749  loss =  194.904\n",
      "training :  97  accuracy =   0.6400  loss =  195.225\n",
      "testing  :  97  accuracy =   0.6763  loss =  194.323\n",
      "training :  98  accuracy =   0.6300  loss =  195.257\n",
      "testing  :  98  accuracy =   0.6767  loss =  193.853\n",
      "training :  99  accuracy =   0.7100  loss =  194.526\n",
      "testing  :  99  accuracy =   0.6786  loss =  193.469\n",
      "training :  100  accuracy =   0.6500  loss =  193.914\n",
      "testing  :  100  accuracy =   0.6784  loss =  193.233\n",
      "training :  101  accuracy =   0.6500  loss =  194.488\n",
      "testing  :  101  accuracy =   0.6835  loss =  192.95\n",
      "training :  102  accuracy =   0.6200  loss =  195.4\n",
      "testing  :  102  accuracy =   0.6914  loss =  192.558\n",
      "training :  103  accuracy =   0.7400  loss =  192.663\n",
      "testing  :  103  accuracy =   0.6978  loss =  192.205\n",
      "training :  104  accuracy =   0.6100  loss =  194.238\n",
      "testing  :  104  accuracy =   0.7031  loss =  191.807\n",
      "training :  105  accuracy =   0.6900  loss =  192.873\n",
      "testing  :  105  accuracy =   0.7041  loss =  191.37\n",
      "training :  106  accuracy =   0.6800  loss =  190.933\n",
      "testing  :  106  accuracy =   0.7092  loss =  190.978\n",
      "training :  107  accuracy =   0.7800  loss =  188.508\n",
      "testing  :  107  accuracy =   0.7154  loss =  190.653\n",
      "training :  108  accuracy =   0.6800  loss =  191.397\n",
      "testing  :  108  accuracy =   0.7195  loss =  190.371\n",
      "training :  109  accuracy =   0.7400  loss =  191.035\n",
      "testing  :  109  accuracy =   0.7251  loss =  190.104\n",
      "training :  110  accuracy =   0.7500  loss =  191.265\n",
      "testing  :  110  accuracy =   0.7261  loss =  189.8\n",
      "training :  111  accuracy =   0.7500  loss =  188.142\n",
      "testing  :  111  accuracy =   0.7320  loss =  189.457\n",
      "training :  112  accuracy =   0.7400  loss =  187.486\n",
      "testing  :  112  accuracy =   0.7351  loss =  189.109\n",
      "training :  113  accuracy =   0.7400  loss =  189.151\n",
      "testing  :  113  accuracy =   0.7381  loss =  188.812\n",
      "training :  114  accuracy =   0.7500  loss =  188.841\n",
      "testing  :  114  accuracy =   0.7371  loss =  188.528\n",
      "training :  115  accuracy =   0.7700  loss =  187.943\n",
      "testing  :  115  accuracy =   0.7363  loss =  188.258\n",
      "training :  116  accuracy =   0.7200  loss =  190.111\n",
      "testing  :  116  accuracy =   0.7348  loss =  187.973\n",
      "training :  117  accuracy =   0.7200  loss =  186.969\n",
      "testing  :  117  accuracy =   0.7282  loss =  187.71\n",
      "training :  118  accuracy =   0.6400  loss =  192.007\n",
      "testing  :  118  accuracy =   0.7188  loss =  187.497\n",
      "training :  119  accuracy =   0.7100  loss =  187.849\n",
      "testing  :  119  accuracy =   0.7156  loss =  187.226\n",
      "training :  120  accuracy =   0.7400  loss =  186.278\n",
      "testing  :  120  accuracy =   0.7151  loss =  186.959\n",
      "training :  121  accuracy =   0.7500  loss =  186.811\n",
      "testing  :  121  accuracy =   0.7185  loss =  186.723\n",
      "training :  122  accuracy =   0.7500  loss =  186.166\n",
      "testing  :  122  accuracy =   0.7198  loss =  186.479\n",
      "training :  123  accuracy =   0.7400  loss =  186.961\n",
      "testing  :  123  accuracy =   0.7199  loss =  186.298\n",
      "training :  124  accuracy =   0.7100  loss =  184.971\n",
      "testing  :  124  accuracy =   0.7271  loss =  185.995\n",
      "training :  125  accuracy =   0.7700  loss =  185.221\n",
      "testing  :  125  accuracy =   0.7267  loss =  185.747\n",
      "training :  126  accuracy =   0.7500  loss =  183.959\n",
      "testing  :  126  accuracy =   0.7177  loss =  185.55\n",
      "training :  127  accuracy =   0.7000  loss =  185.538\n",
      "testing  :  127  accuracy =   0.7134  loss =  185.44\n",
      "training :  128  accuracy =   0.7000  loss =  187.291\n",
      "testing  :  128  accuracy =   0.7079  loss =  185.341\n",
      "training :  129  accuracy =   0.6600  loss =  186.379\n",
      "testing  :  129  accuracy =   0.7088  loss =  185.159\n",
      "training :  130  accuracy =   0.7400  loss =  185.365\n",
      "testing  :  130  accuracy =   0.7215  loss =  184.849\n",
      "training :  131  accuracy =   0.6200  loss =  186.687\n",
      "testing  :  131  accuracy =   0.7282  loss =  184.475\n",
      "training :  132  accuracy =   0.6900  loss =  183.126\n",
      "testing  :  132  accuracy =   0.7191  loss =  184.147\n",
      "training :  133  accuracy =   0.6600  loss =  183.508\n",
      "testing  :  133  accuracy =   0.7067  loss =  183.909\n",
      "training :  134  accuracy =   0.7500  loss =  180.476\n",
      "testing  :  134  accuracy =   0.6978  loss =  183.73\n",
      "training :  135  accuracy =   0.7900  loss =  181.735\n",
      "testing  :  135  accuracy =   0.6930  loss =  183.515\n",
      "training :  136  accuracy =   0.7000  loss =  183.304\n",
      "testing  :  136  accuracy =   0.6878  loss =  183.33\n",
      "training :  137  accuracy =   0.7100  loss =  182.624\n",
      "testing  :  137  accuracy =   0.6933  loss =  183.122\n",
      "training :  138  accuracy =   0.7200  loss =  186.085\n",
      "testing  :  138  accuracy =   0.7066  loss =  182.906\n",
      "training :  139  accuracy =   0.6900  loss =  184.545\n",
      "testing  :  139  accuracy =   0.7216  loss =  182.644\n",
      "training :  140  accuracy =   0.7200  loss =  180.965\n",
      "testing  :  140  accuracy =   0.7314  loss =  182.358\n",
      "training :  141  accuracy =   0.6800  loss =  183.42\n",
      "testing  :  141  accuracy =   0.7304  loss =  182.222\n",
      "training :  142  accuracy =   0.7600  loss =  181.721\n",
      "testing  :  142  accuracy =   0.7279  loss =  182.067\n",
      "training :  143  accuracy =   0.7600  loss =  180.137\n",
      "testing  :  143  accuracy =   0.7214  loss =  181.947\n",
      "training :  144  accuracy =   0.8000  loss =  180.109\n",
      "testing  :  144  accuracy =   0.7154  loss =  181.856\n",
      "training :  145  accuracy =   0.7600  loss =  181.253\n",
      "testing  :  145  accuracy =   0.7117  loss =  181.704\n",
      "training :  146  accuracy =   0.7100  loss =  180.21\n",
      "testing  :  146  accuracy =   0.7189  loss =  181.445\n",
      "training :  147  accuracy =   0.7800  loss =  180.897\n",
      "testing  :  147  accuracy =   0.7278  loss =  181.185\n",
      "training :  148  accuracy =   0.7000  loss =  180.634\n",
      "testing  :  148  accuracy =   0.7326  loss =  180.987\n",
      "training :  149  accuracy =   0.7600  loss =  180.22\n",
      "testing  :  149  accuracy =   0.7419  loss =  180.726\n",
      "training :  150  accuracy =   0.8200  loss =  178.86\n",
      "testing  :  150  accuracy =   0.7557  loss =  180.501\n",
      "training :  151  accuracy =   0.7300  loss =  180.589\n",
      "testing  :  151  accuracy =   0.7641  loss =  180.375\n",
      "training :  152  accuracy =   0.7800  loss =  182.127\n",
      "testing  :  152  accuracy =   0.7704  loss =  180.263\n",
      "training :  153  accuracy =   0.7600  loss =  179.78\n",
      "testing  :  153  accuracy =   0.7750  loss =  180.17\n",
      "training :  154  accuracy =   0.8200  loss =  177.372\n",
      "testing  :  154  accuracy =   0.7740  loss =  180.091\n",
      "training :  155  accuracy =   0.7600  loss =  182.408\n",
      "testing  :  155  accuracy =   0.7681  loss =  179.961\n",
      "training :  156  accuracy =   0.7500  loss =  181.67\n",
      "testing  :  156  accuracy =   0.7618  loss =  179.867\n",
      "training :  157  accuracy =   0.7500  loss =  179.874\n",
      "testing  :  157  accuracy =   0.7403  loss =  179.979\n",
      "training :  158  accuracy =   0.7000  loss =  180.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  158  accuracy =   0.7364  loss =  179.807\n",
      "training :  159  accuracy =   0.7200  loss =  180.114\n",
      "testing  :  159  accuracy =   0.7336  loss =  179.612\n",
      "training :  160  accuracy =   0.7500  loss =  180.392\n",
      "testing  :  160  accuracy =   0.7330  loss =  179.312\n",
      "training :  161  accuracy =   0.7500  loss =  180.611\n",
      "testing  :  161  accuracy =   0.7314  loss =  178.996\n",
      "training :  162  accuracy =   0.7700  loss =  180.813\n",
      "testing  :  162  accuracy =   0.7368  loss =  178.799\n",
      "training :  163  accuracy =   0.7300  loss =  178.717\n",
      "testing  :  163  accuracy =   0.7407  loss =  178.725\n",
      "training :  164  accuracy =   0.7000  loss =  182.534\n",
      "testing  :  164  accuracy =   0.7454  loss =  178.693\n",
      "training :  165  accuracy =   0.7000  loss =  178.229\n",
      "testing  :  165  accuracy =   0.7473  loss =  178.532\n",
      "training :  166  accuracy =   0.7800  loss =  181.197\n",
      "testing  :  166  accuracy =   0.7560  loss =  178.301\n",
      "training :  167  accuracy =   0.8100  loss =  177.667\n",
      "testing  :  167  accuracy =   0.7658  loss =  178.033\n",
      "training :  168  accuracy =   0.7700  loss =  176.586\n",
      "testing  :  168  accuracy =   0.7657  loss =  177.887\n",
      "training :  169  accuracy =   0.7700  loss =  178.011\n",
      "testing  :  169  accuracy =   0.7683  loss =  177.675\n",
      "training :  170  accuracy =   0.7900  loss =  179.937\n",
      "testing  :  170  accuracy =   0.7707  loss =  177.49\n",
      "training :  171  accuracy =   0.7800  loss =  180.023\n",
      "testing  :  171  accuracy =   0.7712  loss =  177.45\n",
      "training :  172  accuracy =   0.7500  loss =  175.455\n",
      "testing  :  172  accuracy =   0.7722  loss =  177.341\n",
      "training :  173  accuracy =   0.8000  loss =  176.396\n",
      "testing  :  173  accuracy =   0.7714  loss =  177.194\n",
      "training :  174  accuracy =   0.7200  loss =  176.559\n",
      "testing  :  174  accuracy =   0.7704  loss =  177.047\n",
      "training :  175  accuracy =   0.7000  loss =  180.387\n",
      "testing  :  175  accuracy =   0.7682  loss =  176.948\n",
      "training :  176  accuracy =   0.7300  loss =  178.203\n",
      "testing  :  176  accuracy =   0.7650  loss =  176.834\n",
      "training :  177  accuracy =   0.7400  loss =  177.746\n",
      "testing  :  177  accuracy =   0.7636  loss =  176.782\n",
      "training :  178  accuracy =   0.7000  loss =  177.0\n",
      "testing  :  178  accuracy =   0.7629  loss =  176.786\n",
      "training :  179  accuracy =   0.7500  loss =  176.986\n",
      "testing  :  179  accuracy =   0.7626  loss =  176.753\n",
      "training :  180  accuracy =   0.7800  loss =  177.07\n",
      "testing  :  180  accuracy =   0.7587  loss =  176.653\n",
      "training :  181  accuracy =   0.7500  loss =  177.255\n",
      "testing  :  181  accuracy =   0.7562  loss =  176.565\n",
      "training :  182  accuracy =   0.7100  loss =  174.914\n",
      "testing  :  182  accuracy =   0.7576  loss =  176.322\n",
      "training :  183  accuracy =   0.8000  loss =  174.738\n",
      "testing  :  183  accuracy =   0.7615  loss =  176.036\n",
      "training :  184  accuracy =   0.8200  loss =  172.669\n",
      "testing  :  184  accuracy =   0.7590  loss =  175.785\n",
      "training :  185  accuracy =   0.7600  loss =  177.27\n",
      "testing  :  185  accuracy =   0.7463  loss =  175.7\n",
      "training :  186  accuracy =   0.7500  loss =  174.706\n",
      "testing  :  186  accuracy =   0.7241  loss =  175.864\n",
      "training :  187  accuracy =   0.7100  loss =  173.665\n",
      "testing  :  187  accuracy =   0.7098  loss =  176.117\n",
      "training :  188  accuracy =   0.7000  loss =  176.749\n",
      "testing  :  188  accuracy =   0.7000  loss =  176.342\n",
      "training :  189  accuracy =   0.7100  loss =  176.373\n",
      "testing  :  189  accuracy =   0.6958  loss =  176.22\n",
      "training :  190  accuracy =   0.5800  loss =  177.165\n",
      "testing  :  190  accuracy =   0.6948  loss =  175.766\n",
      "training :  191  accuracy =   0.6300  loss =  178.207\n",
      "testing  :  191  accuracy =   0.6926  loss =  175.284\n",
      "training :  192  accuracy =   0.6900  loss =  177.697\n",
      "testing  :  192  accuracy =   0.6909  loss =  174.899\n",
      "training :  193  accuracy =   0.6500  loss =  173.806\n",
      "testing  :  193  accuracy =   0.6864  loss =  174.85\n",
      "training :  194  accuracy =   0.6200  loss =  175.783\n",
      "testing  :  194  accuracy =   0.6829  loss =  175.047\n",
      "training :  195  accuracy =   0.6200  loss =  174.714\n",
      "testing  :  195  accuracy =   0.6771  loss =  175.298\n",
      "training :  196  accuracy =   0.7100  loss =  171.244\n",
      "testing  :  196  accuracy =   0.6724  loss =  175.536\n",
      "training :  197  accuracy =   0.7600  loss =  173.985\n",
      "testing  :  197  accuracy =   0.6728  loss =  175.283\n",
      "training :  198  accuracy =   0.7500  loss =  173.079\n",
      "testing  :  198  accuracy =   0.6710  loss =  174.848\n",
      "training :  199  accuracy =   0.6900  loss =  173.019\n",
      "testing  :  199  accuracy =   0.6656  loss =  174.481\n",
      "training :  200  accuracy =   0.6000  loss =  172.707\n",
      "testing  :  200  accuracy =   0.6583  loss =  174.262\n",
      "training :  201  accuracy =   0.6500  loss =  174.516\n",
      "testing  :  201  accuracy =   0.6485  loss =  174.297\n",
      "training :  202  accuracy =   0.6300  loss =  173.933\n",
      "testing  :  202  accuracy =   0.6462  loss =  174.426\n",
      "training :  203  accuracy =   0.5900  loss =  172.762\n",
      "testing  :  203  accuracy =   0.6469  loss =  174.572\n",
      "training :  204  accuracy =   0.6900  loss =  172.083\n",
      "testing  :  204  accuracy =   0.6520  loss =  174.685\n",
      "training :  205  accuracy =   0.7300  loss =  172.753\n",
      "testing  :  205  accuracy =   0.6654  loss =  174.578\n",
      "training :  206  accuracy =   0.6900  loss =  173.223\n",
      "testing  :  206  accuracy =   0.6833  loss =  174.245\n",
      "training :  207  accuracy =   0.6400  loss =  174.085\n",
      "testing  :  207  accuracy =   0.6940  loss =  174.147\n",
      "training :  208  accuracy =   0.8000  loss =  173.243\n",
      "testing  :  208  accuracy =   0.6974  loss =  174.009\n",
      "training :  209  accuracy =   0.6500  loss =  173.549\n",
      "testing  :  209  accuracy =   0.6943  loss =  174.058\n",
      "training :  210  accuracy =   0.6700  loss =  170.977\n",
      "testing  :  210  accuracy =   0.6863  loss =  173.956\n",
      "training :  211  accuracy =   0.7200  loss =  173.194\n",
      "testing  :  211  accuracy =   0.6892  loss =  173.871\n",
      "training :  212  accuracy =   0.6200  loss =  176.855\n",
      "testing  :  212  accuracy =   0.7011  loss =  173.928\n",
      "training :  213  accuracy =   0.6200  loss =  176.799\n",
      "testing  :  213  accuracy =   0.7060  loss =  173.914\n",
      "training :  214  accuracy =   0.7700  loss =  171.26\n",
      "testing  :  214  accuracy =   0.7087  loss =  173.824\n",
      "training :  215  accuracy =   0.7200  loss =  173.724\n",
      "testing  :  215  accuracy =   0.7092  loss =  173.703\n",
      "training :  216  accuracy =   0.7500  loss =  170.453\n",
      "testing  :  216  accuracy =   0.7134  loss =  173.505\n",
      "training :  217  accuracy =   0.7200  loss =  172.512\n",
      "testing  :  217  accuracy =   0.7176  loss =  173.306\n",
      "training :  218  accuracy =   0.8100  loss =  171.087\n",
      "testing  :  218  accuracy =   0.7120  loss =  173.231\n",
      "training :  219  accuracy =   0.7200  loss =  171.278\n",
      "testing  :  219  accuracy =   0.7114  loss =  173.088\n",
      "training :  220  accuracy =   0.7100  loss =  169.388\n",
      "testing  :  220  accuracy =   0.7136  loss =  172.962\n",
      "training :  221  accuracy =   0.6600  loss =  172.906\n",
      "testing  :  221  accuracy =   0.7086  loss =  172.943\n",
      "training :  222  accuracy =   0.7200  loss =  172.434\n",
      "testing  :  222  accuracy =   0.7028  loss =  172.967\n",
      "training :  223  accuracy =   0.6500  loss =  172.827\n",
      "testing  :  223  accuracy =   0.7030  loss =  172.87\n",
      "training :  224  accuracy =   0.7600  loss =  172.31\n",
      "testing  :  224  accuracy =   0.6989  loss =  172.933\n",
      "training :  225  accuracy =   0.7000  loss =  173.594\n",
      "testing  :  225  accuracy =   0.7070  loss =  172.851\n",
      "training :  226  accuracy =   0.7700  loss =  170.848\n",
      "testing  :  226  accuracy =   0.7160  loss =  172.791\n",
      "training :  227  accuracy =   0.7600  loss =  175.534\n",
      "testing  :  227  accuracy =   0.7227  loss =  172.867\n",
      "training :  228  accuracy =   0.7300  loss =  172.362\n",
      "testing  :  228  accuracy =   0.7301  loss =  172.764\n",
      "training :  229  accuracy =   0.7500  loss =  175.252\n",
      "testing  :  229  accuracy =   0.7386  loss =  172.707\n",
      "training :  230  accuracy =   0.6500  loss =  175.967\n",
      "testing  :  230  accuracy =   0.7466  loss =  172.522\n",
      "training :  231  accuracy =   0.7500  loss =  171.239\n",
      "testing  :  231  accuracy =   0.7565  loss =  172.255\n",
      "training :  232  accuracy =   0.8000  loss =  172.805\n",
      "testing  :  232  accuracy =   0.7664  loss =  172.059\n",
      "training :  233  accuracy =   0.7800  loss =  173.338\n",
      "testing  :  233  accuracy =   0.7702  loss =  171.962\n",
      "training :  234  accuracy =   0.8300  loss =  172.774\n",
      "testing  :  234  accuracy =   0.7690  loss =  171.927\n",
      "training :  235  accuracy =   0.7900  loss =  171.412\n",
      "testing  :  235  accuracy =   0.7658  loss =  171.938\n",
      "training :  236  accuracy =   0.7300  loss =  172.169\n",
      "testing  :  236  accuracy =   0.7630  loss =  171.942\n",
      "training :  237  accuracy =   0.7800  loss =  173.248\n",
      "testing  :  237  accuracy =   0.7629  loss =  171.922\n",
      "training :  238  accuracy =   0.6800  loss =  177.482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  238  accuracy =   0.7620  loss =  171.889\n",
      "training :  239  accuracy =   0.7800  loss =  171.866\n",
      "testing  :  239  accuracy =   0.7617  loss =  171.867\n",
      "training :  240  accuracy =   0.7200  loss =  172.366\n",
      "testing  :  240  accuracy =   0.7635  loss =  171.744\n",
      "training :  241  accuracy =   0.8100  loss =  171.051\n",
      "testing  :  241  accuracy =   0.7696  loss =  171.687\n",
      "training :  242  accuracy =   0.7900  loss =  169.972\n",
      "testing  :  242  accuracy =   0.7705  loss =  171.653\n",
      "training :  243  accuracy =   0.7200  loss =  167.959\n",
      "testing  :  243  accuracy =   0.7702  loss =  171.602\n",
      "training :  244  accuracy =   0.7800  loss =  171.831\n",
      "testing  :  244  accuracy =   0.7701  loss =  171.541\n",
      "training :  245  accuracy =   0.7500  loss =  173.824\n",
      "testing  :  245  accuracy =   0.7645  loss =  171.451\n",
      "training :  246  accuracy =   0.7600  loss =  172.087\n",
      "testing  :  246  accuracy =   0.7580  loss =  171.285\n",
      "training :  247  accuracy =   0.8000  loss =  169.799\n",
      "testing  :  247  accuracy =   0.7561  loss =  171.13\n",
      "training :  248  accuracy =   0.8000  loss =  166.016\n",
      "testing  :  248  accuracy =   0.7534  loss =  171.106\n",
      "training :  249  accuracy =   0.7800  loss =  168.766\n",
      "testing  :  249  accuracy =   0.7508  loss =  171.163\n",
      "training :  250  accuracy =   0.7300  loss =  171.29\n",
      "testing  :  250  accuracy =   0.7534  loss =  171.276\n",
      "training :  251  accuracy =   0.6900  loss =  173.853\n",
      "testing  :  251  accuracy =   0.7556  loss =  171.421\n",
      "training :  252  accuracy =   0.7600  loss =  167.932\n",
      "testing  :  252  accuracy =   0.7595  loss =  171.364\n",
      "training :  253  accuracy =   0.6900  loss =  173.751\n",
      "testing  :  253  accuracy =   0.7648  loss =  171.3\n",
      "training :  254  accuracy =   0.7600  loss =  172.022\n",
      "testing  :  254  accuracy =   0.7746  loss =  171.066\n",
      "training :  255  accuracy =   0.8000  loss =  172.525\n",
      "testing  :  255  accuracy =   0.7769  loss =  170.799\n",
      "training :  256  accuracy =   0.8100  loss =  170.151\n",
      "testing  :  256  accuracy =   0.7740  loss =  170.647\n",
      "training :  257  accuracy =   0.7500  loss =  171.847\n",
      "testing  :  257  accuracy =   0.7677  loss =  170.717\n",
      "training :  258  accuracy =   0.6900  loss =  173.857\n",
      "testing  :  258  accuracy =   0.7582  loss =  170.967\n",
      "training :  259  accuracy =   0.8000  loss =  170.978\n",
      "testing  :  259  accuracy =   0.7566  loss =  171.056\n",
      "training :  260  accuracy =   0.7700  loss =  171.851\n",
      "testing  :  260  accuracy =   0.7535  loss =  171.164\n",
      "training :  261  accuracy =   0.7500  loss =  174.374\n",
      "testing  :  261  accuracy =   0.7526  loss =  171.229\n",
      "training :  262  accuracy =   0.6800  loss =  173.822\n",
      "testing  :  262  accuracy =   0.7559  loss =  171.132\n",
      "training :  263  accuracy =   0.8000  loss =  170.55\n",
      "testing  :  263  accuracy =   0.7630  loss =  170.928\n",
      "training :  264  accuracy =   0.8000  loss =  172.536\n",
      "testing  :  264  accuracy =   0.7728  loss =  170.686\n",
      "training :  265  accuracy =   0.8100  loss =  169.48\n",
      "testing  :  265  accuracy =   0.7791  loss =  170.55\n",
      "training :  266  accuracy =   0.8700  loss =  168.245\n",
      "testing  :  266  accuracy =   0.7764  loss =  170.6\n",
      "training :  267  accuracy =   0.8200  loss =  168.39\n",
      "testing  :  267  accuracy =   0.7720  loss =  170.67\n",
      "training :  268  accuracy =   0.7700  loss =  169.825\n",
      "testing  :  268  accuracy =   0.7641  loss =  170.632\n",
      "training :  269  accuracy =   0.7600  loss =  171.355\n",
      "testing  :  269  accuracy =   0.7569  loss =  170.538\n",
      "training :  270  accuracy =   0.7600  loss =  171.303\n",
      "testing  :  270  accuracy =   0.7481  loss =  170.292\n",
      "training :  271  accuracy =   0.7200  loss =  169.422\n",
      "testing  :  271  accuracy =   0.7377  loss =  170.067\n",
      "training :  272  accuracy =   0.7800  loss =  167.837\n",
      "testing  :  272  accuracy =   0.7318  loss =  169.917\n",
      "training :  273  accuracy =   0.7200  loss =  171.478\n",
      "testing  :  273  accuracy =   0.7311  loss =  169.899\n",
      "training :  274  accuracy =   0.7200  loss =  172.08\n",
      "testing  :  274  accuracy =   0.7340  loss =  169.907\n",
      "training :  275  accuracy =   0.7400  loss =  173.937\n",
      "testing  :  275  accuracy =   0.7447  loss =  169.995\n",
      "training :  276  accuracy =   0.7800  loss =  170.08\n",
      "testing  :  276  accuracy =   0.7479  loss =  170.008\n",
      "training :  277  accuracy =   0.8100  loss =  168.368\n",
      "testing  :  277  accuracy =   0.7542  loss =  169.893\n",
      "training :  278  accuracy =   0.7800  loss =  169.184\n",
      "testing  :  278  accuracy =   0.7547  loss =  169.721\n",
      "training :  279  accuracy =   0.6900  loss =  173.533\n",
      "testing  :  279  accuracy =   0.7502  loss =  169.697\n",
      "training :  280  accuracy =   0.7100  loss =  173.263\n",
      "testing  :  280  accuracy =   0.7482  loss =  169.829\n",
      "training :  281  accuracy =   0.7500  loss =  169.239\n",
      "testing  :  281  accuracy =   0.7471  loss =  169.912\n",
      "training :  282  accuracy =   0.7400  loss =  168.66\n",
      "testing  :  282  accuracy =   0.7452  loss =  169.956\n",
      "training :  283  accuracy =   0.7900  loss =  167.325\n",
      "testing  :  283  accuracy =   0.7471  loss =  169.981\n",
      "training :  284  accuracy =   0.8000  loss =  169.418\n",
      "testing  :  284  accuracy =   0.7488  loss =  169.775\n",
      "training :  285  accuracy =   0.8100  loss =  167.043\n",
      "testing  :  285  accuracy =   0.7505  loss =  169.517\n",
      "training :  286  accuracy =   0.7800  loss =  169.231\n",
      "testing  :  286  accuracy =   0.7511  loss =  169.381\n",
      "training :  287  accuracy =   0.7000  loss =  168.699\n",
      "testing  :  287  accuracy =   0.7394  loss =  169.328\n",
      "training :  288  accuracy =   0.7300  loss =  168.309\n",
      "testing  :  288  accuracy =   0.7290  loss =  169.327\n",
      "training :  289  accuracy =   0.7200  loss =  165.95\n",
      "testing  :  289  accuracy =   0.7227  loss =  169.299\n",
      "training :  290  accuracy =   0.7100  loss =  172.118\n",
      "testing  :  290  accuracy =   0.7268  loss =  169.273\n",
      "training :  291  accuracy =   0.7400  loss =  167.605\n",
      "testing  :  291  accuracy =   0.7270  loss =  169.261\n",
      "training :  292  accuracy =   0.7200  loss =  174.04\n",
      "testing  :  292  accuracy =   0.7288  loss =  169.258\n",
      "training :  293  accuracy =   0.7600  loss =  169.763\n",
      "testing  :  293  accuracy =   0.7343  loss =  169.182\n",
      "training :  294  accuracy =   0.7400  loss =  168.986\n",
      "testing  :  294  accuracy =   0.7402  loss =  169.081\n",
      "training :  295  accuracy =   0.7800  loss =  168.357\n",
      "testing  :  295  accuracy =   0.7469  loss =  169.056\n",
      "training :  296  accuracy =   0.7500  loss =  167.487\n",
      "testing  :  296  accuracy =   0.7435  loss =  169.095\n",
      "training :  297  accuracy =   0.7500  loss =  172.378\n",
      "testing  :  297  accuracy =   0.7420  loss =  169.187\n",
      "training :  298  accuracy =   0.7800  loss =  165.722\n",
      "testing  :  298  accuracy =   0.7436  loss =  169.276\n",
      "training :  299  accuracy =   0.8400  loss =  168.378\n",
      "testing  :  299  accuracy =   0.7465  loss =  169.33\n",
      "training :  300  accuracy =   0.7500  loss =  173.533\n",
      "testing  :  300  accuracy =   0.7515  loss =  169.353\n",
      "training :  301  accuracy =   0.7000  loss =  168.081\n",
      "testing  :  301  accuracy =   0.7581  loss =  169.314\n",
      "training :  302  accuracy =   0.7300  loss =  171.19\n",
      "testing  :  302  accuracy =   0.7685  loss =  169.211\n",
      "training :  303  accuracy =   0.7400  loss =  167.398\n",
      "testing  :  303  accuracy =   0.7745  loss =  169.091\n",
      "training :  304  accuracy =   0.7400  loss =  169.412\n",
      "testing  :  304  accuracy =   0.7726  loss =  169.011\n",
      "training :  305  accuracy =   0.7600  loss =  168.936\n",
      "testing  :  305  accuracy =   0.7685  loss =  168.922\n",
      "training :  306  accuracy =   0.7400  loss =  167.206\n",
      "testing  :  306  accuracy =   0.7525  loss =  168.81\n",
      "training :  307  accuracy =   0.7700  loss =  169.062\n",
      "testing  :  307  accuracy =   0.7299  loss =  168.816\n",
      "training :  308  accuracy =   0.7200  loss =  168.135\n",
      "testing  :  308  accuracy =   0.7124  loss =  168.839\n",
      "training :  309  accuracy =   0.6000  loss =  171.127\n",
      "testing  :  309  accuracy =   0.7023  loss =  168.772\n",
      "training :  310  accuracy =   0.6700  loss =  171.205\n",
      "testing  :  310  accuracy =   0.6947  loss =  168.712\n",
      "training :  311  accuracy =   0.7600  loss =  166.39\n",
      "testing  :  311  accuracy =   0.6851  loss =  168.713\n",
      "training :  312  accuracy =   0.6800  loss =  169.103\n",
      "testing  :  312  accuracy =   0.6709  loss =  168.801\n",
      "training :  313  accuracy =   0.6300  loss =  171.209\n",
      "testing  :  313  accuracy =   0.6689  loss =  168.915\n",
      "training :  314  accuracy =   0.6200  loss =  170.158\n",
      "testing  :  314  accuracy =   0.6710  loss =  168.92\n",
      "training :  315  accuracy =   0.6500  loss =  172.503\n",
      "testing  :  315  accuracy =   0.6907  loss =  168.792\n",
      "training :  316  accuracy =   0.7000  loss =  170.342\n",
      "testing  :  316  accuracy =   0.7064  loss =  168.739\n",
      "training :  317  accuracy =   0.6400  loss =  169.157\n",
      "testing  :  317  accuracy =   0.7231  loss =  168.644\n",
      "training :  318  accuracy =   0.7200  loss =  169.295\n",
      "testing  :  318  accuracy =   0.7416  loss =  168.527\n",
      "training :  319  accuracy =   0.7600  loss =  170.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  319  accuracy =   0.7674  loss =  168.466\n",
      "training :  320  accuracy =   0.7500  loss =  168.944\n",
      "testing  :  320  accuracy =   0.7698  loss =  168.515\n",
      "training :  321  accuracy =   0.8400  loss =  168.288\n",
      "testing  :  321  accuracy =   0.7751  loss =  168.655\n",
      "training :  322  accuracy =   0.7800  loss =  166.635\n",
      "testing  :  322  accuracy =   0.7673  loss =  168.791\n",
      "training :  323  accuracy =   0.7800  loss =  170.697\n",
      "testing  :  323  accuracy =   0.7624  loss =  168.881\n",
      "training :  324  accuracy =   0.7400  loss =  168.666\n",
      "testing  :  324  accuracy =   0.7631  loss =  168.859\n",
      "training :  325  accuracy =   0.7000  loss =  170.645\n",
      "testing  :  325  accuracy =   0.7600  loss =  168.813\n",
      "training :  326  accuracy =   0.7000  loss =  171.195\n",
      "testing  :  326  accuracy =   0.7540  loss =  168.878\n",
      "training :  327  accuracy =   0.7600  loss =  170.489\n",
      "testing  :  327  accuracy =   0.7586  loss =  168.735\n",
      "training :  328  accuracy =   0.8100  loss =  167.733\n",
      "testing  :  328  accuracy =   0.7645  loss =  168.533\n",
      "training :  329  accuracy =   0.7800  loss =  166.705\n",
      "testing  :  329  accuracy =   0.7580  loss =  168.383\n",
      "training :  330  accuracy =   0.6800  loss =  169.704\n",
      "testing  :  330  accuracy =   0.7469  loss =  168.2\n",
      "training :  331  accuracy =   0.7200  loss =  168.777\n",
      "testing  :  331  accuracy =   0.7241  loss =  168.016\n",
      "training :  332  accuracy =   0.7300  loss =  167.496\n",
      "testing  :  332  accuracy =   0.6964  loss =  167.952\n",
      "training :  333  accuracy =   0.8100  loss =  165.046\n",
      "testing  :  333  accuracy =   0.6777  loss =  168.008\n",
      "training :  334  accuracy =   0.6000  loss =  169.995\n",
      "testing  :  334  accuracy =   0.6613  loss =  168.134\n",
      "training :  335  accuracy =   0.7300  loss =  168.255\n",
      "testing  :  335  accuracy =   0.6454  loss =  168.287\n",
      "training :  336  accuracy =   0.6400  loss =  172.974\n",
      "testing  :  336  accuracy =   0.6351  loss =  168.425\n",
      "training :  337  accuracy =   0.7200  loss =  166.55\n",
      "testing  :  337  accuracy =   0.6288  loss =  168.508\n",
      "training :  338  accuracy =   0.6100  loss =  168.854\n",
      "testing  :  338  accuracy =   0.6284  loss =  168.543\n",
      "training :  339  accuracy =   0.6700  loss =  166.024\n",
      "testing  :  339  accuracy =   0.6338  loss =  168.473\n",
      "training :  340  accuracy =   0.6200  loss =  173.578\n",
      "testing  :  340  accuracy =   0.6385  loss =  168.323\n",
      "training :  341  accuracy =   0.5600  loss =  168.698\n",
      "testing  :  341  accuracy =   0.6500  loss =  167.991\n",
      "training :  342  accuracy =   0.6200  loss =  167.578\n",
      "testing  :  342  accuracy =   0.6629  loss =  167.8\n",
      "training :  343  accuracy =   0.7100  loss =  169.873\n",
      "testing  :  343  accuracy =   0.6736  loss =  167.743\n",
      "training :  344  accuracy =   0.5800  loss =  170.666\n",
      "testing  :  344  accuracy =   0.6807  loss =  167.919\n",
      "training :  345  accuracy =   0.7300  loss =  167.954\n",
      "testing  :  345  accuracy =   0.6772  loss =  168.426\n",
      "training :  346  accuracy =   0.7100  loss =  167.749\n",
      "testing  :  346  accuracy =   0.6719  loss =  168.981\n",
      "training :  347  accuracy =   0.7000  loss =  171.277\n",
      "testing  :  347  accuracy =   0.6691  loss =  169.102\n",
      "training :  348  accuracy =   0.6000  loss =  172.671\n",
      "testing  :  348  accuracy =   0.6732  loss =  168.775\n",
      "training :  349  accuracy =   0.6800  loss =  166.497\n",
      "testing  :  349  accuracy =   0.6829  loss =  168.274\n",
      "training :  350  accuracy =   0.7300  loss =  166.532\n",
      "testing  :  350  accuracy =   0.6912  loss =  167.848\n",
      "training :  351  accuracy =   0.7000  loss =  166.608\n",
      "testing  :  351  accuracy =   0.6997  loss =  167.624\n",
      "training :  352  accuracy =   0.7300  loss =  168.828\n",
      "testing  :  352  accuracy =   0.7054  loss =  167.605\n",
      "training :  353  accuracy =   0.6900  loss =  166.954\n",
      "testing  :  353  accuracy =   0.7098  loss =  167.633\n",
      "training :  354  accuracy =   0.7600  loss =  167.203\n",
      "testing  :  354  accuracy =   0.7107  loss =  167.695\n",
      "training :  355  accuracy =   0.7600  loss =  167.735\n",
      "testing  :  355  accuracy =   0.7071  loss =  167.708\n",
      "training :  356  accuracy =   0.6700  loss =  169.416\n",
      "testing  :  356  accuracy =   0.6967  loss =  167.671\n",
      "training :  357  accuracy =   0.7100  loss =  168.041\n",
      "testing  :  357  accuracy =   0.6895  loss =  167.574\n",
      "training :  358  accuracy =   0.6600  loss =  167.512\n",
      "testing  :  358  accuracy =   0.6742  loss =  167.546\n",
      "training :  359  accuracy =   0.6500  loss =  169.419\n",
      "testing  :  359  accuracy =   0.6647  loss =  167.465\n",
      "training :  360  accuracy =   0.6500  loss =  166.041\n",
      "testing  :  360  accuracy =   0.6543  loss =  167.435\n",
      "training :  361  accuracy =   0.7300  loss =  163.199\n",
      "testing  :  361  accuracy =   0.6466  loss =  167.456\n",
      "training :  362  accuracy =   0.7000  loss =  164.873\n",
      "testing  :  362  accuracy =   0.6371  loss =  167.524\n",
      "training :  363  accuracy =   0.6400  loss =  166.673\n",
      "testing  :  363  accuracy =   0.6309  loss =  167.589\n",
      "training :  364  accuracy =   0.6700  loss =  168.481\n",
      "testing  :  364  accuracy =   0.6268  loss =  167.691\n",
      "training :  365  accuracy =   0.6000  loss =  170.839\n",
      "testing  :  365  accuracy =   0.6326  loss =  167.575\n",
      "training :  366  accuracy =   0.6600  loss =  167.991\n",
      "testing  :  366  accuracy =   0.6435  loss =  167.403\n",
      "training :  367  accuracy =   0.6400  loss =  167.392\n",
      "testing  :  367  accuracy =   0.6458  loss =  167.284\n",
      "training :  368  accuracy =   0.6100  loss =  169.568\n",
      "testing  :  368  accuracy =   0.6486  loss =  167.188\n",
      "training :  369  accuracy =   0.6600  loss =  166.14\n",
      "testing  :  369  accuracy =   0.6546  loss =  167.17\n",
      "training :  370  accuracy =   0.6700  loss =  169.851\n",
      "testing  :  370  accuracy =   0.6619  loss =  167.247\n",
      "training :  371  accuracy =   0.7100  loss =  166.482\n",
      "testing  :  371  accuracy =   0.6748  loss =  167.325\n",
      "training :  372  accuracy =   0.6600  loss =  167.578\n",
      "testing  :  372  accuracy =   0.6856  loss =  167.386\n",
      "training :  373  accuracy =   0.7000  loss =  166.653\n",
      "testing  :  373  accuracy =   0.6898  loss =  167.426\n",
      "training :  374  accuracy =   0.7200  loss =  169.475\n",
      "testing  :  374  accuracy =   0.6932  loss =  167.45\n",
      "training :  375  accuracy =   0.6900  loss =  167.906\n",
      "testing  :  375  accuracy =   0.6964  loss =  167.392\n",
      "training :  376  accuracy =   0.6700  loss =  166.775\n",
      "testing  :  376  accuracy =   0.7000  loss =  167.312\n",
      "training :  377  accuracy =   0.6400  loss =  168.716\n",
      "testing  :  377  accuracy =   0.7035  loss =  167.257\n",
      "training :  378  accuracy =   0.7100  loss =  165.771\n",
      "testing  :  378  accuracy =   0.7075  loss =  167.156\n",
      "training :  379  accuracy =   0.7100  loss =  168.739\n",
      "testing  :  379  accuracy =   0.7097  loss =  167.159\n",
      "training :  380  accuracy =   0.6400  loss =  169.055\n",
      "testing  :  380  accuracy =   0.7115  loss =  167.215\n",
      "training :  381  accuracy =   0.7500  loss =  167.988\n",
      "testing  :  381  accuracy =   0.7100  loss =  167.252\n",
      "training :  382  accuracy =   0.7300  loss =  167.023\n",
      "testing  :  382  accuracy =   0.7091  loss =  167.22\n",
      "training :  383  accuracy =   0.6700  loss =  169.383\n",
      "testing  :  383  accuracy =   0.7050  loss =  167.135\n",
      "training :  384  accuracy =   0.7400  loss =  166.44\n",
      "testing  :  384  accuracy =   0.7010  loss =  167.056\n",
      "training :  385  accuracy =   0.6900  loss =  167.688\n",
      "testing  :  385  accuracy =   0.6952  loss =  167.103\n",
      "training :  386  accuracy =   0.7200  loss =  167.608\n",
      "testing  :  386  accuracy =   0.6911  loss =  167.149\n",
      "training :  387  accuracy =   0.7000  loss =  169.198\n",
      "testing  :  387  accuracy =   0.6849  loss =  167.211\n",
      "training :  388  accuracy =   0.7300  loss =  167.078\n",
      "testing  :  388  accuracy =   0.6923  loss =  166.91\n",
      "training :  389  accuracy =   0.7100  loss =  165.216\n",
      "testing  :  389  accuracy =   0.6949  loss =  166.748\n",
      "training :  390  accuracy =   0.5800  loss =  167.541\n",
      "testing  :  390  accuracy =   0.6964  loss =  166.639\n",
      "training :  391  accuracy =   0.7300  loss =  166.691\n",
      "testing  :  391  accuracy =   0.6965  loss =  166.646\n",
      "training :  392  accuracy =   0.7400  loss =  166.363\n",
      "testing  :  392  accuracy =   0.6978  loss =  166.743\n",
      "training :  393  accuracy =   0.7200  loss =  166.397\n",
      "testing  :  393  accuracy =   0.6988  loss =  166.905\n",
      "training :  394  accuracy =   0.7800  loss =  162.931\n",
      "testing  :  394  accuracy =   0.7009  loss =  167.064\n",
      "training :  395  accuracy =   0.7500  loss =  169.638\n",
      "testing  :  395  accuracy =   0.7048  loss =  167.104\n",
      "training :  396  accuracy =   0.7300  loss =  167.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  396  accuracy =   0.7067  loss =  167.03\n",
      "training :  397  accuracy =   0.8100  loss =  164.737\n",
      "testing  :  397  accuracy =   0.7072  loss =  166.915\n",
      "training :  398  accuracy =   0.7100  loss =  167.287\n",
      "testing  :  398  accuracy =   0.7074  loss =  166.802\n",
      "training :  399  accuracy =   0.6900  loss =  166.052\n",
      "testing  :  399  accuracy =   0.7081  loss =  166.663\n",
      "training :  400  accuracy =   0.6800  loss =  166.846\n",
      "testing  :  400  accuracy =   0.7079  loss =  166.584\n",
      "training :  401  accuracy =   0.7600  loss =  164.284\n",
      "testing  :  401  accuracy =   0.7078  loss =  166.519\n",
      "training :  402  accuracy =   0.6600  loss =  165.54\n",
      "testing  :  402  accuracy =   0.7050  loss =  166.488\n",
      "training :  403  accuracy =   0.6900  loss =  167.118\n",
      "testing  :  403  accuracy =   0.7055  loss =  166.501\n",
      "training :  404  accuracy =   0.6600  loss =  166.332\n",
      "testing  :  404  accuracy =   0.7054  loss =  166.541\n",
      "training :  405  accuracy =   0.7300  loss =  164.631\n",
      "testing  :  405  accuracy =   0.7040  loss =  166.565\n",
      "training :  406  accuracy =   0.7100  loss =  163.805\n",
      "testing  :  406  accuracy =   0.6983  loss =  166.547\n",
      "training :  407  accuracy =   0.6900  loss =  168.328\n",
      "testing  :  407  accuracy =   0.6909  loss =  166.551\n",
      "training :  408  accuracy =   0.7200  loss =  165.545\n",
      "testing  :  408  accuracy =   0.6854  loss =  166.578\n",
      "training :  409  accuracy =   0.7400  loss =  164.529\n",
      "testing  :  409  accuracy =   0.6786  loss =  166.57\n",
      "training :  410  accuracy =   0.6000  loss =  169.382\n",
      "testing  :  410  accuracy =   0.6702  loss =  166.501\n",
      "training :  411  accuracy =   0.6600  loss =  167.144\n",
      "testing  :  411  accuracy =   0.6687  loss =  166.424\n",
      "training :  412  accuracy =   0.6100  loss =  166.588\n",
      "testing  :  412  accuracy =   0.6698  loss =  166.375\n",
      "training :  413  accuracy =   0.6900  loss =  165.765\n",
      "testing  :  413  accuracy =   0.6735  loss =  166.37\n",
      "training :  414  accuracy =   0.6400  loss =  169.992\n",
      "testing  :  414  accuracy =   0.6821  loss =  166.38\n",
      "training :  415  accuracy =   0.7400  loss =  166.213\n",
      "testing  :  415  accuracy =   0.6837  loss =  166.391\n",
      "training :  416  accuracy =   0.6600  loss =  168.784\n",
      "testing  :  416  accuracy =   0.6828  loss =  166.399\n",
      "training :  417  accuracy =   0.6800  loss =  167.838\n",
      "testing  :  417  accuracy =   0.6759  loss =  166.542\n",
      "training :  418  accuracy =   0.6600  loss =  168.801\n",
      "testing  :  418  accuracy =   0.6700  loss =  166.601\n",
      "training :  419  accuracy =   0.6700  loss =  165.797\n",
      "testing  :  419  accuracy =   0.6666  loss =  166.557\n",
      "training :  420  accuracy =   0.6400  loss =  166.695\n",
      "testing  :  420  accuracy =   0.6636  loss =  166.487\n",
      "training :  421  accuracy =   0.6700  loss =  163.843\n",
      "testing  :  421  accuracy =   0.6643  loss =  166.465\n",
      "training :  422  accuracy =   0.6400  loss =  166.458\n",
      "testing  :  422  accuracy =   0.6666  loss =  166.484\n",
      "training :  423  accuracy =   0.5900  loss =  166.898\n",
      "testing  :  423  accuracy =   0.6696  loss =  166.494\n",
      "training :  424  accuracy =   0.6300  loss =  167.606\n",
      "testing  :  424  accuracy =   0.6757  loss =  166.431\n",
      "training :  425  accuracy =   0.7000  loss =  165.651\n",
      "testing  :  425  accuracy =   0.6797  loss =  166.454\n",
      "training :  426  accuracy =   0.7200  loss =  170.049\n",
      "testing  :  426  accuracy =   0.6857  loss =  166.55\n",
      "training :  427  accuracy =   0.7300  loss =  163.825\n",
      "testing  :  427  accuracy =   0.6896  loss =  166.633\n",
      "training :  428  accuracy =   0.6800  loss =  171.42\n",
      "testing  :  428  accuracy =   0.6919  loss =  166.627\n",
      "training :  429  accuracy =   0.7600  loss =  165.738\n",
      "testing  :  429  accuracy =   0.6931  loss =  166.569\n",
      "training :  430  accuracy =   0.7800  loss =  163.337\n",
      "testing  :  430  accuracy =   0.6927  loss =  166.431\n",
      "training :  431  accuracy =   0.7100  loss =  167.177\n",
      "testing  :  431  accuracy =   0.6942  loss =  166.337\n",
      "training :  432  accuracy =   0.6300  loss =  169.548\n",
      "testing  :  432  accuracy =   0.6983  loss =  166.266\n",
      "training :  433  accuracy =   0.7100  loss =  166.465\n",
      "testing  :  433  accuracy =   0.6976  loss =  166.213\n",
      "training :  434  accuracy =   0.7800  loss =  164.346\n",
      "testing  :  434  accuracy =   0.6972  loss =  166.192\n",
      "training :  435  accuracy =   0.6000  loss =  167.174\n",
      "testing  :  435  accuracy =   0.6904  loss =  166.225\n",
      "training :  436  accuracy =   0.6200  loss =  166.561\n",
      "testing  :  436  accuracy =   0.6828  loss =  166.277\n",
      "training :  437  accuracy =   0.6300  loss =  166.401\n",
      "testing  :  437  accuracy =   0.6781  loss =  166.328\n",
      "training :  438  accuracy =   0.6600  loss =  165.2\n",
      "testing  :  438  accuracy =   0.6735  loss =  166.357\n",
      "training :  439  accuracy =   0.6700  loss =  168.287\n",
      "testing  :  439  accuracy =   0.6656  loss =  166.404\n",
      "training :  440  accuracy =   0.6700  loss =  165.142\n",
      "testing  :  440  accuracy =   0.6512  loss =  166.498\n",
      "training :  441  accuracy =   0.6900  loss =  164.021\n",
      "testing  :  441  accuracy =   0.6373  loss =  166.589\n",
      "training :  442  accuracy =   0.6500  loss =  166.142\n",
      "testing  :  442  accuracy =   0.6200  loss =  166.666\n",
      "training :  443  accuracy =   0.5600  loss =  165.484\n",
      "testing  :  443  accuracy =   0.6113  loss =  166.803\n",
      "training :  444  accuracy =   0.6300  loss =  168.809\n",
      "testing  :  444  accuracy =   0.6133  loss =  166.864\n",
      "training :  445  accuracy =   0.6400  loss =  166.216\n",
      "testing  :  445  accuracy =   0.6218  loss =  166.723\n",
      "training :  446  accuracy =   0.6400  loss =  166.168\n",
      "testing  :  446  accuracy =   0.6260  loss =  166.672\n",
      "training :  447  accuracy =   0.6500  loss =  166.198\n",
      "testing  :  447  accuracy =   0.6311  loss =  166.439\n",
      "training :  448  accuracy =   0.6300  loss =  166.997\n",
      "testing  :  448  accuracy =   0.6346  loss =  166.217\n",
      "training :  449  accuracy =   0.5800  loss =  166.565\n",
      "testing  :  449  accuracy =   0.6337  loss =  166.068\n",
      "training :  450  accuracy =   0.6400  loss =  166.637\n",
      "testing  :  450  accuracy =   0.6298  loss =  165.997\n",
      "training :  451  accuracy =   0.5800  loss =  167.525\n",
      "testing  :  451  accuracy =   0.6223  loss =  165.879\n",
      "training :  452  accuracy =   0.5800  loss =  168.382\n",
      "testing  :  452  accuracy =   0.6133  loss =  165.811\n",
      "training :  453  accuracy =   0.5300  loss =  166.935\n",
      "testing  :  453  accuracy =   0.6050  loss =  165.867\n",
      "training :  454  accuracy =   0.6300  loss =  165.224\n",
      "testing  :  454  accuracy =   0.5989  loss =  165.941\n",
      "training :  455  accuracy =   0.6100  loss =  164.406\n",
      "testing  :  455  accuracy =   0.5977  loss =  165.969\n",
      "training :  456  accuracy =   0.5600  loss =  167.632\n",
      "testing  :  456  accuracy =   0.5992  loss =  165.969\n",
      "training :  457  accuracy =   0.4700  loss =  168.897\n",
      "testing  :  457  accuracy =   0.6025  loss =  165.95\n",
      "training :  458  accuracy =   0.6500  loss =  165.163\n",
      "testing  :  458  accuracy =   0.6186  loss =  165.929\n",
      "training :  459  accuracy =   0.6800  loss =  169.71\n",
      "testing  :  459  accuracy =   0.6369  loss =  165.787\n",
      "training :  460  accuracy =   0.7200  loss =  163.419\n",
      "testing  :  460  accuracy =   0.6559  loss =  165.645\n",
      "training :  461  accuracy =   0.6900  loss =  167.023\n",
      "testing  :  461  accuracy =   0.6641  loss =  165.653\n",
      "training :  462  accuracy =   0.6500  loss =  164.207\n",
      "testing  :  462  accuracy =   0.6589  loss =  165.818\n",
      "training :  463  accuracy =   0.6800  loss =  166.077\n",
      "testing  :  463  accuracy =   0.6555  loss =  166.065\n",
      "training :  464  accuracy =   0.6600  loss =  165.932\n",
      "testing  :  464  accuracy =   0.6508  loss =  166.224\n",
      "training :  465  accuracy =   0.6400  loss =  167.567\n",
      "testing  :  465  accuracy =   0.6538  loss =  166.294\n",
      "training :  466  accuracy =   0.5600  loss =  168.852\n",
      "testing  :  466  accuracy =   0.6564  loss =  166.227\n",
      "training :  467  accuracy =   0.7400  loss =  162.342\n",
      "testing  :  467  accuracy =   0.6608  loss =  166.135\n",
      "training :  468  accuracy =   0.6600  loss =  163.485\n",
      "testing  :  468  accuracy =   0.6637  loss =  166.148\n",
      "training :  469  accuracy =   0.5900  loss =  173.79\n",
      "testing  :  469  accuracy =   0.6611  loss =  166.326\n",
      "training :  470  accuracy =   0.6300  loss =  168.107\n",
      "testing  :  470  accuracy =   0.6574  loss =  166.497\n",
      "training :  471  accuracy =   0.7300  loss =  167.903\n",
      "testing  :  471  accuracy =   0.6549  loss =  166.465\n",
      "training :  472  accuracy =   0.5900  loss =  171.485\n",
      "testing  :  472  accuracy =   0.6547  loss =  166.368\n",
      "training :  473  accuracy =   0.6500  loss =  170.793\n",
      "testing  :  473  accuracy =   0.6533  loss =  166.154\n",
      "training :  474  accuracy =   0.7200  loss =  161.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  474  accuracy =   0.6544  loss =  165.934\n",
      "training :  475  accuracy =   0.7000  loss =  162.949\n",
      "testing  :  475  accuracy =   0.6628  loss =  165.818\n",
      "training :  476  accuracy =   0.7000  loss =  164.193\n",
      "testing  :  476  accuracy =   0.6697  loss =  165.797\n",
      "training :  477  accuracy =   0.6800  loss =  167.994\n",
      "testing  :  477  accuracy =   0.6814  loss =  165.846\n",
      "training :  478  accuracy =   0.7000  loss =  163.091\n",
      "testing  :  478  accuracy =   0.6883  loss =  165.879\n",
      "training :  479  accuracy =   0.7400  loss =  165.936\n",
      "testing  :  479  accuracy =   0.7034  loss =  165.946\n",
      "training :  480  accuracy =   0.6600  loss =  169.147\n",
      "testing  :  480  accuracy =   0.7088  loss =  166.17\n",
      "training :  481  accuracy =   0.7600  loss =  165.6\n",
      "testing  :  481  accuracy =   0.7070  loss =  166.538\n",
      "training :  482  accuracy =   0.7000  loss =  165.288\n",
      "testing  :  482  accuracy =   0.7030  loss =  167.039\n",
      "training :  483  accuracy =   0.6600  loss =  166.909\n",
      "testing  :  483  accuracy =   0.6942  loss =  167.374\n",
      "training :  484  accuracy =   0.6800  loss =  167.742\n",
      "testing  :  484  accuracy =   0.6976  loss =  167.164\n",
      "training :  485  accuracy =   0.7500  loss =  166.939\n",
      "testing  :  485  accuracy =   0.6989  loss =  166.992\n",
      "training :  486  accuracy =   0.7400  loss =  163.869\n",
      "testing  :  486  accuracy =   0.7014  loss =  166.313\n",
      "training :  487  accuracy =   0.7400  loss =  165.066\n",
      "testing  :  487  accuracy =   0.7036  loss =  165.828\n",
      "training :  488  accuracy =   0.7100  loss =  168.238\n",
      "testing  :  488  accuracy =   0.7041  loss =  165.495\n",
      "training :  489  accuracy =   0.6700  loss =  163.386\n",
      "testing  :  489  accuracy =   0.7012  loss =  165.344\n",
      "training :  490  accuracy =   0.7000  loss =  165.534\n",
      "testing  :  490  accuracy =   0.6917  loss =  165.384\n",
      "training :  491  accuracy =   0.7100  loss =  167.883\n",
      "testing  :  491  accuracy =   0.6839  loss =  165.488\n",
      "training :  492  accuracy =   0.6300  loss =  167.354\n",
      "testing  :  492  accuracy =   0.6728  loss =  165.663\n",
      "training :  493  accuracy =   0.6200  loss =  169.393\n",
      "testing  :  493  accuracy =   0.6628  loss =  165.837\n",
      "training :  494  accuracy =   0.6200  loss =  167.714\n",
      "testing  :  494  accuracy =   0.6615  loss =  165.874\n",
      "training :  495  accuracy =   0.6800  loss =  164.154\n",
      "testing  :  495  accuracy =   0.6603  loss =  165.852\n",
      "training :  496  accuracy =   0.6900  loss =  166.867\n",
      "testing  :  496  accuracy =   0.6569  loss =  165.789\n",
      "training :  497  accuracy =   0.6000  loss =  168.655\n",
      "testing  :  497  accuracy =   0.6553  loss =  165.761\n",
      "training :  498  accuracy =   0.7000  loss =  165.545\n",
      "testing  :  498  accuracy =   0.6567  loss =  165.697\n",
      "training :  499  accuracy =   0.6800  loss =  166.171\n",
      "testing  :  499  accuracy =   0.6542  loss =  165.601\n",
      "training :  500  accuracy =   0.5700  loss =  166.388\n",
      "testing  :  500  accuracy =   0.6471  loss =  165.499\n",
      "training :  501  accuracy =   0.6700  loss =  164.965\n",
      "testing  :  501  accuracy =   0.6481  loss =  165.468\n",
      "training :  502  accuracy =   0.6500  loss =  165.324\n",
      "testing  :  502  accuracy =   0.6427  loss =  165.49\n",
      "training :  503  accuracy =   0.5600  loss =  171.277\n",
      "testing  :  503  accuracy =   0.6402  loss =  165.498\n",
      "training :  504  accuracy =   0.7200  loss =  163.055\n",
      "testing  :  504  accuracy =   0.6396  loss =  165.399\n",
      "training :  505  accuracy =   0.7000  loss =  162.765\n",
      "testing  :  505  accuracy =   0.6397  loss =  165.298\n",
      "training :  506  accuracy =   0.6500  loss =  163.08\n",
      "testing  :  506  accuracy =   0.6395  loss =  165.225\n",
      "training :  507  accuracy =   0.6200  loss =  172.23\n",
      "testing  :  507  accuracy =   0.6397  loss =  165.178\n",
      "training :  508  accuracy =   0.6600  loss =  168.581\n",
      "testing  :  508  accuracy =   0.6394  loss =  165.156\n",
      "training :  509  accuracy =   0.5100  loss =  170.295\n",
      "testing  :  509  accuracy =   0.6381  loss =  165.134\n",
      "training :  510  accuracy =   0.6400  loss =  166.995\n",
      "testing  :  510  accuracy =   0.6378  loss =  165.087\n",
      "training :  511  accuracy =   0.5800  loss =  163.989\n",
      "testing  :  511  accuracy =   0.6386  loss =  165.061\n",
      "training :  512  accuracy =   0.6400  loss =  165.977\n",
      "testing  :  512  accuracy =   0.6392  loss =  165.065\n",
      "training :  513  accuracy =   0.6300  loss =  165.623\n",
      "testing  :  513  accuracy =   0.6409  loss =  165.13\n",
      "training :  514  accuracy =   0.6400  loss =  165.544\n",
      "testing  :  514  accuracy =   0.6397  loss =  165.184\n",
      "training :  515  accuracy =   0.7000  loss =  163.941\n",
      "testing  :  515  accuracy =   0.6439  loss =  165.214\n",
      "training :  516  accuracy =   0.7300  loss =  163.222\n",
      "testing  :  516  accuracy =   0.6633  loss =  165.21\n",
      "training :  517  accuracy =   0.7100  loss =  166.233\n",
      "testing  :  517  accuracy =   0.6809  loss =  165.143\n",
      "training :  518  accuracy =   0.7100  loss =  165.12\n",
      "testing  :  518  accuracy =   0.6967  loss =  165.029\n",
      "training :  519  accuracy =   0.7300  loss =  164.219\n",
      "testing  :  519  accuracy =   0.7029  loss =  164.935\n",
      "training :  520  accuracy =   0.7500  loss =  166.106\n",
      "testing  :  520  accuracy =   0.7034  loss =  164.882\n",
      "training :  521  accuracy =   0.6800  loss =  165.675\n",
      "testing  :  521  accuracy =   0.6965  loss =  164.875\n",
      "training :  522  accuracy =   0.6700  loss =  165.03\n",
      "testing  :  522  accuracy =   0.6890  loss =  164.921\n",
      "training :  523  accuracy =   0.6500  loss =  164.766\n",
      "testing  :  523  accuracy =   0.6771  loss =  165.011\n",
      "training :  524  accuracy =   0.7600  loss =  161.891\n",
      "testing  :  524  accuracy =   0.6649  loss =  165.147\n",
      "training :  525  accuracy =   0.5800  loss =  170.304\n",
      "testing  :  525  accuracy =   0.6548  loss =  165.255\n",
      "training :  526  accuracy =   0.5700  loss =  169.005\n",
      "testing  :  526  accuracy =   0.6496  loss =  165.401\n",
      "training :  527  accuracy =   0.6200  loss =  169.926\n",
      "testing  :  527  accuracy =   0.6460  loss =  165.45\n",
      "training :  528  accuracy =   0.6700  loss =  165.222\n",
      "testing  :  528  accuracy =   0.6493  loss =  165.275\n",
      "training :  529  accuracy =   0.6700  loss =  167.377\n",
      "testing  :  529  accuracy =   0.6596  loss =  165.003\n",
      "training :  530  accuracy =   0.6600  loss =  165.343\n",
      "testing  :  530  accuracy =   0.6710  loss =  164.765\n",
      "training :  531  accuracy =   0.6600  loss =  163.493\n",
      "testing  :  531  accuracy =   0.6801  loss =  164.708\n",
      "training :  532  accuracy =   0.7400  loss =  165.049\n",
      "testing  :  532  accuracy =   0.6871  loss =  164.809\n",
      "training :  533  accuracy =   0.6600  loss =  166.508\n",
      "testing  :  533  accuracy =   0.6899  loss =  164.983\n",
      "training :  534  accuracy =   0.6900  loss =  164.339\n",
      "testing  :  534  accuracy =   0.6914  loss =  165.169\n",
      "training :  535  accuracy =   0.6900  loss =  163.468\n",
      "testing  :  535  accuracy =   0.6908  loss =  165.35\n",
      "training :  536  accuracy =   0.6300  loss =  166.985\n",
      "testing  :  536  accuracy =   0.6928  loss =  165.383\n",
      "training :  537  accuracy =   0.6400  loss =  166.46\n",
      "testing  :  537  accuracy =   0.6896  loss =  165.491\n",
      "training :  538  accuracy =   0.6700  loss =  167.795\n",
      "testing  :  538  accuracy =   0.6847  loss =  165.52\n",
      "training :  539  accuracy =   0.6800  loss =  162.016\n",
      "testing  :  539  accuracy =   0.6804  loss =  165.457\n",
      "training :  540  accuracy =   0.6700  loss =  169.682\n",
      "testing  :  540  accuracy =   0.6791  loss =  165.327\n",
      "training :  541  accuracy =   0.7800  loss =  161.348\n",
      "testing  :  541  accuracy =   0.6785  loss =  165.135\n",
      "training :  542  accuracy =   0.6400  loss =  165.967\n",
      "testing  :  542  accuracy =   0.6661  loss =  164.961\n",
      "training :  543  accuracy =   0.5700  loss =  169.081\n",
      "testing  :  543  accuracy =   0.6514  loss =  164.87\n",
      "training :  544  accuracy =   0.6800  loss =  165.109\n",
      "testing  :  544  accuracy =   0.6376  loss =  164.79\n",
      "training :  545  accuracy =   0.6400  loss =  162.803\n",
      "testing  :  545  accuracy =   0.6301  loss =  164.765\n",
      "training :  546  accuracy =   0.6300  loss =  164.948\n",
      "testing  :  546  accuracy =   0.6293  loss =  164.826\n",
      "training :  547  accuracy =   0.6400  loss =  163.045\n",
      "testing  :  547  accuracy =   0.6302  loss =  164.962\n",
      "training :  548  accuracy =   0.5900  loss =  164.854\n",
      "testing  :  548  accuracy =   0.6361  loss =  165.186\n",
      "training :  549  accuracy =   0.6000  loss =  166.835\n",
      "testing  :  549  accuracy =   0.6338  loss =  165.421\n",
      "training :  550  accuracy =   0.7000  loss =  163.009\n",
      "testing  :  550  accuracy =   0.6328  loss =  165.699\n",
      "training :  551  accuracy =   0.6700  loss =  162.088\n",
      "testing  :  551  accuracy =   0.6395  loss =  165.905\n",
      "training :  552  accuracy =   0.6400  loss =  164.281\n",
      "testing  :  552  accuracy =   0.6407  loss =  166.004\n",
      "training :  553  accuracy =   0.5100  loss =  167.195\n",
      "testing  :  553  accuracy =   0.6352  loss =  165.997\n",
      "training :  554  accuracy =   0.6600  loss =  164.269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  554  accuracy =   0.6308  loss =  165.973\n",
      "training :  555  accuracy =   0.6200  loss =  166.101\n",
      "testing  :  555  accuracy =   0.6277  loss =  165.949\n",
      "training :  556  accuracy =   0.6500  loss =  165.614\n",
      "testing  :  556  accuracy =   0.6265  loss =  165.928\n",
      "training :  557  accuracy =   0.6100  loss =  162.698\n",
      "testing  :  557  accuracy =   0.6176  loss =  165.78\n",
      "training :  558  accuracy =   0.5900  loss =  166.658\n",
      "testing  :  558  accuracy =   0.6108  loss =  165.59\n",
      "training :  559  accuracy =   0.5700  loss =  167.184\n",
      "testing  :  559  accuracy =   0.5976  loss =  165.254\n",
      "training :  560  accuracy =   0.5900  loss =  169.545\n",
      "testing  :  560  accuracy =   0.5869  loss =  164.986\n",
      "training :  561  accuracy =   0.6500  loss =  163.898\n",
      "testing  :  561  accuracy =   0.5874  loss =  164.775\n",
      "training :  562  accuracy =   0.5800  loss =  163.129\n",
      "testing  :  562  accuracy =   0.5886  loss =  164.667\n",
      "training :  563  accuracy =   0.6300  loss =  164.631\n",
      "testing  :  563  accuracy =   0.5897  loss =  164.637\n",
      "training :  564  accuracy =   0.5700  loss =  163.372\n",
      "testing  :  564  accuracy =   0.5898  loss =  164.635\n",
      "training :  565  accuracy =   0.6300  loss =  165.93\n",
      "testing  :  565  accuracy =   0.5903  loss =  164.619\n",
      "training :  566  accuracy =   0.5700  loss =  165.711\n",
      "testing  :  566  accuracy =   0.5904  loss =  164.583\n",
      "training :  567  accuracy =   0.6600  loss =  164.824\n",
      "testing  :  567  accuracy =   0.5892  loss =  164.526\n",
      "training :  568  accuracy =   0.5400  loss =  164.54\n",
      "testing  :  568  accuracy =   0.5890  loss =  164.443\n",
      "training :  569  accuracy =   0.5900  loss =  165.049\n",
      "testing  :  569  accuracy =   0.5888  loss =  164.385\n",
      "training :  570  accuracy =   0.5300  loss =  167.222\n",
      "testing  :  570  accuracy =   0.5900  loss =  164.321\n",
      "training :  571  accuracy =   0.5500  loss =  166.979\n",
      "testing  :  571  accuracy =   0.5890  loss =  164.263\n",
      "training :  572  accuracy =   0.6000  loss =  164.08\n",
      "testing  :  572  accuracy =   0.5902  loss =  164.226\n",
      "training :  573  accuracy =   0.5500  loss =  163.929\n",
      "testing  :  573  accuracy =   0.5893  loss =  164.233\n",
      "training :  574  accuracy =   0.6200  loss =  164.542\n",
      "testing  :  574  accuracy =   0.5897  loss =  164.245\n",
      "training :  575  accuracy =   0.6100  loss =  168.562\n",
      "testing  :  575  accuracy =   0.5884  loss =  164.242\n",
      "training :  576  accuracy =   0.6000  loss =  164.531\n",
      "testing  :  576  accuracy =   0.5877  loss =  164.23\n",
      "training :  577  accuracy =   0.6300  loss =  163.444\n",
      "testing  :  577  accuracy =   0.5877  loss =  164.224\n",
      "training :  578  accuracy =   0.5900  loss =  164.59\n",
      "testing  :  578  accuracy =   0.5856  loss =  164.241\n",
      "training :  579  accuracy =   0.6100  loss =  162.224\n",
      "testing  :  579  accuracy =   0.5863  loss =  164.162\n",
      "training :  580  accuracy =   0.5900  loss =  163.589\n",
      "testing  :  580  accuracy =   0.5882  loss =  164.082\n",
      "training :  581  accuracy =   0.5400  loss =  166.806\n",
      "testing  :  581  accuracy =   0.5885  loss =  164.032\n",
      "training :  582  accuracy =   0.7400  loss =  161.582\n",
      "testing  :  582  accuracy =   0.5892  loss =  163.986\n",
      "training :  583  accuracy =   0.5700  loss =  162.219\n",
      "testing  :  583  accuracy =   0.5904  loss =  163.946\n",
      "training :  584  accuracy =   0.5500  loss =  166.502\n",
      "testing  :  584  accuracy =   0.5921  loss =  163.911\n",
      "training :  585  accuracy =   0.6600  loss =  162.408\n",
      "testing  :  585  accuracy =   0.5933  loss =  163.885\n",
      "training :  586  accuracy =   0.5400  loss =  166.504\n",
      "testing  :  586  accuracy =   0.5934  loss =  163.893\n",
      "training :  587  accuracy =   0.6200  loss =  163.565\n",
      "testing  :  587  accuracy =   0.5920  loss =  163.917\n",
      "training :  588  accuracy =   0.5600  loss =  168.413\n",
      "testing  :  588  accuracy =   0.5916  loss =  163.901\n",
      "training :  589  accuracy =   0.5900  loss =  164.775\n",
      "testing  :  589  accuracy =   0.5917  loss =  163.857\n",
      "training :  590  accuracy =   0.6800  loss =  160.651\n",
      "testing  :  590  accuracy =   0.5929  loss =  163.766\n",
      "training :  591  accuracy =   0.6800  loss =  162.451\n",
      "testing  :  591  accuracy =   0.5925  loss =  163.713\n",
      "training :  592  accuracy =   0.6600  loss =  165.428\n",
      "testing  :  592  accuracy =   0.5922  loss =  163.686\n",
      "training :  593  accuracy =   0.6300  loss =  162.894\n",
      "testing  :  593  accuracy =   0.5911  loss =  163.677\n",
      "training :  594  accuracy =   0.6000  loss =  162.153\n",
      "testing  :  594  accuracy =   0.5908  loss =  163.696\n",
      "training :  595  accuracy =   0.6400  loss =  162.299\n",
      "testing  :  595  accuracy =   0.5898  loss =  163.744\n",
      "training :  596  accuracy =   0.5900  loss =  164.575\n",
      "testing  :  596  accuracy =   0.5896  loss =  163.784\n",
      "training :  597  accuracy =   0.5800  loss =  161.009\n",
      "testing  :  597  accuracy =   0.5890  loss =  163.773\n",
      "training :  598  accuracy =   0.4200  loss =  166.486\n",
      "testing  :  598  accuracy =   0.5881  loss =  163.777\n",
      "training :  599  accuracy =   0.5900  loss =  162.013\n",
      "testing  :  599  accuracy =   0.5878  loss =  163.713\n",
      "training :  600  accuracy =   0.6300  loss =  161.852\n",
      "testing  :  600  accuracy =   0.5878  loss =  163.642\n",
      "training :  601  accuracy =   0.5600  loss =  161.87\n",
      "testing  :  601  accuracy =   0.5885  loss =  163.598\n",
      "training :  602  accuracy =   0.5600  loss =  167.047\n",
      "testing  :  602  accuracy =   0.5880  loss =  163.57\n",
      "training :  603  accuracy =   0.6300  loss =  161.121\n",
      "testing  :  603  accuracy =   0.5881  loss =  163.566\n",
      "training :  604  accuracy =   0.5600  loss =  164.028\n",
      "testing  :  604  accuracy =   0.5876  loss =  163.561\n",
      "training :  605  accuracy =   0.6800  loss =  162.519\n",
      "testing  :  605  accuracy =   0.5857  loss =  163.557\n",
      "training :  606  accuracy =   0.5300  loss =  166.552\n",
      "testing  :  606  accuracy =   0.5861  loss =  163.574\n",
      "training :  607  accuracy =   0.5300  loss =  164.874\n",
      "testing  :  607  accuracy =   0.5861  loss =  163.573\n",
      "training :  608  accuracy =   0.5700  loss =  161.581\n",
      "testing  :  608  accuracy =   0.5862  loss =  163.554\n",
      "training :  609  accuracy =   0.4800  loss =  166.134\n",
      "testing  :  609  accuracy =   0.5871  loss =  163.541\n",
      "training :  610  accuracy =   0.6400  loss =  163.026\n",
      "testing  :  610  accuracy =   0.5879  loss =  163.495\n",
      "training :  611  accuracy =   0.5400  loss =  162.032\n",
      "testing  :  611  accuracy =   0.5883  loss =  163.462\n",
      "training :  612  accuracy =   0.5900  loss =  165.047\n",
      "testing  :  612  accuracy =   0.5899  loss =  163.426\n",
      "training :  613  accuracy =   0.6300  loss =  165.326\n",
      "testing  :  613  accuracy =   0.6063  loss =  163.41\n",
      "training :  614  accuracy =   0.6100  loss =  163.011\n",
      "testing  :  614  accuracy =   0.6416  loss =  163.447\n",
      "training :  615  accuracy =   0.6300  loss =  164.268\n",
      "testing  :  615  accuracy =   0.6597  loss =  163.553\n",
      "training :  616  accuracy =   0.5300  loss =  165.255\n",
      "testing  :  616  accuracy =   0.6322  loss =  163.689\n",
      "training :  617  accuracy =   0.6400  loss =  162.382\n",
      "testing  :  617  accuracy =   0.6045  loss =  163.862\n",
      "training :  618  accuracy =   0.5600  loss =  165.493\n",
      "testing  :  618  accuracy =   0.5943  loss =  164.018\n",
      "training :  619  accuracy =   0.5700  loss =  163.524\n",
      "testing  :  619  accuracy =   0.5892  loss =  164.129\n",
      "training :  620  accuracy =   0.5100  loss =  163.663\n",
      "testing  :  620  accuracy =   0.5872  loss =  164.122\n",
      "training :  621  accuracy =   0.5100  loss =  167.76\n",
      "testing  :  621  accuracy =   0.5892  loss =  163.954\n",
      "training :  622  accuracy =   0.6100  loss =  164.057\n",
      "testing  :  622  accuracy =   0.5957  loss =  163.623\n",
      "training :  623  accuracy =   0.6700  loss =  162.536\n",
      "testing  :  623  accuracy =   0.5996  loss =  163.477\n",
      "training :  624  accuracy =   0.7200  loss =  160.526\n",
      "testing  :  624  accuracy =   0.6030  loss =  163.447\n",
      "training :  625  accuracy =   0.6000  loss =  161.808\n",
      "testing  :  625  accuracy =   0.6041  loss =  163.455\n",
      "training :  626  accuracy =   0.5900  loss =  162.399\n",
      "testing  :  626  accuracy =   0.6048  loss =  163.471\n",
      "training :  627  accuracy =   0.6100  loss =  162.135\n",
      "testing  :  627  accuracy =   0.6045  loss =  163.447\n",
      "training :  628  accuracy =   0.5500  loss =  162.529\n",
      "testing  :  628  accuracy =   0.6041  loss =  163.4\n",
      "training :  629  accuracy =   0.6500  loss =  160.821\n",
      "testing  :  629  accuracy =   0.6038  loss =  163.354\n",
      "training :  630  accuracy =   0.5200  loss =  163.376\n",
      "testing  :  630  accuracy =   0.6035  loss =  163.341\n",
      "training :  631  accuracy =   0.5900  loss =  162.417\n",
      "testing  :  631  accuracy =   0.6035  loss =  163.339\n",
      "training :  632  accuracy =   0.5800  loss =  165.907\n",
      "testing  :  632  accuracy =   0.6061  loss =  163.316\n",
      "training :  633  accuracy =   0.6400  loss =  159.793\n",
      "testing  :  633  accuracy =   0.6109  loss =  163.309\n",
      "training :  634  accuracy =   0.5600  loss =  165.569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  634  accuracy =   0.6244  loss =  163.331\n",
      "training :  635  accuracy =   0.6400  loss =  164.199\n",
      "testing  :  635  accuracy =   0.6526  loss =  163.405\n",
      "training :  636  accuracy =   0.6100  loss =  162.78\n",
      "testing  :  636  accuracy =   0.6355  loss =  163.485\n",
      "training :  637  accuracy =   0.5900  loss =  163.133\n",
      "testing  :  637  accuracy =   0.5898  loss =  163.529\n",
      "training :  638  accuracy =   0.5700  loss =  165.059\n",
      "testing  :  638  accuracy =   0.5846  loss =  163.47\n",
      "training :  639  accuracy =   0.6300  loss =  161.401\n",
      "testing  :  639  accuracy =   0.5845  loss =  163.38\n",
      "training :  640  accuracy =   0.5800  loss =  160.568\n",
      "testing  :  640  accuracy =   0.5823  loss =  163.373\n",
      "training :  641  accuracy =   0.6000  loss =  162.317\n",
      "testing  :  641  accuracy =   0.5820  loss =  163.459\n",
      "training :  642  accuracy =   0.7200  loss =  159.525\n",
      "testing  :  642  accuracy =   0.5809  loss =  163.596\n",
      "training :  643  accuracy =   0.5900  loss =  164.144\n",
      "testing  :  643  accuracy =   0.5787  loss =  163.72\n",
      "training :  644  accuracy =   0.6600  loss =  163.077\n",
      "testing  :  644  accuracy =   0.5787  loss =  163.819\n",
      "training :  645  accuracy =   0.5400  loss =  165.127\n",
      "testing  :  645  accuracy =   0.5786  loss =  163.787\n",
      "training :  646  accuracy =   0.5900  loss =  167.533\n",
      "testing  :  646  accuracy =   0.5795  loss =  163.618\n",
      "training :  647  accuracy =   0.5600  loss =  164.3\n",
      "testing  :  647  accuracy =   0.5827  loss =  163.343\n",
      "training :  648  accuracy =   0.6500  loss =  161.913\n",
      "testing  :  648  accuracy =   0.5848  loss =  163.113\n",
      "training :  649  accuracy =   0.6300  loss =  163.839\n",
      "testing  :  649  accuracy =   0.5850  loss =  163.0\n",
      "training :  650  accuracy =   0.6800  loss =  160.83\n",
      "testing  :  650  accuracy =   0.5842  loss =  162.97\n",
      "training :  651  accuracy =   0.5800  loss =  164.44\n",
      "testing  :  651  accuracy =   0.5840  loss =  162.967\n",
      "training :  652  accuracy =   0.6100  loss =  162.387\n",
      "testing  :  652  accuracy =   0.5843  loss =  162.948\n",
      "training :  653  accuracy =   0.6200  loss =  163.791\n",
      "testing  :  653  accuracy =   0.5845  loss =  162.943\n",
      "training :  654  accuracy =   0.5200  loss =  168.333\n",
      "testing  :  654  accuracy =   0.5850  loss =  162.972\n",
      "training :  655  accuracy =   0.6100  loss =  164.499\n",
      "testing  :  655  accuracy =   0.5854  loss =  163.04\n",
      "training :  656  accuracy =   0.5900  loss =  163.236\n",
      "testing  :  656  accuracy =   0.5849  loss =  163.132\n",
      "training :  657  accuracy =   0.6700  loss =  160.895\n",
      "testing  :  657  accuracy =   0.5846  loss =  163.173\n",
      "training :  658  accuracy =   0.5900  loss =  162.638\n",
      "testing  :  658  accuracy =   0.5840  loss =  163.22\n",
      "training :  659  accuracy =   0.6600  loss =  162.506\n",
      "testing  :  659  accuracy =   0.5844  loss =  163.301\n",
      "training :  660  accuracy =   0.4500  loss =  168.245\n",
      "testing  :  660  accuracy =   0.5839  loss =  163.372\n",
      "training :  661  accuracy =   0.5000  loss =  162.802\n",
      "testing  :  661  accuracy =   0.5834  loss =  163.496\n",
      "training :  662  accuracy =   0.6200  loss =  164.519\n",
      "testing  :  662  accuracy =   0.5854  loss =  163.707\n",
      "training :  663  accuracy =   0.6300  loss =  162.335\n",
      "testing  :  663  accuracy =   0.5857  loss =  163.845\n",
      "training :  664  accuracy =   0.5600  loss =  164.391\n",
      "testing  :  664  accuracy =   0.5859  loss =  163.943\n",
      "training :  665  accuracy =   0.5500  loss =  162.292\n",
      "testing  :  665  accuracy =   0.5848  loss =  164.015\n",
      "training :  666  accuracy =   0.5700  loss =  163.466\n",
      "testing  :  666  accuracy =   0.5856  loss =  164.012\n",
      "training :  667  accuracy =   0.6600  loss =  162.3\n",
      "testing  :  667  accuracy =   0.5836  loss =  163.877\n",
      "training :  668  accuracy =   0.5800  loss =  166.114\n",
      "testing  :  668  accuracy =   0.5840  loss =  163.794\n",
      "training :  669  accuracy =   0.5900  loss =  163.918\n",
      "testing  :  669  accuracy =   0.5809  loss =  163.819\n",
      "training :  670  accuracy =   0.5700  loss =  163.54\n",
      "testing  :  670  accuracy =   0.5810  loss =  163.834\n",
      "training :  671  accuracy =   0.6600  loss =  161.348\n",
      "testing  :  671  accuracy =   0.5795  loss =  163.77\n",
      "training :  672  accuracy =   0.6900  loss =  161.448\n",
      "testing  :  672  accuracy =   0.5805  loss =  163.637\n",
      "training :  673  accuracy =   0.5700  loss =  162.497\n",
      "testing  :  673  accuracy =   0.5803  loss =  163.448\n",
      "training :  674  accuracy =   0.5800  loss =  161.559\n",
      "testing  :  674  accuracy =   0.5820  loss =  163.233\n",
      "training :  675  accuracy =   0.5000  loss =  164.724\n",
      "testing  :  675  accuracy =   0.5827  loss =  163.05\n",
      "training :  676  accuracy =   0.6200  loss =  161.745\n",
      "testing  :  676  accuracy =   0.5834  loss =  162.951\n",
      "training :  677  accuracy =   0.6000  loss =  162.188\n",
      "testing  :  677  accuracy =   0.5818  loss =  162.943\n",
      "training :  678  accuracy =   0.6200  loss =  162.824\n",
      "testing  :  678  accuracy =   0.5817  loss =  163.008\n",
      "training :  679  accuracy =   0.5400  loss =  163.404\n",
      "testing  :  679  accuracy =   0.5817  loss =  163.121\n",
      "training :  680  accuracy =   0.5600  loss =  162.974\n",
      "testing  :  680  accuracy =   0.5821  loss =  163.084\n",
      "training :  681  accuracy =   0.6100  loss =  163.131\n",
      "testing  :  681  accuracy =   0.5830  loss =  162.937\n",
      "training :  682  accuracy =   0.5700  loss =  163.235\n",
      "testing  :  682  accuracy =   0.5836  loss =  162.795\n",
      "training :  683  accuracy =   0.5400  loss =  163.087\n",
      "testing  :  683  accuracy =   0.5840  loss =  162.739\n",
      "training :  684  accuracy =   0.6600  loss =  162.488\n",
      "testing  :  684  accuracy =   0.5839  loss =  162.743\n",
      "training :  685  accuracy =   0.6300  loss =  163.412\n",
      "testing  :  685  accuracy =   0.5836  loss =  162.762\n",
      "training :  686  accuracy =   0.5100  loss =  163.576\n",
      "testing  :  686  accuracy =   0.5837  loss =  162.763\n",
      "training :  687  accuracy =   0.7100  loss =  159.013\n",
      "testing  :  687  accuracy =   0.5834  loss =  162.775\n",
      "training :  688  accuracy =   0.6000  loss =  164.064\n",
      "testing  :  688  accuracy =   0.5831  loss =  162.801\n",
      "training :  689  accuracy =   0.5500  loss =  162.962\n",
      "testing  :  689  accuracy =   0.5838  loss =  162.743\n",
      "training :  690  accuracy =   0.5800  loss =  162.211\n",
      "testing  :  690  accuracy =   0.5844  loss =  162.704\n",
      "training :  691  accuracy =   0.6100  loss =  161.833\n",
      "testing  :  691  accuracy =   0.5842  loss =  162.695\n",
      "training :  692  accuracy =   0.6000  loss =  160.849\n",
      "testing  :  692  accuracy =   0.5849  loss =  162.7\n",
      "training :  693  accuracy =   0.6100  loss =  161.791\n",
      "testing  :  693  accuracy =   0.5850  loss =  162.735\n",
      "training :  694  accuracy =   0.5500  loss =  163.225\n",
      "testing  :  694  accuracy =   0.5841  loss =  162.72\n",
      "training :  695  accuracy =   0.5500  loss =  162.822\n",
      "testing  :  695  accuracy =   0.5847  loss =  162.69\n",
      "training :  696  accuracy =   0.5900  loss =  164.246\n",
      "testing  :  696  accuracy =   0.5852  loss =  162.684\n",
      "training :  697  accuracy =   0.6400  loss =  162.772\n",
      "testing  :  697  accuracy =   0.5857  loss =  162.693\n",
      "training :  698  accuracy =   0.5500  loss =  162.754\n",
      "testing  :  698  accuracy =   0.5855  loss =  162.711\n",
      "training :  699  accuracy =   0.5200  loss =  164.966\n",
      "testing  :  699  accuracy =   0.5853  loss =  162.735\n",
      "training :  700  accuracy =   0.6100  loss =  164.571\n",
      "testing  :  700  accuracy =   0.5853  loss =  162.763\n",
      "training :  701  accuracy =   0.5700  loss =  164.567\n",
      "testing  :  701  accuracy =   0.5851  loss =  162.795\n",
      "training :  702  accuracy =   0.6200  loss =  164.231\n",
      "testing  :  702  accuracy =   0.5850  loss =  162.882\n",
      "training :  703  accuracy =   0.5700  loss =  164.526\n",
      "testing  :  703  accuracy =   0.5850  loss =  162.965\n",
      "training :  704  accuracy =   0.5300  loss =  167.084\n",
      "testing  :  704  accuracy =   0.5836  loss =  163.087\n",
      "training :  705  accuracy =   0.5700  loss =  165.449\n",
      "testing  :  705  accuracy =   0.5830  loss =  163.151\n",
      "training :  706  accuracy =   0.5400  loss =  165.658\n",
      "testing  :  706  accuracy =   0.5820  loss =  163.186\n",
      "training :  707  accuracy =   0.6800  loss =  160.322\n",
      "testing  :  707  accuracy =   0.5810  loss =  163.215\n",
      "training :  708  accuracy =   0.5800  loss =  164.456\n",
      "testing  :  708  accuracy =   0.5799  loss =  163.21\n",
      "training :  709  accuracy =   0.5200  loss =  163.585\n",
      "testing  :  709  accuracy =   0.5799  loss =  163.128\n",
      "training :  710  accuracy =   0.5200  loss =  164.605\n",
      "testing  :  710  accuracy =   0.5798  loss =  163.093\n",
      "training :  711  accuracy =   0.6100  loss =  160.16\n",
      "testing  :  711  accuracy =   0.5800  loss =  163.054\n",
      "training :  712  accuracy =   0.6100  loss =  161.947\n",
      "testing  :  712  accuracy =   0.5802  loss =  163.017\n",
      "training :  713  accuracy =   0.6000  loss =  161.878\n",
      "testing  :  713  accuracy =   0.5805  loss =  162.925\n",
      "training :  714  accuracy =   0.6300  loss =  163.193\n",
      "testing  :  714  accuracy =   0.5815  loss =  162.822\n",
      "training :  715  accuracy =   0.6400  loss =  160.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  715  accuracy =   0.5825  loss =  162.749\n",
      "training :  716  accuracy =   0.5900  loss =  161.966\n",
      "testing  :  716  accuracy =   0.5842  loss =  162.676\n",
      "training :  717  accuracy =   0.5300  loss =  161.504\n",
      "testing  :  717  accuracy =   0.5835  loss =  162.647\n",
      "training :  718  accuracy =   0.5800  loss =  166.253\n",
      "testing  :  718  accuracy =   0.5834  loss =  162.637\n",
      "training :  719  accuracy =   0.6000  loss =  163.042\n",
      "testing  :  719  accuracy =   0.5836  loss =  162.6\n",
      "training :  720  accuracy =   0.5600  loss =  161.714\n",
      "testing  :  720  accuracy =   0.5841  loss =  162.53\n",
      "training :  721  accuracy =   0.5500  loss =  161.949\n",
      "testing  :  721  accuracy =   0.5848  loss =  162.483\n",
      "training :  722  accuracy =   0.6100  loss =  164.225\n",
      "testing  :  722  accuracy =   0.5856  loss =  162.447\n",
      "training :  723  accuracy =   0.5600  loss =  164.447\n",
      "testing  :  723  accuracy =   0.5854  loss =  162.383\n",
      "training :  724  accuracy =   0.5200  loss =  163.118\n",
      "testing  :  724  accuracy =   0.5852  loss =  162.319\n",
      "training :  725  accuracy =   0.5900  loss =  161.586\n",
      "testing  :  725  accuracy =   0.5851  loss =  162.304\n",
      "training :  726  accuracy =   0.6300  loss =  159.63\n",
      "testing  :  726  accuracy =   0.5852  loss =  162.307\n",
      "training :  727  accuracy =   0.5500  loss =  162.766\n",
      "testing  :  727  accuracy =   0.5841  loss =  162.348\n",
      "training :  728  accuracy =   0.4900  loss =  163.91\n",
      "testing  :  728  accuracy =   0.5845  loss =  162.398\n",
      "training :  729  accuracy =   0.6000  loss =  163.927\n",
      "testing  :  729  accuracy =   0.5834  loss =  162.482\n",
      "training :  730  accuracy =   0.5800  loss =  163.225\n",
      "testing  :  730  accuracy =   0.5823  loss =  162.597\n",
      "training :  731  accuracy =   0.6400  loss =  160.46\n",
      "testing  :  731  accuracy =   0.5819  loss =  162.685\n",
      "training :  732  accuracy =   0.5900  loss =  160.882\n",
      "testing  :  732  accuracy =   0.5835  loss =  162.772\n",
      "training :  733  accuracy =   0.5700  loss =  164.035\n",
      "testing  :  733  accuracy =   0.5957  loss =  162.854\n",
      "training :  734  accuracy =   0.6700  loss =  159.428\n",
      "testing  :  734  accuracy =   0.6024  loss =  162.811\n",
      "training :  735  accuracy =   0.6800  loss =  161.775\n",
      "testing  :  735  accuracy =   0.6097  loss =  162.753\n",
      "training :  736  accuracy =   0.6500  loss =  163.616\n",
      "testing  :  736  accuracy =   0.6188  loss =  162.706\n",
      "training :  737  accuracy =   0.7000  loss =  162.724\n",
      "testing  :  737  accuracy =   0.6330  loss =  162.623\n",
      "training :  738  accuracy =   0.6200  loss =  167.113\n",
      "testing  :  738  accuracy =   0.6404  loss =  162.555\n",
      "training :  739  accuracy =   0.6100  loss =  166.347\n",
      "testing  :  739  accuracy =   0.6431  loss =  162.509\n",
      "training :  740  accuracy =   0.7200  loss =  161.084\n",
      "testing  :  740  accuracy =   0.6170  loss =  162.508\n",
      "training :  741  accuracy =   0.6700  loss =  161.955\n",
      "testing  :  741  accuracy =   0.6041  loss =  162.503\n",
      "training :  742  accuracy =   0.6600  loss =  161.6\n",
      "testing  :  742  accuracy =   0.5999  loss =  162.465\n",
      "training :  743  accuracy =   0.7000  loss =  159.078\n",
      "testing  :  743  accuracy =   0.5969  loss =  162.447\n",
      "training :  744  accuracy =   0.5900  loss =  159.57\n",
      "testing  :  744  accuracy =   0.5975  loss =  162.378\n",
      "training :  745  accuracy =   0.6300  loss =  160.967\n",
      "testing  :  745  accuracy =   0.5984  loss =  162.295\n",
      "training :  746  accuracy =   0.5900  loss =  161.865\n",
      "testing  :  746  accuracy =   0.5994  loss =  162.246\n",
      "training :  747  accuracy =   0.5700  loss =  163.716\n",
      "testing  :  747  accuracy =   0.6012  loss =  162.204\n",
      "training :  748  accuracy =   0.5600  loss =  160.499\n",
      "testing  :  748  accuracy =   0.6023  loss =  162.27\n",
      "training :  749  accuracy =   0.6000  loss =  159.894\n",
      "testing  :  749  accuracy =   0.6046  loss =  162.353\n",
      "training :  750  accuracy =   0.6900  loss =  158.616\n",
      "testing  :  750  accuracy =   0.6042  loss =  162.459\n",
      "training :  751  accuracy =   0.6000  loss =  161.627\n",
      "testing  :  751  accuracy =   0.6043  loss =  162.562\n",
      "training :  752  accuracy =   0.5600  loss =  167.767\n",
      "testing  :  752  accuracy =   0.6056  loss =  162.638\n",
      "training :  753  accuracy =   0.6600  loss =  162.928\n",
      "testing  :  753  accuracy =   0.6066  loss =  162.631\n",
      "training :  754  accuracy =   0.7200  loss =  158.139\n",
      "testing  :  754  accuracy =   0.6079  loss =  162.529\n",
      "training :  755  accuracy =   0.6400  loss =  166.462\n",
      "testing  :  755  accuracy =   0.6121  loss =  162.393\n",
      "training :  756  accuracy =   0.6000  loss =  166.586\n",
      "testing  :  756  accuracy =   0.6111  loss =  162.255\n",
      "training :  757  accuracy =   0.5900  loss =  161.933\n",
      "testing  :  757  accuracy =   0.6099  loss =  162.165\n",
      "training :  758  accuracy =   0.5700  loss =  162.864\n",
      "testing  :  758  accuracy =   0.6120  loss =  162.131\n",
      "training :  759  accuracy =   0.6200  loss =  161.292\n",
      "testing  :  759  accuracy =   0.6111  loss =  162.126\n",
      "training :  760  accuracy =   0.6100  loss =  163.256\n",
      "testing  :  760  accuracy =   0.6093  loss =  162.157\n",
      "training :  761  accuracy =   0.6400  loss =  163.853\n",
      "testing  :  761  accuracy =   0.6092  loss =  162.252\n",
      "training :  762  accuracy =   0.5400  loss =  163.183\n",
      "testing  :  762  accuracy =   0.6087  loss =  162.367\n",
      "training :  763  accuracy =   0.6200  loss =  163.026\n",
      "testing  :  763  accuracy =   0.6080  loss =  162.496\n",
      "training :  764  accuracy =   0.6100  loss =  164.982\n",
      "testing  :  764  accuracy =   0.6058  loss =  162.618\n",
      "training :  765  accuracy =   0.6400  loss =  161.047\n",
      "testing  :  765  accuracy =   0.6085  loss =  162.666\n",
      "training :  766  accuracy =   0.6500  loss =  165.557\n",
      "testing  :  766  accuracy =   0.6061  loss =  162.717\n",
      "training :  767  accuracy =   0.5400  loss =  163.815\n",
      "testing  :  767  accuracy =   0.6036  loss =  162.794\n",
      "training :  768  accuracy =   0.7100  loss =  161.154\n",
      "testing  :  768  accuracy =   0.6025  loss =  162.795\n",
      "training :  769  accuracy =   0.5200  loss =  164.957\n",
      "testing  :  769  accuracy =   0.6020  loss =  162.722\n",
      "training :  770  accuracy =   0.6200  loss =  163.932\n",
      "testing  :  770  accuracy =   0.6017  loss =  162.632\n",
      "training :  771  accuracy =   0.6400  loss =  165.962\n",
      "testing  :  771  accuracy =   0.6007  loss =  162.528\n",
      "training :  772  accuracy =   0.6800  loss =  158.327\n",
      "testing  :  772  accuracy =   0.6011  loss =  162.425\n",
      "training :  773  accuracy =   0.6000  loss =  164.741\n",
      "testing  :  773  accuracy =   0.6006  loss =  162.376\n",
      "training :  774  accuracy =   0.5800  loss =  161.569\n",
      "testing  :  774  accuracy =   0.6001  loss =  162.335\n",
      "training :  775  accuracy =   0.6500  loss =  163.461\n",
      "testing  :  775  accuracy =   0.6003  loss =  162.329\n",
      "training :  776  accuracy =   0.5300  loss =  164.304\n",
      "testing  :  776  accuracy =   0.6009  loss =  162.266\n",
      "training :  777  accuracy =   0.6300  loss =  163.051\n",
      "testing  :  777  accuracy =   0.6009  loss =  162.211\n",
      "training :  778  accuracy =   0.6200  loss =  161.825\n",
      "testing  :  778  accuracy =   0.6006  loss =  162.204\n",
      "training :  779  accuracy =   0.6900  loss =  162.612\n",
      "testing  :  779  accuracy =   0.5997  loss =  162.213\n",
      "training :  780  accuracy =   0.6100  loss =  161.157\n",
      "testing  :  780  accuracy =   0.5981  loss =  162.211\n",
      "training :  781  accuracy =   0.6100  loss =  163.22\n",
      "testing  :  781  accuracy =   0.5983  loss =  162.222\n",
      "training :  782  accuracy =   0.6000  loss =  161.297\n",
      "testing  :  782  accuracy =   0.5985  loss =  162.215\n",
      "training :  783  accuracy =   0.6200  loss =  159.632\n",
      "testing  :  783  accuracy =   0.5986  loss =  162.197\n",
      "training :  784  accuracy =   0.6700  loss =  157.95\n",
      "testing  :  784  accuracy =   0.5983  loss =  162.176\n",
      "training :  785  accuracy =   0.6100  loss =  163.906\n",
      "testing  :  785  accuracy =   0.5986  loss =  162.152\n",
      "training :  786  accuracy =   0.6400  loss =  161.127\n",
      "testing  :  786  accuracy =   0.5972  loss =  162.142\n",
      "training :  787  accuracy =   0.5800  loss =  160.834\n",
      "testing  :  787  accuracy =   0.5973  loss =  162.128\n",
      "training :  788  accuracy =   0.5600  loss =  162.872\n",
      "testing  :  788  accuracy =   0.5987  loss =  162.071\n",
      "training :  789  accuracy =   0.5800  loss =  162.959\n",
      "testing  :  789  accuracy =   0.5987  loss =  162.05\n",
      "training :  790  accuracy =   0.5800  loss =  161.474\n",
      "testing  :  790  accuracy =   0.6002  loss =  162.02\n",
      "training :  791  accuracy =   0.5900  loss =  165.128\n",
      "testing  :  791  accuracy =   0.6041  loss =  161.962\n",
      "training :  792  accuracy =   0.6200  loss =  163.122\n",
      "testing  :  792  accuracy =   0.6188  loss =  161.946\n",
      "training :  793  accuracy =   0.6300  loss =  160.92\n",
      "testing  :  793  accuracy =   0.6304  loss =  162.003\n",
      "training :  794  accuracy =   0.5300  loss =  162.918\n",
      "testing  :  794  accuracy =   0.6317  loss =  162.06\n",
      "training :  795  accuracy =   0.7100  loss =  160.248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  795  accuracy =   0.6345  loss =  162.106\n",
      "training :  796  accuracy =   0.7200  loss =  157.983\n",
      "testing  :  796  accuracy =   0.6375  loss =  162.125\n",
      "training :  797  accuracy =   0.6900  loss =  159.702\n",
      "testing  :  797  accuracy =   0.6364  loss =  162.117\n",
      "training :  798  accuracy =   0.7100  loss =  160.861\n",
      "testing  :  798  accuracy =   0.6140  loss =  162.065\n",
      "training :  799  accuracy =   0.6900  loss =  161.858\n",
      "testing  :  799  accuracy =   0.5965  loss =  161.976\n",
      "training :  800  accuracy =   0.5700  loss =  162.298\n",
      "testing  :  800  accuracy =   0.5833  loss =  161.875\n",
      "training :  801  accuracy =   0.5800  loss =  163.036\n",
      "testing  :  801  accuracy =   0.5804  loss =  161.811\n",
      "training :  802  accuracy =   0.5300  loss =  162.114\n",
      "testing  :  802  accuracy =   0.5810  loss =  161.765\n",
      "training :  803  accuracy =   0.6000  loss =  159.42\n",
      "testing  :  803  accuracy =   0.5806  loss =  161.764\n",
      "training :  804  accuracy =   0.6400  loss =  159.912\n",
      "testing  :  804  accuracy =   0.5805  loss =  161.882\n",
      "training :  805  accuracy =   0.5500  loss =  160.524\n",
      "testing  :  805  accuracy =   0.5797  loss =  162.187\n",
      "training :  806  accuracy =   0.5600  loss =  160.353\n",
      "testing  :  806  accuracy =   0.5778  loss =  162.478\n",
      "training :  807  accuracy =   0.5200  loss =  161.729\n",
      "testing  :  807  accuracy =   0.5746  loss =  162.882\n",
      "training :  808  accuracy =   0.7200  loss =  159.319\n",
      "testing  :  808  accuracy =   0.5733  loss =  163.13\n",
      "training :  809  accuracy =   0.5800  loss =  163.001\n",
      "testing  :  809  accuracy =   0.5715  loss =  163.371\n",
      "training :  810  accuracy =   0.5600  loss =  160.257\n",
      "testing  :  810  accuracy =   0.5717  loss =  163.416\n",
      "training :  811  accuracy =   0.5600  loss =  161.247\n",
      "testing  :  811  accuracy =   0.5721  loss =  163.204\n",
      "training :  812  accuracy =   0.5000  loss =  162.261\n",
      "testing  :  812  accuracy =   0.5764  loss =  162.668\n",
      "training :  813  accuracy =   0.5000  loss =  163.036\n",
      "testing  :  813  accuracy =   0.5784  loss =  162.252\n",
      "training :  814  accuracy =   0.7100  loss =  160.253\n",
      "testing  :  814  accuracy =   0.6101  loss =  162.015\n",
      "training :  815  accuracy =   0.6500  loss =  164.046\n",
      "testing  :  815  accuracy =   0.6389  loss =  161.933\n",
      "training :  816  accuracy =   0.6600  loss =  158.902\n",
      "testing  :  816  accuracy =   0.6405  loss =  161.99\n",
      "training :  817  accuracy =   0.5800  loss =  161.759\n",
      "testing  :  817  accuracy =   0.6363  loss =  162.112\n",
      "training :  818  accuracy =   0.6800  loss =  162.36\n",
      "testing  :  818  accuracy =   0.6207  loss =  162.173\n",
      "training :  819  accuracy =   0.5800  loss =  159.728\n",
      "testing  :  819  accuracy =   0.5922  loss =  162.199\n",
      "training :  820  accuracy =   0.5500  loss =  160.015\n",
      "testing  :  820  accuracy =   0.5814  loss =  162.176\n",
      "training :  821  accuracy =   0.6000  loss =  161.74\n",
      "testing  :  821  accuracy =   0.5786  loss =  162.136\n",
      "training :  822  accuracy =   0.6500  loss =  161.495\n",
      "testing  :  822  accuracy =   0.5777  loss =  162.117\n",
      "training :  823  accuracy =   0.5200  loss =  163.445\n",
      "testing  :  823  accuracy =   0.5772  loss =  162.063\n",
      "training :  824  accuracy =   0.6300  loss =  158.472\n",
      "testing  :  824  accuracy =   0.5776  loss =  161.972\n",
      "training :  825  accuracy =   0.6100  loss =  159.482\n",
      "testing  :  825  accuracy =   0.5791  loss =  161.909\n",
      "training :  826  accuracy =   0.6700  loss =  160.304\n",
      "testing  :  826  accuracy =   0.5800  loss =  161.888\n",
      "training :  827  accuracy =   0.6100  loss =  164.798\n",
      "testing  :  827  accuracy =   0.5812  loss =  161.937\n",
      "training :  828  accuracy =   0.4400  loss =  161.718\n",
      "testing  :  828  accuracy =   0.5779  loss =  162.005\n",
      "training :  829  accuracy =   0.5800  loss =  164.789\n",
      "testing  :  829  accuracy =   0.5787  loss =  162.057\n",
      "training :  830  accuracy =   0.5800  loss =  162.782\n",
      "testing  :  830  accuracy =   0.5772  loss =  162.063\n",
      "training :  831  accuracy =   0.5100  loss =  163.638\n",
      "testing  :  831  accuracy =   0.5771  loss =  162.105\n",
      "training :  832  accuracy =   0.5200  loss =  163.122\n",
      "testing  :  832  accuracy =   0.5778  loss =  162.084\n",
      "training :  833  accuracy =   0.6200  loss =  163.14\n",
      "testing  :  833  accuracy =   0.5803  loss =  162.075\n",
      "training :  834  accuracy =   0.6300  loss =  162.201\n",
      "testing  :  834  accuracy =   0.5830  loss =  162.068\n",
      "training :  835  accuracy =   0.5900  loss =  163.614\n",
      "testing  :  835  accuracy =   0.5832  loss =  162.066\n",
      "training :  836  accuracy =   0.5000  loss =  162.059\n",
      "testing  :  836  accuracy =   0.5833  loss =  162.025\n",
      "training :  837  accuracy =   0.5900  loss =  163.075\n",
      "testing  :  837  accuracy =   0.5832  loss =  161.984\n",
      "training :  838  accuracy =   0.5900  loss =  164.601\n",
      "testing  :  838  accuracy =   0.5836  loss =  161.941\n",
      "training :  839  accuracy =   0.6200  loss =  161.533\n",
      "testing  :  839  accuracy =   0.5827  loss =  161.868\n",
      "training :  840  accuracy =   0.4600  loss =  162.754\n",
      "testing  :  840  accuracy =   0.5832  loss =  161.835\n",
      "training :  841  accuracy =   0.6100  loss =  162.05\n",
      "testing  :  841  accuracy =   0.5816  loss =  161.825\n",
      "training :  842  accuracy =   0.5500  loss =  160.262\n",
      "testing  :  842  accuracy =   0.5810  loss =  161.859\n",
      "training :  843  accuracy =   0.5800  loss =  158.224\n",
      "testing  :  843  accuracy =   0.5807  loss =  161.904\n",
      "training :  844  accuracy =   0.6100  loss =  160.25\n",
      "testing  :  844  accuracy =   0.5796  loss =  161.959\n",
      "training :  845  accuracy =   0.5300  loss =  165.292\n",
      "testing  :  845  accuracy =   0.5799  loss =  162.026\n",
      "training :  846  accuracy =   0.6400  loss =  159.38\n",
      "testing  :  846  accuracy =   0.5787  loss =  162.057\n",
      "training :  847  accuracy =   0.6600  loss =  158.038\n",
      "testing  :  847  accuracy =   0.5778  loss =  162.085\n",
      "training :  848  accuracy =   0.6800  loss =  158.582\n",
      "testing  :  848  accuracy =   0.5766  loss =  162.104\n",
      "training :  849  accuracy =   0.5500  loss =  159.783\n",
      "testing  :  849  accuracy =   0.5760  loss =  162.108\n",
      "training :  850  accuracy =   0.5400  loss =  161.421\n",
      "testing  :  850  accuracy =   0.5753  loss =  162.109\n",
      "training :  851  accuracy =   0.5400  loss =  160.61\n",
      "testing  :  851  accuracy =   0.5745  loss =  162.163\n",
      "training :  852  accuracy =   0.6600  loss =  158.836\n",
      "testing  :  852  accuracy =   0.5747  loss =  162.178\n",
      "training :  853  accuracy =   0.6300  loss =  159.986\n",
      "testing  :  853  accuracy =   0.5761  loss =  162.137\n",
      "training :  854  accuracy =   0.6200  loss =  165.319\n",
      "testing  :  854  accuracy =   0.5790  loss =  162.045\n",
      "training :  855  accuracy =   0.5700  loss =  163.923\n",
      "testing  :  855  accuracy =   0.5779  loss =  161.941\n",
      "training :  856  accuracy =   0.6800  loss =  159.289\n",
      "testing  :  856  accuracy =   0.5790  loss =  161.816\n",
      "training :  857  accuracy =   0.6200  loss =  161.403\n",
      "testing  :  857  accuracy =   0.5823  loss =  161.786\n",
      "training :  858  accuracy =   0.6000  loss =  161.694\n",
      "testing  :  858  accuracy =   0.5866  loss =  161.802\n",
      "training :  859  accuracy =   0.5300  loss =  163.047\n",
      "testing  :  859  accuracy =   0.6098  loss =  161.843\n",
      "training :  860  accuracy =   0.6900  loss =  159.862\n",
      "testing  :  860  accuracy =   0.6367  loss =  161.93\n",
      "training :  861  accuracy =   0.6400  loss =  163.438\n",
      "testing  :  861  accuracy =   0.6429  loss =  162.077\n",
      "training :  862  accuracy =   0.6700  loss =  164.25\n",
      "testing  :  862  accuracy =   0.6288  loss =  162.238\n",
      "training :  863  accuracy =   0.6600  loss =  162.616\n",
      "testing  :  863  accuracy =   0.6230  loss =  162.346\n",
      "training :  864  accuracy =   0.7000  loss =  161.639\n",
      "testing  :  864  accuracy =   0.6167  loss =  162.373\n",
      "training :  865  accuracy =   0.6800  loss =  160.385\n",
      "testing  :  865  accuracy =   0.6162  loss =  162.404\n",
      "training :  866  accuracy =   0.6500  loss =  159.622\n",
      "testing  :  866  accuracy =   0.6171  loss =  162.359\n",
      "training :  867  accuracy =   0.6600  loss =  162.079\n",
      "testing  :  867  accuracy =   0.6336  loss =  162.247\n",
      "training :  868  accuracy =   0.5800  loss =  161.743\n",
      "testing  :  868  accuracy =   0.6399  loss =  162.139\n",
      "training :  869  accuracy =   0.6900  loss =  161.455\n",
      "testing  :  869  accuracy =   0.6207  loss =  162.073\n",
      "training :  870  accuracy =   0.6500  loss =  162.396\n",
      "testing  :  870  accuracy =   0.5957  loss =  162.012\n",
      "training :  871  accuracy =   0.6600  loss =  158.67\n",
      "testing  :  871  accuracy =   0.5854  loss =  161.939\n",
      "training :  872  accuracy =   0.5400  loss =  161.24\n",
      "testing  :  872  accuracy =   0.5870  loss =  161.91\n",
      "training :  873  accuracy =   0.5600  loss =  163.591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  873  accuracy =   0.5895  loss =  161.875\n",
      "training :  874  accuracy =   0.6600  loss =  162.721\n",
      "testing  :  874  accuracy =   0.5917  loss =  161.878\n",
      "training :  875  accuracy =   0.5600  loss =  164.724\n",
      "testing  :  875  accuracy =   0.6009  loss =  161.902\n",
      "training :  876  accuracy =   0.6000  loss =  161.257\n",
      "testing  :  876  accuracy =   0.6133  loss =  161.938\n",
      "training :  877  accuracy =   0.6500  loss =  157.67\n",
      "testing  :  877  accuracy =   0.6119  loss =  162.001\n",
      "training :  878  accuracy =   0.7000  loss =  158.619\n",
      "testing  :  878  accuracy =   0.6080  loss =  162.069\n",
      "training :  879  accuracy =   0.5500  loss =  164.104\n",
      "testing  :  879  accuracy =   0.5913  loss =  162.076\n",
      "training :  880  accuracy =   0.5300  loss =  164.132\n",
      "testing  :  880  accuracy =   0.5879  loss =  162.065\n",
      "training :  881  accuracy =   0.6600  loss =  160.02\n",
      "testing  :  881  accuracy =   0.5870  loss =  162.013\n",
      "training :  882  accuracy =   0.6100  loss =  162.336\n",
      "testing  :  882  accuracy =   0.5869  loss =  162.001\n",
      "training :  883  accuracy =   0.6700  loss =  157.299\n",
      "testing  :  883  accuracy =   0.5869  loss =  161.96\n",
      "training :  884  accuracy =   0.6200  loss =  161.847\n",
      "testing  :  884  accuracy =   0.5873  loss =  161.924\n",
      "training :  885  accuracy =   0.6300  loss =  158.837\n",
      "testing  :  885  accuracy =   0.5878  loss =  161.847\n",
      "training :  886  accuracy =   0.6000  loss =  162.45\n",
      "testing  :  886  accuracy =   0.5873  loss =  161.79\n",
      "training :  887  accuracy =   0.6100  loss =  160.723\n",
      "testing  :  887  accuracy =   0.5884  loss =  161.741\n",
      "training :  888  accuracy =   0.6500  loss =  158.626\n",
      "testing  :  888  accuracy =   0.5892  loss =  161.744\n",
      "training :  889  accuracy =   0.6300  loss =  159.124\n",
      "testing  :  889  accuracy =   0.5887  loss =  161.801\n",
      "training :  890  accuracy =   0.5800  loss =  163.532\n",
      "testing  :  890  accuracy =   0.5893  loss =  161.824\n",
      "training :  891  accuracy =   0.5800  loss =  159.95\n",
      "testing  :  891  accuracy =   0.5881  loss =  161.943\n",
      "training :  892  accuracy =   0.5900  loss =  163.609\n",
      "testing  :  892  accuracy =   0.5864  loss =  162.13\n",
      "training :  893  accuracy =   0.6200  loss =  160.848\n",
      "testing  :  893  accuracy =   0.5849  loss =  162.266\n",
      "training :  894  accuracy =   0.5900  loss =  161.814\n",
      "testing  :  894  accuracy =   0.5849  loss =  162.195\n",
      "training :  895  accuracy =   0.6400  loss =  161.721\n",
      "testing  :  895  accuracy =   0.5857  loss =  162.07\n",
      "training :  896  accuracy =   0.6200  loss =  160.253\n",
      "testing  :  896  accuracy =   0.5858  loss =  161.881\n",
      "training :  897  accuracy =   0.5500  loss =  165.614\n",
      "testing  :  897  accuracy =   0.5869  loss =  161.754\n",
      "training :  898  accuracy =   0.5800  loss =  160.022\n",
      "testing  :  898  accuracy =   0.5887  loss =  161.692\n",
      "training :  899  accuracy =   0.6900  loss =  160.022\n",
      "testing  :  899  accuracy =   0.5886  loss =  161.662\n",
      "training :  900  accuracy =   0.6200  loss =  159.81\n",
      "testing  :  900  accuracy =   0.5880  loss =  161.655\n",
      "training :  901  accuracy =   0.5800  loss =  159.184\n",
      "testing  :  901  accuracy =   0.5877  loss =  161.66\n",
      "training :  902  accuracy =   0.5600  loss =  162.204\n",
      "testing  :  902  accuracy =   0.5876  loss =  161.661\n",
      "training :  903  accuracy =   0.5500  loss =  159.051\n",
      "testing  :  903  accuracy =   0.5866  loss =  161.681\n",
      "training :  904  accuracy =   0.6000  loss =  161.279\n",
      "testing  :  904  accuracy =   0.5868  loss =  161.702\n",
      "training :  905  accuracy =   0.6400  loss =  160.444\n",
      "testing  :  905  accuracy =   0.5871  loss =  161.679\n",
      "training :  906  accuracy =   0.5300  loss =  162.25\n",
      "testing  :  906  accuracy =   0.5874  loss =  161.623\n",
      "training :  907  accuracy =   0.5400  loss =  163.913\n",
      "testing  :  907  accuracy =   0.5877  loss =  161.551\n",
      "training :  908  accuracy =   0.5000  loss =  160.353\n",
      "testing  :  908  accuracy =   0.5886  loss =  161.478\n",
      "training :  909  accuracy =   0.4500  loss =  164.192\n",
      "testing  :  909  accuracy =   0.5888  loss =  161.424\n",
      "training :  910  accuracy =   0.5600  loss =  164.487\n",
      "testing  :  910  accuracy =   0.5891  loss =  161.416\n",
      "training :  911  accuracy =   0.6800  loss =  159.068\n",
      "testing  :  911  accuracy =   0.5894  loss =  161.465\n",
      "training :  912  accuracy =   0.5500  loss =  160.835\n",
      "testing  :  912  accuracy =   0.5890  loss =  161.614\n",
      "training :  913  accuracy =   0.5200  loss =  162.615\n",
      "testing  :  913  accuracy =   0.5877  loss =  161.819\n",
      "training :  914  accuracy =   0.6100  loss =  161.592\n",
      "testing  :  914  accuracy =   0.5859  loss =  161.985\n",
      "training :  915  accuracy =   0.5600  loss =  166.369\n",
      "testing  :  915  accuracy =   0.5846  loss =  162.089\n",
      "training :  916  accuracy =   0.5400  loss =  162.027\n",
      "testing  :  916  accuracy =   0.5849  loss =  161.967\n",
      "training :  917  accuracy =   0.5300  loss =  160.514\n",
      "testing  :  917  accuracy =   0.5841  loss =  161.823\n",
      "training :  918  accuracy =   0.5400  loss =  160.564\n",
      "testing  :  918  accuracy =   0.5853  loss =  161.626\n",
      "training :  919  accuracy =   0.5700  loss =  163.444\n",
      "testing  :  919  accuracy =   0.5868  loss =  161.487\n",
      "training :  920  accuracy =   0.6800  loss =  162.691\n",
      "testing  :  920  accuracy =   0.5873  loss =  161.444\n",
      "training :  921  accuracy =   0.6400  loss =  158.666\n",
      "testing  :  921  accuracy =   0.5864  loss =  161.475\n",
      "training :  922  accuracy =   0.6600  loss =  159.086\n",
      "testing  :  922  accuracy =   0.5863  loss =  161.55\n",
      "training :  923  accuracy =   0.6100  loss =  163.164\n",
      "testing  :  923  accuracy =   0.5863  loss =  161.62\n",
      "training :  924  accuracy =   0.6000  loss =  161.05\n",
      "testing  :  924  accuracy =   0.5853  loss =  161.644\n",
      "training :  925  accuracy =   0.6000  loss =  163.903\n",
      "testing  :  925  accuracy =   0.5849  loss =  161.666\n",
      "training :  926  accuracy =   0.5400  loss =  162.37\n",
      "testing  :  926  accuracy =   0.5835  loss =  161.724\n",
      "training :  927  accuracy =   0.5400  loss =  162.169\n",
      "testing  :  927  accuracy =   0.5834  loss =  161.741\n",
      "training :  928  accuracy =   0.6400  loss =  159.358\n",
      "testing  :  928  accuracy =   0.5832  loss =  161.72\n",
      "training :  929  accuracy =   0.4800  loss =  160.852\n",
      "testing  :  929  accuracy =   0.5833  loss =  161.712\n",
      "training :  930  accuracy =   0.5900  loss =  161.482\n",
      "testing  :  930  accuracy =   0.5829  loss =  161.698\n",
      "training :  931  accuracy =   0.5700  loss =  161.573\n",
      "testing  :  931  accuracy =   0.5832  loss =  161.605\n",
      "training :  932  accuracy =   0.5900  loss =  160.491\n",
      "testing  :  932  accuracy =   0.5838  loss =  161.506\n",
      "training :  933  accuracy =   0.5800  loss =  159.359\n",
      "testing  :  933  accuracy =   0.5845  loss =  161.475\n",
      "training :  934  accuracy =   0.5800  loss =  162.322\n",
      "testing  :  934  accuracy =   0.5840  loss =  161.49\n",
      "training :  935  accuracy =   0.5500  loss =  162.386\n",
      "testing  :  935  accuracy =   0.5829  loss =  161.595\n",
      "training :  936  accuracy =   0.6000  loss =  165.446\n",
      "testing  :  936  accuracy =   0.5817  loss =  161.756\n",
      "training :  937  accuracy =   0.5700  loss =  163.527\n",
      "testing  :  937  accuracy =   0.5806  loss =  161.9\n",
      "training :  938  accuracy =   0.5500  loss =  161.204\n",
      "testing  :  938  accuracy =   0.5811  loss =  161.832\n",
      "training :  939  accuracy =   0.6300  loss =  159.616\n",
      "testing  :  939  accuracy =   0.5817  loss =  161.811\n",
      "training :  940  accuracy =   0.5000  loss =  165.395\n",
      "testing  :  940  accuracy =   0.5822  loss =  161.737\n",
      "training :  941  accuracy =   0.5400  loss =  162.245\n",
      "testing  :  941  accuracy =   0.5827  loss =  161.64\n",
      "training :  942  accuracy =   0.5200  loss =  161.647\n",
      "testing  :  942  accuracy =   0.5834  loss =  161.55\n",
      "training :  943  accuracy =   0.5200  loss =  163.624\n",
      "testing  :  943  accuracy =   0.5840  loss =  161.501\n",
      "training :  944  accuracy =   0.6200  loss =  161.337\n",
      "testing  :  944  accuracy =   0.5838  loss =  161.484\n",
      "training :  945  accuracy =   0.5800  loss =  161.178\n",
      "testing  :  945  accuracy =   0.5836  loss =  161.501\n",
      "training :  946  accuracy =   0.6200  loss =  159.952\n",
      "testing  :  946  accuracy =   0.5844  loss =  161.532\n",
      "training :  947  accuracy =   0.7200  loss =  159.641\n",
      "testing  :  947  accuracy =   0.5854  loss =  161.55\n",
      "training :  948  accuracy =   0.5700  loss =  163.369\n",
      "testing  :  948  accuracy =   0.5870  loss =  161.534\n",
      "training :  949  accuracy =   0.6100  loss =  160.6\n",
      "testing  :  949  accuracy =   0.5912  loss =  161.51\n",
      "training :  950  accuracy =   0.5800  loss =  159.847\n",
      "testing  :  950  accuracy =   0.5891  loss =  161.51\n",
      "training :  951  accuracy =   0.6000  loss =  160.066\n",
      "testing  :  951  accuracy =   0.5866  loss =  161.479\n",
      "training :  952  accuracy =   0.6000  loss =  159.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  952  accuracy =   0.5830  loss =  161.446\n",
      "training :  953  accuracy =   0.5400  loss =  161.478\n",
      "testing  :  953  accuracy =   0.5819  loss =  161.434\n",
      "training :  954  accuracy =   0.6200  loss =  161.674\n",
      "testing  :  954  accuracy =   0.5822  loss =  161.432\n",
      "training :  955  accuracy =   0.5800  loss =  162.235\n",
      "testing  :  955  accuracy =   0.5818  loss =  161.419\n",
      "training :  956  accuracy =   0.6300  loss =  159.182\n",
      "testing  :  956  accuracy =   0.5805  loss =  161.384\n",
      "training :  957  accuracy =   0.6300  loss =  163.139\n",
      "testing  :  957  accuracy =   0.5807  loss =  161.353\n",
      "training :  958  accuracy =   0.5900  loss =  160.918\n",
      "testing  :  958  accuracy =   0.5812  loss =  161.334\n",
      "training :  959  accuracy =   0.5400  loss =  163.086\n",
      "testing  :  959  accuracy =   0.5841  loss =  161.325\n",
      "training :  960  accuracy =   0.5500  loss =  160.839\n",
      "testing  :  960  accuracy =   0.5834  loss =  161.342\n",
      "training :  961  accuracy =   0.6700  loss =  158.007\n",
      "testing  :  961  accuracy =   0.5871  loss =  161.431\n",
      "training :  962  accuracy =   0.6300  loss =  160.024\n",
      "testing  :  962  accuracy =   0.5869  loss =  161.588\n",
      "training :  963  accuracy =   0.5900  loss =  160.94\n",
      "testing  :  963  accuracy =   0.5861  loss =  161.719\n",
      "training :  964  accuracy =   0.6100  loss =  160.859\n",
      "testing  :  964  accuracy =   0.5839  loss =  161.872\n",
      "training :  965  accuracy =   0.5400  loss =  165.192\n",
      "testing  :  965  accuracy =   0.5821  loss =  161.98\n",
      "training :  966  accuracy =   0.5600  loss =  164.231\n",
      "testing  :  966  accuracy =   0.5805  loss =  162.031\n",
      "training :  967  accuracy =   0.5800  loss =  161.138\n",
      "testing  :  967  accuracy =   0.5796  loss =  161.826\n",
      "training :  968  accuracy =   0.5800  loss =  161.652\n",
      "testing  :  968  accuracy =   0.5792  loss =  161.632\n",
      "training :  969  accuracy =   0.5600  loss =  160.799\n",
      "testing  :  969  accuracy =   0.5792  loss =  161.496\n",
      "training :  970  accuracy =   0.5700  loss =  161.334\n",
      "testing  :  970  accuracy =   0.5812  loss =  161.391\n",
      "training :  971  accuracy =   0.5900  loss =  159.043\n",
      "testing  :  971  accuracy =   0.5803  loss =  161.309\n",
      "training :  972  accuracy =   0.6100  loss =  159.86\n",
      "testing  :  972  accuracy =   0.5806  loss =  161.242\n",
      "training :  973  accuracy =   0.5400  loss =  161.639\n",
      "testing  :  973  accuracy =   0.5806  loss =  161.204\n",
      "training :  974  accuracy =   0.6200  loss =  163.451\n",
      "testing  :  974  accuracy =   0.5796  loss =  161.188\n",
      "training :  975  accuracy =   0.6100  loss =  161.834\n",
      "testing  :  975  accuracy =   0.5802  loss =  161.188\n",
      "training :  976  accuracy =   0.5600  loss =  160.99\n",
      "testing  :  976  accuracy =   0.5798  loss =  161.196\n",
      "training :  977  accuracy =   0.5900  loss =  160.803\n",
      "testing  :  977  accuracy =   0.5802  loss =  161.201\n",
      "training :  978  accuracy =   0.6300  loss =  159.203\n",
      "testing  :  978  accuracy =   0.5803  loss =  161.213\n",
      "training :  979  accuracy =   0.5500  loss =  161.693\n",
      "testing  :  979  accuracy =   0.5802  loss =  161.247\n",
      "training :  980  accuracy =   0.5100  loss =  161.781\n",
      "testing  :  980  accuracy =   0.5793  loss =  161.274\n",
      "training :  981  accuracy =   0.5600  loss =  161.482\n",
      "testing  :  981  accuracy =   0.5793  loss =  161.281\n",
      "training :  982  accuracy =   0.7000  loss =  160.059\n",
      "testing  :  982  accuracy =   0.5789  loss =  161.307\n",
      "training :  983  accuracy =   0.6600  loss =  162.018\n",
      "testing  :  983  accuracy =   0.5794  loss =  161.336\n",
      "training :  984  accuracy =   0.6000  loss =  160.492\n",
      "testing  :  984  accuracy =   0.5787  loss =  161.323\n",
      "training :  985  accuracy =   0.5700  loss =  161.368\n",
      "testing  :  985  accuracy =   0.5784  loss =  161.321\n",
      "training :  986  accuracy =   0.5500  loss =  162.908\n",
      "testing  :  986  accuracy =   0.5784  loss =  161.313\n",
      "training :  987  accuracy =   0.6000  loss =  158.998\n",
      "testing  :  987  accuracy =   0.5791  loss =  161.309\n",
      "training :  988  accuracy =   0.5500  loss =  160.871\n",
      "testing  :  988  accuracy =   0.5787  loss =  161.297\n",
      "training :  989  accuracy =   0.6500  loss =  160.864\n",
      "testing  :  989  accuracy =   0.5793  loss =  161.287\n",
      "training :  990  accuracy =   0.4900  loss =  163.501\n",
      "testing  :  990  accuracy =   0.5793  loss =  161.26\n",
      "training :  991  accuracy =   0.6200  loss =  163.234\n",
      "testing  :  991  accuracy =   0.5796  loss =  161.217\n",
      "training :  992  accuracy =   0.7100  loss =  159.472\n",
      "testing  :  992  accuracy =   0.5790  loss =  161.203\n",
      "training :  993  accuracy =   0.6000  loss =  160.735\n",
      "testing  :  993  accuracy =   0.5793  loss =  161.227\n",
      "training :  994  accuracy =   0.7000  loss =  156.409\n",
      "testing  :  994  accuracy =   0.5796  loss =  161.269\n",
      "training :  995  accuracy =   0.6400  loss =  162.609\n",
      "testing  :  995  accuracy =   0.5801  loss =  161.335\n",
      "training :  996  accuracy =   0.5700  loss =  161.426\n",
      "testing  :  996  accuracy =   0.5803  loss =  161.329\n",
      "training :  997  accuracy =   0.6900  loss =  158.585\n",
      "testing  :  997  accuracy =   0.5808  loss =  161.313\n",
      "training :  998  accuracy =   0.5400  loss =  162.799\n",
      "testing  :  998  accuracy =   0.5813  loss =  161.283\n",
      "training :  999  accuracy =   0.5600  loss =  161.106\n",
      "testing  :  999  accuracy =   0.5805  loss =  161.243\n",
      "training :  1000  accuracy =   0.5800  loss =  160.743\n",
      "testing  :  1000  accuracy =   0.5815  loss =  161.209\n",
      "training :  1001  accuracy =   0.6000  loss =  158.669\n",
      "testing  :  1001  accuracy =   0.5810  loss =  161.18\n",
      "training :  1002  accuracy =   0.5400  loss =  159.913\n",
      "testing  :  1002  accuracy =   0.5820  loss =  161.167\n",
      "training :  1003  accuracy =   0.6600  loss =  158.738\n",
      "testing  :  1003  accuracy =   0.5824  loss =  161.18\n",
      "training :  1004  accuracy =   0.5300  loss =  161.554\n",
      "testing  :  1004  accuracy =   0.5827  loss =  161.193\n",
      "training :  1005  accuracy =   0.6200  loss =  160.141\n",
      "testing  :  1005  accuracy =   0.5833  loss =  161.213\n",
      "training :  1006  accuracy =   0.5600  loss =  159.578\n",
      "testing  :  1006  accuracy =   0.5837  loss =  161.229\n",
      "training :  1007  accuracy =   0.5200  loss =  162.141\n",
      "testing  :  1007  accuracy =   0.5837  loss =  161.243\n",
      "training :  1008  accuracy =   0.6500  loss =  160.087\n",
      "testing  :  1008  accuracy =   0.5839  loss =  161.233\n",
      "training :  1009  accuracy =   0.6700  loss =  158.158\n",
      "testing  :  1009  accuracy =   0.5836  loss =  161.233\n",
      "training :  1010  accuracy =   0.5400  loss =  162.747\n",
      "testing  :  1010  accuracy =   0.5838  loss =  161.245\n",
      "training :  1011  accuracy =   0.6300  loss =  158.133\n",
      "testing  :  1011  accuracy =   0.5838  loss =  161.269\n",
      "training :  1012  accuracy =   0.5400  loss =  162.533\n",
      "testing  :  1012  accuracy =   0.5821  loss =  161.288\n",
      "training :  1013  accuracy =   0.5800  loss =  160.026\n",
      "testing  :  1013  accuracy =   0.5821  loss =  161.337\n",
      "training :  1014  accuracy =   0.5800  loss =  162.299\n",
      "testing  :  1014  accuracy =   0.5821  loss =  161.376\n",
      "training :  1015  accuracy =   0.6800  loss =  159.921\n",
      "testing  :  1015  accuracy =   0.5819  loss =  161.398\n",
      "training :  1016  accuracy =   0.6000  loss =  160.426\n",
      "testing  :  1016  accuracy =   0.5808  loss =  161.38\n",
      "training :  1017  accuracy =   0.6100  loss =  162.028\n",
      "testing  :  1017  accuracy =   0.5808  loss =  161.386\n",
      "training :  1018  accuracy =   0.6100  loss =  161.241\n",
      "testing  :  1018  accuracy =   0.5805  loss =  161.339\n",
      "training :  1019  accuracy =   0.6100  loss =  159.402\n",
      "testing  :  1019  accuracy =   0.5801  loss =  161.287\n",
      "training :  1020  accuracy =   0.5700  loss =  161.925\n",
      "testing  :  1020  accuracy =   0.5804  loss =  161.302\n",
      "training :  1021  accuracy =   0.5900  loss =  159.244\n",
      "testing  :  1021  accuracy =   0.5779  loss =  161.447\n",
      "training :  1022  accuracy =   0.4900  loss =  161.757\n",
      "testing  :  1022  accuracy =   0.5771  loss =  161.716\n",
      "training :  1023  accuracy =   0.5100  loss =  162.783\n",
      "testing  :  1023  accuracy =   0.5754  loss =  161.989\n",
      "training :  1024  accuracy =   0.5700  loss =  163.916\n",
      "testing  :  1024  accuracy =   0.5752  loss =  162.18\n",
      "training :  1025  accuracy =   0.5100  loss =  162.116\n",
      "testing  :  1025  accuracy =   0.5755  loss =  162.35\n",
      "training :  1026  accuracy =   0.5600  loss =  165.041\n",
      "testing  :  1026  accuracy =   0.5769  loss =  162.366\n",
      "training :  1027  accuracy =   0.5700  loss =  159.249\n",
      "testing  :  1027  accuracy =   0.5774  loss =  162.324\n",
      "training :  1028  accuracy =   0.5700  loss =  164.986\n",
      "testing  :  1028  accuracy =   0.5788  loss =  162.232\n",
      "training :  1029  accuracy =   0.6400  loss =  160.871\n",
      "testing  :  1029  accuracy =   0.5804  loss =  162.114\n",
      "training :  1030  accuracy =   0.6500  loss =  160.581\n",
      "testing  :  1030  accuracy =   0.5870  loss =  161.955\n",
      "training :  1031  accuracy =   0.5700  loss =  162.472\n",
      "testing  :  1031  accuracy =   0.5907  loss =  161.811\n",
      "training :  1032  accuracy =   0.6200  loss =  164.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1032  accuracy =   0.5910  loss =  161.653\n",
      "training :  1033  accuracy =   0.5600  loss =  161.453\n",
      "testing  :  1033  accuracy =   0.5902  loss =  161.518\n",
      "training :  1034  accuracy =   0.5500  loss =  159.339\n",
      "testing  :  1034  accuracy =   0.5894  loss =  161.403\n",
      "training :  1035  accuracy =   0.5700  loss =  162.493\n",
      "testing  :  1035  accuracy =   0.5906  loss =  161.31\n",
      "training :  1036  accuracy =   0.6200  loss =  160.481\n",
      "testing  :  1036  accuracy =   0.5904  loss =  161.234\n",
      "training :  1037  accuracy =   0.5700  loss =  160.514\n",
      "testing  :  1037  accuracy =   0.5902  loss =  161.152\n",
      "training :  1038  accuracy =   0.6200  loss =  159.301\n",
      "testing  :  1038  accuracy =   0.5906  loss =  161.081\n",
      "training :  1039  accuracy =   0.6000  loss =  162.012\n",
      "testing  :  1039  accuracy =   0.5909  loss =  161.06\n",
      "training :  1040  accuracy =   0.6100  loss =  159.981\n",
      "testing  :  1040  accuracy =   0.5902  loss =  161.066\n",
      "training :  1041  accuracy =   0.7000  loss =  158.127\n",
      "testing  :  1041  accuracy =   0.5915  loss =  161.071\n",
      "training :  1042  accuracy =   0.6400  loss =  159.95\n",
      "testing  :  1042  accuracy =   0.5924  loss =  161.105\n",
      "training :  1043  accuracy =   0.5300  loss =  160.827\n",
      "testing  :  1043  accuracy =   0.5920  loss =  161.173\n",
      "training :  1044  accuracy =   0.5900  loss =  161.064\n",
      "testing  :  1044  accuracy =   0.5907  loss =  161.263\n",
      "training :  1045  accuracy =   0.5800  loss =  161.705\n",
      "testing  :  1045  accuracy =   0.5895  loss =  161.361\n",
      "training :  1046  accuracy =   0.5900  loss =  161.077\n",
      "testing  :  1046  accuracy =   0.5886  loss =  161.535\n",
      "training :  1047  accuracy =   0.6500  loss =  160.283\n",
      "testing  :  1047  accuracy =   0.5858  loss =  161.765\n",
      "training :  1048  accuracy =   0.6100  loss =  162.741\n",
      "testing  :  1048  accuracy =   0.5846  loss =  161.873\n",
      "training :  1049  accuracy =   0.6500  loss =  162.307\n",
      "testing  :  1049  accuracy =   0.5815  loss =  161.806\n",
      "training :  1050  accuracy =   0.6000  loss =  161.531\n",
      "testing  :  1050  accuracy =   0.5830  loss =  161.666\n",
      "training :  1051  accuracy =   0.6100  loss =  162.672\n",
      "testing  :  1051  accuracy =   0.5856  loss =  161.546\n",
      "training :  1052  accuracy =   0.5500  loss =  165.651\n",
      "testing  :  1052  accuracy =   0.5866  loss =  161.442\n",
      "training :  1053  accuracy =   0.5500  loss =  160.581\n",
      "testing  :  1053  accuracy =   0.5863  loss =  161.385\n",
      "training :  1054  accuracy =   0.6300  loss =  158.738\n",
      "testing  :  1054  accuracy =   0.5877  loss =  161.37\n",
      "training :  1055  accuracy =   0.5500  loss =  161.933\n",
      "testing  :  1055  accuracy =   0.5863  loss =  161.37\n",
      "training :  1056  accuracy =   0.5900  loss =  160.599\n",
      "testing  :  1056  accuracy =   0.5864  loss =  161.329\n",
      "training :  1057  accuracy =   0.5200  loss =  162.345\n",
      "testing  :  1057  accuracy =   0.5866  loss =  161.288\n",
      "training :  1058  accuracy =   0.5900  loss =  160.054\n",
      "testing  :  1058  accuracy =   0.5879  loss =  161.253\n",
      "training :  1059  accuracy =   0.6000  loss =  163.008\n",
      "testing  :  1059  accuracy =   0.5885  loss =  161.189\n",
      "training :  1060  accuracy =   0.6500  loss =  159.161\n",
      "testing  :  1060  accuracy =   0.5880  loss =  161.13\n",
      "training :  1061  accuracy =   0.6200  loss =  159.757\n",
      "testing  :  1061  accuracy =   0.5878  loss =  161.12\n",
      "training :  1062  accuracy =   0.5600  loss =  159.543\n",
      "testing  :  1062  accuracy =   0.5871  loss =  161.205\n",
      "training :  1063  accuracy =   0.5800  loss =  161.567\n",
      "testing  :  1063  accuracy =   0.5855  loss =  161.325\n",
      "training :  1064  accuracy =   0.5900  loss =  161.337\n",
      "testing  :  1064  accuracy =   0.5859  loss =  161.328\n",
      "training :  1065  accuracy =   0.5800  loss =  163.204\n",
      "testing  :  1065  accuracy =   0.5856  loss =  161.312\n",
      "training :  1066  accuracy =   0.5200  loss =  160.865\n",
      "testing  :  1066  accuracy =   0.5856  loss =  161.141\n",
      "training :  1067  accuracy =   0.6600  loss =  158.559\n",
      "testing  :  1067  accuracy =   0.5862  loss =  161.041\n",
      "training :  1068  accuracy =   0.6300  loss =  159.789\n",
      "testing  :  1068  accuracy =   0.5857  loss =  161.073\n",
      "training :  1069  accuracy =   0.5600  loss =  166.49\n",
      "testing  :  1069  accuracy =   0.5851  loss =  161.199\n",
      "training :  1070  accuracy =   0.5800  loss =  163.561\n",
      "testing  :  1070  accuracy =   0.5840  loss =  161.36\n",
      "training :  1071  accuracy =   0.6600  loss =  161.54\n",
      "testing  :  1071  accuracy =   0.5829  loss =  161.495\n",
      "training :  1072  accuracy =   0.5600  loss =  165.609\n",
      "testing  :  1072  accuracy =   0.5818  loss =  161.581\n",
      "training :  1073  accuracy =   0.5500  loss =  166.011\n",
      "testing  :  1073  accuracy =   0.5818  loss =  161.613\n",
      "training :  1074  accuracy =   0.6000  loss =  157.579\n",
      "testing  :  1074  accuracy =   0.5820  loss =  161.614\n",
      "training :  1075  accuracy =   0.6200  loss =  157.637\n",
      "testing  :  1075  accuracy =   0.5822  loss =  161.619\n",
      "training :  1076  accuracy =   0.5700  loss =  159.5\n",
      "testing  :  1076  accuracy =   0.5823  loss =  161.604\n",
      "training :  1077  accuracy =   0.5800  loss =  161.007\n",
      "testing  :  1077  accuracy =   0.5818  loss =  161.594\n",
      "training :  1078  accuracy =   0.5600  loss =  159.499\n",
      "testing  :  1078  accuracy =   0.5831  loss =  161.544\n",
      "training :  1079  accuracy =   0.6000  loss =  162.017\n",
      "testing  :  1079  accuracy =   0.5833  loss =  161.505\n",
      "training :  1080  accuracy =   0.5800  loss =  164.585\n",
      "testing  :  1080  accuracy =   0.5842  loss =  161.407\n",
      "training :  1081  accuracy =   0.6400  loss =  162.266\n",
      "testing  :  1081  accuracy =   0.5848  loss =  161.299\n",
      "training :  1082  accuracy =   0.6300  loss =  159.603\n",
      "testing  :  1082  accuracy =   0.5859  loss =  161.216\n",
      "training :  1083  accuracy =   0.5600  loss =  160.764\n",
      "testing  :  1083  accuracy =   0.5858  loss =  161.154\n",
      "training :  1084  accuracy =   0.6000  loss =  162.831\n",
      "testing  :  1084  accuracy =   0.5866  loss =  161.112\n",
      "training :  1085  accuracy =   0.5500  loss =  160.471\n",
      "testing  :  1085  accuracy =   0.5873  loss =  161.099\n",
      "training :  1086  accuracy =   0.6700  loss =  160.356\n",
      "testing  :  1086  accuracy =   0.5870  loss =  161.128\n",
      "training :  1087  accuracy =   0.6000  loss =  159.883\n",
      "testing  :  1087  accuracy =   0.5864  loss =  161.224\n",
      "training :  1088  accuracy =   0.6000  loss =  162.509\n",
      "testing  :  1088  accuracy =   0.5853  loss =  161.338\n",
      "training :  1089  accuracy =   0.5600  loss =  159.769\n",
      "testing  :  1089  accuracy =   0.5853  loss =  161.319\n",
      "training :  1090  accuracy =   0.6100  loss =  159.241\n",
      "testing  :  1090  accuracy =   0.5855  loss =  161.267\n",
      "training :  1091  accuracy =   0.4900  loss =  164.167\n",
      "testing  :  1091  accuracy =   0.5862  loss =  161.223\n",
      "training :  1092  accuracy =   0.5700  loss =  163.434\n",
      "testing  :  1092  accuracy =   0.5861  loss =  161.158\n",
      "training :  1093  accuracy =   0.5300  loss =  163.453\n",
      "testing  :  1093  accuracy =   0.5859  loss =  161.101\n",
      "training :  1094  accuracy =   0.5800  loss =  162.132\n",
      "testing  :  1094  accuracy =   0.5852  loss =  161.095\n",
      "training :  1095  accuracy =   0.6100  loss =  158.08\n",
      "testing  :  1095  accuracy =   0.5856  loss =  161.141\n",
      "training :  1096  accuracy =   0.6400  loss =  160.594\n",
      "testing  :  1096  accuracy =   0.5856  loss =  161.22\n",
      "training :  1097  accuracy =   0.5400  loss =  162.297\n",
      "testing  :  1097  accuracy =   0.5860  loss =  161.304\n",
      "training :  1098  accuracy =   0.6000  loss =  161.19\n",
      "testing  :  1098  accuracy =   0.5853  loss =  161.367\n",
      "training :  1099  accuracy =   0.6000  loss =  161.025\n",
      "testing  :  1099  accuracy =   0.5860  loss =  161.344\n",
      "training :  1100  accuracy =   0.5300  loss =  161.423\n",
      "testing  :  1100  accuracy =   0.5870  loss =  161.184\n",
      "training :  1101  accuracy =   0.6200  loss =  161.026\n",
      "testing  :  1101  accuracy =   0.5879  loss =  161.078\n",
      "training :  1102  accuracy =   0.5600  loss =  160.693\n",
      "testing  :  1102  accuracy =   0.5880  loss =  161.026\n",
      "training :  1103  accuracy =   0.5700  loss =  165.113\n",
      "testing  :  1103  accuracy =   0.5892  loss =  160.994\n",
      "training :  1104  accuracy =   0.6400  loss =  160.071\n",
      "testing  :  1104  accuracy =   0.5897  loss =  160.962\n",
      "training :  1105  accuracy =   0.6300  loss =  158.715\n",
      "testing  :  1105  accuracy =   0.5904  loss =  160.942\n",
      "training :  1106  accuracy =   0.6600  loss =  158.722\n",
      "testing  :  1106  accuracy =   0.5903  loss =  160.935\n",
      "training :  1107  accuracy =   0.5900  loss =  162.709\n",
      "testing  :  1107  accuracy =   0.5907  loss =  160.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  1108  accuracy =   0.6000  loss =  164.406\n",
      "testing  :  1108  accuracy =   0.5896  loss =  160.958\n",
      "training :  1109  accuracy =   0.5200  loss =  162.247\n",
      "testing  :  1109  accuracy =   0.5887  loss =  161.03\n",
      "training :  1110  accuracy =   0.6100  loss =  162.783\n",
      "testing  :  1110  accuracy =   0.5886  loss =  161.049\n",
      "training :  1111  accuracy =   0.5900  loss =  159.907\n",
      "testing  :  1111  accuracy =   0.5891  loss =  161.012\n",
      "training :  1112  accuracy =   0.6000  loss =  160.663\n",
      "testing  :  1112  accuracy =   0.5892  loss =  160.985\n",
      "training :  1113  accuracy =   0.6500  loss =  160.057\n",
      "testing  :  1113  accuracy =   0.5908  loss =  160.977\n",
      "training :  1114  accuracy =   0.5900  loss =  161.379\n",
      "testing  :  1114  accuracy =   0.5869  loss =  160.999\n",
      "training :  1115  accuracy =   0.5100  loss =  160.939\n",
      "testing  :  1115  accuracy =   0.5841  loss =  161.004\n",
      "training :  1116  accuracy =   0.6300  loss =  157.916\n",
      "testing  :  1116  accuracy =   0.5835  loss =  160.979\n",
      "training :  1117  accuracy =   0.5900  loss =  162.634\n",
      "testing  :  1117  accuracy =   0.5827  loss =  160.958\n",
      "training :  1118  accuracy =   0.6100  loss =  160.315\n",
      "testing  :  1118  accuracy =   0.5830  loss =  160.895\n",
      "training :  1119  accuracy =   0.5300  loss =  160.747\n",
      "testing  :  1119  accuracy =   0.5821  loss =  160.853\n",
      "training :  1120  accuracy =   0.5500  loss =  161.784\n",
      "testing  :  1120  accuracy =   0.5821  loss =  160.85\n",
      "training :  1121  accuracy =   0.6200  loss =  161.281\n",
      "testing  :  1121  accuracy =   0.5831  loss =  160.87\n",
      "training :  1122  accuracy =   0.6100  loss =  160.638\n",
      "testing  :  1122  accuracy =   0.5839  loss =  160.9\n",
      "training :  1123  accuracy =   0.5100  loss =  159.8\n",
      "testing  :  1123  accuracy =   0.5846  loss =  160.898\n",
      "training :  1124  accuracy =   0.7000  loss =  156.49\n",
      "testing  :  1124  accuracy =   0.5849  loss =  160.87\n",
      "training :  1125  accuracy =   0.5300  loss =  167.127\n",
      "testing  :  1125  accuracy =   0.5872  loss =  160.827\n",
      "training :  1126  accuracy =   0.5000  loss =  163.624\n",
      "testing  :  1126  accuracy =   0.5933  loss =  160.823\n",
      "training :  1127  accuracy =   0.5200  loss =  164.246\n",
      "testing  :  1127  accuracy =   0.5954  loss =  160.885\n",
      "training :  1128  accuracy =   0.6700  loss =  157.629\n",
      "testing  :  1128  accuracy =   0.5948  loss =  161.001\n",
      "training :  1129  accuracy =   0.6300  loss =  163.287\n",
      "testing  :  1129  accuracy =   0.5934  loss =  161.096\n",
      "training :  1130  accuracy =   0.6600  loss =  160.004\n",
      "testing  :  1130  accuracy =   0.5940  loss =  161.202\n",
      "training :  1131  accuracy =   0.5700  loss =  160.658\n",
      "testing  :  1131  accuracy =   0.5920  loss =  161.346\n",
      "training :  1132  accuracy =   0.6300  loss =  160.732\n",
      "testing  :  1132  accuracy =   0.5907  loss =  161.324\n",
      "training :  1133  accuracy =   0.5800  loss =  161.551\n",
      "testing  :  1133  accuracy =   0.5896  loss =  161.337\n",
      "training :  1134  accuracy =   0.6500  loss =  160.28\n",
      "testing  :  1134  accuracy =   0.5887  loss =  161.276\n",
      "training :  1135  accuracy =   0.6300  loss =  159.091\n",
      "testing  :  1135  accuracy =   0.5868  loss =  161.197\n",
      "training :  1136  accuracy =   0.6100  loss =  163.158\n",
      "testing  :  1136  accuracy =   0.5848  loss =  161.186\n",
      "training :  1137  accuracy =   0.5800  loss =  161.44\n",
      "testing  :  1137  accuracy =   0.5859  loss =  161.161\n",
      "training :  1138  accuracy =   0.6300  loss =  162.493\n",
      "testing  :  1138  accuracy =   0.6075  loss =  161.099\n",
      "training :  1139  accuracy =   0.6800  loss =  158.195\n",
      "testing  :  1139  accuracy =   0.6473  loss =  161.102\n",
      "training :  1140  accuracy =   0.6000  loss =  163.241\n",
      "testing  :  1140  accuracy =   0.6420  loss =  161.156\n",
      "training :  1141  accuracy =   0.7500  loss =  158.351\n",
      "testing  :  1141  accuracy =   0.6464  loss =  161.123\n",
      "training :  1142  accuracy =   0.6000  loss =  161.943\n",
      "testing  :  1142  accuracy =   0.6442  loss =  161.018\n",
      "training :  1143  accuracy =   0.5400  loss =  166.057\n",
      "testing  :  1143  accuracy =   0.6390  loss =  160.953\n",
      "training :  1144  accuracy =   0.7000  loss =  159.013\n",
      "testing  :  1144  accuracy =   0.6362  loss =  160.898\n",
      "training :  1145  accuracy =   0.6500  loss =  159.782\n",
      "testing  :  1145  accuracy =   0.6388  loss =  160.861\n",
      "training :  1146  accuracy =   0.6200  loss =  161.354\n",
      "testing  :  1146  accuracy =   0.6425  loss =  160.855\n",
      "training :  1147  accuracy =   0.6900  loss =  160.024\n",
      "testing  :  1147  accuracy =   0.6568  loss =  160.882\n",
      "training :  1148  accuracy =   0.6200  loss =  160.262\n",
      "testing  :  1148  accuracy =   0.6583  loss =  160.921\n",
      "training :  1149  accuracy =   0.6600  loss =  162.206\n",
      "testing  :  1149  accuracy =   0.6559  loss =  160.982\n",
      "training :  1150  accuracy =   0.6700  loss =  158.765\n",
      "testing  :  1150  accuracy =   0.6526  loss =  161.037\n",
      "training :  1151  accuracy =   0.7000  loss =  158.552\n",
      "testing  :  1151  accuracy =   0.6431  loss =  161.042\n",
      "training :  1152  accuracy =   0.6400  loss =  159.107\n",
      "testing  :  1152  accuracy =   0.6331  loss =  161.048\n",
      "training :  1153  accuracy =   0.5400  loss =  162.198\n",
      "testing  :  1153  accuracy =   0.6246  loss =  161.024\n",
      "training :  1154  accuracy =   0.6400  loss =  159.131\n",
      "testing  :  1154  accuracy =   0.6251  loss =  160.962\n",
      "training :  1155  accuracy =   0.6200  loss =  161.692\n",
      "testing  :  1155  accuracy =   0.6254  loss =  160.954\n",
      "training :  1156  accuracy =   0.6700  loss =  161.754\n",
      "testing  :  1156  accuracy =   0.6273  loss =  160.989\n",
      "training :  1157  accuracy =   0.5900  loss =  158.542\n",
      "testing  :  1157  accuracy =   0.6259  loss =  161.007\n",
      "training :  1158  accuracy =   0.6000  loss =  160.498\n",
      "testing  :  1158  accuracy =   0.6168  loss =  161.013\n",
      "training :  1159  accuracy =   0.5900  loss =  161.349\n",
      "testing  :  1159  accuracy =   0.5995  loss =  160.995\n",
      "training :  1160  accuracy =   0.5800  loss =  164.233\n",
      "testing  :  1160  accuracy =   0.5907  loss =  160.971\n",
      "training :  1161  accuracy =   0.6800  loss =  159.805\n",
      "testing  :  1161  accuracy =   0.5894  loss =  160.984\n",
      "training :  1162  accuracy =   0.6300  loss =  159.977\n",
      "testing  :  1162  accuracy =   0.5881  loss =  161.022\n",
      "training :  1163  accuracy =   0.6100  loss =  159.862\n",
      "testing  :  1163  accuracy =   0.5878  loss =  161.075\n",
      "training :  1164  accuracy =   0.5500  loss =  159.537\n",
      "testing  :  1164  accuracy =   0.5873  loss =  161.145\n",
      "training :  1165  accuracy =   0.6100  loss =  163.005\n",
      "testing  :  1165  accuracy =   0.5873  loss =  161.185\n",
      "training :  1166  accuracy =   0.5800  loss =  160.605\n",
      "testing  :  1166  accuracy =   0.5867  loss =  161.198\n",
      "training :  1167  accuracy =   0.6800  loss =  161.639\n",
      "testing  :  1167  accuracy =   0.5869  loss =  161.153\n",
      "training :  1168  accuracy =   0.5900  loss =  161.868\n",
      "testing  :  1168  accuracy =   0.5869  loss =  161.122\n",
      "training :  1169  accuracy =   0.5700  loss =  161.636\n",
      "testing  :  1169  accuracy =   0.5879  loss =  161.067\n",
      "training :  1170  accuracy =   0.5700  loss =  162.008\n",
      "testing  :  1170  accuracy =   0.5882  loss =  160.997\n",
      "training :  1171  accuracy =   0.5700  loss =  160.764\n",
      "testing  :  1171  accuracy =   0.5895  loss =  160.879\n",
      "training :  1172  accuracy =   0.5800  loss =  160.166\n",
      "testing  :  1172  accuracy =   0.5899  loss =  160.801\n",
      "training :  1173  accuracy =   0.5500  loss =  159.459\n",
      "testing  :  1173  accuracy =   0.5907  loss =  160.754\n",
      "training :  1174  accuracy =   0.6500  loss =  161.297\n",
      "testing  :  1174  accuracy =   0.5912  loss =  160.743\n",
      "training :  1175  accuracy =   0.6100  loss =  165.404\n",
      "testing  :  1175  accuracy =   0.5916  loss =  160.744\n",
      "training :  1176  accuracy =   0.5800  loss =  161.805\n",
      "testing  :  1176  accuracy =   0.5918  loss =  160.749\n",
      "training :  1177  accuracy =   0.6100  loss =  159.005\n",
      "testing  :  1177  accuracy =   0.5921  loss =  160.761\n",
      "training :  1178  accuracy =   0.6300  loss =  158.5\n",
      "testing  :  1178  accuracy =   0.5915  loss =  160.787\n",
      "training :  1179  accuracy =   0.6200  loss =  158.246\n",
      "testing  :  1179  accuracy =   0.5905  loss =  160.862\n",
      "training :  1180  accuracy =   0.5500  loss =  161.106\n",
      "testing  :  1180  accuracy =   0.5891  loss =  161.008\n",
      "training :  1181  accuracy =   0.5300  loss =  162.724\n",
      "testing  :  1181  accuracy =   0.5885  loss =  161.113\n",
      "training :  1182  accuracy =   0.7000  loss =  158.066\n",
      "testing  :  1182  accuracy =   0.5883  loss =  161.171\n",
      "training :  1183  accuracy =   0.5800  loss =  159.311\n",
      "testing  :  1183  accuracy =   0.5878  loss =  161.208\n",
      "training :  1184  accuracy =   0.5600  loss =  162.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1184  accuracy =   0.5879  loss =  161.133\n",
      "training :  1185  accuracy =   0.6900  loss =  158.836\n",
      "testing  :  1185  accuracy =   0.5887  loss =  161.044\n",
      "training :  1186  accuracy =   0.5300  loss =  164.08\n",
      "testing  :  1186  accuracy =   0.5893  loss =  161.0\n",
      "training :  1187  accuracy =   0.6000  loss =  158.922\n",
      "testing  :  1187  accuracy =   0.5889  loss =  160.929\n",
      "training :  1188  accuracy =   0.5800  loss =  164.68\n",
      "testing  :  1188  accuracy =   0.5891  loss =  160.873\n",
      "training :  1189  accuracy =   0.5700  loss =  162.22\n",
      "testing  :  1189  accuracy =   0.5895  loss =  160.801\n",
      "training :  1190  accuracy =   0.6300  loss =  158.423\n",
      "testing  :  1190  accuracy =   0.5892  loss =  160.775\n",
      "training :  1191  accuracy =   0.6800  loss =  159.232\n",
      "testing  :  1191  accuracy =   0.5890  loss =  160.772\n",
      "training :  1192  accuracy =   0.6400  loss =  162.952\n",
      "testing  :  1192  accuracy =   0.5894  loss =  160.762\n",
      "training :  1193  accuracy =   0.6300  loss =  160.068\n",
      "testing  :  1193  accuracy =   0.5897  loss =  160.704\n",
      "training :  1194  accuracy =   0.6200  loss =  158.963\n",
      "testing  :  1194  accuracy =   0.5896  loss =  160.674\n",
      "training :  1195  accuracy =   0.6500  loss =  159.257\n",
      "testing  :  1195  accuracy =   0.5898  loss =  160.652\n",
      "training :  1196  accuracy =   0.6000  loss =  161.114\n",
      "testing  :  1196  accuracy =   0.5901  loss =  160.642\n",
      "training :  1197  accuracy =   0.5700  loss =  158.459\n",
      "testing  :  1197  accuracy =   0.5899  loss =  160.65\n",
      "training :  1198  accuracy =   0.4500  loss =  162.385\n",
      "testing  :  1198  accuracy =   0.5895  loss =  160.671\n",
      "training :  1199  accuracy =   0.6000  loss =  158.819\n",
      "testing  :  1199  accuracy =   0.5900  loss =  160.691\n",
      "training :  1200  accuracy =   0.6000  loss =  157.78\n",
      "testing  :  1200  accuracy =   0.5901  loss =  160.704\n",
      "training :  1201  accuracy =   0.5300  loss =  160.139\n",
      "testing  :  1201  accuracy =   0.5905  loss =  160.696\n",
      "training :  1202  accuracy =   0.6000  loss =  162.873\n",
      "testing  :  1202  accuracy =   0.5908  loss =  160.706\n",
      "training :  1203  accuracy =   0.6300  loss =  159.1\n",
      "testing  :  1203  accuracy =   0.5907  loss =  160.684\n",
      "training :  1204  accuracy =   0.5700  loss =  161.425\n",
      "testing  :  1204  accuracy =   0.5909  loss =  160.665\n",
      "training :  1205  accuracy =   0.6600  loss =  161.519\n",
      "testing  :  1205  accuracy =   0.5906  loss =  160.656\n",
      "training :  1206  accuracy =   0.5500  loss =  162.0\n",
      "testing  :  1206  accuracy =   0.5903  loss =  160.628\n",
      "training :  1207  accuracy =   0.5500  loss =  160.715\n",
      "testing  :  1207  accuracy =   0.5903  loss =  160.622\n",
      "training :  1208  accuracy =   0.5800  loss =  158.522\n",
      "testing  :  1208  accuracy =   0.5906  loss =  160.633\n",
      "training :  1209  accuracy =   0.4800  loss =  162.54\n",
      "testing  :  1209  accuracy =   0.5903  loss =  160.66\n",
      "training :  1210  accuracy =   0.6500  loss =  160.615\n",
      "testing  :  1210  accuracy =   0.5905  loss =  160.662\n",
      "training :  1211  accuracy =   0.5500  loss =  158.244\n",
      "testing  :  1211  accuracy =   0.5900  loss =  160.647\n",
      "training :  1212  accuracy =   0.6200  loss =  160.236\n",
      "testing  :  1212  accuracy =   0.5901  loss =  160.607\n",
      "training :  1213  accuracy =   0.6100  loss =  161.531\n",
      "testing  :  1213  accuracy =   0.5899  loss =  160.575\n",
      "training :  1214  accuracy =   0.6200  loss =  158.693\n",
      "testing  :  1214  accuracy =   0.5917  loss =  160.552\n",
      "training :  1215  accuracy =   0.5700  loss =  160.636\n",
      "testing  :  1215  accuracy =   0.5918  loss =  160.541\n",
      "training :  1216  accuracy =   0.5300  loss =  160.795\n",
      "testing  :  1216  accuracy =   0.5927  loss =  160.533\n",
      "training :  1217  accuracy =   0.5900  loss =  160.596\n",
      "testing  :  1217  accuracy =   0.5930  loss =  160.524\n",
      "training :  1218  accuracy =   0.4700  loss =  164.669\n",
      "testing  :  1218  accuracy =   0.5924  loss =  160.543\n",
      "training :  1219  accuracy =   0.5400  loss =  160.574\n",
      "testing  :  1219  accuracy =   0.5908  loss =  160.615\n",
      "training :  1220  accuracy =   0.6000  loss =  158.737\n",
      "testing  :  1220  accuracy =   0.5893  loss =  160.666\n",
      "training :  1221  accuracy =   0.5300  loss =  162.801\n",
      "testing  :  1221  accuracy =   0.5873  loss =  160.745\n",
      "training :  1222  accuracy =   0.5600  loss =  160.103\n",
      "testing  :  1222  accuracy =   0.5863  loss =  160.843\n",
      "training :  1223  accuracy =   0.6600  loss =  160.08\n",
      "testing  :  1223  accuracy =   0.5852  loss =  161.036\n",
      "training :  1224  accuracy =   0.7100  loss =  158.614\n",
      "testing  :  1224  accuracy =   0.5823  loss =  161.223\n",
      "training :  1225  accuracy =   0.6000  loss =  159.08\n",
      "testing  :  1225  accuracy =   0.5783  loss =  161.44\n",
      "training :  1226  accuracy =   0.5800  loss =  161.352\n",
      "testing  :  1226  accuracy =   0.5778  loss =  161.523\n",
      "training :  1227  accuracy =   0.5900  loss =  159.223\n",
      "testing  :  1227  accuracy =   0.5788  loss =  161.405\n",
      "training :  1228  accuracy =   0.5700  loss =  159.728\n",
      "testing  :  1228  accuracy =   0.5799  loss =  161.268\n",
      "training :  1229  accuracy =   0.6200  loss =  159.951\n",
      "testing  :  1229  accuracy =   0.5801  loss =  161.187\n",
      "training :  1230  accuracy =   0.5000  loss =  160.534\n",
      "testing  :  1230  accuracy =   0.5838  loss =  160.973\n",
      "training :  1231  accuracy =   0.5700  loss =  158.967\n",
      "testing  :  1231  accuracy =   0.5884  loss =  160.747\n",
      "training :  1232  accuracy =   0.5800  loss =  162.612\n",
      "testing  :  1232  accuracy =   0.5913  loss =  160.589\n",
      "training :  1233  accuracy =   0.7000  loss =  158.007\n",
      "testing  :  1233  accuracy =   0.5945  loss =  160.555\n",
      "training :  1234  accuracy =   0.5500  loss =  162.287\n",
      "testing  :  1234  accuracy =   0.5939  loss =  160.587\n",
      "training :  1235  accuracy =   0.5600  loss =  161.452\n",
      "testing  :  1235  accuracy =   0.5928  loss =  160.653\n",
      "training :  1236  accuracy =   0.5500  loss =  160.677\n",
      "testing  :  1236  accuracy =   0.5925  loss =  160.712\n",
      "training :  1237  accuracy =   0.6100  loss =  159.137\n",
      "testing  :  1237  accuracy =   0.5923  loss =  160.757\n",
      "training :  1238  accuracy =   0.5600  loss =  161.678\n",
      "testing  :  1238  accuracy =   0.5922  loss =  160.814\n",
      "training :  1239  accuracy =   0.6200  loss =  160.396\n",
      "testing  :  1239  accuracy =   0.5930  loss =  160.85\n",
      "training :  1240  accuracy =   0.6000  loss =  157.787\n",
      "testing  :  1240  accuracy =   0.5932  loss =  160.865\n",
      "training :  1241  accuracy =   0.6300  loss =  159.58\n",
      "testing  :  1241  accuracy =   0.5929  loss =  160.851\n",
      "training :  1242  accuracy =   0.7100  loss =  157.126\n",
      "testing  :  1242  accuracy =   0.5931  loss =  160.823\n",
      "training :  1243  accuracy =   0.6100  loss =  160.421\n",
      "testing  :  1243  accuracy =   0.5928  loss =  160.797\n",
      "training :  1244  accuracy =   0.6800  loss =  160.015\n",
      "testing  :  1244  accuracy =   0.5927  loss =  160.704\n",
      "training :  1245  accuracy =   0.5700  loss =  159.655\n",
      "testing  :  1245  accuracy =   0.5910  loss =  160.644\n",
      "training :  1246  accuracy =   0.6200  loss =  164.12\n",
      "testing  :  1246  accuracy =   0.5910  loss =  160.638\n",
      "training :  1247  accuracy =   0.6000  loss =  159.612\n",
      "testing  :  1247  accuracy =   0.5902  loss =  160.655\n",
      "training :  1248  accuracy =   0.6400  loss =  160.753\n",
      "testing  :  1248  accuracy =   0.5884  loss =  160.751\n",
      "training :  1249  accuracy =   0.6300  loss =  161.301\n",
      "testing  :  1249  accuracy =   0.5857  loss =  160.904\n",
      "training :  1250  accuracy =   0.6800  loss =  159.4\n",
      "testing  :  1250  accuracy =   0.5846  loss =  160.964\n",
      "training :  1251  accuracy =   0.5900  loss =  162.816\n",
      "testing  :  1251  accuracy =   0.5843  loss =  160.93\n",
      "training :  1252  accuracy =   0.6000  loss =  161.926\n",
      "testing  :  1252  accuracy =   0.5850  loss =  160.906\n",
      "training :  1253  accuracy =   0.6200  loss =  161.286\n",
      "testing  :  1253  accuracy =   0.5860  loss =  160.846\n",
      "training :  1254  accuracy =   0.5400  loss =  163.982\n",
      "testing  :  1254  accuracy =   0.5857  loss =  160.878\n",
      "training :  1255  accuracy =   0.5700  loss =  163.061\n",
      "testing  :  1255  accuracy =   0.5865  loss =  160.882\n",
      "training :  1256  accuracy =   0.6200  loss =  159.526\n",
      "testing  :  1256  accuracy =   0.5877  loss =  160.811\n",
      "training :  1257  accuracy =   0.6800  loss =  159.077\n",
      "testing  :  1257  accuracy =   0.5891  loss =  160.74\n",
      "training :  1258  accuracy =   0.6000  loss =  159.881\n",
      "testing  :  1258  accuracy =   0.5899  loss =  160.659\n",
      "training :  1259  accuracy =   0.6500  loss =  159.541\n",
      "testing  :  1259  accuracy =   0.5907  loss =  160.637\n",
      "training :  1260  accuracy =   0.4700  loss =  164.303\n",
      "testing  :  1260  accuracy =   0.5925  loss =  160.73\n",
      "training :  1261  accuracy =   0.5200  loss =  160.918\n",
      "testing  :  1261  accuracy =   0.5932  loss =  160.921\n",
      "training :  1262  accuracy =   0.6500  loss =  160.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1262  accuracy =   0.5936  loss =  161.194\n",
      "training :  1263  accuracy =   0.6200  loss =  159.489\n",
      "testing  :  1263  accuracy =   0.5926  loss =  161.405\n",
      "training :  1264  accuracy =   0.5300  loss =  161.769\n",
      "testing  :  1264  accuracy =   0.5915  loss =  161.491\n",
      "training :  1265  accuracy =   0.5600  loss =  160.061\n",
      "testing  :  1265  accuracy =   0.5912  loss =  161.518\n",
      "training :  1266  accuracy =   0.6000  loss =  159.942\n",
      "testing  :  1266  accuracy =   0.5912  loss =  161.505\n",
      "training :  1267  accuracy =   0.6300  loss =  160.886\n",
      "testing  :  1267  accuracy =   0.5917  loss =  161.411\n",
      "training :  1268  accuracy =   0.5900  loss =  160.696\n",
      "testing  :  1268  accuracy =   0.5910  loss =  161.296\n",
      "training :  1269  accuracy =   0.5800  loss =  161.407\n",
      "testing  :  1269  accuracy =   0.5907  loss =  161.19\n",
      "training :  1270  accuracy =   0.5700  loss =  161.302\n",
      "testing  :  1270  accuracy =   0.5928  loss =  161.107\n",
      "training :  1271  accuracy =   0.6500  loss =  160.404\n",
      "testing  :  1271  accuracy =   0.5996  loss =  161.019\n",
      "training :  1272  accuracy =   0.7200  loss =  158.998\n",
      "testing  :  1272  accuracy =   0.6124  loss =  160.927\n",
      "training :  1273  accuracy =   0.6400  loss =  159.599\n",
      "testing  :  1273  accuracy =   0.6135  loss =  160.783\n",
      "training :  1274  accuracy =   0.5900  loss =  159.41\n",
      "testing  :  1274  accuracy =   0.6081  loss =  160.637\n",
      "training :  1275  accuracy =   0.5600  loss =  161.431\n",
      "testing  :  1275  accuracy =   0.5994  loss =  160.561\n",
      "training :  1276  accuracy =   0.6100  loss =  158.695\n",
      "testing  :  1276  accuracy =   0.5952  loss =  160.552\n",
      "training :  1277  accuracy =   0.5800  loss =  160.775\n",
      "testing  :  1277  accuracy =   0.5917  loss =  160.63\n",
      "training :  1278  accuracy =   0.6100  loss =  160.775\n",
      "testing  :  1278  accuracy =   0.5891  loss =  160.747\n",
      "training :  1279  accuracy =   0.5700  loss =  160.606\n",
      "testing  :  1279  accuracy =   0.5883  loss =  160.806\n",
      "training :  1280  accuracy =   0.5600  loss =  160.848\n",
      "testing  :  1280  accuracy =   0.5888  loss =  160.827\n",
      "training :  1281  accuracy =   0.6000  loss =  160.857\n",
      "testing  :  1281  accuracy =   0.5884  loss =  160.855\n",
      "training :  1282  accuracy =   0.6300  loss =  159.44\n",
      "testing  :  1282  accuracy =   0.5888  loss =  160.828\n",
      "training :  1283  accuracy =   0.5400  loss =  161.146\n",
      "testing  :  1283  accuracy =   0.5881  loss =  160.856\n",
      "training :  1284  accuracy =   0.6500  loss =  161.047\n",
      "testing  :  1284  accuracy =   0.5880  loss =  160.879\n",
      "training :  1285  accuracy =   0.6400  loss =  161.516\n",
      "testing  :  1285  accuracy =   0.5887  loss =  160.859\n",
      "training :  1286  accuracy =   0.5300  loss =  161.667\n",
      "testing  :  1286  accuracy =   0.5896  loss =  160.831\n",
      "training :  1287  accuracy =   0.7000  loss =  157.974\n",
      "testing  :  1287  accuracy =   0.5899  loss =  160.812\n",
      "training :  1288  accuracy =   0.6400  loss =  158.985\n",
      "testing  :  1288  accuracy =   0.5902  loss =  160.744\n",
      "training :  1289  accuracy =   0.5400  loss =  161.033\n",
      "testing  :  1289  accuracy =   0.5906  loss =  160.742\n",
      "training :  1290  accuracy =   0.5900  loss =  158.738\n",
      "testing  :  1290  accuracy =   0.5905  loss =  160.752\n",
      "training :  1291  accuracy =   0.6100  loss =  159.353\n",
      "testing  :  1291  accuracy =   0.5904  loss =  160.789\n",
      "training :  1292  accuracy =   0.5900  loss =  159.322\n",
      "testing  :  1292  accuracy =   0.5895  loss =  160.822\n",
      "training :  1293  accuracy =   0.6400  loss =  159.199\n",
      "testing  :  1293  accuracy =   0.5897  loss =  160.848\n",
      "training :  1294  accuracy =   0.5800  loss =  160.04\n",
      "testing  :  1294  accuracy =   0.5896  loss =  160.866\n",
      "training :  1295  accuracy =   0.5500  loss =  160.61\n",
      "testing  :  1295  accuracy =   0.5883  loss =  160.896\n",
      "training :  1296  accuracy =   0.5800  loss =  163.344\n",
      "testing  :  1296  accuracy =   0.5877  loss =  160.923\n",
      "training :  1297  accuracy =   0.6400  loss =  160.487\n",
      "testing  :  1297  accuracy =   0.5896  loss =  160.838\n",
      "training :  1298  accuracy =   0.5500  loss =  162.2\n",
      "testing  :  1298  accuracy =   0.5904  loss =  160.78\n",
      "training :  1299  accuracy =   0.5400  loss =  163.336\n",
      "testing  :  1299  accuracy =   0.5914  loss =  160.715\n",
      "training :  1300  accuracy =   0.6300  loss =  161.76\n",
      "testing  :  1300  accuracy =   0.5929  loss =  160.676\n",
      "training :  1301  accuracy =   0.5900  loss =  161.616\n",
      "testing  :  1301  accuracy =   0.5920  loss =  160.665\n",
      "training :  1302  accuracy =   0.6400  loss =  162.104\n",
      "testing  :  1302  accuracy =   0.5925  loss =  160.659\n",
      "training :  1303  accuracy =   0.5600  loss =  160.281\n",
      "testing  :  1303  accuracy =   0.5929  loss =  160.676\n",
      "training :  1304  accuracy =   0.5500  loss =  164.373\n",
      "testing  :  1304  accuracy =   0.5919  loss =  160.716\n",
      "training :  1305  accuracy =   0.6000  loss =  162.308\n",
      "testing  :  1305  accuracy =   0.5916  loss =  160.769\n",
      "training :  1306  accuracy =   0.5600  loss =  164.184\n",
      "testing  :  1306  accuracy =   0.5916  loss =  160.814\n",
      "training :  1307  accuracy =   0.7000  loss =  157.905\n",
      "testing  :  1307  accuracy =   0.5910  loss =  160.929\n",
      "training :  1308  accuracy =   0.5700  loss =  161.136\n",
      "testing  :  1308  accuracy =   0.5890  loss =  161.015\n",
      "training :  1309  accuracy =   0.5400  loss =  159.209\n",
      "testing  :  1309  accuracy =   0.5883  loss =  161.11\n",
      "training :  1310  accuracy =   0.5300  loss =  162.691\n",
      "testing  :  1310  accuracy =   0.5870  loss =  161.198\n",
      "training :  1311  accuracy =   0.6100  loss =  158.465\n",
      "testing  :  1311  accuracy =   0.5876  loss =  161.223\n",
      "training :  1312  accuracy =   0.6100  loss =  160.031\n",
      "testing  :  1312  accuracy =   0.5880  loss =  161.207\n",
      "training :  1313  accuracy =   0.6000  loss =  159.844\n",
      "testing  :  1313  accuracy =   0.5882  loss =  161.074\n",
      "training :  1314  accuracy =   0.6300  loss =  160.618\n",
      "testing  :  1314  accuracy =   0.5894  loss =  160.913\n",
      "training :  1315  accuracy =   0.6300  loss =  159.197\n",
      "testing  :  1315  accuracy =   0.5890  loss =  160.752\n",
      "training :  1316  accuracy =   0.5900  loss =  160.188\n",
      "testing  :  1316  accuracy =   0.5880  loss =  160.762\n",
      "training :  1317  accuracy =   0.5400  loss =  159.459\n",
      "testing  :  1317  accuracy =   0.5841  loss =  161.013\n",
      "training :  1318  accuracy =   0.5400  loss =  164.836\n",
      "testing  :  1318  accuracy =   0.5780  loss =  161.408\n",
      "training :  1319  accuracy =   0.6000  loss =  161.342\n",
      "testing  :  1319  accuracy =   0.5747  loss =  161.711\n",
      "training :  1320  accuracy =   0.5600  loss =  159.711\n",
      "testing  :  1320  accuracy =   0.5749  loss =  161.701\n",
      "training :  1321  accuracy =   0.5500  loss =  160.981\n",
      "testing  :  1321  accuracy =   0.5751  loss =  161.697\n",
      "training :  1322  accuracy =   0.6000  loss =  164.55\n",
      "testing  :  1322  accuracy =   0.5780  loss =  161.593\n",
      "training :  1323  accuracy =   0.5700  loss =  162.241\n",
      "testing  :  1323  accuracy =   0.5818  loss =  161.209\n",
      "training :  1324  accuracy =   0.5200  loss =  160.293\n",
      "testing  :  1324  accuracy =   0.5855  loss =  160.863\n",
      "training :  1325  accuracy =   0.6100  loss =  158.602\n",
      "testing  :  1325  accuracy =   0.5868  loss =  160.667\n",
      "training :  1326  accuracy =   0.6300  loss =  157.894\n",
      "testing  :  1326  accuracy =   0.5858  loss =  160.638\n",
      "training :  1327  accuracy =   0.5700  loss =  159.912\n",
      "testing  :  1327  accuracy =   0.5850  loss =  160.722\n",
      "training :  1328  accuracy =   0.5200  loss =  161.537\n",
      "testing  :  1328  accuracy =   0.5835  loss =  160.846\n",
      "training :  1329  accuracy =   0.6000  loss =  162.237\n",
      "testing  :  1329  accuracy =   0.5823  loss =  160.992\n",
      "training :  1330  accuracy =   0.5700  loss =  162.083\n",
      "testing  :  1330  accuracy =   0.5821  loss =  161.133\n",
      "training :  1331  accuracy =   0.6200  loss =  159.01\n",
      "testing  :  1331  accuracy =   0.5815  loss =  161.195\n",
      "training :  1332  accuracy =   0.5700  loss =  158.482\n",
      "testing  :  1332  accuracy =   0.5812  loss =  161.229\n",
      "training :  1333  accuracy =   0.5800  loss =  161.614\n",
      "testing  :  1333  accuracy =   0.5817  loss =  161.172\n",
      "training :  1334  accuracy =   0.6500  loss =  159.296\n",
      "testing  :  1334  accuracy =   0.5819  loss =  161.098\n",
      "training :  1335  accuracy =   0.6500  loss =  159.619\n",
      "testing  :  1335  accuracy =   0.5822  loss =  161.076\n",
      "training :  1336  accuracy =   0.5900  loss =  159.411\n",
      "testing  :  1336  accuracy =   0.5830  loss =  161.077\n",
      "training :  1337  accuracy =   0.6800  loss =  160.131\n",
      "testing  :  1337  accuracy =   0.5829  loss =  161.079\n",
      "training :  1338  accuracy =   0.5300  loss =  165.052\n",
      "testing  :  1338  accuracy =   0.5846  loss =  160.97\n",
      "training :  1339  accuracy =   0.5100  loss =  163.155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1339  accuracy =   0.5875  loss =  160.839\n",
      "training :  1340  accuracy =   0.7000  loss =  158.446\n",
      "testing  :  1340  accuracy =   0.5895  loss =  160.719\n",
      "training :  1341  accuracy =   0.6400  loss =  159.837\n",
      "testing  :  1341  accuracy =   0.5904  loss =  160.637\n",
      "training :  1342  accuracy =   0.5500  loss =  159.592\n",
      "testing  :  1342  accuracy =   0.5903  loss =  160.587\n",
      "training :  1343  accuracy =   0.7100  loss =  157.636\n",
      "testing  :  1343  accuracy =   0.5903  loss =  160.572\n",
      "training :  1344  accuracy =   0.5800  loss =  158.354\n",
      "testing  :  1344  accuracy =   0.5910  loss =  160.579\n",
      "training :  1345  accuracy =   0.6400  loss =  159.308\n",
      "testing  :  1345  accuracy =   0.5922  loss =  160.59\n",
      "training :  1346  accuracy =   0.5800  loss =  159.531\n",
      "testing  :  1346  accuracy =   0.6068  loss =  160.647\n",
      "training :  1347  accuracy =   0.6500  loss =  162.37\n",
      "testing  :  1347  accuracy =   0.6436  loss =  160.622\n",
      "training :  1348  accuracy =   0.6700  loss =  159.457\n",
      "testing  :  1348  accuracy =   0.6609  loss =  160.597\n",
      "training :  1349  accuracy =   0.7100  loss =  158.147\n",
      "testing  :  1349  accuracy =   0.6644  loss =  160.533\n",
      "training :  1350  accuracy =   0.6800  loss =  157.593\n",
      "testing  :  1350  accuracy =   0.6463  loss =  160.493\n",
      "training :  1351  accuracy =   0.6300  loss =  159.461\n",
      "testing  :  1351  accuracy =   0.6346  loss =  160.464\n",
      "training :  1352  accuracy =   0.6000  loss =  162.502\n",
      "testing  :  1352  accuracy =   0.6314  loss =  160.435\n",
      "training :  1353  accuracy =   0.6400  loss =  161.289\n",
      "testing  :  1353  accuracy =   0.6373  loss =  160.422\n",
      "training :  1354  accuracy =   0.7000  loss =  156.586\n",
      "testing  :  1354  accuracy =   0.6429  loss =  160.438\n",
      "training :  1355  accuracy =   0.7200  loss =  165.018\n",
      "testing  :  1355  accuracy =   0.6579  loss =  160.472\n",
      "training :  1356  accuracy =   0.7000  loss =  163.111\n",
      "testing  :  1356  accuracy =   0.6611  loss =  160.483\n",
      "training :  1357  accuracy =   0.6900  loss =  160.203\n",
      "testing  :  1357  accuracy =   0.6529  loss =  160.475\n",
      "training :  1358  accuracy =   0.6500  loss =  159.85\n",
      "testing  :  1358  accuracy =   0.6319  loss =  160.477\n",
      "training :  1359  accuracy =   0.6300  loss =  159.771\n",
      "testing  :  1359  accuracy =   0.6094  loss =  160.487\n",
      "training :  1360  accuracy =   0.6000  loss =  159.495\n",
      "testing  :  1360  accuracy =   0.5932  loss =  160.504\n",
      "training :  1361  accuracy =   0.6000  loss =  162.051\n",
      "testing  :  1361  accuracy =   0.5905  loss =  160.541\n",
      "training :  1362  accuracy =   0.5200  loss =  160.273\n",
      "testing  :  1362  accuracy =   0.5903  loss =  160.593\n",
      "training :  1363  accuracy =   0.5600  loss =  161.675\n",
      "testing  :  1363  accuracy =   0.5916  loss =  160.621\n",
      "training :  1364  accuracy =   0.5500  loss =  160.907\n",
      "testing  :  1364  accuracy =   0.5903  loss =  160.616\n",
      "training :  1365  accuracy =   0.6100  loss =  158.816\n",
      "testing  :  1365  accuracy =   0.5906  loss =  160.594\n",
      "training :  1366  accuracy =   0.6200  loss =  164.671\n",
      "testing  :  1366  accuracy =   0.5899  loss =  160.595\n",
      "training :  1367  accuracy =   0.5600  loss =  160.235\n",
      "testing  :  1367  accuracy =   0.5905  loss =  160.614\n",
      "training :  1368  accuracy =   0.7100  loss =  158.623\n",
      "testing  :  1368  accuracy =   0.5901  loss =  160.653\n",
      "training :  1369  accuracy =   0.5600  loss =  162.729\n",
      "testing  :  1369  accuracy =   0.5897  loss =  160.681\n",
      "training :  1370  accuracy =   0.6200  loss =  161.221\n",
      "testing  :  1370  accuracy =   0.5903  loss =  160.731\n",
      "training :  1371  accuracy =   0.5600  loss =  163.923\n",
      "testing  :  1371  accuracy =   0.5899  loss =  160.74\n",
      "training :  1372  accuracy =   0.6800  loss =  156.912\n",
      "testing  :  1372  accuracy =   0.5896  loss =  160.724\n",
      "training :  1373  accuracy =   0.5100  loss =  163.46\n",
      "testing  :  1373  accuracy =   0.5898  loss =  160.71\n",
      "training :  1374  accuracy =   0.6600  loss =  159.52\n",
      "testing  :  1374  accuracy =   0.5894  loss =  160.677\n",
      "training :  1375  accuracy =   0.5900  loss =  160.768\n",
      "testing  :  1375  accuracy =   0.5895  loss =  160.67\n",
      "training :  1376  accuracy =   0.5800  loss =  162.921\n",
      "testing  :  1376  accuracy =   0.5885  loss =  160.733\n",
      "training :  1377  accuracy =   0.6100  loss =  161.617\n",
      "testing  :  1377  accuracy =   0.5858  loss =  160.874\n",
      "training :  1378  accuracy =   0.5300  loss =  160.292\n",
      "testing  :  1378  accuracy =   0.5858  loss =  160.963\n",
      "training :  1379  accuracy =   0.6100  loss =  162.063\n",
      "testing  :  1379  accuracy =   0.5835  loss =  161.055\n",
      "training :  1380  accuracy =   0.5800  loss =  160.355\n",
      "testing  :  1380  accuracy =   0.5845  loss =  161.027\n",
      "training :  1381  accuracy =   0.6000  loss =  161.28\n",
      "testing  :  1381  accuracy =   0.5853  loss =  160.927\n",
      "training :  1382  accuracy =   0.5700  loss =  159.497\n",
      "testing  :  1382  accuracy =   0.5877  loss =  160.755\n",
      "training :  1383  accuracy =   0.5700  loss =  158.476\n",
      "testing  :  1383  accuracy =   0.5916  loss =  160.504\n",
      "training :  1384  accuracy =   0.6500  loss =  156.267\n",
      "testing  :  1384  accuracy =   0.5937  loss =  160.358\n",
      "training :  1385  accuracy =   0.5300  loss =  161.246\n",
      "testing  :  1385  accuracy =   0.5995  loss =  160.298\n",
      "training :  1386  accuracy =   0.5800  loss =  159.687\n",
      "testing  :  1386  accuracy =   0.6073  loss =  160.268\n",
      "training :  1387  accuracy =   0.6300  loss =  159.059\n",
      "testing  :  1387  accuracy =   0.6190  loss =  160.255\n",
      "training :  1388  accuracy =   0.6200  loss =  161.318\n",
      "testing  :  1388  accuracy =   0.6218  loss =  160.249\n",
      "training :  1389  accuracy =   0.6000  loss =  160.935\n",
      "testing  :  1389  accuracy =   0.6097  loss =  160.255\n",
      "training :  1390  accuracy =   0.5200  loss =  159.448\n",
      "testing  :  1390  accuracy =   0.5910  loss =  160.275\n",
      "training :  1391  accuracy =   0.5500  loss =  162.265\n",
      "testing  :  1391  accuracy =   0.5846  loss =  160.298\n",
      "training :  1392  accuracy =   0.5600  loss =  161.139\n",
      "testing  :  1392  accuracy =   0.5830  loss =  160.331\n",
      "training :  1393  accuracy =   0.6300  loss =  160.506\n",
      "testing  :  1393  accuracy =   0.5824  loss =  160.366\n",
      "training :  1394  accuracy =   0.5000  loss =  160.379\n",
      "testing  :  1394  accuracy =   0.5818  loss =  160.391\n",
      "training :  1395  accuracy =   0.6200  loss =  159.069\n",
      "testing  :  1395  accuracy =   0.5809  loss =  160.42\n",
      "training :  1396  accuracy =   0.6900  loss =  156.678\n",
      "testing  :  1396  accuracy =   0.5813  loss =  160.414\n",
      "training :  1397  accuracy =   0.6600  loss =  157.359\n",
      "testing  :  1397  accuracy =   0.5815  loss =  160.412\n",
      "training :  1398  accuracy =   0.6300  loss =  160.203\n",
      "testing  :  1398  accuracy =   0.5818  loss =  160.367\n",
      "training :  1399  accuracy =   0.6700  loss =  159.253\n",
      "testing  :  1399  accuracy =   0.5818  loss =  160.322\n",
      "training :  1400  accuracy =   0.5800  loss =  159.454\n",
      "testing  :  1400  accuracy =   0.5823  loss =  160.284\n",
      "training :  1401  accuracy =   0.6000  loss =  160.948\n",
      "testing  :  1401  accuracy =   0.5824  loss =  160.269\n",
      "training :  1402  accuracy =   0.5300  loss =  159.823\n",
      "testing  :  1402  accuracy =   0.5829  loss =  160.264\n",
      "training :  1403  accuracy =   0.6000  loss =  158.168\n",
      "testing  :  1403  accuracy =   0.5831  loss =  160.26\n",
      "training :  1404  accuracy =   0.6600  loss =  157.851\n",
      "testing  :  1404  accuracy =   0.5829  loss =  160.269\n",
      "training :  1405  accuracy =   0.5500  loss =  158.961\n",
      "testing  :  1405  accuracy =   0.5828  loss =  160.289\n",
      "training :  1406  accuracy =   0.5400  loss =  158.601\n",
      "testing  :  1406  accuracy =   0.5828  loss =  160.297\n",
      "training :  1407  accuracy =   0.5300  loss =  160.321\n",
      "testing  :  1407  accuracy =   0.5827  loss =  160.317\n",
      "training :  1408  accuracy =   0.7200  loss =  157.885\n",
      "testing  :  1408  accuracy =   0.5829  loss =  160.338\n",
      "training :  1409  accuracy =   0.6000  loss =  159.013\n",
      "testing  :  1409  accuracy =   0.5828  loss =  160.353\n",
      "training :  1410  accuracy =   0.5500  loss =  158.432\n",
      "testing  :  1410  accuracy =   0.5827  loss =  160.358\n",
      "training :  1411  accuracy =   0.6000  loss =  159.094\n",
      "testing  :  1411  accuracy =   0.5833  loss =  160.359\n",
      "training :  1412  accuracy =   0.5200  loss =  161.608\n",
      "testing  :  1412  accuracy =   0.5833  loss =  160.359\n",
      "training :  1413  accuracy =   0.5100  loss =  160.705\n",
      "testing  :  1413  accuracy =   0.5840  loss =  160.386\n",
      "training :  1414  accuracy =   0.6500  loss =  158.869\n",
      "testing  :  1414  accuracy =   0.5843  loss =  160.416\n",
      "training :  1415  accuracy =   0.6400  loss =  161.816\n",
      "testing  :  1415  accuracy =   0.5843  loss =  160.496\n",
      "training :  1416  accuracy =   0.5300  loss =  157.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1416  accuracy =   0.5838  loss =  160.58\n",
      "training :  1417  accuracy =   0.5600  loss =  158.786\n",
      "testing  :  1417  accuracy =   0.5842  loss =  160.657\n",
      "training :  1418  accuracy =   0.6200  loss =  159.7\n",
      "testing  :  1418  accuracy =   0.5829  loss =  160.764\n",
      "training :  1419  accuracy =   0.5800  loss =  159.22\n",
      "testing  :  1419  accuracy =   0.5828  loss =  160.885\n",
      "training :  1420  accuracy =   0.5700  loss =  158.062\n",
      "testing  :  1420  accuracy =   0.5827  loss =  160.964\n",
      "training :  1421  accuracy =   0.6100  loss =  159.492\n",
      "testing  :  1421  accuracy =   0.5827  loss =  161.005\n",
      "training :  1422  accuracy =   0.6600  loss =  159.782\n",
      "testing  :  1422  accuracy =   0.5826  loss =  160.975\n",
      "training :  1423  accuracy =   0.5600  loss =  159.952\n",
      "testing  :  1423  accuracy =   0.5840  loss =  160.992\n",
      "training :  1424  accuracy =   0.6200  loss =  157.144\n",
      "testing  :  1424  accuracy =   0.5848  loss =  161.058\n",
      "training :  1425  accuracy =   0.6200  loss =  158.107\n",
      "testing  :  1425  accuracy =   0.5856  loss =  161.133\n",
      "training :  1426  accuracy =   0.6500  loss =  160.666\n",
      "testing  :  1426  accuracy =   0.5860  loss =  161.062\n",
      "training :  1427  accuracy =   0.6400  loss =  162.798\n",
      "testing  :  1427  accuracy =   0.5858  loss =  160.772\n",
      "training :  1428  accuracy =   0.4500  loss =  160.726\n",
      "testing  :  1428  accuracy =   0.5872  loss =  160.528\n",
      "training :  1429  accuracy =   0.6100  loss =  162.232\n",
      "testing  :  1429  accuracy =   0.5867  loss =  160.406\n",
      "training :  1430  accuracy =   0.5700  loss =  161.789\n",
      "testing  :  1430  accuracy =   0.5859  loss =  160.336\n",
      "training :  1431  accuracy =   0.5500  loss =  161.062\n",
      "testing  :  1431  accuracy =   0.5855  loss =  160.353\n",
      "training :  1432  accuracy =   0.5600  loss =  160.679\n",
      "testing  :  1432  accuracy =   0.5850  loss =  160.339\n",
      "training :  1433  accuracy =   0.6300  loss =  161.658\n",
      "testing  :  1433  accuracy =   0.5836  loss =  160.355\n",
      "training :  1434  accuracy =   0.5800  loss =  162.305\n",
      "testing  :  1434  accuracy =   0.5826  loss =  160.391\n",
      "training :  1435  accuracy =   0.5800  loss =  161.267\n",
      "testing  :  1435  accuracy =   0.5825  loss =  160.44\n",
      "training :  1436  accuracy =   0.5600  loss =  160.38\n",
      "testing  :  1436  accuracy =   0.5828  loss =  160.421\n",
      "training :  1437  accuracy =   0.6000  loss =  162.35\n",
      "testing  :  1437  accuracy =   0.5833  loss =  160.408\n",
      "training :  1438  accuracy =   0.5400  loss =  162.9\n",
      "testing  :  1438  accuracy =   0.5838  loss =  160.412\n",
      "training :  1439  accuracy =   0.6200  loss =  159.789\n",
      "testing  :  1439  accuracy =   0.5840  loss =  160.384\n",
      "training :  1440  accuracy =   0.4700  loss =  160.842\n",
      "testing  :  1440  accuracy =   0.5832  loss =  160.36\n",
      "training :  1441  accuracy =   0.6300  loss =  158.963\n",
      "testing  :  1441  accuracy =   0.5834  loss =  160.349\n",
      "training :  1442  accuracy =   0.6000  loss =  158.435\n",
      "testing  :  1442  accuracy =   0.5836  loss =  160.375\n",
      "training :  1443  accuracy =   0.5800  loss =  157.158\n",
      "testing  :  1443  accuracy =   0.5843  loss =  160.383\n",
      "training :  1444  accuracy =   0.6200  loss =  158.775\n",
      "testing  :  1444  accuracy =   0.5858  loss =  160.414\n",
      "training :  1445  accuracy =   0.5200  loss =  163.435\n",
      "testing  :  1445  accuracy =   0.5861  loss =  160.453\n",
      "training :  1446  accuracy =   0.6300  loss =  158.239\n",
      "testing  :  1446  accuracy =   0.5871  loss =  160.506\n",
      "training :  1447  accuracy =   0.6700  loss =  158.386\n",
      "testing  :  1447  accuracy =   0.5877  loss =  160.585\n",
      "training :  1448  accuracy =   0.6500  loss =  158.522\n",
      "testing  :  1448  accuracy =   0.5894  loss =  160.67\n",
      "training :  1449  accuracy =   0.5600  loss =  159.28\n",
      "testing  :  1449  accuracy =   0.5916  loss =  160.707\n",
      "training :  1450  accuracy =   0.5700  loss =  161.021\n",
      "testing  :  1450  accuracy =   0.5935  loss =  160.714\n",
      "training :  1451  accuracy =   0.5600  loss =  159.92\n",
      "testing  :  1451  accuracy =   0.5960  loss =  160.699\n",
      "training :  1452  accuracy =   0.6900  loss =  157.528\n",
      "testing  :  1452  accuracy =   0.5997  loss =  160.659\n",
      "training :  1453  accuracy =   0.6200  loss =  159.496\n",
      "testing  :  1453  accuracy =   0.6023  loss =  160.623\n",
      "training :  1454  accuracy =   0.6600  loss =  161.462\n",
      "testing  :  1454  accuracy =   0.6083  loss =  160.598\n",
      "training :  1455  accuracy =   0.6400  loss =  160.787\n",
      "testing  :  1455  accuracy =   0.6148  loss =  160.629\n",
      "training :  1456  accuracy =   0.6500  loss =  158.76\n",
      "testing  :  1456  accuracy =   0.6025  loss =  160.638\n",
      "training :  1457  accuracy =   0.5900  loss =  160.449\n",
      "testing  :  1457  accuracy =   0.5892  loss =  160.656\n",
      "training :  1458  accuracy =   0.6000  loss =  161.258\n",
      "testing  :  1458  accuracy =   0.5888  loss =  160.65\n",
      "training :  1459  accuracy =   0.5000  loss =  162.061\n",
      "testing  :  1459  accuracy =   0.5877  loss =  160.576\n",
      "training :  1460  accuracy =   0.6400  loss =  158.963\n",
      "testing  :  1460  accuracy =   0.5877  loss =  160.493\n",
      "training :  1461  accuracy =   0.5800  loss =  162.967\n",
      "testing  :  1461  accuracy =   0.5883  loss =  160.427\n",
      "training :  1462  accuracy =   0.6200  loss =  163.376\n",
      "testing  :  1462  accuracy =   0.5884  loss =  160.387\n",
      "training :  1463  accuracy =   0.6200  loss =  160.148\n",
      "testing  :  1463  accuracy =   0.5882  loss =  160.336\n",
      "training :  1464  accuracy =   0.6000  loss =  159.894\n",
      "testing  :  1464  accuracy =   0.5881  loss =  160.303\n",
      "training :  1465  accuracy =   0.6500  loss =  157.495\n",
      "testing  :  1465  accuracy =   0.5878  loss =  160.28\n",
      "training :  1466  accuracy =   0.5900  loss =  157.787\n",
      "testing  :  1466  accuracy =   0.5876  loss =  160.267\n",
      "training :  1467  accuracy =   0.6200  loss =  159.323\n",
      "testing  :  1467  accuracy =   0.5881  loss =  160.237\n",
      "training :  1468  accuracy =   0.5100  loss =  159.422\n",
      "testing  :  1468  accuracy =   0.5883  loss =  160.2\n",
      "training :  1469  accuracy =   0.6700  loss =  159.964\n",
      "testing  :  1469  accuracy =   0.5884  loss =  160.181\n",
      "training :  1470  accuracy =   0.6700  loss =  160.311\n",
      "testing  :  1470  accuracy =   0.5883  loss =  160.159\n",
      "training :  1471  accuracy =   0.6800  loss =  156.79\n",
      "testing  :  1471  accuracy =   0.5884  loss =  160.137\n",
      "training :  1472  accuracy =   0.5300  loss =  159.732\n",
      "testing  :  1472  accuracy =   0.5888  loss =  160.109\n",
      "training :  1473  accuracy =   0.5700  loss =  160.052\n",
      "testing  :  1473  accuracy =   0.5889  loss =  160.098\n",
      "training :  1474  accuracy =   0.6500  loss =  160.724\n",
      "testing  :  1474  accuracy =   0.5892  loss =  160.087\n",
      "training :  1475  accuracy =   0.5500  loss =  161.324\n",
      "testing  :  1475  accuracy =   0.5895  loss =  160.088\n",
      "training :  1476  accuracy =   0.6300  loss =  158.444\n",
      "testing  :  1476  accuracy =   0.5898  loss =  160.09\n",
      "training :  1477  accuracy =   0.6300  loss =  156.838\n",
      "testing  :  1477  accuracy =   0.5901  loss =  160.098\n",
      "training :  1478  accuracy =   0.6600  loss =  156.684\n",
      "testing  :  1478  accuracy =   0.5900  loss =  160.109\n",
      "training :  1479  accuracy =   0.5400  loss =  163.038\n",
      "testing  :  1479  accuracy =   0.5900  loss =  160.151\n",
      "training :  1480  accuracy =   0.5000  loss =  163.461\n",
      "testing  :  1480  accuracy =   0.5898  loss =  160.085\n",
      "training :  1481  accuracy =   0.6300  loss =  161.45\n",
      "testing  :  1481  accuracy =   0.5898  loss =  160.046\n",
      "training :  1482  accuracy =   0.5900  loss =  158.667\n",
      "testing  :  1482  accuracy =   0.5896  loss =  160.036\n",
      "training :  1483  accuracy =   0.6700  loss =  156.162\n",
      "testing  :  1483  accuracy =   0.5893  loss =  160.04\n",
      "training :  1484  accuracy =   0.6300  loss =  159.766\n",
      "testing  :  1484  accuracy =   0.5892  loss =  160.052\n",
      "training :  1485  accuracy =   0.6300  loss =  159.067\n",
      "testing  :  1485  accuracy =   0.5885  loss =  160.063\n",
      "training :  1486  accuracy =   0.6200  loss =  160.249\n",
      "testing  :  1486  accuracy =   0.5887  loss =  160.05\n",
      "training :  1487  accuracy =   0.6300  loss =  159.558\n",
      "testing  :  1487  accuracy =   0.5881  loss =  160.079\n",
      "training :  1488  accuracy =   0.6300  loss =  158.453\n",
      "testing  :  1488  accuracy =   0.5885  loss =  160.116\n",
      "training :  1489  accuracy =   0.6200  loss =  156.67\n",
      "testing  :  1489  accuracy =   0.5881  loss =  160.109\n",
      "training :  1490  accuracy =   0.5900  loss =  162.113\n",
      "testing  :  1490  accuracy =   0.5884  loss =  160.087\n",
      "training :  1491  accuracy =   0.5700  loss =  159.407\n",
      "testing  :  1491  accuracy =   0.5893  loss =  160.046\n",
      "training :  1492  accuracy =   0.5800  loss =  163.516\n",
      "testing  :  1492  accuracy =   0.5893  loss =  160.042\n",
      "training :  1493  accuracy =   0.6100  loss =  159.869\n",
      "testing  :  1493  accuracy =   0.5901  loss =  160.063\n",
      "training :  1494  accuracy =   0.5800  loss =  159.661\n",
      "testing  :  1494  accuracy =   0.5903  loss =  160.148\n",
      "training :  1495  accuracy =   0.6400  loss =  159.868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1495  accuracy =   0.5895  loss =  160.241\n",
      "training :  1496  accuracy =   0.6300  loss =  158.591\n",
      "testing  :  1496  accuracy =   0.5892  loss =  160.309\n",
      "training :  1497  accuracy =   0.5400  loss =  164.85\n",
      "testing  :  1497  accuracy =   0.5891  loss =  160.354\n",
      "training :  1498  accuracy =   0.5800  loss =  159.05\n",
      "testing  :  1498  accuracy =   0.5889  loss =  160.374\n",
      "training :  1499  accuracy =   0.7000  loss =  158.482\n",
      "testing  :  1499  accuracy =   0.5892  loss =  160.378\n",
      "training :  1500  accuracy =   0.5800  loss =  159.417\n",
      "testing  :  1500  accuracy =   0.5896  loss =  160.37\n",
      "training :  1501  accuracy =   0.5800  loss =  157.803\n",
      "testing  :  1501  accuracy =   0.5903  loss =  160.338\n",
      "training :  1502  accuracy =   0.5600  loss =  159.373\n",
      "testing  :  1502  accuracy =   0.5913  loss =  160.307\n",
      "training :  1503  accuracy =   0.5400  loss =  158.305\n",
      "testing  :  1503  accuracy =   0.5916  loss =  160.249\n",
      "training :  1504  accuracy =   0.6200  loss =  158.192\n",
      "testing  :  1504  accuracy =   0.5926  loss =  160.179\n",
      "training :  1505  accuracy =   0.6600  loss =  158.843\n",
      "testing  :  1505  accuracy =   0.5922  loss =  160.132\n",
      "training :  1506  accuracy =   0.5500  loss =  159.947\n",
      "testing  :  1506  accuracy =   0.5918  loss =  160.097\n",
      "training :  1507  accuracy =   0.5400  loss =  162.42\n",
      "testing  :  1507  accuracy =   0.5915  loss =  160.088\n",
      "training :  1508  accuracy =   0.5000  loss =  159.464\n",
      "testing  :  1508  accuracy =   0.5907  loss =  160.092\n",
      "training :  1509  accuracy =   0.4400  loss =  162.196\n",
      "testing  :  1509  accuracy =   0.5912  loss =  160.123\n",
      "training :  1510  accuracy =   0.5800  loss =  161.638\n",
      "testing  :  1510  accuracy =   0.5910  loss =  160.163\n",
      "training :  1511  accuracy =   0.6700  loss =  157.506\n",
      "testing  :  1511  accuracy =   0.5903  loss =  160.227\n",
      "training :  1512  accuracy =   0.5500  loss =  158.118\n",
      "testing  :  1512  accuracy =   0.5894  loss =  160.242\n",
      "training :  1513  accuracy =   0.5300  loss =  160.316\n",
      "testing  :  1513  accuracy =   0.5891  loss =  160.267\n",
      "training :  1514  accuracy =   0.5900  loss =  159.9\n",
      "testing  :  1514  accuracy =   0.5889  loss =  160.29\n",
      "training :  1515  accuracy =   0.5900  loss =  161.971\n",
      "testing  :  1515  accuracy =   0.5882  loss =  160.31\n",
      "training :  1516  accuracy =   0.5500  loss =  160.72\n",
      "testing  :  1516  accuracy =   0.5875  loss =  160.292\n",
      "training :  1517  accuracy =   0.5300  loss =  160.046\n",
      "testing  :  1517  accuracy =   0.5873  loss =  160.284\n",
      "training :  1518  accuracy =   0.5600  loss =  159.958\n",
      "testing  :  1518  accuracy =   0.5880  loss =  160.202\n",
      "training :  1519  accuracy =   0.5600  loss =  160.39\n",
      "testing  :  1519  accuracy =   0.5885  loss =  160.093\n",
      "training :  1520  accuracy =   0.6800  loss =  161.21\n",
      "testing  :  1520  accuracy =   0.5896  loss =  160.029\n",
      "training :  1521  accuracy =   0.6500  loss =  157.012\n",
      "testing  :  1521  accuracy =   0.5904  loss =  159.985\n",
      "training :  1522  accuracy =   0.6700  loss =  157.037\n",
      "testing  :  1522  accuracy =   0.5904  loss =  159.965\n",
      "training :  1523  accuracy =   0.6100  loss =  161.331\n",
      "testing  :  1523  accuracy =   0.5906  loss =  159.95\n",
      "training :  1524  accuracy =   0.6100  loss =  160.04\n",
      "testing  :  1524  accuracy =   0.5902  loss =  159.945\n",
      "training :  1525  accuracy =   0.6100  loss =  162.229\n",
      "testing  :  1525  accuracy =   0.5900  loss =  159.938\n",
      "training :  1526  accuracy =   0.5400  loss =  161.526\n",
      "testing  :  1526  accuracy =   0.5896  loss =  160.036\n",
      "training :  1527  accuracy =   0.5200  loss =  160.979\n",
      "testing  :  1527  accuracy =   0.5874  loss =  160.172\n",
      "training :  1528  accuracy =   0.6400  loss =  158.176\n",
      "testing  :  1528  accuracy =   0.5858  loss =  160.379\n",
      "training :  1529  accuracy =   0.4900  loss =  159.326\n",
      "testing  :  1529  accuracy =   0.5850  loss =  160.443\n",
      "training :  1530  accuracy =   0.6000  loss =  159.702\n",
      "testing  :  1530  accuracy =   0.5842  loss =  160.505\n",
      "training :  1531  accuracy =   0.5600  loss =  160.804\n",
      "testing  :  1531  accuracy =   0.5845  loss =  160.458\n",
      "training :  1532  accuracy =   0.5700  loss =  159.727\n",
      "testing  :  1532  accuracy =   0.5852  loss =  160.293\n",
      "training :  1533  accuracy =   0.5900  loss =  157.806\n",
      "testing  :  1533  accuracy =   0.5865  loss =  160.103\n",
      "training :  1534  accuracy =   0.5700  loss =  162.239\n",
      "testing  :  1534  accuracy =   0.5877  loss =  159.965\n",
      "training :  1535  accuracy =   0.6000  loss =  157.904\n",
      "testing  :  1535  accuracy =   0.5882  loss =  159.862\n",
      "training :  1536  accuracy =   0.5900  loss =  164.569\n",
      "testing  :  1536  accuracy =   0.5884  loss =  159.83\n",
      "training :  1537  accuracy =   0.5900  loss =  159.639\n",
      "testing  :  1537  accuracy =   0.5889  loss =  159.848\n",
      "training :  1538  accuracy =   0.5400  loss =  160.91\n",
      "testing  :  1538  accuracy =   0.5886  loss =  159.899\n",
      "training :  1539  accuracy =   0.6300  loss =  158.473\n",
      "testing  :  1539  accuracy =   0.5865  loss =  160.023\n",
      "training :  1540  accuracy =   0.4900  loss =  162.148\n",
      "testing  :  1540  accuracy =   0.5865  loss =  160.102\n",
      "training :  1541  accuracy =   0.5500  loss =  160.923\n",
      "testing  :  1541  accuracy =   0.5867  loss =  160.073\n",
      "training :  1542  accuracy =   0.5200  loss =  159.497\n",
      "testing  :  1542  accuracy =   0.5865  loss =  160.065\n",
      "training :  1543  accuracy =   0.5200  loss =  161.253\n",
      "testing  :  1543  accuracy =   0.5863  loss =  160.053\n",
      "training :  1544  accuracy =   0.6000  loss =  160.858\n",
      "testing  :  1544  accuracy =   0.5864  loss =  159.981\n",
      "training :  1545  accuracy =   0.5800  loss =  158.508\n",
      "testing  :  1545  accuracy =   0.5869  loss =  159.901\n",
      "training :  1546  accuracy =   0.6100  loss =  158.497\n",
      "testing  :  1546  accuracy =   0.5875  loss =  159.852\n",
      "training :  1547  accuracy =   0.7000  loss =  156.949\n",
      "testing  :  1547  accuracy =   0.5878  loss =  159.824\n",
      "training :  1548  accuracy =   0.5400  loss =  161.795\n",
      "testing  :  1548  accuracy =   0.5877  loss =  159.802\n",
      "training :  1549  accuracy =   0.6000  loss =  159.221\n",
      "testing  :  1549  accuracy =   0.5876  loss =  159.779\n",
      "training :  1550  accuracy =   0.6000  loss =  156.798\n",
      "testing  :  1550  accuracy =   0.5880  loss =  159.754\n",
      "training :  1551  accuracy =   0.5500  loss =  158.777\n",
      "testing  :  1551  accuracy =   0.5882  loss =  159.739\n",
      "training :  1552  accuracy =   0.5800  loss =  158.216\n",
      "testing  :  1552  accuracy =   0.5886  loss =  159.73\n",
      "training :  1553  accuracy =   0.5600  loss =  160.812\n",
      "testing  :  1553  accuracy =   0.5887  loss =  159.725\n",
      "training :  1554  accuracy =   0.6000  loss =  161.528\n",
      "testing  :  1554  accuracy =   0.5880  loss =  159.755\n",
      "training :  1555  accuracy =   0.5400  loss =  159.81\n",
      "testing  :  1555  accuracy =   0.5884  loss =  159.732\n",
      "training :  1556  accuracy =   0.6600  loss =  157.393\n",
      "testing  :  1556  accuracy =   0.5882  loss =  159.713\n",
      "training :  1557  accuracy =   0.6600  loss =  162.008\n",
      "testing  :  1557  accuracy =   0.5882  loss =  159.703\n",
      "training :  1558  accuracy =   0.5900  loss =  159.411\n",
      "testing  :  1558  accuracy =   0.5879  loss =  159.69\n",
      "training :  1559  accuracy =   0.5500  loss =  160.027\n",
      "testing  :  1559  accuracy =   0.5886  loss =  159.67\n",
      "training :  1560  accuracy =   0.6200  loss =  158.577\n",
      "testing  :  1560  accuracy =   0.5886  loss =  159.676\n",
      "training :  1561  accuracy =   0.7000  loss =  156.356\n",
      "testing  :  1561  accuracy =   0.5883  loss =  159.708\n",
      "training :  1562  accuracy =   0.6100  loss =  157.685\n",
      "testing  :  1562  accuracy =   0.5874  loss =  159.765\n",
      "training :  1563  accuracy =   0.5800  loss =  159.406\n",
      "testing  :  1563  accuracy =   0.5867  loss =  159.808\n",
      "training :  1564  accuracy =   0.6600  loss =  159.119\n",
      "testing  :  1564  accuracy =   0.5855  loss =  159.922\n",
      "training :  1565  accuracy =   0.5100  loss =  163.173\n",
      "testing  :  1565  accuracy =   0.5848  loss =  160.018\n",
      "training :  1566  accuracy =   0.5900  loss =  160.555\n",
      "testing  :  1566  accuracy =   0.5862  loss =  159.901\n",
      "training :  1567  accuracy =   0.5500  loss =  158.997\n",
      "testing  :  1567  accuracy =   0.5880  loss =  159.776\n",
      "training :  1568  accuracy =   0.5800  loss =  159.826\n",
      "testing  :  1568  accuracy =   0.5899  loss =  159.658\n",
      "training :  1569  accuracy =   0.6000  loss =  157.863\n",
      "testing  :  1569  accuracy =   0.5916  loss =  159.589\n",
      "training :  1570  accuracy =   0.5400  loss =  159.748\n",
      "testing  :  1570  accuracy =   0.5919  loss =  159.597\n",
      "training :  1571  accuracy =   0.6500  loss =  157.164\n",
      "testing  :  1571  accuracy =   0.5920  loss =  159.604\n",
      "training :  1572  accuracy =   0.6600  loss =  157.315\n",
      "testing  :  1572  accuracy =   0.5916  loss =  159.611\n",
      "training :  1573  accuracy =   0.5500  loss =  159.982\n",
      "testing  :  1573  accuracy =   0.5913  loss =  159.619\n",
      "training :  1574  accuracy =   0.5700  loss =  162.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1574  accuracy =   0.5905  loss =  159.649\n",
      "training :  1575  accuracy =   0.6900  loss =  159.171\n",
      "testing  :  1575  accuracy =   0.5902  loss =  159.665\n",
      "training :  1576  accuracy =   0.6000  loss =  159.764\n",
      "testing  :  1576  accuracy =   0.5898  loss =  159.67\n",
      "training :  1577  accuracy =   0.6100  loss =  159.112\n",
      "testing  :  1577  accuracy =   0.5900  loss =  159.658\n",
      "training :  1578  accuracy =   0.6700  loss =  157.943\n",
      "testing  :  1578  accuracy =   0.5898  loss =  159.647\n",
      "training :  1579  accuracy =   0.4900  loss =  160.344\n",
      "testing  :  1579  accuracy =   0.5895  loss =  159.633\n",
      "training :  1580  accuracy =   0.5700  loss =  159.067\n",
      "testing  :  1580  accuracy =   0.5894  loss =  159.634\n",
      "training :  1581  accuracy =   0.6200  loss =  160.267\n",
      "testing  :  1581  accuracy =   0.5897  loss =  159.646\n",
      "training :  1582  accuracy =   0.6500  loss =  158.234\n",
      "testing  :  1582  accuracy =   0.5898  loss =  159.647\n",
      "training :  1583  accuracy =   0.7500  loss =  158.593\n",
      "testing  :  1583  accuracy =   0.5896  loss =  159.654\n",
      "training :  1584  accuracy =   0.5600  loss =  159.199\n",
      "testing  :  1584  accuracy =   0.5901  loss =  159.651\n",
      "training :  1585  accuracy =   0.5500  loss =  160.393\n",
      "testing  :  1585  accuracy =   0.5902  loss =  159.65\n",
      "training :  1586  accuracy =   0.5400  loss =  159.69\n",
      "testing  :  1586  accuracy =   0.5903  loss =  159.655\n",
      "training :  1587  accuracy =   0.5800  loss =  157.237\n",
      "testing  :  1587  accuracy =   0.5903  loss =  159.664\n",
      "training :  1588  accuracy =   0.5800  loss =  160.209\n",
      "testing  :  1588  accuracy =   0.5899  loss =  159.669\n",
      "training :  1589  accuracy =   0.6600  loss =  158.095\n",
      "testing  :  1589  accuracy =   0.5897  loss =  159.705\n",
      "training :  1590  accuracy =   0.5400  loss =  161.637\n",
      "testing  :  1590  accuracy =   0.5884  loss =  159.797\n",
      "training :  1591  accuracy =   0.6400  loss =  157.98\n",
      "testing  :  1591  accuracy =   0.5875  loss =  159.87\n",
      "training :  1592  accuracy =   0.6200  loss =  159.804\n",
      "testing  :  1592  accuracy =   0.5873  loss =  159.899\n",
      "training :  1593  accuracy =   0.6000  loss =  158.996\n",
      "testing  :  1593  accuracy =   0.5892  loss =  159.804\n",
      "training :  1594  accuracy =   0.7000  loss =  154.741\n",
      "testing  :  1594  accuracy =   0.5907  loss =  159.686\n",
      "training :  1595  accuracy =   0.6600  loss =  159.058\n",
      "testing  :  1595  accuracy =   0.5917  loss =  159.605\n",
      "training :  1596  accuracy =   0.5500  loss =  159.13\n",
      "testing  :  1596  accuracy =   0.5913  loss =  159.556\n",
      "training :  1597  accuracy =   0.6200  loss =  158.133\n",
      "testing  :  1597  accuracy =   0.5918  loss =  159.538\n",
      "training :  1598  accuracy =   0.5600  loss =  161.543\n",
      "testing  :  1598  accuracy =   0.5925  loss =  159.532\n",
      "training :  1599  accuracy =   0.6000  loss =  160.332\n",
      "testing  :  1599  accuracy =   0.5922  loss =  159.531\n",
      "training :  1600  accuracy =   0.6200  loss =  157.755\n",
      "testing  :  1600  accuracy =   0.5915  loss =  159.52\n",
      "training :  1601  accuracy =   0.5700  loss =  157.635\n",
      "testing  :  1601  accuracy =   0.5906  loss =  159.547\n",
      "training :  1602  accuracy =   0.5800  loss =  158.436\n",
      "testing  :  1602  accuracy =   0.5901  loss =  159.564\n",
      "training :  1603  accuracy =   0.6600  loss =  156.825\n",
      "testing  :  1603  accuracy =   0.5898  loss =  159.583\n",
      "training :  1604  accuracy =   0.6200  loss =  160.27\n",
      "testing  :  1604  accuracy =   0.5898  loss =  159.585\n",
      "training :  1605  accuracy =   0.5500  loss =  158.421\n",
      "testing  :  1605  accuracy =   0.5897  loss =  159.578\n",
      "training :  1606  accuracy =   0.5700  loss =  158.039\n",
      "testing  :  1606  accuracy =   0.5901  loss =  159.58\n",
      "training :  1607  accuracy =   0.5500  loss =  160.544\n",
      "testing  :  1607  accuracy =   0.5909  loss =  159.573\n",
      "training :  1608  accuracy =   0.6400  loss =  157.686\n",
      "testing  :  1608  accuracy =   0.5904  loss =  159.566\n",
      "training :  1609  accuracy =   0.6400  loss =  156.283\n",
      "testing  :  1609  accuracy =   0.5910  loss =  159.59\n",
      "training :  1610  accuracy =   0.5600  loss =  160.429\n",
      "testing  :  1610  accuracy =   0.5914  loss =  159.581\n",
      "training :  1611  accuracy =   0.6200  loss =  156.753\n",
      "testing  :  1611  accuracy =   0.5904  loss =  159.581\n",
      "training :  1612  accuracy =   0.6200  loss =  161.635\n",
      "testing  :  1612  accuracy =   0.5900  loss =  159.583\n",
      "training :  1613  accuracy =   0.6200  loss =  158.679\n",
      "testing  :  1613  accuracy =   0.5896  loss =  159.592\n",
      "training :  1614  accuracy =   0.6200  loss =  158.6\n",
      "testing  :  1614  accuracy =   0.5889  loss =  159.605\n",
      "training :  1615  accuracy =   0.5800  loss =  158.572\n",
      "testing  :  1615  accuracy =   0.5882  loss =  159.613\n",
      "training :  1616  accuracy =   0.5700  loss =  159.168\n",
      "testing  :  1616  accuracy =   0.5879  loss =  159.636\n",
      "training :  1617  accuracy =   0.6100  loss =  159.094\n",
      "testing  :  1617  accuracy =   0.5881  loss =  159.605\n",
      "training :  1618  accuracy =   0.5800  loss =  158.669\n",
      "testing  :  1618  accuracy =   0.5888  loss =  159.556\n",
      "training :  1619  accuracy =   0.6200  loss =  157.617\n",
      "testing  :  1619  accuracy =   0.5895  loss =  159.524\n",
      "training :  1620  accuracy =   0.6300  loss =  160.835\n",
      "testing  :  1620  accuracy =   0.5907  loss =  159.494\n",
      "training :  1621  accuracy =   0.6000  loss =  158.522\n",
      "testing  :  1621  accuracy =   0.5912  loss =  159.514\n",
      "training :  1622  accuracy =   0.4700  loss =  160.606\n",
      "testing  :  1622  accuracy =   0.5904  loss =  159.588\n",
      "training :  1623  accuracy =   0.5500  loss =  160.788\n",
      "testing  :  1623  accuracy =   0.5897  loss =  159.685\n",
      "training :  1624  accuracy =   0.5600  loss =  161.797\n",
      "testing  :  1624  accuracy =   0.5899  loss =  159.769\n",
      "training :  1625  accuracy =   0.4800  loss =  162.049\n",
      "testing  :  1625  accuracy =   0.5893  loss =  160.07\n",
      "training :  1626  accuracy =   0.5600  loss =  161.402\n",
      "testing  :  1626  accuracy =   0.5864  loss =  160.449\n",
      "training :  1627  accuracy =   0.5300  loss =  158.177\n",
      "testing  :  1627  accuracy =   0.5859  loss =  160.784\n",
      "training :  1628  accuracy =   0.5500  loss =  165.868\n",
      "testing  :  1628  accuracy =   0.5850  loss =  161.044\n",
      "training :  1629  accuracy =   0.5700  loss =  158.16\n",
      "testing  :  1629  accuracy =   0.5844  loss =  161.049\n",
      "training :  1630  accuracy =   0.6700  loss =  157.457\n",
      "testing  :  1630  accuracy =   0.5866  loss =  160.778\n",
      "training :  1631  accuracy =   0.5700  loss =  161.311\n",
      "testing  :  1631  accuracy =   0.5891  loss =  160.528\n",
      "training :  1632  accuracy =   0.5700  loss =  162.52\n",
      "testing  :  1632  accuracy =   0.5899  loss =  160.28\n",
      "training :  1633  accuracy =   0.5500  loss =  159.712\n",
      "testing  :  1633  accuracy =   0.5917  loss =  160.033\n",
      "training :  1634  accuracy =   0.5600  loss =  157.512\n",
      "testing  :  1634  accuracy =   0.5930  loss =  159.827\n",
      "training :  1635  accuracy =   0.5600  loss =  160.651\n",
      "testing  :  1635  accuracy =   0.5941  loss =  159.692\n",
      "training :  1636  accuracy =   0.6400  loss =  159.036\n",
      "testing  :  1636  accuracy =   0.5940  loss =  159.599\n",
      "training :  1637  accuracy =   0.5700  loss =  160.462\n",
      "testing  :  1637  accuracy =   0.5932  loss =  159.589\n",
      "training :  1638  accuracy =   0.6100  loss =  157.363\n",
      "testing  :  1638  accuracy =   0.5911  loss =  159.686\n",
      "training :  1639  accuracy =   0.5900  loss =  161.233\n",
      "testing  :  1639  accuracy =   0.5891  loss =  159.851\n",
      "training :  1640  accuracy =   0.6100  loss =  159.872\n",
      "testing  :  1640  accuracy =   0.5868  loss =  159.984\n",
      "training :  1641  accuracy =   0.6800  loss =  157.569\n",
      "testing  :  1641  accuracy =   0.5868  loss =  160.039\n",
      "training :  1642  accuracy =   0.6100  loss =  159.166\n",
      "testing  :  1642  accuracy =   0.5859  loss =  160.086\n",
      "training :  1643  accuracy =   0.6200  loss =  158.262\n",
      "testing  :  1643  accuracy =   0.5852  loss =  160.002\n",
      "training :  1644  accuracy =   0.5400  loss =  160.72\n",
      "testing  :  1644  accuracy =   0.5865  loss =  159.866\n",
      "training :  1645  accuracy =   0.6000  loss =  157.882\n",
      "testing  :  1645  accuracy =   0.5873  loss =  159.741\n",
      "training :  1646  accuracy =   0.5900  loss =  159.859\n",
      "testing  :  1646  accuracy =   0.5885  loss =  159.657\n",
      "training :  1647  accuracy =   0.6300  loss =  158.313\n",
      "testing  :  1647  accuracy =   0.5883  loss =  159.661\n",
      "training :  1648  accuracy =   0.6300  loss =  159.812\n",
      "testing  :  1648  accuracy =   0.5869  loss =  159.76\n",
      "training :  1649  accuracy =   0.6200  loss =  159.645\n",
      "testing  :  1649  accuracy =   0.5859  loss =  159.93\n",
      "training :  1650  accuracy =   0.6500  loss =  157.786\n",
      "testing  :  1650  accuracy =   0.5855  loss =  159.967\n",
      "training :  1651  accuracy =   0.5800  loss =  161.472\n",
      "testing  :  1651  accuracy =   0.5852  loss =  160.038\n",
      "training :  1652  accuracy =   0.5200  loss =  164.751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1652  accuracy =   0.5853  loss =  160.037\n",
      "training :  1653  accuracy =   0.5300  loss =  158.859\n",
      "testing  :  1653  accuracy =   0.5855  loss =  159.969\n",
      "training :  1654  accuracy =   0.6300  loss =  158.758\n",
      "testing  :  1654  accuracy =   0.5863  loss =  159.925\n",
      "training :  1655  accuracy =   0.5700  loss =  159.287\n",
      "testing  :  1655  accuracy =   0.5864  loss =  159.905\n",
      "training :  1656  accuracy =   0.6200  loss =  160.055\n",
      "testing  :  1656  accuracy =   0.5860  loss =  159.886\n",
      "training :  1657  accuracy =   0.5000  loss =  161.679\n",
      "testing  :  1657  accuracy =   0.5868  loss =  159.82\n",
      "training :  1658  accuracy =   0.6100  loss =  158.53\n",
      "testing  :  1658  accuracy =   0.5874  loss =  159.736\n",
      "training :  1659  accuracy =   0.6200  loss =  161.469\n",
      "testing  :  1659  accuracy =   0.5890  loss =  159.662\n",
      "training :  1660  accuracy =   0.6400  loss =  157.649\n",
      "testing  :  1660  accuracy =   0.5890  loss =  159.662\n",
      "training :  1661  accuracy =   0.6100  loss =  158.78\n",
      "testing  :  1661  accuracy =   0.5885  loss =  159.676\n",
      "training :  1662  accuracy =   0.5600  loss =  157.797\n",
      "testing  :  1662  accuracy =   0.5877  loss =  159.715\n",
      "training :  1663  accuracy =   0.5700  loss =  158.736\n",
      "testing  :  1663  accuracy =   0.5868  loss =  159.783\n",
      "training :  1664  accuracy =   0.5800  loss =  158.963\n",
      "testing  :  1664  accuracy =   0.5864  loss =  159.826\n",
      "training :  1665  accuracy =   0.6100  loss =  161.835\n",
      "testing  :  1665  accuracy =   0.5866  loss =  159.785\n",
      "training :  1666  accuracy =   0.5100  loss =  158.521\n",
      "testing  :  1666  accuracy =   0.5869  loss =  159.787\n",
      "training :  1667  accuracy =   0.6600  loss =  157.235\n",
      "testing  :  1667  accuracy =   0.5878  loss =  159.685\n",
      "training :  1668  accuracy =   0.6200  loss =  158.598\n",
      "testing  :  1668  accuracy =   0.5882  loss =  159.609\n",
      "training :  1669  accuracy =   0.5900  loss =  163.19\n",
      "testing  :  1669  accuracy =   0.5882  loss =  159.526\n",
      "training :  1670  accuracy =   0.5900  loss =  161.903\n",
      "testing  :  1670  accuracy =   0.5891  loss =  159.455\n",
      "training :  1671  accuracy =   0.6700  loss =  158.495\n",
      "testing  :  1671  accuracy =   0.5900  loss =  159.416\n",
      "training :  1672  accuracy =   0.5800  loss =  161.628\n",
      "testing  :  1672  accuracy =   0.5894  loss =  159.409\n",
      "training :  1673  accuracy =   0.5400  loss =  164.383\n",
      "testing  :  1673  accuracy =   0.5900  loss =  159.426\n",
      "training :  1674  accuracy =   0.6000  loss =  155.63\n",
      "testing  :  1674  accuracy =   0.5893  loss =  159.441\n",
      "training :  1675  accuracy =   0.6300  loss =  156.226\n",
      "testing  :  1675  accuracy =   0.5889  loss =  159.472\n",
      "training :  1676  accuracy =   0.5700  loss =  159.295\n",
      "testing  :  1676  accuracy =   0.5890  loss =  159.514\n",
      "training :  1677  accuracy =   0.6000  loss =  157.709\n",
      "testing  :  1677  accuracy =   0.5887  loss =  159.522\n",
      "training :  1678  accuracy =   0.5800  loss =  158.338\n",
      "testing  :  1678  accuracy =   0.5877  loss =  159.549\n",
      "training :  1679  accuracy =   0.6000  loss =  159.835\n",
      "testing  :  1679  accuracy =   0.5878  loss =  159.561\n",
      "training :  1680  accuracy =   0.6000  loss =  161.889\n",
      "testing  :  1680  accuracy =   0.5879  loss =  159.54\n",
      "training :  1681  accuracy =   0.6400  loss =  160.244\n",
      "testing  :  1681  accuracy =   0.5883  loss =  159.503\n",
      "training :  1682  accuracy =   0.6200  loss =  157.702\n",
      "testing  :  1682  accuracy =   0.5888  loss =  159.462\n",
      "training :  1683  accuracy =   0.5700  loss =  159.054\n",
      "testing  :  1683  accuracy =   0.5891  loss =  159.45\n",
      "training :  1684  accuracy =   0.5900  loss =  161.342\n",
      "testing  :  1684  accuracy =   0.5893  loss =  159.455\n",
      "training :  1685  accuracy =   0.5500  loss =  159.501\n",
      "testing  :  1685  accuracy =   0.5895  loss =  159.462\n",
      "training :  1686  accuracy =   0.6400  loss =  159.37\n",
      "testing  :  1686  accuracy =   0.5891  loss =  159.526\n",
      "training :  1687  accuracy =   0.6000  loss =  157.495\n",
      "testing  :  1687  accuracy =   0.5875  loss =  159.693\n",
      "training :  1688  accuracy =   0.6100  loss =  160.29\n",
      "testing  :  1688  accuracy =   0.5864  loss =  159.882\n",
      "training :  1689  accuracy =   0.5700  loss =  159.047\n",
      "testing  :  1689  accuracy =   0.5854  loss =  160.074\n",
      "training :  1690  accuracy =   0.6100  loss =  158.164\n",
      "testing  :  1690  accuracy =   0.5840  loss =  160.217\n",
      "training :  1691  accuracy =   0.4900  loss =  162.209\n",
      "testing  :  1691  accuracy =   0.5847  loss =  160.217\n",
      "training :  1692  accuracy =   0.5800  loss =  162.261\n",
      "testing  :  1692  accuracy =   0.5855  loss =  160.105\n",
      "training :  1693  accuracy =   0.5500  loss =  161.989\n",
      "testing  :  1693  accuracy =   0.5864  loss =  159.924\n",
      "training :  1694  accuracy =   0.5900  loss =  160.95\n",
      "testing  :  1694  accuracy =   0.5874  loss =  159.814\n",
      "training :  1695  accuracy =   0.6200  loss =  156.401\n",
      "testing  :  1695  accuracy =   0.5881  loss =  159.666\n",
      "training :  1696  accuracy =   0.6500  loss =  158.884\n",
      "testing  :  1696  accuracy =   0.5897  loss =  159.594\n",
      "training :  1697  accuracy =   0.5200  loss =  160.639\n",
      "testing  :  1697  accuracy =   0.5905  loss =  159.586\n",
      "training :  1698  accuracy =   0.6100  loss =  159.32\n",
      "testing  :  1698  accuracy =   0.5905  loss =  159.57\n",
      "training :  1699  accuracy =   0.6100  loss =  159.326\n",
      "testing  :  1699  accuracy =   0.5902  loss =  159.572\n",
      "training :  1700  accuracy =   0.5300  loss =  160.98\n",
      "testing  :  1700  accuracy =   0.5898  loss =  159.509\n",
      "training :  1701  accuracy =   0.6400  loss =  159.256\n",
      "testing  :  1701  accuracy =   0.5897  loss =  159.461\n",
      "training :  1702  accuracy =   0.5700  loss =  159.656\n",
      "testing  :  1702  accuracy =   0.5899  loss =  159.458\n",
      "training :  1703  accuracy =   0.5900  loss =  160.787\n",
      "testing  :  1703  accuracy =   0.5903  loss =  159.518\n",
      "training :  1704  accuracy =   0.6500  loss =  157.556\n",
      "testing  :  1704  accuracy =   0.5899  loss =  159.669\n",
      "training :  1705  accuracy =   0.6400  loss =  157.735\n",
      "testing  :  1705  accuracy =   0.5895  loss =  159.848\n",
      "training :  1706  accuracy =   0.6500  loss =  157.823\n",
      "testing  :  1706  accuracy =   0.5889  loss =  159.994\n",
      "training :  1707  accuracy =   0.5500  loss =  161.238\n",
      "testing  :  1707  accuracy =   0.5886  loss =  160.083\n",
      "training :  1708  accuracy =   0.5900  loss =  163.909\n",
      "testing  :  1708  accuracy =   0.5888  loss =  160.107\n",
      "training :  1709  accuracy =   0.5000  loss =  161.81\n",
      "testing  :  1709  accuracy =   0.5900  loss =  160.05\n",
      "training :  1710  accuracy =   0.6000  loss =  160.72\n",
      "testing  :  1710  accuracy =   0.5915  loss =  159.994\n",
      "training :  1711  accuracy =   0.5900  loss =  158.605\n",
      "testing  :  1711  accuracy =   0.5949  loss =  159.87\n",
      "training :  1712  accuracy =   0.6700  loss =  158.744\n",
      "testing  :  1712  accuracy =   0.6419  loss =  159.736\n",
      "training :  1713  accuracy =   0.7200  loss =  159.138\n",
      "testing  :  1713  accuracy =   0.6164  loss =  159.661\n",
      "training :  1714  accuracy =   0.6200  loss =  159.259\n",
      "testing  :  1714  accuracy =   0.6059  loss =  159.59\n",
      "training :  1715  accuracy =   0.5700  loss =  159.375\n",
      "testing  :  1715  accuracy =   0.6024  loss =  159.546\n",
      "training :  1716  accuracy =   0.6400  loss =  156.27\n",
      "testing  :  1716  accuracy =   0.6004  loss =  159.513\n",
      "training :  1717  accuracy =   0.6800  loss =  158.674\n",
      "testing  :  1717  accuracy =   0.6003  loss =  159.483\n",
      "training :  1718  accuracy =   0.6300  loss =  158.657\n",
      "testing  :  1718  accuracy =   0.6002  loss =  159.409\n",
      "training :  1719  accuracy =   0.5800  loss =  157.593\n",
      "testing  :  1719  accuracy =   0.6004  loss =  159.368\n",
      "training :  1720  accuracy =   0.5600  loss =  160.129\n",
      "testing  :  1720  accuracy =   0.6006  loss =  159.343\n",
      "training :  1721  accuracy =   0.5600  loss =  159.072\n",
      "testing  :  1721  accuracy =   0.6005  loss =  159.328\n",
      "training :  1722  accuracy =   0.6300  loss =  158.762\n",
      "testing  :  1722  accuracy =   0.6001  loss =  159.319\n",
      "training :  1723  accuracy =   0.5900  loss =  158.648\n",
      "testing  :  1723  accuracy =   0.5990  loss =  159.334\n",
      "training :  1724  accuracy =   0.7200  loss =  154.039\n",
      "testing  :  1724  accuracy =   0.5984  loss =  159.372\n",
      "training :  1725  accuracy =   0.5500  loss =  163.998\n",
      "testing  :  1725  accuracy =   0.5975  loss =  159.436\n",
      "training :  1726  accuracy =   0.5600  loss =  161.134\n",
      "testing  :  1726  accuracy =   0.5974  loss =  159.488\n",
      "training :  1727  accuracy =   0.5700  loss =  158.987\n",
      "testing  :  1727  accuracy =   0.5969  loss =  159.482\n",
      "training :  1728  accuracy =   0.6900  loss =  156.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1728  accuracy =   0.5972  loss =  159.416\n",
      "training :  1729  accuracy =   0.5400  loss =  161.975\n",
      "testing  :  1729  accuracy =   0.5976  loss =  159.345\n",
      "training :  1730  accuracy =   0.6300  loss =  159.278\n",
      "testing  :  1730  accuracy =   0.5992  loss =  159.279\n",
      "training :  1731  accuracy =   0.6300  loss =  157.085\n",
      "testing  :  1731  accuracy =   0.6003  loss =  159.261\n",
      "training :  1732  accuracy =   0.6400  loss =  159.7\n",
      "testing  :  1732  accuracy =   0.6007  loss =  159.277\n",
      "training :  1733  accuracy =   0.5900  loss =  159.706\n",
      "testing  :  1733  accuracy =   0.6006  loss =  159.299\n",
      "training :  1734  accuracy =   0.6200  loss =  156.979\n",
      "testing  :  1734  accuracy =   0.6003  loss =  159.335\n",
      "training :  1735  accuracy =   0.6200  loss =  156.639\n",
      "testing  :  1735  accuracy =   0.5997  loss =  159.392\n",
      "training :  1736  accuracy =   0.5800  loss =  159.031\n",
      "testing  :  1736  accuracy =   0.5988  loss =  159.442\n",
      "training :  1737  accuracy =   0.6300  loss =  158.922\n",
      "testing  :  1737  accuracy =   0.5980  loss =  159.513\n",
      "training :  1738  accuracy =   0.5800  loss =  160.403\n",
      "testing  :  1738  accuracy =   0.5979  loss =  159.561\n",
      "training :  1739  accuracy =   0.5800  loss =  156.921\n",
      "testing  :  1739  accuracy =   0.5972  loss =  159.592\n",
      "training :  1740  accuracy =   0.6000  loss =  159.703\n",
      "testing  :  1740  accuracy =   0.5975  loss =  159.608\n",
      "training :  1741  accuracy =   0.6900  loss =  156.647\n",
      "testing  :  1741  accuracy =   0.5972  loss =  159.6\n",
      "training :  1742  accuracy =   0.5800  loss =  161.704\n",
      "testing  :  1742  accuracy =   0.5969  loss =  159.572\n",
      "training :  1743  accuracy =   0.5600  loss =  164.69\n",
      "testing  :  1743  accuracy =   0.5967  loss =  159.528\n",
      "training :  1744  accuracy =   0.6400  loss =  159.013\n",
      "testing  :  1744  accuracy =   0.5968  loss =  159.495\n",
      "training :  1745  accuracy =   0.5500  loss =  158.868\n",
      "testing  :  1745  accuracy =   0.5964  loss =  159.489\n",
      "training :  1746  accuracy =   0.6100  loss =  158.296\n",
      "testing  :  1746  accuracy =   0.5942  loss =  159.522\n",
      "training :  1747  accuracy =   0.5800  loss =  158.744\n",
      "testing  :  1747  accuracy =   0.5927  loss =  159.596\n",
      "training :  1748  accuracy =   0.5600  loss =  159.035\n",
      "testing  :  1748  accuracy =   0.5944  loss =  159.548\n",
      "training :  1749  accuracy =   0.5700  loss =  158.058\n",
      "testing  :  1749  accuracy =   0.5962  loss =  159.457\n",
      "training :  1750  accuracy =   0.6000  loss =  156.963\n",
      "testing  :  1750  accuracy =   0.5982  loss =  159.393\n",
      "training :  1751  accuracy =   0.5700  loss =  156.808\n",
      "testing  :  1751  accuracy =   0.6008  loss =  159.365\n",
      "training :  1752  accuracy =   0.5800  loss =  157.145\n",
      "testing  :  1752  accuracy =   0.6034  loss =  159.341\n",
      "training :  1753  accuracy =   0.5700  loss =  160.905\n",
      "testing  :  1753  accuracy =   0.6063  loss =  159.323\n",
      "training :  1754  accuracy =   0.6300  loss =  157.395\n",
      "testing  :  1754  accuracy =   0.6095  loss =  159.27\n",
      "training :  1755  accuracy =   0.6700  loss =  159.148\n",
      "testing  :  1755  accuracy =   0.6122  loss =  159.261\n",
      "training :  1756  accuracy =   0.6000  loss =  159.32\n",
      "testing  :  1756  accuracy =   0.6134  loss =  159.267\n",
      "training :  1757  accuracy =   0.6000  loss =  156.513\n",
      "testing  :  1757  accuracy =   0.6151  loss =  159.266\n",
      "training :  1758  accuracy =   0.6100  loss =  158.647\n",
      "testing  :  1758  accuracy =   0.6160  loss =  159.265\n",
      "training :  1759  accuracy =   0.6700  loss =  157.51\n",
      "testing  :  1759  accuracy =   0.6191  loss =  159.248\n",
      "training :  1760  accuracy =   0.5500  loss =  162.399\n",
      "testing  :  1760  accuracy =   0.6310  loss =  159.257\n",
      "training :  1761  accuracy =   0.7300  loss =  157.068\n",
      "testing  :  1761  accuracy =   0.6523  loss =  159.309\n",
      "training :  1762  accuracy =   0.6900  loss =  158.449\n",
      "testing  :  1762  accuracy =   0.6307  loss =  159.366\n",
      "training :  1763  accuracy =   0.6500  loss =  158.025\n",
      "testing  :  1763  accuracy =   0.6063  loss =  159.418\n",
      "training :  1764  accuracy =   0.5500  loss =  157.528\n",
      "testing  :  1764  accuracy =   0.5934  loss =  159.472\n",
      "training :  1765  accuracy =   0.6300  loss =  160.88\n",
      "testing  :  1765  accuracy =   0.5901  loss =  159.515\n",
      "training :  1766  accuracy =   0.5700  loss =  159.894\n",
      "testing  :  1766  accuracy =   0.5894  loss =  159.487\n",
      "training :  1767  accuracy =   0.6900  loss =  157.962\n",
      "testing  :  1767  accuracy =   0.5894  loss =  159.423\n",
      "training :  1768  accuracy =   0.5900  loss =  159.321\n",
      "testing  :  1768  accuracy =   0.5902  loss =  159.358\n",
      "training :  1769  accuracy =   0.5800  loss =  159.21\n",
      "testing  :  1769  accuracy =   0.5907  loss =  159.236\n",
      "training :  1770  accuracy =   0.5700  loss =  158.873\n",
      "testing  :  1770  accuracy =   0.5914  loss =  159.148\n",
      "training :  1771  accuracy =   0.5600  loss =  159.07\n",
      "testing  :  1771  accuracy =   0.5923  loss =  159.095\n",
      "training :  1772  accuracy =   0.5700  loss =  158.276\n",
      "testing  :  1772  accuracy =   0.5919  loss =  159.094\n",
      "training :  1773  accuracy =   0.5700  loss =  157.206\n",
      "testing  :  1773  accuracy =   0.5920  loss =  159.098\n",
      "training :  1774  accuracy =   0.6500  loss =  160.385\n",
      "testing  :  1774  accuracy =   0.5922  loss =  159.094\n",
      "training :  1775  accuracy =   0.6000  loss =  163.356\n",
      "testing  :  1775  accuracy =   0.5922  loss =  159.081\n",
      "training :  1776  accuracy =   0.5500  loss =  159.969\n",
      "testing  :  1776  accuracy =   0.5924  loss =  159.082\n",
      "training :  1777  accuracy =   0.6200  loss =  157.317\n",
      "testing  :  1777  accuracy =   0.5921  loss =  159.104\n",
      "training :  1778  accuracy =   0.6300  loss =  157.284\n",
      "testing  :  1778  accuracy =   0.5911  loss =  159.16\n",
      "training :  1779  accuracy =   0.6400  loss =  156.347\n",
      "testing  :  1779  accuracy =   0.5911  loss =  159.193\n",
      "training :  1780  accuracy =   0.5500  loss =  158.938\n",
      "testing  :  1780  accuracy =   0.5904  loss =  159.245\n",
      "training :  1781  accuracy =   0.5400  loss =  159.313\n",
      "testing  :  1781  accuracy =   0.5900  loss =  159.304\n",
      "training :  1782  accuracy =   0.7100  loss =  156.103\n",
      "testing  :  1782  accuracy =   0.5901  loss =  159.35\n",
      "training :  1783  accuracy =   0.5800  loss =  157.419\n",
      "testing  :  1783  accuracy =   0.5898  loss =  159.395\n",
      "training :  1784  accuracy =   0.5700  loss =  160.424\n",
      "testing  :  1784  accuracy =   0.5895  loss =  159.409\n",
      "training :  1785  accuracy =   0.6800  loss =  158.603\n",
      "testing  :  1785  accuracy =   0.5895  loss =  159.396\n",
      "training :  1786  accuracy =   0.5200  loss =  164.012\n",
      "testing  :  1786  accuracy =   0.5896  loss =  159.356\n",
      "training :  1787  accuracy =   0.6100  loss =  157.942\n",
      "testing  :  1787  accuracy =   0.5895  loss =  159.31\n",
      "training :  1788  accuracy =   0.6000  loss =  161.194\n",
      "testing  :  1788  accuracy =   0.5895  loss =  159.292\n",
      "training :  1789  accuracy =   0.5900  loss =  160.303\n",
      "testing  :  1789  accuracy =   0.5898  loss =  159.311\n",
      "training :  1790  accuracy =   0.6300  loss =  157.01\n",
      "testing  :  1790  accuracy =   0.5896  loss =  159.259\n",
      "training :  1791  accuracy =   0.6900  loss =  158.818\n",
      "testing  :  1791  accuracy =   0.5903  loss =  159.225\n",
      "training :  1792  accuracy =   0.6600  loss =  159.994\n",
      "testing  :  1792  accuracy =   0.5911  loss =  159.21\n",
      "training :  1793  accuracy =   0.6300  loss =  158.917\n",
      "testing  :  1793  accuracy =   0.5921  loss =  159.139\n",
      "training :  1794  accuracy =   0.6300  loss =  156.322\n",
      "testing  :  1794  accuracy =   0.5922  loss =  159.124\n",
      "training :  1795  accuracy =   0.6700  loss =  157.74\n",
      "testing  :  1795  accuracy =   0.5926  loss =  159.151\n",
      "training :  1796  accuracy =   0.6100  loss =  158.827\n",
      "testing  :  1796  accuracy =   0.5933  loss =  159.174\n",
      "training :  1797  accuracy =   0.5700  loss =  157.281\n",
      "testing  :  1797  accuracy =   0.5933  loss =  159.209\n",
      "training :  1798  accuracy =   0.4400  loss =  162.014\n",
      "testing  :  1798  accuracy =   0.5931  loss =  159.267\n",
      "training :  1799  accuracy =   0.6000  loss =  156.889\n",
      "testing  :  1799  accuracy =   0.5932  loss =  159.323\n",
      "training :  1800  accuracy =   0.5800  loss =  157.607\n",
      "testing  :  1800  accuracy =   0.5934  loss =  159.37\n",
      "training :  1801  accuracy =   0.5400  loss =  159.089\n",
      "testing  :  1801  accuracy =   0.5931  loss =  159.341\n",
      "training :  1802  accuracy =   0.6000  loss =  160.157\n",
      "testing  :  1802  accuracy =   0.5934  loss =  159.314\n",
      "training :  1803  accuracy =   0.6200  loss =  157.992\n",
      "testing  :  1803  accuracy =   0.5934  loss =  159.272\n",
      "training :  1804  accuracy =   0.5700  loss =  160.702\n",
      "testing  :  1804  accuracy =   0.5938  loss =  159.23\n",
      "training :  1805  accuracy =   0.6700  loss =  158.813\n",
      "testing  :  1805  accuracy =   0.5932  loss =  159.144\n",
      "training :  1806  accuracy =   0.5500  loss =  161.091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1806  accuracy =   0.5933  loss =  159.069\n",
      "training :  1807  accuracy =   0.5500  loss =  160.077\n",
      "testing  :  1807  accuracy =   0.5931  loss =  159.018\n",
      "training :  1808  accuracy =   0.5700  loss =  156.599\n",
      "testing  :  1808  accuracy =   0.5928  loss =  158.997\n",
      "training :  1809  accuracy =   0.4900  loss =  160.019\n",
      "testing  :  1809  accuracy =   0.5930  loss =  158.999\n",
      "training :  1810  accuracy =   0.6600  loss =  157.952\n",
      "testing  :  1810  accuracy =   0.5926  loss =  159.021\n",
      "training :  1811  accuracy =   0.5500  loss =  157.429\n",
      "testing  :  1811  accuracy =   0.5922  loss =  159.034\n",
      "training :  1812  accuracy =   0.6300  loss =  158.572\n",
      "testing  :  1812  accuracy =   0.5925  loss =  159.029\n",
      "training :  1813  accuracy =   0.6300  loss =  158.842\n",
      "testing  :  1813  accuracy =   0.5929  loss =  159.004\n",
      "training :  1814  accuracy =   0.6200  loss =  157.628\n",
      "testing  :  1814  accuracy =   0.5932  loss =  158.964\n",
      "training :  1815  accuracy =   0.5400  loss =  159.209\n",
      "testing  :  1815  accuracy =   0.5933  loss =  158.952\n",
      "training :  1816  accuracy =   0.5400  loss =  158.955\n",
      "testing  :  1816  accuracy =   0.5938  loss =  158.961\n",
      "training :  1817  accuracy =   0.6100  loss =  158.196\n",
      "testing  :  1817  accuracy =   0.5943  loss =  158.959\n",
      "training :  1818  accuracy =   0.4700  loss =  162.289\n",
      "testing  :  1818  accuracy =   0.5967  loss =  158.955\n",
      "training :  1819  accuracy =   0.5500  loss =  160.163\n",
      "testing  :  1819  accuracy =   0.6029  loss =  158.933\n",
      "training :  1820  accuracy =   0.6100  loss =  157.621\n",
      "testing  :  1820  accuracy =   0.6047  loss =  158.908\n",
      "training :  1821  accuracy =   0.5400  loss =  160.801\n",
      "testing  :  1821  accuracy =   0.6048  loss =  158.905\n",
      "training :  1822  accuracy =   0.5900  loss =  159.691\n",
      "testing  :  1822  accuracy =   0.6059  loss =  158.908\n",
      "training :  1823  accuracy =   0.6900  loss =  156.81\n",
      "testing  :  1823  accuracy =   0.5968  loss =  158.932\n",
      "training :  1824  accuracy =   0.7200  loss =  155.865\n",
      "testing  :  1824  accuracy =   0.5940  loss =  159.005\n",
      "training :  1825  accuracy =   0.6100  loss =  157.371\n",
      "testing  :  1825  accuracy =   0.5930  loss =  159.097\n",
      "training :  1826  accuracy =   0.5800  loss =  158.931\n",
      "testing  :  1826  accuracy =   0.5915  loss =  159.259\n",
      "training :  1827  accuracy =   0.5800  loss =  158.049\n",
      "testing  :  1827  accuracy =   0.5902  loss =  159.457\n",
      "training :  1828  accuracy =   0.5700  loss =  159.036\n",
      "testing  :  1828  accuracy =   0.5882  loss =  159.652\n",
      "training :  1829  accuracy =   0.6200  loss =  158.488\n",
      "testing  :  1829  accuracy =   0.5855  loss =  159.838\n",
      "training :  1830  accuracy =   0.5100  loss =  159.279\n",
      "testing  :  1830  accuracy =   0.5848  loss =  159.9\n",
      "training :  1831  accuracy =   0.5700  loss =  158.363\n",
      "testing  :  1831  accuracy =   0.5851  loss =  159.826\n",
      "training :  1832  accuracy =   0.5700  loss =  161.68\n",
      "testing  :  1832  accuracy =   0.5872  loss =  159.62\n",
      "training :  1833  accuracy =   0.7100  loss =  155.404\n",
      "testing  :  1833  accuracy =   0.5884  loss =  159.416\n",
      "training :  1834  accuracy =   0.5300  loss =  161.017\n",
      "testing  :  1834  accuracy =   0.5901  loss =  159.288\n",
      "training :  1835  accuracy =   0.5700  loss =  159.179\n",
      "testing  :  1835  accuracy =   0.5903  loss =  159.225\n",
      "training :  1836  accuracy =   0.5400  loss =  159.071\n",
      "testing  :  1836  accuracy =   0.5907  loss =  159.211\n",
      "training :  1837  accuracy =   0.6100  loss =  158.821\n",
      "testing  :  1837  accuracy =   0.5911  loss =  159.25\n",
      "training :  1838  accuracy =   0.5400  loss =  160.481\n",
      "testing  :  1838  accuracy =   0.5901  loss =  159.31\n",
      "training :  1839  accuracy =   0.6200  loss =  157.035\n",
      "testing  :  1839  accuracy =   0.5892  loss =  159.361\n",
      "training :  1840  accuracy =   0.5900  loss =  157.825\n",
      "testing  :  1840  accuracy =   0.5876  loss =  159.435\n",
      "training :  1841  accuracy =   0.6100  loss =  157.356\n",
      "testing  :  1841  accuracy =   0.5871  loss =  159.528\n",
      "training :  1842  accuracy =   0.7200  loss =  156.64\n",
      "testing  :  1842  accuracy =   0.5861  loss =  159.62\n",
      "training :  1843  accuracy =   0.6100  loss =  158.22\n",
      "testing  :  1843  accuracy =   0.5850  loss =  159.687\n",
      "training :  1844  accuracy =   0.7000  loss =  155.88\n",
      "testing  :  1844  accuracy =   0.5859  loss =  159.598\n",
      "training :  1845  accuracy =   0.5600  loss =  157.133\n",
      "testing  :  1845  accuracy =   0.5863  loss =  159.531\n",
      "training :  1846  accuracy =   0.5800  loss =  165.068\n",
      "testing  :  1846  accuracy =   0.5867  loss =  159.477\n",
      "training :  1847  accuracy =   0.5900  loss =  158.486\n",
      "testing  :  1847  accuracy =   0.5876  loss =  159.416\n",
      "training :  1848  accuracy =   0.6700  loss =  158.916\n",
      "testing  :  1848  accuracy =   0.5881  loss =  159.366\n",
      "training :  1849  accuracy =   0.6500  loss =  157.634\n",
      "testing  :  1849  accuracy =   0.5895  loss =  159.328\n",
      "training :  1850  accuracy =   0.6700  loss =  157.156\n",
      "testing  :  1850  accuracy =   0.5906  loss =  159.23\n",
      "training :  1851  accuracy =   0.6100  loss =  158.58\n",
      "testing  :  1851  accuracy =   0.5910  loss =  159.121\n",
      "training :  1852  accuracy =   0.6100  loss =  158.475\n",
      "testing  :  1852  accuracy =   0.5919  loss =  159.022\n",
      "training :  1853  accuracy =   0.6100  loss =  160.18\n",
      "testing  :  1853  accuracy =   0.5928  loss =  158.966\n",
      "training :  1854  accuracy =   0.5300  loss =  162.7\n",
      "testing  :  1854  accuracy =   0.5930  loss =  158.961\n",
      "training :  1855  accuracy =   0.6100  loss =  159.135\n",
      "testing  :  1855  accuracy =   0.5928  loss =  158.984\n",
      "training :  1856  accuracy =   0.6000  loss =  157.538\n",
      "testing  :  1856  accuracy =   0.5930  loss =  159.039\n",
      "training :  1857  accuracy =   0.6800  loss =  156.709\n",
      "testing  :  1857  accuracy =   0.5925  loss =  159.12\n",
      "training :  1858  accuracy =   0.6200  loss =  157.842\n",
      "testing  :  1858  accuracy =   0.5923  loss =  159.178\n",
      "training :  1859  accuracy =   0.6700  loss =  157.256\n",
      "testing  :  1859  accuracy =   0.5926  loss =  159.266\n",
      "training :  1860  accuracy =   0.4700  loss =  162.196\n",
      "testing  :  1860  accuracy =   0.5916  loss =  159.343\n",
      "training :  1861  accuracy =   0.5000  loss =  159.627\n",
      "testing  :  1861  accuracy =   0.5927  loss =  159.326\n",
      "training :  1862  accuracy =   0.6400  loss =  160.416\n",
      "testing  :  1862  accuracy =   0.5926  loss =  159.327\n",
      "training :  1863  accuracy =   0.6200  loss =  157.498\n",
      "testing  :  1863  accuracy =   0.5924  loss =  159.28\n",
      "training :  1864  accuracy =   0.5300  loss =  159.704\n",
      "testing  :  1864  accuracy =   0.5934  loss =  159.198\n",
      "training :  1865  accuracy =   0.5500  loss =  157.288\n",
      "testing  :  1865  accuracy =   0.5934  loss =  159.139\n",
      "training :  1866  accuracy =   0.6000  loss =  158.321\n",
      "testing  :  1866  accuracy =   0.5932  loss =  159.096\n",
      "training :  1867  accuracy =   0.6800  loss =  157.768\n",
      "testing  :  1867  accuracy =   0.5933  loss =  159.046\n",
      "training :  1868  accuracy =   0.6000  loss =  159.055\n",
      "testing  :  1868  accuracy =   0.5926  loss =  159.009\n",
      "training :  1869  accuracy =   0.6000  loss =  156.752\n",
      "testing  :  1869  accuracy =   0.5923  loss =  158.994\n",
      "training :  1870  accuracy =   0.5800  loss =  160.718\n",
      "testing  :  1870  accuracy =   0.5922  loss =  158.974\n",
      "training :  1871  accuracy =   0.6700  loss =  156.447\n",
      "testing  :  1871  accuracy =   0.5922  loss =  158.978\n",
      "training :  1872  accuracy =   0.7100  loss =  157.652\n",
      "testing  :  1872  accuracy =   0.5918  loss =  158.984\n",
      "training :  1873  accuracy =   0.5900  loss =  157.861\n",
      "testing  :  1873  accuracy =   0.5914  loss =  159.001\n",
      "training :  1874  accuracy =   0.5900  loss =  157.664\n",
      "testing  :  1874  accuracy =   0.5911  loss =  159.002\n",
      "training :  1875  accuracy =   0.5200  loss =  159.891\n",
      "testing  :  1875  accuracy =   0.5913  loss =  159.0\n",
      "training :  1876  accuracy =   0.6100  loss =  157.451\n",
      "testing  :  1876  accuracy =   0.5912  loss =  158.999\n",
      "training :  1877  accuracy =   0.6000  loss =  156.687\n",
      "testing  :  1877  accuracy =   0.5913  loss =  159.001\n",
      "training :  1878  accuracy =   0.6400  loss =  157.203\n",
      "testing  :  1878  accuracy =   0.5912  loss =  159.025\n",
      "training :  1879  accuracy =   0.5700  loss =  157.883\n",
      "testing  :  1879  accuracy =   0.5906  loss =  159.071\n",
      "training :  1880  accuracy =   0.5700  loss =  158.985\n",
      "testing  :  1880  accuracy =   0.5900  loss =  159.094\n",
      "training :  1881  accuracy =   0.6400  loss =  158.316\n",
      "testing  :  1881  accuracy =   0.5893  loss =  159.122\n",
      "training :  1882  accuracy =   0.6100  loss =  157.167\n",
      "testing  :  1882  accuracy =   0.5898  loss =  159.111\n",
      "training :  1883  accuracy =   0.5500  loss =  158.949\n",
      "testing  :  1883  accuracy =   0.5897  loss =  159.121\n",
      "training :  1884  accuracy =   0.6600  loss =  158.964\n",
      "testing  :  1884  accuracy =   0.5899  loss =  159.139\n",
      "training :  1885  accuracy =   0.6400  loss =  159.915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1885  accuracy =   0.5890  loss =  159.145\n",
      "training :  1886  accuracy =   0.5300  loss =  160.185\n",
      "testing  :  1886  accuracy =   0.5890  loss =  159.167\n",
      "training :  1887  accuracy =   0.7100  loss =  155.419\n",
      "testing  :  1887  accuracy =   0.5889  loss =  159.22\n",
      "training :  1888  accuracy =   0.6400  loss =  157.562\n",
      "testing  :  1888  accuracy =   0.5887  loss =  159.272\n",
      "training :  1889  accuracy =   0.5500  loss =  158.373\n",
      "testing  :  1889  accuracy =   0.5883  loss =  159.326\n",
      "training :  1890  accuracy =   0.6000  loss =  158.058\n",
      "testing  :  1890  accuracy =   0.5880  loss =  159.36\n",
      "training :  1891  accuracy =   0.6200  loss =  157.662\n",
      "testing  :  1891  accuracy =   0.5888  loss =  159.379\n",
      "training :  1892  accuracy =   0.5900  loss =  158.774\n",
      "testing  :  1892  accuracy =   0.5892  loss =  159.385\n",
      "training :  1893  accuracy =   0.6300  loss =  158.226\n",
      "testing  :  1893  accuracy =   0.5895  loss =  159.341\n",
      "training :  1894  accuracy =   0.5700  loss =  158.545\n",
      "testing  :  1894  accuracy =   0.5908  loss =  159.258\n",
      "training :  1895  accuracy =   0.5500  loss =  158.109\n",
      "testing  :  1895  accuracy =   0.5919  loss =  159.226\n",
      "training :  1896  accuracy =   0.6000  loss =  159.928\n",
      "testing  :  1896  accuracy =   0.5925  loss =  159.224\n",
      "training :  1897  accuracy =   0.6300  loss =  158.445\n",
      "testing  :  1897  accuracy =   0.5923  loss =  159.244\n",
      "training :  1898  accuracy =   0.5600  loss =  158.882\n",
      "testing  :  1898  accuracy =   0.5920  loss =  159.284\n",
      "training :  1899  accuracy =   0.5500  loss =  161.945\n",
      "testing  :  1899  accuracy =   0.5918  loss =  159.303\n",
      "training :  1900  accuracy =   0.6200  loss =  162.384\n",
      "testing  :  1900  accuracy =   0.5925  loss =  159.331\n",
      "training :  1901  accuracy =   0.6000  loss =  159.498\n",
      "testing  :  1901  accuracy =   0.5929  loss =  159.367\n",
      "training :  1902  accuracy =   0.6300  loss =  162.87\n",
      "testing  :  1902  accuracy =   0.5933  loss =  159.391\n",
      "training :  1903  accuracy =   0.5900  loss =  159.19\n",
      "testing  :  1903  accuracy =   0.5931  loss =  159.347\n",
      "training :  1904  accuracy =   0.5400  loss =  161.754\n",
      "testing  :  1904  accuracy =   0.5927  loss =  159.309\n",
      "training :  1905  accuracy =   0.6000  loss =  161.419\n",
      "testing  :  1905  accuracy =   0.5926  loss =  159.292\n",
      "training :  1906  accuracy =   0.5800  loss =  159.946\n",
      "testing  :  1906  accuracy =   0.5921  loss =  159.293\n",
      "training :  1907  accuracy =   0.7100  loss =  154.657\n",
      "testing  :  1907  accuracy =   0.5911  loss =  159.308\n",
      "training :  1908  accuracy =   0.5800  loss =  160.194\n",
      "testing  :  1908  accuracy =   0.5907  loss =  159.344\n",
      "training :  1909  accuracy =   0.5400  loss =  158.567\n",
      "testing  :  1909  accuracy =   0.5902  loss =  159.361\n",
      "training :  1910  accuracy =   0.5500  loss =  159.748\n",
      "testing  :  1910  accuracy =   0.5887  loss =  159.408\n",
      "training :  1911  accuracy =   0.6100  loss =  155.917\n",
      "testing  :  1911  accuracy =   0.5881  loss =  159.434\n",
      "training :  1912  accuracy =   0.5800  loss =  159.455\n",
      "testing  :  1912  accuracy =   0.5886  loss =  159.433\n",
      "training :  1913  accuracy =   0.6200  loss =  156.966\n",
      "testing  :  1913  accuracy =   0.5919  loss =  159.253\n",
      "training :  1914  accuracy =   0.6300  loss =  157.118\n",
      "testing  :  1914  accuracy =   0.5931  loss =  159.155\n",
      "training :  1915  accuracy =   0.6300  loss =  159.236\n",
      "testing  :  1915  accuracy =   0.5946  loss =  159.221\n",
      "training :  1916  accuracy =   0.6300  loss =  158.822\n",
      "testing  :  1916  accuracy =   0.5953  loss =  159.337\n",
      "training :  1917  accuracy =   0.5600  loss =  158.423\n",
      "testing  :  1917  accuracy =   0.5943  loss =  159.523\n",
      "training :  1918  accuracy =   0.5700  loss =  161.715\n",
      "testing  :  1918  accuracy =   0.5928  loss =  159.762\n",
      "training :  1919  accuracy =   0.6400  loss =  160.913\n",
      "testing  :  1919  accuracy =   0.5907  loss =  160.002\n",
      "training :  1920  accuracy =   0.5800  loss =  157.927\n",
      "testing  :  1920  accuracy =   0.5891  loss =  160.045\n",
      "training :  1921  accuracy =   0.5700  loss =  158.949\n",
      "testing  :  1921  accuracy =   0.5872  loss =  159.991\n",
      "training :  1922  accuracy =   0.6100  loss =  162.193\n",
      "testing  :  1922  accuracy =   0.5872  loss =  159.893\n",
      "training :  1923  accuracy =   0.6100  loss =  159.48\n",
      "testing  :  1923  accuracy =   0.5881  loss =  159.737\n",
      "training :  1924  accuracy =   0.5300  loss =  159.186\n",
      "testing  :  1924  accuracy =   0.5900  loss =  159.577\n",
      "training :  1925  accuracy =   0.6100  loss =  157.24\n",
      "testing  :  1925  accuracy =   0.5918  loss =  159.419\n",
      "training :  1926  accuracy =   0.6200  loss =  157.444\n",
      "testing  :  1926  accuracy =   0.5925  loss =  159.308\n",
      "training :  1927  accuracy =   0.5800  loss =  157.366\n",
      "testing  :  1927  accuracy =   0.5920  loss =  159.23\n",
      "training :  1928  accuracy =   0.5300  loss =  160.045\n",
      "testing  :  1928  accuracy =   0.5917  loss =  159.216\n",
      "training :  1929  accuracy =   0.6000  loss =  160.116\n",
      "testing  :  1929  accuracy =   0.5915  loss =  159.261\n",
      "training :  1930  accuracy =   0.5800  loss =  161.054\n",
      "testing  :  1930  accuracy =   0.5904  loss =  159.353\n",
      "training :  1931  accuracy =   0.6500  loss =  157.1\n",
      "testing  :  1931  accuracy =   0.5886  loss =  159.462\n",
      "training :  1932  accuracy =   0.5800  loss =  157.515\n",
      "testing  :  1932  accuracy =   0.5873  loss =  159.568\n",
      "training :  1933  accuracy =   0.5900  loss =  158.752\n",
      "testing  :  1933  accuracy =   0.5859  loss =  159.61\n",
      "training :  1934  accuracy =   0.6400  loss =  157.999\n",
      "testing  :  1934  accuracy =   0.5852  loss =  159.641\n",
      "training :  1935  accuracy =   0.6600  loss =  158.557\n",
      "testing  :  1935  accuracy =   0.5846  loss =  159.617\n",
      "training :  1936  accuracy =   0.5900  loss =  158.799\n",
      "testing  :  1936  accuracy =   0.5852  loss =  159.497\n",
      "training :  1937  accuracy =   0.6800  loss =  157.694\n",
      "testing  :  1937  accuracy =   0.5850  loss =  159.412\n",
      "training :  1938  accuracy =   0.5400  loss =  161.969\n",
      "testing  :  1938  accuracy =   0.5860  loss =  159.273\n",
      "training :  1939  accuracy =   0.5000  loss =  161.584\n",
      "testing  :  1939  accuracy =   0.5884  loss =  159.157\n",
      "training :  1940  accuracy =   0.7300  loss =  155.967\n",
      "testing  :  1940  accuracy =   0.5911  loss =  159.067\n",
      "training :  1941  accuracy =   0.6500  loss =  156.947\n",
      "testing  :  1941  accuracy =   0.5916  loss =  159.028\n",
      "training :  1942  accuracy =   0.5500  loss =  158.451\n",
      "testing  :  1942  accuracy =   0.5925  loss =  159.007\n",
      "training :  1943  accuracy =   0.7000  loss =  155.97\n",
      "testing  :  1943  accuracy =   0.5937  loss =  159.005\n",
      "training :  1944  accuracy =   0.5900  loss =  155.83\n",
      "testing  :  1944  accuracy =   0.5943  loss =  159.015\n",
      "training :  1945  accuracy =   0.6400  loss =  157.526\n",
      "testing  :  1945  accuracy =   0.5941  loss =  159.076\n",
      "training :  1946  accuracy =   0.5800  loss =  157.73\n",
      "testing  :  1946  accuracy =   0.5924  loss =  159.212\n",
      "training :  1947  accuracy =   0.5600  loss =  160.913\n",
      "testing  :  1947  accuracy =   0.5912  loss =  159.378\n",
      "training :  1948  accuracy =   0.6000  loss =  158.634\n",
      "testing  :  1948  accuracy =   0.5902  loss =  159.601\n",
      "training :  1949  accuracy =   0.6300  loss =  156.953\n",
      "testing  :  1949  accuracy =   0.5891  loss =  159.749\n",
      "training :  1950  accuracy =   0.6100  loss =  156.636\n",
      "testing  :  1950  accuracy =   0.5881  loss =  159.856\n",
      "training :  1951  accuracy =   0.6000  loss =  158.837\n",
      "testing  :  1951  accuracy =   0.5885  loss =  159.806\n",
      "training :  1952  accuracy =   0.5900  loss =  162.642\n",
      "testing  :  1952  accuracy =   0.5907  loss =  159.456\n",
      "training :  1953  accuracy =   0.6200  loss =  160.118\n",
      "testing  :  1953  accuracy =   0.5915  loss =  159.157\n",
      "training :  1954  accuracy =   0.5900  loss =  155.442\n",
      "testing  :  1954  accuracy =   0.5924  loss =  158.978\n",
      "training :  1955  accuracy =   0.6200  loss =  160.836\n",
      "testing  :  1955  accuracy =   0.5915  loss =  158.923\n",
      "training :  1956  accuracy =   0.5800  loss =  160.538\n",
      "testing  :  1956  accuracy =   0.5903  loss =  158.965\n",
      "training :  1957  accuracy =   0.6600  loss =  158.392\n",
      "testing  :  1957  accuracy =   0.5883  loss =  159.07\n",
      "training :  1958  accuracy =   0.6200  loss =  158.333\n",
      "testing  :  1958  accuracy =   0.5922  loss =  159.214\n",
      "training :  1959  accuracy =   0.6700  loss =  157.685\n",
      "testing  :  1959  accuracy =   0.6051  loss =  159.362\n",
      "training :  1960  accuracy =   0.6000  loss =  158.549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1960  accuracy =   0.5880  loss =  159.5\n",
      "training :  1961  accuracy =   0.5700  loss =  160.088\n",
      "testing  :  1961  accuracy =   0.5839  loss =  159.619\n",
      "training :  1962  accuracy =   0.5600  loss =  158.917\n",
      "testing  :  1962  accuracy =   0.5812  loss =  159.685\n",
      "training :  1963  accuracy =   0.5700  loss =  161.491\n",
      "testing  :  1963  accuracy =   0.5802  loss =  159.741\n",
      "training :  1964  accuracy =   0.5800  loss =  160.277\n",
      "testing  :  1964  accuracy =   0.5814  loss =  159.576\n",
      "training :  1965  accuracy =   0.5400  loss =  157.819\n",
      "testing  :  1965  accuracy =   0.5824  loss =  159.361\n",
      "training :  1966  accuracy =   0.5900  loss =  163.688\n",
      "testing  :  1966  accuracy =   0.5837  loss =  159.188\n",
      "training :  1967  accuracy =   0.5700  loss =  159.285\n",
      "testing  :  1967  accuracy =   0.5851  loss =  159.072\n",
      "training :  1968  accuracy =   0.7200  loss =  157.725\n",
      "testing  :  1968  accuracy =   0.5856  loss =  159.04\n",
      "training :  1969  accuracy =   0.5500  loss =  160.788\n",
      "testing  :  1969  accuracy =   0.5866  loss =  159.042\n",
      "training :  1970  accuracy =   0.6400  loss =  159.063\n",
      "testing  :  1970  accuracy =   0.5874  loss =  159.107\n",
      "training :  1971  accuracy =   0.6600  loss =  160.497\n",
      "testing  :  1971  accuracy =   0.5875  loss =  159.145\n",
      "training :  1972  accuracy =   0.6300  loss =  156.444\n",
      "testing  :  1972  accuracy =   0.5873  loss =  159.177\n",
      "training :  1973  accuracy =   0.5100  loss =  161.091\n",
      "testing  :  1973  accuracy =   0.5881  loss =  159.165\n",
      "training :  1974  accuracy =   0.5900  loss =  157.076\n",
      "testing  :  1974  accuracy =   0.5894  loss =  159.114\n",
      "training :  1975  accuracy =   0.6000  loss =  158.438\n",
      "testing  :  1975  accuracy =   0.5905  loss =  159.098\n",
      "training :  1976  accuracy =   0.5500  loss =  161.733\n",
      "testing  :  1976  accuracy =   0.5918  loss =  159.072\n",
      "training :  1977  accuracy =   0.6000  loss =  160.373\n",
      "testing  :  1977  accuracy =   0.5912  loss =  159.035\n",
      "training :  1978  accuracy =   0.6100  loss =  158.179\n",
      "testing  :  1978  accuracy =   0.5906  loss =  159.002\n",
      "training :  1979  accuracy =   0.6400  loss =  159.602\n",
      "testing  :  1979  accuracy =   0.5894  loss =  158.969\n",
      "training :  1980  accuracy =   0.6500  loss =  157.52\n",
      "testing  :  1980  accuracy =   0.5875  loss =  158.904\n",
      "training :  1981  accuracy =   0.6300  loss =  159.902\n",
      "testing  :  1981  accuracy =   0.5868  loss =  158.871\n",
      "training :  1982  accuracy =   0.5500  loss =  156.402\n",
      "testing  :  1982  accuracy =   0.5860  loss =  158.859\n",
      "training :  1983  accuracy =   0.6000  loss =  157.452\n",
      "testing  :  1983  accuracy =   0.5857  loss =  158.866\n",
      "training :  1984  accuracy =   0.7200  loss =  155.306\n",
      "testing  :  1984  accuracy =   0.5854  loss =  158.882\n",
      "training :  1985  accuracy =   0.6500  loss =  158.245\n",
      "testing  :  1985  accuracy =   0.5843  loss =  158.899\n",
      "training :  1986  accuracy =   0.5800  loss =  157.915\n",
      "testing  :  1986  accuracy =   0.5845  loss =  158.912\n",
      "training :  1987  accuracy =   0.5900  loss =  157.504\n",
      "testing  :  1987  accuracy =   0.5846  loss =  158.922\n",
      "training :  1988  accuracy =   0.6400  loss =  158.947\n",
      "testing  :  1988  accuracy =   0.5845  loss =  158.902\n",
      "training :  1989  accuracy =   0.5700  loss =  160.679\n",
      "testing  :  1989  accuracy =   0.5853  loss =  158.882\n",
      "training :  1990  accuracy =   0.5300  loss =  157.119\n",
      "testing  :  1990  accuracy =   0.5851  loss =  158.866\n",
      "training :  1991  accuracy =   0.5600  loss =  161.95\n",
      "testing  :  1991  accuracy =   0.5848  loss =  158.85\n",
      "training :  1992  accuracy =   0.5600  loss =  160.004\n",
      "testing  :  1992  accuracy =   0.5852  loss =  158.822\n",
      "training :  1993  accuracy =   0.5900  loss =  158.566\n",
      "testing  :  1993  accuracy =   0.5850  loss =  158.831\n",
      "training :  1994  accuracy =   0.4900  loss =  159.518\n",
      "testing  :  1994  accuracy =   0.5842  loss =  158.866\n",
      "training :  1995  accuracy =   0.6200  loss =  157.403\n",
      "testing  :  1995  accuracy =   0.5845  loss =  158.936\n",
      "training :  1996  accuracy =   0.6900  loss =  155.344\n",
      "testing  :  1996  accuracy =   0.5841  loss =  159.027\n",
      "training :  1997  accuracy =   0.6900  loss =  154.665\n",
      "testing  :  1997  accuracy =   0.5840  loss =  159.132\n",
      "training :  1998  accuracy =   0.6300  loss =  157.563\n",
      "testing  :  1998  accuracy =   0.5840  loss =  159.205\n",
      "training :  1999  accuracy =   0.6700  loss =  158.357\n",
      "testing  :  1999  accuracy =   0.5838  loss =  159.243\n",
      "training :  2000  accuracy =   0.5400  loss =  159.66\n",
      "testing  :  2000  accuracy =   0.5842  loss =  159.276\n",
      "training :  2001  accuracy =   0.6000  loss =  158.654\n",
      "testing  :  2001  accuracy =   0.5839  loss =  159.257\n",
      "training :  2002  accuracy =   0.5500  loss =  159.047\n",
      "testing  :  2002  accuracy =   0.5845  loss =  159.278\n",
      "training :  2003  accuracy =   0.6200  loss =  158.22\n",
      "testing  :  2003  accuracy =   0.5845  loss =  159.199\n",
      "training :  2004  accuracy =   0.6500  loss =  155.979\n",
      "testing  :  2004  accuracy =   0.5850  loss =  159.125\n",
      "training :  2005  accuracy =   0.5500  loss =  156.244\n",
      "testing  :  2005  accuracy =   0.5843  loss =  159.088\n",
      "training :  2006  accuracy =   0.5600  loss =  157.688\n",
      "testing  :  2006  accuracy =   0.5848  loss =  159.062\n",
      "training :  2007  accuracy =   0.5200  loss =  158.922\n",
      "testing  :  2007  accuracy =   0.5848  loss =  159.025\n",
      "training :  2008  accuracy =   0.7200  loss =  155.532\n",
      "testing  :  2008  accuracy =   0.5854  loss =  159.031\n",
      "training :  2009  accuracy =   0.5800  loss =  158.764\n",
      "testing  :  2009  accuracy =   0.5866  loss =  159.062\n",
      "training :  2010  accuracy =   0.5700  loss =  156.072\n",
      "testing  :  2010  accuracy =   0.5879  loss =  159.086\n",
      "training :  2011  accuracy =   0.6300  loss =  157.24\n",
      "testing  :  2011  accuracy =   0.5896  loss =  159.145\n",
      "training :  2012  accuracy =   0.5500  loss =  160.225\n",
      "testing  :  2012  accuracy =   0.5892  loss =  159.142\n",
      "training :  2013  accuracy =   0.4900  loss =  159.495\n",
      "testing  :  2013  accuracy =   0.5906  loss =  159.187\n",
      "training :  2014  accuracy =   0.6600  loss =  156.83\n",
      "testing  :  2014  accuracy =   0.5917  loss =  159.241\n",
      "training :  2015  accuracy =   0.6400  loss =  158.827\n",
      "testing  :  2015  accuracy =   0.5923  loss =  159.302\n",
      "training :  2016  accuracy =   0.5500  loss =  156.321\n",
      "testing  :  2016  accuracy =   0.5932  loss =  159.354\n",
      "training :  2017  accuracy =   0.5800  loss =  159.009\n",
      "testing  :  2017  accuracy =   0.5934  loss =  159.401\n",
      "training :  2018  accuracy =   0.6000  loss =  160.009\n",
      "testing  :  2018  accuracy =   0.5938  loss =  159.451\n",
      "training :  2019  accuracy =   0.5900  loss =  156.911\n",
      "testing  :  2019  accuracy =   0.5934  loss =  159.488\n",
      "training :  2020  accuracy =   0.5800  loss =  157.522\n",
      "testing  :  2020  accuracy =   0.5933  loss =  159.462\n",
      "training :  2021  accuracy =   0.5900  loss =  159.099\n",
      "testing  :  2021  accuracy =   0.5937  loss =  159.357\n",
      "training :  2022  accuracy =   0.7000  loss =  156.853\n",
      "testing  :  2022  accuracy =   0.5934  loss =  159.235\n",
      "training :  2023  accuracy =   0.5800  loss =  158.69\n",
      "testing  :  2023  accuracy =   0.5938  loss =  159.146\n",
      "training :  2024  accuracy =   0.6300  loss =  157.742\n",
      "testing  :  2024  accuracy =   0.5938  loss =  159.079\n",
      "training :  2025  accuracy =   0.6600  loss =  156.646\n",
      "testing  :  2025  accuracy =   0.5948  loss =  159.02\n",
      "training :  2026  accuracy =   0.6900  loss =  156.76\n",
      "testing  :  2026  accuracy =   0.5945  loss =  158.98\n",
      "training :  2027  accuracy =   0.6500  loss =  161.671\n",
      "testing  :  2027  accuracy =   0.5946  loss =  158.948\n",
      "training :  2028  accuracy =   0.4500  loss =  159.406\n",
      "testing  :  2028  accuracy =   0.5946  loss =  158.926\n",
      "training :  2029  accuracy =   0.6000  loss =  161.03\n",
      "testing  :  2029  accuracy =   0.5936  loss =  158.939\n",
      "training :  2030  accuracy =   0.5500  loss =  160.75\n",
      "testing  :  2030  accuracy =   0.5924  loss =  159.0\n",
      "training :  2031  accuracy =   0.5500  loss =  158.359\n",
      "testing  :  2031  accuracy =   0.5922  loss =  159.094\n",
      "training :  2032  accuracy =   0.5600  loss =  160.085\n",
      "testing  :  2032  accuracy =   0.5927  loss =  159.153\n",
      "training :  2033  accuracy =   0.6200  loss =  159.018\n",
      "testing  :  2033  accuracy =   0.5928  loss =  159.205\n",
      "training :  2034  accuracy =   0.6000  loss =  160.712\n",
      "testing  :  2034  accuracy =   0.5941  loss =  159.381\n",
      "training :  2035  accuracy =   0.6400  loss =  159.306\n",
      "testing  :  2035  accuracy =   0.5939  loss =  159.426\n",
      "training :  2036  accuracy =   0.5500  loss =  159.272\n",
      "testing  :  2036  accuracy =   0.5927  loss =  159.405\n",
      "training :  2037  accuracy =   0.6400  loss =  160.169\n",
      "testing  :  2037  accuracy =   0.5914  loss =  159.411\n",
      "training :  2038  accuracy =   0.5300  loss =  160.305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2038  accuracy =   0.5914  loss =  159.432\n",
      "training :  2039  accuracy =   0.6300  loss =  158.763\n",
      "testing  :  2039  accuracy =   0.5921  loss =  159.286\n",
      "training :  2040  accuracy =   0.4800  loss =  159.868\n",
      "testing  :  2040  accuracy =   0.5925  loss =  159.203\n",
      "training :  2041  accuracy =   0.6100  loss =  157.598\n",
      "testing  :  2041  accuracy =   0.5936  loss =  159.124\n",
      "training :  2042  accuracy =   0.6100  loss =  157.61\n",
      "testing  :  2042  accuracy =   0.5946  loss =  159.04\n",
      "training :  2043  accuracy =   0.6300  loss =  154.708\n",
      "testing  :  2043  accuracy =   0.5953  loss =  159.033\n",
      "training :  2044  accuracy =   0.6300  loss =  157.505\n",
      "testing  :  2044  accuracy =   0.5952  loss =  159.086\n",
      "training :  2045  accuracy =   0.5500  loss =  161.587\n",
      "testing  :  2045  accuracy =   0.5953  loss =  159.158\n",
      "training :  2046  accuracy =   0.6200  loss =  157.703\n",
      "testing  :  2046  accuracy =   0.5949  loss =  159.207\n",
      "training :  2047  accuracy =   0.6600  loss =  156.823\n",
      "testing  :  2047  accuracy =   0.5950  loss =  159.269\n",
      "training :  2048  accuracy =   0.6800  loss =  154.84\n",
      "testing  :  2048  accuracy =   0.5974  loss =  159.29\n",
      "training :  2049  accuracy =   0.5700  loss =  157.871\n",
      "testing  :  2049  accuracy =   0.6001  loss =  159.313\n",
      "training :  2050  accuracy =   0.6000  loss =  158.505\n",
      "testing  :  2050  accuracy =   0.6036  loss =  159.335\n",
      "training :  2051  accuracy =   0.5800  loss =  158.505\n",
      "testing  :  2051  accuracy =   0.6089  loss =  159.332\n",
      "training :  2052  accuracy =   0.7000  loss =  155.731\n",
      "testing  :  2052  accuracy =   0.6140  loss =  159.328\n",
      "training :  2053  accuracy =   0.6600  loss =  158.803\n",
      "testing  :  2053  accuracy =   0.6189  loss =  159.321\n",
      "training :  2054  accuracy =   0.6600  loss =  159.472\n",
      "testing  :  2054  accuracy =   0.6177  loss =  159.287\n",
      "training :  2055  accuracy =   0.6600  loss =  158.104\n",
      "testing  :  2055  accuracy =   0.6193  loss =  159.293\n",
      "training :  2056  accuracy =   0.6700  loss =  157.52\n",
      "testing  :  2056  accuracy =   0.6199  loss =  159.307\n",
      "training :  2057  accuracy =   0.6700  loss =  158.382\n",
      "testing  :  2057  accuracy =   0.6195  loss =  159.305\n",
      "training :  2058  accuracy =   0.6600  loss =  159.972\n",
      "testing  :  2058  accuracy =   0.6220  loss =  159.307\n",
      "training :  2059  accuracy =   0.5500  loss =  161.94\n",
      "testing  :  2059  accuracy =   0.6210  loss =  159.287\n",
      "training :  2060  accuracy =   0.7000  loss =  156.758\n",
      "testing  :  2060  accuracy =   0.6209  loss =  159.247\n",
      "training :  2061  accuracy =   0.6700  loss =  159.388\n",
      "testing  :  2061  accuracy =   0.6206  loss =  159.2\n",
      "training :  2062  accuracy =   0.7000  loss =  157.687\n",
      "testing  :  2062  accuracy =   0.6187  loss =  159.16\n",
      "training :  2063  accuracy =   0.6300  loss =  158.357\n",
      "testing  :  2063  accuracy =   0.6084  loss =  159.142\n",
      "training :  2064  accuracy =   0.5900  loss =  158.292\n",
      "testing  :  2064  accuracy =   0.5963  loss =  159.115\n",
      "training :  2065  accuracy =   0.6900  loss =  156.071\n",
      "testing  :  2065  accuracy =   0.5939  loss =  159.079\n",
      "training :  2066  accuracy =   0.6100  loss =  156.008\n",
      "testing  :  2066  accuracy =   0.5954  loss =  159.044\n",
      "training :  2067  accuracy =   0.6300  loss =  157.789\n",
      "testing  :  2067  accuracy =   0.5982  loss =  159.061\n",
      "training :  2068  accuracy =   0.5400  loss =  160.066\n",
      "testing  :  2068  accuracy =   0.6054  loss =  159.117\n",
      "training :  2069  accuracy =   0.6700  loss =  158.638\n",
      "testing  :  2069  accuracy =   0.6048  loss =  159.125\n",
      "training :  2070  accuracy =   0.6700  loss =  160.291\n",
      "testing  :  2070  accuracy =   0.6025  loss =  159.082\n",
      "training :  2071  accuracy =   0.6800  loss =  155.679\n",
      "testing  :  2071  accuracy =   0.5924  loss =  159.038\n",
      "training :  2072  accuracy =   0.5500  loss =  159.045\n",
      "testing  :  2072  accuracy =   0.5909  loss =  159.012\n",
      "training :  2073  accuracy =   0.5800  loss =  158.465\n",
      "testing  :  2073  accuracy =   0.5904  loss =  159.029\n",
      "training :  2074  accuracy =   0.6700  loss =  159.401\n",
      "testing  :  2074  accuracy =   0.5901  loss =  159.081\n",
      "training :  2075  accuracy =   0.5700  loss =  159.182\n",
      "testing  :  2075  accuracy =   0.5897  loss =  159.117\n",
      "training :  2076  accuracy =   0.6200  loss =  157.316\n",
      "testing  :  2076  accuracy =   0.5892  loss =  159.149\n",
      "training :  2077  accuracy =   0.6300  loss =  155.993\n",
      "testing  :  2077  accuracy =   0.5904  loss =  159.162\n",
      "training :  2078  accuracy =   0.6500  loss =  156.854\n",
      "testing  :  2078  accuracy =   0.5901  loss =  159.148\n",
      "training :  2079  accuracy =   0.5800  loss =  159.94\n",
      "testing  :  2079  accuracy =   0.5902  loss =  159.152\n",
      "training :  2080  accuracy =   0.4900  loss =  162.427\n",
      "testing  :  2080  accuracy =   0.5898  loss =  159.15\n",
      "training :  2081  accuracy =   0.6600  loss =  157.054\n",
      "testing  :  2081  accuracy =   0.5882  loss =  159.181\n",
      "training :  2082  accuracy =   0.6000  loss =  157.097\n",
      "testing  :  2082  accuracy =   0.5878  loss =  159.22\n",
      "training :  2083  accuracy =   0.6600  loss =  155.181\n",
      "testing  :  2083  accuracy =   0.5876  loss =  159.219\n",
      "training :  2084  accuracy =   0.6400  loss =  159.248\n",
      "testing  :  2084  accuracy =   0.5873  loss =  159.217\n",
      "training :  2085  accuracy =   0.6400  loss =  156.914\n",
      "testing  :  2085  accuracy =   0.5883  loss =  159.201\n",
      "training :  2086  accuracy =   0.6100  loss =  160.35\n",
      "testing  :  2086  accuracy =   0.5889  loss =  159.2\n",
      "training :  2087  accuracy =   0.6300  loss =  159.434\n",
      "testing  :  2087  accuracy =   0.5901  loss =  159.222\n",
      "training :  2088  accuracy =   0.6500  loss =  155.866\n",
      "testing  :  2088  accuracy =   0.5901  loss =  159.215\n",
      "training :  2089  accuracy =   0.6200  loss =  155.048\n",
      "testing  :  2089  accuracy =   0.5898  loss =  159.188\n",
      "training :  2090  accuracy =   0.6000  loss =  160.923\n",
      "testing  :  2090  accuracy =   0.5902  loss =  159.126\n",
      "training :  2091  accuracy =   0.5700  loss =  158.127\n",
      "testing  :  2091  accuracy =   0.5905  loss =  159.088\n",
      "training :  2092  accuracy =   0.5900  loss =  159.722\n",
      "testing  :  2092  accuracy =   0.5909  loss =  159.016\n",
      "training :  2093  accuracy =   0.6100  loss =  158.917\n",
      "testing  :  2093  accuracy =   0.5921  loss =  158.93\n",
      "training :  2094  accuracy =   0.5900  loss =  158.972\n",
      "testing  :  2094  accuracy =   0.5930  loss =  158.859\n",
      "training :  2095  accuracy =   0.6600  loss =  157.731\n",
      "testing  :  2095  accuracy =   0.5947  loss =  158.796\n",
      "training :  2096  accuracy =   0.6300  loss =  155.21\n",
      "testing  :  2096  accuracy =   0.5944  loss =  158.767\n",
      "training :  2097  accuracy =   0.5700  loss =  160.658\n",
      "testing  :  2097  accuracy =   0.5954  loss =  158.755\n",
      "training :  2098  accuracy =   0.5900  loss =  157.849\n",
      "testing  :  2098  accuracy =   0.5959  loss =  158.721\n",
      "training :  2099  accuracy =   0.7000  loss =  156.221\n",
      "testing  :  2099  accuracy =   0.5968  loss =  158.717\n",
      "training :  2100  accuracy =   0.5900  loss =  157.466\n",
      "testing  :  2100  accuracy =   0.5972  loss =  158.735\n",
      "training :  2101  accuracy =   0.5800  loss =  156.312\n",
      "testing  :  2101  accuracy =   0.5979  loss =  158.776\n",
      "training :  2102  accuracy =   0.5800  loss =  157.501\n",
      "testing  :  2102  accuracy =   0.5987  loss =  158.832\n",
      "training :  2103  accuracy =   0.5400  loss =  157.094\n",
      "testing  :  2103  accuracy =   0.5989  loss =  158.875\n",
      "training :  2104  accuracy =   0.5900  loss =  157.867\n",
      "testing  :  2104  accuracy =   0.6003  loss =  158.904\n",
      "training :  2105  accuracy =   0.6700  loss =  156.839\n",
      "testing  :  2105  accuracy =   0.5990  loss =  158.857\n",
      "training :  2106  accuracy =   0.5600  loss =  157.499\n",
      "testing  :  2106  accuracy =   0.5993  loss =  158.835\n",
      "training :  2107  accuracy =   0.5700  loss =  159.978\n",
      "testing  :  2107  accuracy =   0.5988  loss =  158.837\n",
      "training :  2108  accuracy =   0.5300  loss =  157.94\n",
      "testing  :  2108  accuracy =   0.5992  loss =  158.83\n",
      "training :  2109  accuracy =   0.4500  loss =  160.966\n",
      "testing  :  2109  accuracy =   0.5993  loss =  158.824\n",
      "training :  2110  accuracy =   0.5900  loss =  160.851\n",
      "testing  :  2110  accuracy =   0.5999  loss =  158.827\n",
      "training :  2111  accuracy =   0.6700  loss =  156.261\n",
      "testing  :  2111  accuracy =   0.5989  loss =  158.827\n",
      "training :  2112  accuracy =   0.5700  loss =  157.411\n",
      "testing  :  2112  accuracy =   0.5988  loss =  158.793\n",
      "training :  2113  accuracy =   0.5400  loss =  158.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2113  accuracy =   0.5991  loss =  158.749\n",
      "training :  2114  accuracy =   0.6000  loss =  158.756\n",
      "testing  :  2114  accuracy =   0.5979  loss =  158.727\n",
      "training :  2115  accuracy =   0.5900  loss =  160.867\n",
      "testing  :  2115  accuracy =   0.5971  loss =  158.714\n",
      "training :  2116  accuracy =   0.5500  loss =  159.875\n",
      "testing  :  2116  accuracy =   0.5961  loss =  158.708\n",
      "training :  2117  accuracy =   0.5500  loss =  157.572\n",
      "testing  :  2117  accuracy =   0.5966  loss =  158.714\n",
      "training :  2118  accuracy =   0.5300  loss =  157.599\n",
      "testing  :  2118  accuracy =   0.5954  loss =  158.735\n",
      "training :  2119  accuracy =   0.5700  loss =  158.507\n",
      "testing  :  2119  accuracy =   0.5954  loss =  158.769\n",
      "training :  2120  accuracy =   0.6900  loss =  158.786\n",
      "testing  :  2120  accuracy =   0.5949  loss =  158.803\n",
      "training :  2121  accuracy =   0.6400  loss =  155.933\n",
      "testing  :  2121  accuracy =   0.5947  loss =  158.822\n",
      "training :  2122  accuracy =   0.6700  loss =  155.956\n",
      "testing  :  2122  accuracy =   0.5947  loss =  158.836\n",
      "training :  2123  accuracy =   0.6500  loss =  158.647\n",
      "testing  :  2123  accuracy =   0.5950  loss =  158.821\n",
      "training :  2124  accuracy =   0.6200  loss =  158.224\n",
      "testing  :  2124  accuracy =   0.5946  loss =  158.776\n",
      "training :  2125  accuracy =   0.6200  loss =  162.589\n",
      "testing  :  2125  accuracy =   0.5956  loss =  158.736\n",
      "training :  2126  accuracy =   0.5500  loss =  160.121\n",
      "testing  :  2126  accuracy =   0.5958  loss =  158.666\n",
      "training :  2127  accuracy =   0.5600  loss =  158.721\n",
      "testing  :  2127  accuracy =   0.5962  loss =  158.635\n",
      "training :  2128  accuracy =   0.6600  loss =  156.718\n",
      "testing  :  2128  accuracy =   0.5979  loss =  158.631\n",
      "training :  2129  accuracy =   0.5200  loss =  158.038\n",
      "testing  :  2129  accuracy =   0.5976  loss =  158.644\n",
      "training :  2130  accuracy =   0.6200  loss =  157.961\n",
      "testing  :  2130  accuracy =   0.5975  loss =  158.672\n",
      "training :  2131  accuracy =   0.5700  loss =  159.175\n",
      "testing  :  2131  accuracy =   0.5970  loss =  158.721\n",
      "training :  2132  accuracy =   0.6000  loss =  156.619\n",
      "testing  :  2132  accuracy =   0.5967  loss =  158.777\n",
      "training :  2133  accuracy =   0.6000  loss =  157.148\n",
      "testing  :  2133  accuracy =   0.5963  loss =  158.841\n",
      "training :  2134  accuracy =   0.5700  loss =  161.802\n",
      "testing  :  2134  accuracy =   0.5962  loss =  158.897\n",
      "training :  2135  accuracy =   0.6000  loss =  157.509\n",
      "testing  :  2135  accuracy =   0.5953  loss =  158.937\n",
      "training :  2136  accuracy =   0.5900  loss =  162.152\n",
      "testing  :  2136  accuracy =   0.5952  loss =  158.936\n",
      "training :  2137  accuracy =   0.6400  loss =  158.684\n",
      "testing  :  2137  accuracy =   0.5948  loss =  158.959\n",
      "training :  2138  accuracy =   0.5300  loss =  161.094\n",
      "testing  :  2138  accuracy =   0.5946  loss =  158.955\n",
      "training :  2139  accuracy =   0.6400  loss =  157.927\n",
      "testing  :  2139  accuracy =   0.5947  loss =  158.938\n",
      "training :  2140  accuracy =   0.5100  loss =  162.159\n",
      "testing  :  2140  accuracy =   0.5948  loss =  158.88\n",
      "training :  2141  accuracy =   0.5500  loss =  159.757\n",
      "testing  :  2141  accuracy =   0.5958  loss =  158.759\n",
      "training :  2142  accuracy =   0.5200  loss =  158.21\n",
      "testing  :  2142  accuracy =   0.5957  loss =  158.692\n",
      "training :  2143  accuracy =   0.5200  loss =  158.356\n",
      "testing  :  2143  accuracy =   0.5937  loss =  158.673\n",
      "training :  2144  accuracy =   0.6000  loss =  159.481\n",
      "testing  :  2144  accuracy =   0.5926  loss =  158.73\n",
      "training :  2145  accuracy =   0.5900  loss =  157.048\n",
      "testing  :  2145  accuracy =   0.5899  loss =  158.865\n",
      "training :  2146  accuracy =   0.6000  loss =  157.589\n",
      "testing  :  2146  accuracy =   0.5887  loss =  159.04\n",
      "training :  2147  accuracy =   0.6800  loss =  157.153\n",
      "testing  :  2147  accuracy =   0.5866  loss =  159.255\n",
      "training :  2148  accuracy =   0.5300  loss =  160.234\n",
      "testing  :  2148  accuracy =   0.5843  loss =  159.438\n",
      "training :  2149  accuracy =   0.6000  loss =  158.817\n",
      "testing  :  2149  accuracy =   0.5837  loss =  159.54\n",
      "training :  2150  accuracy =   0.6000  loss =  158.293\n",
      "testing  :  2150  accuracy =   0.5834  loss =  159.573\n",
      "training :  2151  accuracy =   0.5400  loss =  158.553\n",
      "testing  :  2151  accuracy =   0.5845  loss =  159.398\n",
      "training :  2152  accuracy =   0.5800  loss =  158.205\n",
      "testing  :  2152  accuracy =   0.5888  loss =  158.981\n",
      "training :  2153  accuracy =   0.5700  loss =  158.34\n",
      "testing  :  2153  accuracy =   0.5914  loss =  158.711\n",
      "training :  2154  accuracy =   0.6100  loss =  159.196\n",
      "testing  :  2154  accuracy =   0.5924  loss =  158.636\n",
      "training :  2155  accuracy =   0.5600  loss =  158.088\n",
      "testing  :  2155  accuracy =   0.5933  loss =  158.622\n",
      "training :  2156  accuracy =   0.6700  loss =  157.255\n",
      "testing  :  2156  accuracy =   0.5947  loss =  158.624\n",
      "training :  2157  accuracy =   0.6800  loss =  161.248\n",
      "testing  :  2157  accuracy =   0.5948  loss =  158.637\n",
      "training :  2158  accuracy =   0.6000  loss =  157.748\n",
      "testing  :  2158  accuracy =   0.5948  loss =  158.653\n",
      "training :  2159  accuracy =   0.5500  loss =  159.611\n",
      "testing  :  2159  accuracy =   0.5943  loss =  158.668\n",
      "training :  2160  accuracy =   0.6200  loss =  158.201\n",
      "testing  :  2160  accuracy =   0.5940  loss =  158.668\n",
      "training :  2161  accuracy =   0.6900  loss =  155.438\n",
      "testing  :  2161  accuracy =   0.5945  loss =  158.711\n",
      "training :  2162  accuracy =   0.6200  loss =  156.351\n",
      "testing  :  2162  accuracy =   0.5941  loss =  158.751\n",
      "training :  2163  accuracy =   0.5800  loss =  158.862\n",
      "testing  :  2163  accuracy =   0.5945  loss =  158.803\n",
      "training :  2164  accuracy =   0.6600  loss =  158.011\n",
      "testing  :  2164  accuracy =   0.5942  loss =  158.853\n",
      "training :  2165  accuracy =   0.5300  loss =  159.516\n",
      "testing  :  2165  accuracy =   0.5946  loss =  158.87\n",
      "training :  2166  accuracy =   0.5700  loss =  160.755\n",
      "testing  :  2166  accuracy =   0.5949  loss =  158.815\n",
      "training :  2167  accuracy =   0.5600  loss =  158.16\n",
      "testing  :  2167  accuracy =   0.5956  loss =  158.746\n",
      "training :  2168  accuracy =   0.6000  loss =  158.173\n",
      "testing  :  2168  accuracy =   0.5958  loss =  158.703\n",
      "training :  2169  accuracy =   0.6000  loss =  158.33\n",
      "testing  :  2169  accuracy =   0.5962  loss =  158.685\n",
      "training :  2170  accuracy =   0.5300  loss =  159.24\n",
      "testing  :  2170  accuracy =   0.5969  loss =  158.711\n",
      "training :  2171  accuracy =   0.6400  loss =  157.101\n",
      "testing  :  2171  accuracy =   0.5967  loss =  158.731\n",
      "training :  2172  accuracy =   0.6600  loss =  156.555\n",
      "testing  :  2172  accuracy =   0.5965  loss =  158.731\n",
      "training :  2173  accuracy =   0.5400  loss =  160.451\n",
      "testing  :  2173  accuracy =   0.5959  loss =  158.731\n",
      "training :  2174  accuracy =   0.5700  loss =  161.329\n",
      "testing  :  2174  accuracy =   0.5960  loss =  158.744\n",
      "training :  2175  accuracy =   0.6800  loss =  157.308\n",
      "testing  :  2175  accuracy =   0.5953  loss =  158.739\n",
      "training :  2176  accuracy =   0.5900  loss =  158.577\n",
      "testing  :  2176  accuracy =   0.5954  loss =  158.746\n",
      "training :  2177  accuracy =   0.6100  loss =  157.93\n",
      "testing  :  2177  accuracy =   0.5949  loss =  158.754\n",
      "training :  2178  accuracy =   0.6500  loss =  158.551\n",
      "testing  :  2178  accuracy =   0.5947  loss =  158.763\n",
      "training :  2179  accuracy =   0.5000  loss =  159.148\n",
      "testing  :  2179  accuracy =   0.5936  loss =  158.714\n",
      "training :  2180  accuracy =   0.5600  loss =  158.14\n",
      "testing  :  2180  accuracy =   0.5932  loss =  158.7\n",
      "training :  2181  accuracy =   0.6400  loss =  158.591\n",
      "testing  :  2181  accuracy =   0.5920  loss =  158.702\n",
      "training :  2182  accuracy =   0.6500  loss =  157.74\n",
      "testing  :  2182  accuracy =   0.5914  loss =  158.721\n",
      "training :  2183  accuracy =   0.7700  loss =  156.678\n",
      "testing  :  2183  accuracy =   0.5908  loss =  158.745\n",
      "training :  2184  accuracy =   0.5600  loss =  157.694\n",
      "testing  :  2184  accuracy =   0.5905  loss =  158.766\n",
      "training :  2185  accuracy =   0.5600  loss =  159.225\n",
      "testing  :  2185  accuracy =   0.5908  loss =  158.793\n",
      "training :  2186  accuracy =   0.5300  loss =  160.437\n",
      "testing  :  2186  accuracy =   0.5907  loss =  158.831\n",
      "training :  2187  accuracy =   0.5600  loss =  158.403\n",
      "testing  :  2187  accuracy =   0.5905  loss =  158.893\n",
      "training :  2188  accuracy =   0.5800  loss =  157.708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2188  accuracy =   0.5889  loss =  158.987\n",
      "training :  2189  accuracy =   0.6700  loss =  157.678\n",
      "testing  :  2189  accuracy =   0.5881  loss =  159.033\n",
      "training :  2190  accuracy =   0.5400  loss =  161.787\n",
      "testing  :  2190  accuracy =   0.5874  loss =  159.097\n",
      "training :  2191  accuracy =   0.6300  loss =  158.74\n",
      "testing  :  2191  accuracy =   0.5883  loss =  158.998\n",
      "training :  2192  accuracy =   0.6500  loss =  157.13\n",
      "testing  :  2192  accuracy =   0.5901  loss =  158.909\n",
      "training :  2193  accuracy =   0.5900  loss =  158.047\n",
      "testing  :  2193  accuracy =   0.5911  loss =  158.842\n",
      "training :  2194  accuracy =   0.7000  loss =  154.352\n",
      "testing  :  2194  accuracy =   0.5912  loss =  158.846\n",
      "training :  2195  accuracy =   0.6500  loss =  158.556\n",
      "testing  :  2195  accuracy =   0.5913  loss =  158.861\n",
      "training :  2196  accuracy =   0.5600  loss =  158.66\n",
      "testing  :  2196  accuracy =   0.5916  loss =  158.846\n",
      "training :  2197  accuracy =   0.6200  loss =  157.23\n",
      "testing  :  2197  accuracy =   0.5926  loss =  158.828\n",
      "training :  2198  accuracy =   0.5600  loss =  160.235\n",
      "testing  :  2198  accuracy =   0.5929  loss =  158.805\n",
      "training :  2199  accuracy =   0.6300  loss =  158.608\n",
      "testing  :  2199  accuracy =   0.5927  loss =  158.848\n",
      "training :  2200  accuracy =   0.6200  loss =  157.086\n",
      "testing  :  2200  accuracy =   0.5923  loss =  158.902\n",
      "training :  2201  accuracy =   0.5700  loss =  157.517\n",
      "testing  :  2201  accuracy =   0.5924  loss =  158.966\n",
      "training :  2202  accuracy =   0.5800  loss =  157.342\n",
      "testing  :  2202  accuracy =   0.5921  loss =  158.982\n",
      "training :  2203  accuracy =   0.6400  loss =  156.898\n",
      "testing  :  2203  accuracy =   0.5916  loss =  159.005\n",
      "training :  2204  accuracy =   0.6100  loss =  159.861\n",
      "testing  :  2204  accuracy =   0.5930  loss =  158.913\n",
      "training :  2205  accuracy =   0.5700  loss =  157.399\n",
      "testing  :  2205  accuracy =   0.5942  loss =  158.831\n",
      "training :  2206  accuracy =   0.5800  loss =  157.521\n",
      "testing  :  2206  accuracy =   0.5945  loss =  158.751\n",
      "training :  2207  accuracy =   0.5500  loss =  160.008\n",
      "testing  :  2207  accuracy =   0.5950  loss =  158.682\n",
      "training :  2208  accuracy =   0.6500  loss =  157.085\n",
      "testing  :  2208  accuracy =   0.5947  loss =  158.656\n",
      "training :  2209  accuracy =   0.6400  loss =  155.517\n",
      "testing  :  2209  accuracy =   0.5931  loss =  158.674\n",
      "training :  2210  accuracy =   0.5600  loss =  158.937\n",
      "testing  :  2210  accuracy =   0.5925  loss =  158.727\n",
      "training :  2211  accuracy =   0.6300  loss =  156.394\n",
      "testing  :  2211  accuracy =   0.5915  loss =  158.82\n",
      "training :  2212  accuracy =   0.6300  loss =  160.135\n",
      "testing  :  2212  accuracy =   0.5903  loss =  158.926\n",
      "training :  2213  accuracy =   0.6300  loss =  156.233\n",
      "testing  :  2213  accuracy =   0.5886  loss =  159.041\n",
      "training :  2214  accuracy =   0.6100  loss =  158.836\n",
      "testing  :  2214  accuracy =   0.5874  loss =  159.118\n",
      "training :  2215  accuracy =   0.5900  loss =  157.783\n",
      "testing  :  2215  accuracy =   0.5870  loss =  159.128\n",
      "training :  2216  accuracy =   0.5800  loss =  157.077\n",
      "testing  :  2216  accuracy =   0.5869  loss =  159.131\n",
      "training :  2217  accuracy =   0.6200  loss =  157.287\n",
      "testing  :  2217  accuracy =   0.5868  loss =  159.132\n",
      "training :  2218  accuracy =   0.5600  loss =  157.723\n",
      "testing  :  2218  accuracy =   0.5868  loss =  159.141\n",
      "training :  2219  accuracy =   0.6200  loss =  157.034\n",
      "testing  :  2219  accuracy =   0.5868  loss =  159.03\n",
      "training :  2220  accuracy =   0.6300  loss =  158.736\n",
      "testing  :  2220  accuracy =   0.5882  loss =  158.931\n",
      "training :  2221  accuracy =   0.6000  loss =  157.882\n",
      "testing  :  2221  accuracy =   0.5891  loss =  158.856\n",
      "training :  2222  accuracy =   0.4700  loss =  158.633\n",
      "testing  :  2222  accuracy =   0.5905  loss =  158.826\n",
      "training :  2223  accuracy =   0.5700  loss =  159.239\n",
      "testing  :  2223  accuracy =   0.5905  loss =  158.785\n",
      "training :  2224  accuracy =   0.6000  loss =  158.577\n",
      "testing  :  2224  accuracy =   0.5907  loss =  158.764\n",
      "training :  2225  accuracy =   0.4900  loss =  160.5\n",
      "testing  :  2225  accuracy =   0.5911  loss =  158.803\n",
      "training :  2226  accuracy =   0.6000  loss =  158.648\n",
      "testing  :  2226  accuracy =   0.5910  loss =  158.923\n",
      "training :  2227  accuracy =   0.5300  loss =  157.792\n",
      "testing  :  2227  accuracy =   0.5898  loss =  159.095\n",
      "training :  2228  accuracy =   0.5800  loss =  161.391\n",
      "testing  :  2228  accuracy =   0.5899  loss =  159.237\n",
      "training :  2229  accuracy =   0.5800  loss =  157.559\n",
      "testing  :  2229  accuracy =   0.5896  loss =  159.323\n",
      "training :  2230  accuracy =   0.6900  loss =  155.216\n",
      "testing  :  2230  accuracy =   0.5887  loss =  159.45\n",
      "training :  2231  accuracy =   0.5800  loss =  159.847\n",
      "testing  :  2231  accuracy =   0.5882  loss =  159.503\n",
      "training :  2232  accuracy =   0.5600  loss =  161.629\n",
      "testing  :  2232  accuracy =   0.5879  loss =  159.552\n",
      "training :  2233  accuracy =   0.5600  loss =  159.15\n",
      "testing  :  2233  accuracy =   0.5883  loss =  159.554\n",
      "training :  2234  accuracy =   0.5500  loss =  156.746\n",
      "testing  :  2234  accuracy =   0.5881  loss =  159.542\n",
      "training :  2235  accuracy =   0.5700  loss =  159.668\n",
      "testing  :  2235  accuracy =   0.5880  loss =  159.554\n",
      "training :  2236  accuracy =   0.6400  loss =  157.36\n",
      "testing  :  2236  accuracy =   0.5897  loss =  159.453\n",
      "training :  2237  accuracy =   0.5700  loss =  159.405\n",
      "testing  :  2237  accuracy =   0.5908  loss =  159.408\n",
      "training :  2238  accuracy =   0.5900  loss =  159.19\n",
      "testing  :  2238  accuracy =   0.5911  loss =  159.39\n",
      "training :  2239  accuracy =   0.6000  loss =  157.719\n",
      "testing  :  2239  accuracy =   0.5908  loss =  159.339\n",
      "training :  2240  accuracy =   0.6300  loss =  157.64\n",
      "testing  :  2240  accuracy =   0.5910  loss =  159.251\n",
      "training :  2241  accuracy =   0.6800  loss =  156.807\n",
      "testing  :  2241  accuracy =   0.5910  loss =  159.187\n",
      "training :  2242  accuracy =   0.6200  loss =  158.116\n",
      "testing  :  2242  accuracy =   0.5896  loss =  159.204\n",
      "training :  2243  accuracy =   0.6100  loss =  158.57\n",
      "testing  :  2243  accuracy =   0.5899  loss =  159.117\n",
      "training :  2244  accuracy =   0.5300  loss =  159.891\n",
      "testing  :  2244  accuracy =   0.5896  loss =  159.052\n",
      "training :  2245  accuracy =   0.6100  loss =  157.24\n",
      "testing  :  2245  accuracy =   0.5889  loss =  159.003\n",
      "training :  2246  accuracy =   0.6000  loss =  157.476\n",
      "testing  :  2246  accuracy =   0.5890  loss =  158.933\n",
      "training :  2247  accuracy =   0.6200  loss =  158.112\n",
      "testing  :  2247  accuracy =   0.5898  loss =  158.876\n",
      "training :  2248  accuracy =   0.6400  loss =  158.573\n",
      "testing  :  2248  accuracy =   0.5904  loss =  158.831\n",
      "training :  2249  accuracy =   0.6400  loss =  157.498\n",
      "testing  :  2249  accuracy =   0.5909  loss =  158.782\n",
      "training :  2250  accuracy =   0.6500  loss =  156.043\n",
      "testing  :  2250  accuracy =   0.5910  loss =  158.741\n",
      "training :  2251  accuracy =   0.5900  loss =  159.486\n",
      "testing  :  2251  accuracy =   0.5912  loss =  158.708\n",
      "training :  2252  accuracy =   0.5200  loss =  163.208\n",
      "testing  :  2252  accuracy =   0.5918  loss =  158.694\n",
      "training :  2253  accuracy =   0.5400  loss =  157.625\n",
      "testing  :  2253  accuracy =   0.5921  loss =  158.681\n",
      "training :  2254  accuracy =   0.6400  loss =  157.274\n",
      "testing  :  2254  accuracy =   0.5925  loss =  158.66\n",
      "training :  2255  accuracy =   0.5600  loss =  157.847\n",
      "testing  :  2255  accuracy =   0.5934  loss =  158.653\n",
      "training :  2256  accuracy =   0.6300  loss =  158.243\n",
      "testing  :  2256  accuracy =   0.5930  loss =  158.65\n",
      "training :  2257  accuracy =   0.5200  loss =  159.955\n",
      "testing  :  2257  accuracy =   0.5928  loss =  158.656\n",
      "training :  2258  accuracy =   0.6200  loss =  157.581\n",
      "testing  :  2258  accuracy =   0.5924  loss =  158.674\n",
      "training :  2259  accuracy =   0.6200  loss =  160.235\n",
      "testing  :  2259  accuracy =   0.5927  loss =  158.705\n",
      "training :  2260  accuracy =   0.6700  loss =  154.994\n",
      "testing  :  2260  accuracy =   0.5931  loss =  158.743\n",
      "training :  2261  accuracy =   0.6000  loss =  158.171\n",
      "testing  :  2261  accuracy =   0.5936  loss =  158.785\n",
      "training :  2262  accuracy =   0.5500  loss =  157.668\n",
      "testing  :  2262  accuracy =   0.5936  loss =  158.792\n",
      "training :  2263  accuracy =   0.5800  loss =  158.379\n",
      "testing  :  2263  accuracy =   0.5933  loss =  158.797\n",
      "training :  2264  accuracy =   0.6000  loss =  157.806\n",
      "testing  :  2264  accuracy =   0.5933  loss =  158.796\n",
      "training :  2265  accuracy =   0.6400  loss =  159.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2265  accuracy =   0.5928  loss =  158.768\n",
      "training :  2266  accuracy =   0.5200  loss =  158.056\n",
      "testing  :  2266  accuracy =   0.5928  loss =  158.725\n",
      "training :  2267  accuracy =   0.6600  loss =  156.779\n",
      "testing  :  2267  accuracy =   0.5926  loss =  158.702\n",
      "training :  2268  accuracy =   0.6200  loss =  158.517\n",
      "testing  :  2268  accuracy =   0.5924  loss =  158.692\n",
      "training :  2269  accuracy =   0.5800  loss =  162.207\n",
      "testing  :  2269  accuracy =   0.5921  loss =  158.693\n",
      "training :  2270  accuracy =   0.5900  loss =  161.392\n",
      "testing  :  2270  accuracy =   0.5917  loss =  158.708\n",
      "training :  2271  accuracy =   0.6700  loss =  158.109\n",
      "testing  :  2271  accuracy =   0.5916  loss =  158.73\n",
      "training :  2272  accuracy =   0.5900  loss =  160.093\n",
      "testing  :  2272  accuracy =   0.5912  loss =  158.753\n",
      "training :  2273  accuracy =   0.5500  loss =  160.758\n",
      "testing  :  2273  accuracy =   0.5906  loss =  158.779\n",
      "training :  2274  accuracy =   0.6000  loss =  155.209\n",
      "testing  :  2274  accuracy =   0.5900  loss =  158.812\n",
      "training :  2275  accuracy =   0.6200  loss =  155.806\n",
      "testing  :  2275  accuracy =   0.5900  loss =  158.846\n",
      "training :  2276  accuracy =   0.5700  loss =  159.438\n",
      "testing  :  2276  accuracy =   0.5898  loss =  158.841\n",
      "training :  2277  accuracy =   0.6000  loss =  157.206\n",
      "testing  :  2277  accuracy =   0.5897  loss =  158.834\n",
      "training :  2278  accuracy =   0.5700  loss =  157.985\n",
      "testing  :  2278  accuracy =   0.5896  loss =  158.818\n",
      "training :  2279  accuracy =   0.6000  loss =  159.104\n",
      "testing  :  2279  accuracy =   0.5900  loss =  158.799\n",
      "training :  2280  accuracy =   0.6200  loss =  158.998\n",
      "testing  :  2280  accuracy =   0.5902  loss =  158.774\n",
      "training :  2281  accuracy =   0.6500  loss =  158.735\n",
      "testing  :  2281  accuracy =   0.5908  loss =  158.744\n",
      "training :  2282  accuracy =   0.6300  loss =  156.012\n",
      "testing  :  2282  accuracy =   0.5914  loss =  158.72\n",
      "training :  2283  accuracy =   0.5600  loss =  158.807\n",
      "testing  :  2283  accuracy =   0.5916  loss =  158.692\n",
      "training :  2284  accuracy =   0.6100  loss =  159.113\n",
      "testing  :  2284  accuracy =   0.5918  loss =  158.737\n",
      "training :  2285  accuracy =   0.5800  loss =  157.997\n",
      "testing  :  2285  accuracy =   0.5916  loss =  158.824\n",
      "training :  2286  accuracy =   0.6500  loss =  158.4\n",
      "testing  :  2286  accuracy =   0.5917  loss =  158.941\n",
      "training :  2287  accuracy =   0.6000  loss =  156.647\n",
      "testing  :  2287  accuracy =   0.5917  loss =  159.059\n",
      "training :  2288  accuracy =   0.6200  loss =  160.321\n",
      "testing  :  2288  accuracy =   0.5914  loss =  159.17\n",
      "training :  2289  accuracy =   0.5800  loss =  157.619\n",
      "testing  :  2289  accuracy =   0.5920  loss =  159.295\n",
      "training :  2290  accuracy =   0.6100  loss =  157.635\n",
      "testing  :  2290  accuracy =   0.5921  loss =  159.348\n",
      "training :  2291  accuracy =   0.5000  loss =  160.541\n",
      "testing  :  2291  accuracy =   0.5933  loss =  159.297\n",
      "training :  2292  accuracy =   0.5700  loss =  163.277\n",
      "testing  :  2292  accuracy =   0.5936  loss =  159.179\n",
      "training :  2293  accuracy =   0.5700  loss =  160.993\n",
      "testing  :  2293  accuracy =   0.5942  loss =  159.029\n",
      "training :  2294  accuracy =   0.6100  loss =  159.275\n",
      "testing  :  2294  accuracy =   0.5945  loss =  158.935\n",
      "training :  2295  accuracy =   0.6400  loss =  156.246\n",
      "testing  :  2295  accuracy =   0.5952  loss =  158.865\n",
      "training :  2296  accuracy =   0.6600  loss =  158.456\n",
      "testing  :  2296  accuracy =   0.5946  loss =  158.811\n",
      "training :  2297  accuracy =   0.5400  loss =  159.994\n",
      "testing  :  2297  accuracy =   0.5948  loss =  158.791\n",
      "training :  2298  accuracy =   0.6300  loss =  156.749\n",
      "testing  :  2298  accuracy =   0.5938  loss =  158.77\n",
      "training :  2299  accuracy =   0.6200  loss =  158.193\n",
      "testing  :  2299  accuracy =   0.5944  loss =  158.759\n",
      "training :  2300  accuracy =   0.5300  loss =  159.423\n",
      "testing  :  2300  accuracy =   0.5940  loss =  158.757\n",
      "training :  2301  accuracy =   0.6400  loss =  158.237\n",
      "testing  :  2301  accuracy =   0.5934  loss =  158.742\n",
      "training :  2302  accuracy =   0.5600  loss =  158.711\n",
      "testing  :  2302  accuracy =   0.5935  loss =  158.723\n",
      "training :  2303  accuracy =   0.6100  loss =  159.127\n",
      "testing  :  2303  accuracy =   0.5926  loss =  158.739\n",
      "training :  2304  accuracy =   0.6700  loss =  156.92\n",
      "testing  :  2304  accuracy =   0.5921  loss =  158.788\n",
      "training :  2305  accuracy =   0.6400  loss =  156.693\n",
      "testing  :  2305  accuracy =   0.5927  loss =  158.826\n",
      "training :  2306  accuracy =   0.6500  loss =  157.084\n",
      "testing  :  2306  accuracy =   0.5927  loss =  158.864\n",
      "training :  2307  accuracy =   0.5600  loss =  158.56\n",
      "testing  :  2307  accuracy =   0.5942  loss =  158.866\n",
      "training :  2308  accuracy =   0.6000  loss =  161.479\n",
      "testing  :  2308  accuracy =   0.5968  loss =  158.811\n",
      "training :  2309  accuracy =   0.5400  loss =  158.133\n",
      "testing  :  2309  accuracy =   0.6022  loss =  158.707\n",
      "training :  2310  accuracy =   0.6200  loss =  158.238\n",
      "testing  :  2310  accuracy =   0.6078  loss =  158.633\n",
      "training :  2311  accuracy =   0.6100  loss =  157.313\n",
      "testing  :  2311  accuracy =   0.6152  loss =  158.603\n",
      "training :  2312  accuracy =   0.5800  loss =  158.313\n",
      "testing  :  2312  accuracy =   0.6278  loss =  158.607\n",
      "training :  2313  accuracy =   0.6600  loss =  159.03\n",
      "testing  :  2313  accuracy =   0.6368  loss =  158.637\n",
      "training :  2314  accuracy =   0.6000  loss =  158.368\n",
      "testing  :  2314  accuracy =   0.6449  loss =  158.694\n",
      "training :  2315  accuracy =   0.6800  loss =  157.685\n",
      "testing  :  2315  accuracy =   0.6494  loss =  158.767\n",
      "training :  2316  accuracy =   0.6300  loss =  156.25\n",
      "testing  :  2316  accuracy =   0.6500  loss =  158.854\n",
      "training :  2317  accuracy =   0.6700  loss =  158.854\n",
      "testing  :  2317  accuracy =   0.6489  loss =  158.896\n",
      "training :  2318  accuracy =   0.7200  loss =  159.788\n",
      "testing  :  2318  accuracy =   0.6409  loss =  158.899\n",
      "training :  2319  accuracy =   0.5900  loss =  158.494\n",
      "testing  :  2319  accuracy =   0.6253  loss =  158.79\n",
      "training :  2320  accuracy =   0.6100  loss =  159.074\n",
      "testing  :  2320  accuracy =   0.6138  loss =  158.743\n",
      "training :  2321  accuracy =   0.6300  loss =  158.097\n",
      "testing  :  2321  accuracy =   0.6141  loss =  158.774\n",
      "training :  2322  accuracy =   0.6600  loss =  158.484\n",
      "testing  :  2322  accuracy =   0.6125  loss =  158.837\n",
      "training :  2323  accuracy =   0.5600  loss =  157.892\n",
      "testing  :  2323  accuracy =   0.6109  loss =  158.916\n",
      "training :  2324  accuracy =   0.7400  loss =  154.696\n",
      "testing  :  2324  accuracy =   0.6127  loss =  158.956\n",
      "training :  2325  accuracy =   0.5700  loss =  165.228\n",
      "testing  :  2325  accuracy =   0.6087  loss =  158.933\n",
      "training :  2326  accuracy =   0.5300  loss =  160.2\n",
      "testing  :  2326  accuracy =   0.6077  loss =  158.876\n",
      "training :  2327  accuracy =   0.5600  loss =  158.958\n",
      "testing  :  2327  accuracy =   0.6062  loss =  158.768\n",
      "training :  2328  accuracy =   0.6600  loss =  155.798\n",
      "testing  :  2328  accuracy =   0.6029  loss =  158.639\n",
      "training :  2329  accuracy =   0.6000  loss =  160.662\n",
      "testing  :  2329  accuracy =   0.6022  loss =  158.623\n",
      "training :  2330  accuracy =   0.6100  loss =  157.823\n",
      "testing  :  2330  accuracy =   0.6008  loss =  158.666\n",
      "training :  2331  accuracy =   0.5600  loss =  157.433\n",
      "testing  :  2331  accuracy =   0.5999  loss =  158.736\n",
      "training :  2332  accuracy =   0.6600  loss =  157.985\n",
      "testing  :  2332  accuracy =   0.5999  loss =  158.787\n",
      "training :  2333  accuracy =   0.5900  loss =  160.026\n",
      "testing  :  2333  accuracy =   0.5990  loss =  158.772\n",
      "training :  2334  accuracy =   0.6500  loss =  156.067\n",
      "testing  :  2334  accuracy =   0.5985  loss =  158.758\n",
      "training :  2335  accuracy =   0.6400  loss =  156.561\n",
      "testing  :  2335  accuracy =   0.5989  loss =  158.751\n",
      "training :  2336  accuracy =   0.5700  loss =  157.769\n",
      "testing  :  2336  accuracy =   0.5985  loss =  158.742\n",
      "training :  2337  accuracy =   0.6100  loss =  158.396\n",
      "testing  :  2337  accuracy =   0.5984  loss =  158.748\n",
      "training :  2338  accuracy =   0.5900  loss =  160.626\n",
      "testing  :  2338  accuracy =   0.5976  loss =  158.746\n",
      "training :  2339  accuracy =   0.5900  loss =  156.628\n",
      "testing  :  2339  accuracy =   0.5974  loss =  158.738\n",
      "training :  2340  accuracy =   0.5600  loss =  159.049\n",
      "testing  :  2340  accuracy =   0.5973  loss =  158.73\n",
      "training :  2341  accuracy =   0.6600  loss =  155.722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2341  accuracy =   0.5976  loss =  158.721\n",
      "training :  2342  accuracy =   0.5700  loss =  158.859\n",
      "testing  :  2342  accuracy =   0.5973  loss =  158.702\n",
      "training :  2343  accuracy =   0.5100  loss =  163.173\n",
      "testing  :  2343  accuracy =   0.5970  loss =  158.69\n",
      "training :  2344  accuracy =   0.7200  loss =  156.203\n",
      "testing  :  2344  accuracy =   0.5963  loss =  158.674\n",
      "training :  2345  accuracy =   0.6000  loss =  159.309\n",
      "testing  :  2345  accuracy =   0.5964  loss =  158.651\n",
      "training :  2346  accuracy =   0.5700  loss =  156.471\n",
      "testing  :  2346  accuracy =   0.5957  loss =  158.635\n",
      "training :  2347  accuracy =   0.6200  loss =  157.631\n",
      "testing  :  2347  accuracy =   0.5953  loss =  158.639\n",
      "training :  2348  accuracy =   0.5300  loss =  158.907\n",
      "testing  :  2348  accuracy =   0.5955  loss =  158.629\n",
      "training :  2349  accuracy =   0.6200  loss =  156.475\n",
      "testing  :  2349  accuracy =   0.5951  loss =  158.657\n",
      "training :  2350  accuracy =   0.6500  loss =  155.453\n",
      "testing  :  2350  accuracy =   0.5950  loss =  158.677\n",
      "training :  2351  accuracy =   0.6500  loss =  156.43\n",
      "testing  :  2351  accuracy =   0.5952  loss =  158.696\n",
      "training :  2352  accuracy =   0.6000  loss =  156.72\n",
      "testing  :  2352  accuracy =   0.5954  loss =  158.7\n",
      "training :  2353  accuracy =   0.4700  loss =  160.598\n",
      "testing  :  2353  accuracy =   0.5961  loss =  158.692\n",
      "training :  2354  accuracy =   0.5900  loss =  157.362\n",
      "testing  :  2354  accuracy =   0.5961  loss =  158.692\n",
      "training :  2355  accuracy =   0.6200  loss =  158.521\n",
      "testing  :  2355  accuracy =   0.5951  loss =  158.709\n",
      "training :  2356  accuracy =   0.6400  loss =  157.768\n",
      "testing  :  2356  accuracy =   0.5944  loss =  158.728\n",
      "training :  2357  accuracy =   0.5900  loss =  156.443\n",
      "testing  :  2357  accuracy =   0.5936  loss =  158.731\n",
      "training :  2358  accuracy =   0.6300  loss =  158.169\n",
      "testing  :  2358  accuracy =   0.5936  loss =  158.745\n",
      "training :  2359  accuracy =   0.6000  loss =  156.98\n",
      "testing  :  2359  accuracy =   0.5929  loss =  158.779\n",
      "training :  2360  accuracy =   0.5800  loss =  162.009\n",
      "testing  :  2360  accuracy =   0.5926  loss =  158.814\n",
      "training :  2361  accuracy =   0.6700  loss =  156.933\n",
      "testing  :  2361  accuracy =   0.5922  loss =  158.854\n",
      "training :  2362  accuracy =   0.6200  loss =  157.693\n",
      "testing  :  2362  accuracy =   0.5916  loss =  158.838\n",
      "training :  2363  accuracy =   0.6300  loss =  158.081\n",
      "testing  :  2363  accuracy =   0.5919  loss =  158.845\n",
      "training :  2364  accuracy =   0.5300  loss =  157.478\n",
      "testing  :  2364  accuracy =   0.5922  loss =  158.815\n",
      "training :  2365  accuracy =   0.6300  loss =  158.218\n",
      "testing  :  2365  accuracy =   0.5928  loss =  158.754\n",
      "training :  2366  accuracy =   0.5600  loss =  159.224\n",
      "testing  :  2366  accuracy =   0.5929  loss =  158.736\n",
      "training :  2367  accuracy =   0.6800  loss =  158.355\n",
      "testing  :  2367  accuracy =   0.5927  loss =  158.756\n",
      "training :  2368  accuracy =   0.6200  loss =  157.721\n",
      "testing  :  2368  accuracy =   0.5927  loss =  158.791\n",
      "training :  2369  accuracy =   0.5700  loss =  159.312\n",
      "testing  :  2369  accuracy =   0.5925  loss =  158.835\n",
      "training :  2370  accuracy =   0.5800  loss =  156.851\n",
      "testing  :  2370  accuracy =   0.5933  loss =  158.814\n",
      "training :  2371  accuracy =   0.5800  loss =  158.451\n",
      "testing  :  2371  accuracy =   0.5944  loss =  158.798\n",
      "training :  2372  accuracy =   0.5900  loss =  157.485\n",
      "testing  :  2372  accuracy =   0.5951  loss =  158.786\n",
      "training :  2373  accuracy =   0.5600  loss =  156.59\n",
      "testing  :  2373  accuracy =   0.5968  loss =  158.823\n",
      "training :  2374  accuracy =   0.6400  loss =  160.023\n",
      "testing  :  2374  accuracy =   0.5972  loss =  158.866\n",
      "training :  2375  accuracy =   0.6200  loss =  162.399\n",
      "testing  :  2375  accuracy =   0.5981  loss =  158.89\n",
      "training :  2376  accuracy =   0.5600  loss =  161.63\n",
      "testing  :  2376  accuracy =   0.5992  loss =  158.966\n",
      "training :  2377  accuracy =   0.6200  loss =  157.998\n",
      "testing  :  2377  accuracy =   0.5992  loss =  158.963\n",
      "training :  2378  accuracy =   0.6600  loss =  156.46\n",
      "testing  :  2378  accuracy =   0.5988  loss =  158.93\n",
      "training :  2379  accuracy =   0.6600  loss =  155.763\n",
      "testing  :  2379  accuracy =   0.5983  loss =  158.883\n",
      "training :  2380  accuracy =   0.5500  loss =  157.514\n",
      "testing  :  2380  accuracy =   0.5975  loss =  158.861\n",
      "training :  2381  accuracy =   0.5400  loss =  158.95\n",
      "testing  :  2381  accuracy =   0.5963  loss =  158.846\n",
      "training :  2382  accuracy =   0.7100  loss =  155.258\n",
      "testing  :  2382  accuracy =   0.5953  loss =  158.857\n",
      "training :  2383  accuracy =   0.5800  loss =  157.078\n",
      "testing  :  2383  accuracy =   0.5949  loss =  158.853\n",
      "training :  2384  accuracy =   0.5700  loss =  159.407\n",
      "testing  :  2384  accuracy =   0.5953  loss =  158.872\n",
      "training :  2385  accuracy =   0.6900  loss =  156.584\n",
      "testing  :  2385  accuracy =   0.5945  loss =  158.908\n",
      "training :  2386  accuracy =   0.5300  loss =  162.355\n",
      "testing  :  2386  accuracy =   0.5945  loss =  158.943\n",
      "training :  2387  accuracy =   0.6200  loss =  156.847\n",
      "testing  :  2387  accuracy =   0.5938  loss =  159.003\n",
      "training :  2388  accuracy =   0.5900  loss =  163.014\n",
      "testing  :  2388  accuracy =   0.5937  loss =  159.08\n",
      "training :  2389  accuracy =   0.6100  loss =  158.614\n",
      "testing  :  2389  accuracy =   0.5934  loss =  159.137\n",
      "training :  2390  accuracy =   0.6300  loss =  156.563\n",
      "testing  :  2390  accuracy =   0.5942  loss =  159.119\n",
      "training :  2391  accuracy =   0.7000  loss =  157.519\n",
      "testing  :  2391  accuracy =   0.5948  loss =  159.09\n",
      "training :  2392  accuracy =   0.6400  loss =  159.575\n",
      "testing  :  2392  accuracy =   0.5955  loss =  159.062\n",
      "training :  2393  accuracy =   0.6400  loss =  158.34\n",
      "testing  :  2393  accuracy =   0.5972  loss =  158.944\n",
      "training :  2394  accuracy =   0.6300  loss =  155.689\n",
      "testing  :  2394  accuracy =   0.5983  loss =  158.855\n",
      "training :  2395  accuracy =   0.6700  loss =  156.658\n",
      "testing  :  2395  accuracy =   0.6001  loss =  158.794\n",
      "training :  2396  accuracy =   0.6300  loss =  158.128\n",
      "testing  :  2396  accuracy =   0.6021  loss =  158.752\n",
      "training :  2397  accuracy =   0.5900  loss =  157.59\n",
      "testing  :  2397  accuracy =   0.6039  loss =  158.723\n",
      "training :  2398  accuracy =   0.4800  loss =  161.48\n",
      "testing  :  2398  accuracy =   0.6055  loss =  158.709\n",
      "training :  2399  accuracy =   0.6300  loss =  156.363\n",
      "testing  :  2399  accuracy =   0.6084  loss =  158.694\n",
      "training :  2400  accuracy =   0.6000  loss =  156.882\n",
      "testing  :  2400  accuracy =   0.6123  loss =  158.711\n",
      "training :  2401  accuracy =   0.5700  loss =  158.758\n",
      "testing  :  2401  accuracy =   0.6183  loss =  158.737\n",
      "training :  2402  accuracy =   0.6200  loss =  160.213\n",
      "testing  :  2402  accuracy =   0.6265  loss =  158.783\n",
      "training :  2403  accuracy =   0.6700  loss =  157.134\n",
      "testing  :  2403  accuracy =   0.6319  loss =  158.818\n",
      "training :  2404  accuracy =   0.6500  loss =  158.983\n",
      "testing  :  2404  accuracy =   0.6428  loss =  158.834\n",
      "training :  2405  accuracy =   0.6900  loss =  158.318\n",
      "testing  :  2405  accuracy =   0.6507  loss =  158.846\n",
      "training :  2406  accuracy =   0.6300  loss =  160.322\n",
      "testing  :  2406  accuracy =   0.6596  loss =  158.84\n",
      "training :  2407  accuracy =   0.6500  loss =  157.802\n",
      "testing  :  2407  accuracy =   0.6649  loss =  158.812\n",
      "training :  2408  accuracy =   0.6300  loss =  156.417\n",
      "testing  :  2408  accuracy =   0.6642  loss =  158.769\n",
      "training :  2409  accuracy =   0.5700  loss =  159.635\n",
      "testing  :  2409  accuracy =   0.6627  loss =  158.717\n",
      "training :  2410  accuracy =   0.7300  loss =  156.532\n",
      "testing  :  2410  accuracy =   0.6628  loss =  158.665\n",
      "training :  2411  accuracy =   0.6100  loss =  156.686\n",
      "testing  :  2411  accuracy =   0.6618  loss =  158.617\n",
      "training :  2412  accuracy =   0.6700  loss =  158.558\n",
      "testing  :  2412  accuracy =   0.6610  loss =  158.581\n",
      "training :  2413  accuracy =   0.7000  loss =  157.331\n",
      "testing  :  2413  accuracy =   0.6605  loss =  158.563\n",
      "training :  2414  accuracy =   0.6500  loss =  156.3\n",
      "testing  :  2414  accuracy =   0.6604  loss =  158.562\n",
      "training :  2415  accuracy =   0.6200  loss =  158.015\n",
      "testing  :  2415  accuracy =   0.6367  loss =  158.568\n",
      "training :  2416  accuracy =   0.6000  loss =  159.971\n",
      "testing  :  2416  accuracy =   0.6204  loss =  158.62\n",
      "training :  2417  accuracy =   0.6000  loss =  157.73\n",
      "testing  :  2417  accuracy =   0.6092  loss =  158.728\n",
      "training :  2418  accuracy =   0.5100  loss =  163.476\n",
      "testing  :  2418  accuracy =   0.6049  loss =  158.75\n",
      "training :  2419  accuracy =   0.5500  loss =  158.75\n",
      "testing  :  2419  accuracy =   0.6038  loss =  158.678\n",
      "training :  2420  accuracy =   0.6200  loss =  157.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2420  accuracy =   0.6027  loss =  158.621\n",
      "training :  2421  accuracy =   0.5200  loss =  159.572\n",
      "testing  :  2421  accuracy =   0.6009  loss =  158.603\n",
      "training :  2422  accuracy =   0.5800  loss =  157.756\n",
      "testing  :  2422  accuracy =   0.5986  loss =  158.629\n",
      "training :  2423  accuracy =   0.7000  loss =  155.78\n",
      "testing  :  2423  accuracy =   0.5970  loss =  158.664\n",
      "training :  2424  accuracy =   0.7200  loss =  155.791\n",
      "testing  :  2424  accuracy =   0.5956  loss =  158.722\n",
      "training :  2425  accuracy =   0.6000  loss =  156.77\n",
      "testing  :  2425  accuracy =   0.5952  loss =  158.735\n",
      "training :  2426  accuracy =   0.5800  loss =  158.685\n",
      "testing  :  2426  accuracy =   0.5945  loss =  158.75\n",
      "training :  2427  accuracy =   0.6000  loss =  156.882\n",
      "testing  :  2427  accuracy =   0.5939  loss =  158.744\n",
      "training :  2428  accuracy =   0.5900  loss =  157.874\n",
      "testing  :  2428  accuracy =   0.5936  loss =  158.758\n",
      "training :  2429  accuracy =   0.6200  loss =  157.194\n",
      "testing  :  2429  accuracy =   0.5931  loss =  158.775\n",
      "training :  2430  accuracy =   0.5200  loss =  157.783\n",
      "testing  :  2430  accuracy =   0.5929  loss =  158.794\n",
      "training :  2431  accuracy =   0.5800  loss =  155.576\n",
      "testing  :  2431  accuracy =   0.5924  loss =  158.816\n",
      "training :  2432  accuracy =   0.5800  loss =  160.352\n",
      "testing  :  2432  accuracy =   0.5928  loss =  158.83\n",
      "training :  2433  accuracy =   0.7100  loss =  155.109\n",
      "testing  :  2433  accuracy =   0.5931  loss =  158.835\n",
      "training :  2434  accuracy =   0.5300  loss =  161.036\n",
      "testing  :  2434  accuracy =   0.5925  loss =  158.883\n",
      "training :  2435  accuracy =   0.5700  loss =  157.939\n",
      "testing  :  2435  accuracy =   0.5923  loss =  158.919\n",
      "training :  2436  accuracy =   0.5500  loss =  159.224\n",
      "testing  :  2436  accuracy =   0.5932  loss =  158.973\n",
      "training :  2437  accuracy =   0.6100  loss =  158.399\n",
      "testing  :  2437  accuracy =   0.5928  loss =  159.047\n",
      "training :  2438  accuracy =   0.5800  loss =  160.768\n",
      "testing  :  2438  accuracy =   0.5932  loss =  159.061\n",
      "training :  2439  accuracy =   0.6000  loss =  157.872\n",
      "testing  :  2439  accuracy =   0.5939  loss =  159.017\n",
      "training :  2440  accuracy =   0.6000  loss =  156.791\n",
      "testing  :  2440  accuracy =   0.5946  loss =  158.932\n",
      "training :  2441  accuracy =   0.6100  loss =  156.752\n",
      "testing  :  2441  accuracy =   0.5944  loss =  158.873\n",
      "training :  2442  accuracy =   0.7200  loss =  155.475\n",
      "testing  :  2442  accuracy =   0.5949  loss =  158.845\n",
      "training :  2443  accuracy =   0.6500  loss =  154.86\n",
      "testing  :  2443  accuracy =   0.5957  loss =  158.795\n",
      "training :  2444  accuracy =   0.7100  loss =  156.499\n",
      "testing  :  2444  accuracy =   0.5965  loss =  158.71\n",
      "training :  2445  accuracy =   0.5600  loss =  158.107\n",
      "testing  :  2445  accuracy =   0.5975  loss =  158.601\n",
      "training :  2446  accuracy =   0.6100  loss =  161.212\n",
      "testing  :  2446  accuracy =   0.5978  loss =  158.514\n",
      "training :  2447  accuracy =   0.6000  loss =  158.0\n",
      "testing  :  2447  accuracy =   0.5989  loss =  158.46\n",
      "training :  2448  accuracy =   0.6700  loss =  157.349\n",
      "testing  :  2448  accuracy =   0.5986  loss =  158.435\n",
      "training :  2449  accuracy =   0.6600  loss =  156.965\n",
      "testing  :  2449  accuracy =   0.5991  loss =  158.413\n",
      "training :  2450  accuracy =   0.7000  loss =  156.166\n",
      "testing  :  2450  accuracy =   0.5994  loss =  158.406\n",
      "training :  2451  accuracy =   0.6100  loss =  158.105\n",
      "testing  :  2451  accuracy =   0.5999  loss =  158.444\n",
      "training :  2452  accuracy =   0.6000  loss =  158.021\n",
      "testing  :  2452  accuracy =   0.6002  loss =  158.533\n",
      "training :  2453  accuracy =   0.6200  loss =  159.211\n",
      "testing  :  2453  accuracy =   0.6002  loss =  158.659\n",
      "training :  2454  accuracy =   0.5200  loss =  162.993\n",
      "testing  :  2454  accuracy =   0.6011  loss =  158.774\n",
      "training :  2455  accuracy =   0.5900  loss =  158.394\n",
      "testing  :  2455  accuracy =   0.6027  loss =  158.791\n",
      "training :  2456  accuracy =   0.6000  loss =  157.273\n",
      "testing  :  2456  accuracy =   0.6040  loss =  158.83\n",
      "training :  2457  accuracy =   0.7200  loss =  155.47\n",
      "testing  :  2457  accuracy =   0.6047  loss =  158.802\n",
      "training :  2458  accuracy =   0.6600  loss =  156.832\n",
      "testing  :  2458  accuracy =   0.6053  loss =  158.773\n",
      "training :  2459  accuracy =   0.6900  loss =  156.503\n",
      "testing  :  2459  accuracy =   0.6078  loss =  158.781\n",
      "training :  2460  accuracy =   0.5100  loss =  161.482\n",
      "testing  :  2460  accuracy =   0.6132  loss =  158.781\n",
      "training :  2461  accuracy =   0.5300  loss =  159.803\n",
      "testing  :  2461  accuracy =   0.6184  loss =  158.727\n",
      "training :  2462  accuracy =   0.6500  loss =  158.499\n",
      "testing  :  2462  accuracy =   0.6203  loss =  158.702\n",
      "training :  2463  accuracy =   0.6300  loss =  156.878\n",
      "testing  :  2463  accuracy =   0.6216  loss =  158.681\n",
      "training :  2464  accuracy =   0.5400  loss =  160.48\n",
      "testing  :  2464  accuracy =   0.6267  loss =  158.653\n",
      "training :  2465  accuracy =   0.5900  loss =  157.968\n",
      "testing  :  2465  accuracy =   0.6252  loss =  158.632\n",
      "training :  2466  accuracy =   0.6300  loss =  157.656\n",
      "testing  :  2466  accuracy =   0.6244  loss =  158.584\n",
      "training :  2467  accuracy =   0.6800  loss =  157.105\n",
      "testing  :  2467  accuracy =   0.6194  loss =  158.518\n",
      "training :  2468  accuracy =   0.6300  loss =  158.571\n",
      "testing  :  2468  accuracy =   0.6140  loss =  158.448\n",
      "training :  2469  accuracy =   0.6300  loss =  156.576\n",
      "testing  :  2469  accuracy =   0.6107  loss =  158.399\n",
      "training :  2470  accuracy =   0.6000  loss =  160.363\n",
      "testing  :  2470  accuracy =   0.6072  loss =  158.386\n",
      "training :  2471  accuracy =   0.6600  loss =  157.712\n",
      "testing  :  2471  accuracy =   0.6051  loss =  158.376\n",
      "training :  2472  accuracy =   0.6900  loss =  159.066\n",
      "testing  :  2472  accuracy =   0.6028  loss =  158.386\n",
      "training :  2473  accuracy =   0.5800  loss =  157.477\n",
      "testing  :  2473  accuracy =   0.6005  loss =  158.381\n",
      "training :  2474  accuracy =   0.5900  loss =  157.251\n",
      "testing  :  2474  accuracy =   0.5991  loss =  158.394\n",
      "training :  2475  accuracy =   0.5500  loss =  158.899\n",
      "testing  :  2475  accuracy =   0.5981  loss =  158.437\n",
      "training :  2476  accuracy =   0.6100  loss =  157.209\n",
      "testing  :  2476  accuracy =   0.5972  loss =  158.48\n",
      "training :  2477  accuracy =   0.6000  loss =  156.251\n",
      "testing  :  2477  accuracy =   0.5971  loss =  158.53\n",
      "training :  2478  accuracy =   0.6200  loss =  158.347\n",
      "testing  :  2478  accuracy =   0.5965  loss =  158.588\n",
      "training :  2479  accuracy =   0.5700  loss =  156.532\n",
      "testing  :  2479  accuracy =   0.5975  loss =  158.552\n",
      "training :  2480  accuracy =   0.5800  loss =  159.553\n",
      "testing  :  2480  accuracy =   0.5980  loss =  158.529\n",
      "training :  2481  accuracy =   0.6300  loss =  157.82\n",
      "testing  :  2481  accuracy =   0.5980  loss =  158.514\n",
      "training :  2482  accuracy =   0.5900  loss =  157.686\n",
      "testing  :  2482  accuracy =   0.5996  loss =  158.447\n",
      "training :  2483  accuracy =   0.5500  loss =  158.924\n",
      "testing  :  2483  accuracy =   0.5999  loss =  158.387\n",
      "training :  2484  accuracy =   0.6700  loss =  158.443\n",
      "testing  :  2484  accuracy =   0.6001  loss =  158.377\n",
      "training :  2485  accuracy =   0.6300  loss =  160.052\n",
      "testing  :  2485  accuracy =   0.6013  loss =  158.384\n",
      "training :  2486  accuracy =   0.5200  loss =  159.239\n",
      "testing  :  2486  accuracy =   0.6017  loss =  158.413\n",
      "training :  2487  accuracy =   0.7100  loss =  155.247\n",
      "testing  :  2487  accuracy =   0.6029  loss =  158.474\n",
      "training :  2488  accuracy =   0.6200  loss =  158.757\n",
      "testing  :  2488  accuracy =   0.6036  loss =  158.541\n",
      "training :  2489  accuracy =   0.5800  loss =  156.993\n",
      "testing  :  2489  accuracy =   0.6033  loss =  158.623\n",
      "training :  2490  accuracy =   0.6000  loss =  157.65\n",
      "testing  :  2490  accuracy =   0.6034  loss =  158.698\n",
      "training :  2491  accuracy =   0.6500  loss =  157.203\n",
      "testing  :  2491  accuracy =   0.6032  loss =  158.754\n",
      "training :  2492  accuracy =   0.6200  loss =  157.634\n",
      "testing  :  2492  accuracy =   0.6019  loss =  158.755\n",
      "training :  2493  accuracy =   0.6400  loss =  158.851\n",
      "testing  :  2493  accuracy =   0.6012  loss =  158.733\n",
      "training :  2494  accuracy =   0.6000  loss =  157.986\n",
      "testing  :  2494  accuracy =   0.6017  loss =  158.714\n",
      "training :  2495  accuracy =   0.5600  loss =  159.239\n",
      "testing  :  2495  accuracy =   0.6021  loss =  158.719\n",
      "training :  2496  accuracy =   0.6200  loss =  159.967\n",
      "testing  :  2496  accuracy =   0.6020  loss =  158.702\n",
      "training :  2497  accuracy =   0.6400  loss =  159.484\n",
      "testing  :  2497  accuracy =   0.6014  loss =  158.678\n",
      "training :  2498  accuracy =   0.5800  loss =  159.134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2498  accuracy =   0.6002  loss =  158.612\n",
      "training :  2499  accuracy =   0.5600  loss =  161.615\n",
      "testing  :  2499  accuracy =   0.5997  loss =  158.572\n",
      "training :  2500  accuracy =   0.6200  loss =  161.699\n",
      "testing  :  2500  accuracy =   0.5989  loss =  158.531\n",
      "training :  2501  accuracy =   0.6000  loss =  158.334\n",
      "testing  :  2501  accuracy =   0.5979  loss =  158.506\n",
      "training :  2502  accuracy =   0.6100  loss =  160.999\n",
      "testing  :  2502  accuracy =   0.5975  loss =  158.484\n",
      "training :  2503  accuracy =   0.5900  loss =  158.247\n",
      "testing  :  2503  accuracy =   0.5959  loss =  158.447\n",
      "training :  2504  accuracy =   0.5300  loss =  161.402\n",
      "testing  :  2504  accuracy =   0.5958  loss =  158.424\n",
      "training :  2505  accuracy =   0.5900  loss =  160.7\n",
      "testing  :  2505  accuracy =   0.5950  loss =  158.401\n",
      "training :  2506  accuracy =   0.5500  loss =  159.812\n",
      "testing  :  2506  accuracy =   0.5938  loss =  158.394\n",
      "training :  2507  accuracy =   0.7000  loss =  154.984\n",
      "testing  :  2507  accuracy =   0.5935  loss =  158.412\n",
      "training :  2508  accuracy =   0.5900  loss =  158.23\n",
      "testing  :  2508  accuracy =   0.5935  loss =  158.439\n",
      "training :  2509  accuracy =   0.5300  loss =  159.382\n",
      "testing  :  2509  accuracy =   0.5945  loss =  158.417\n",
      "training :  2510  accuracy =   0.5400  loss =  159.161\n",
      "testing  :  2510  accuracy =   0.5963  loss =  158.394\n",
      "training :  2511  accuracy =   0.6200  loss =  155.983\n",
      "testing  :  2511  accuracy =   0.5968  loss =  158.389\n",
      "training :  2512  accuracy =   0.6200  loss =  157.185\n",
      "testing  :  2512  accuracy =   0.5980  loss =  158.393\n",
      "training :  2513  accuracy =   0.6300  loss =  156.561\n",
      "testing  :  2513  accuracy =   0.5999  loss =  158.398\n",
      "training :  2514  accuracy =   0.6400  loss =  157.698\n",
      "testing  :  2514  accuracy =   0.6021  loss =  158.41\n",
      "training :  2515  accuracy =   0.6400  loss =  158.049\n",
      "testing  :  2515  accuracy =   0.6044  loss =  158.43\n",
      "training :  2516  accuracy =   0.5800  loss =  159.425\n",
      "testing  :  2516  accuracy =   0.6095  loss =  158.478\n",
      "training :  2517  accuracy =   0.5800  loss =  157.015\n",
      "testing  :  2517  accuracy =   0.6209  loss =  158.535\n",
      "training :  2518  accuracy =   0.6500  loss =  159.84\n",
      "testing  :  2518  accuracy =   0.6427  loss =  158.62\n",
      "training :  2519  accuracy =   0.7000  loss =  157.211\n",
      "testing  :  2519  accuracy =   0.6719  loss =  158.731\n",
      "training :  2520  accuracy =   0.6900  loss =  157.581\n",
      "testing  :  2520  accuracy =   0.6838  loss =  158.78\n",
      "training :  2521  accuracy =   0.7100  loss =  159.18\n",
      "testing  :  2521  accuracy =   0.6870  loss =  158.797\n",
      "training :  2522  accuracy =   0.7400  loss =  161.245\n",
      "testing  :  2522  accuracy =   0.6883  loss =  158.81\n",
      "training :  2523  accuracy =   0.6300  loss =  158.395\n",
      "testing  :  2523  accuracy =   0.6883  loss =  158.825\n",
      "training :  2524  accuracy =   0.6200  loss =  159.516\n",
      "testing  :  2524  accuracy =   0.6892  loss =  158.82\n",
      "training :  2525  accuracy =   0.7000  loss =  157.501\n",
      "testing  :  2525  accuracy =   0.6901  loss =  158.759\n",
      "training :  2526  accuracy =   0.7800  loss =  156.779\n",
      "testing  :  2526  accuracy =   0.6907  loss =  158.655\n",
      "training :  2527  accuracy =   0.6900  loss =  157.02\n",
      "testing  :  2527  accuracy =   0.6902  loss =  158.572\n",
      "training :  2528  accuracy =   0.6500  loss =  159.497\n",
      "testing  :  2528  accuracy =   0.6901  loss =  158.528\n",
      "training :  2529  accuracy =   0.7200  loss =  159.368\n",
      "testing  :  2529  accuracy =   0.6899  loss =  158.491\n",
      "training :  2530  accuracy =   0.6900  loss =  159.9\n",
      "testing  :  2530  accuracy =   0.6892  loss =  158.458\n",
      "training :  2531  accuracy =   0.6900  loss =  156.073\n",
      "testing  :  2531  accuracy =   0.6893  loss =  158.443\n",
      "training :  2532  accuracy =   0.6500  loss =  157.554\n",
      "testing  :  2532  accuracy =   0.6884  loss =  158.432\n",
      "training :  2533  accuracy =   0.6900  loss =  157.775\n",
      "testing  :  2533  accuracy =   0.6858  loss =  158.42\n",
      "training :  2534  accuracy =   0.7300  loss =  156.974\n",
      "testing  :  2534  accuracy =   0.6835  loss =  158.434\n",
      "training :  2535  accuracy =   0.7500  loss =  156.432\n",
      "testing  :  2535  accuracy =   0.6752  loss =  158.428\n",
      "training :  2536  accuracy =   0.6200  loss =  157.831\n",
      "testing  :  2536  accuracy =   0.6663  loss =  158.426\n",
      "training :  2537  accuracy =   0.7300  loss =  157.017\n",
      "testing  :  2537  accuracy =   0.6581  loss =  158.445\n",
      "training :  2538  accuracy =   0.6200  loss =  161.741\n",
      "testing  :  2538  accuracy =   0.6526  loss =  158.461\n",
      "training :  2539  accuracy =   0.5400  loss =  160.969\n",
      "testing  :  2539  accuracy =   0.6463  loss =  158.467\n",
      "training :  2540  accuracy =   0.7400  loss =  155.821\n",
      "testing  :  2540  accuracy =   0.6430  loss =  158.474\n",
      "training :  2541  accuracy =   0.7100  loss =  156.582\n",
      "testing  :  2541  accuracy =   0.6539  loss =  158.482\n",
      "training :  2542  accuracy =   0.6500  loss =  157.533\n",
      "testing  :  2542  accuracy =   0.6726  loss =  158.476\n",
      "training :  2543  accuracy =   0.7700  loss =  156.711\n",
      "testing  :  2543  accuracy =   0.6802  loss =  158.479\n",
      "training :  2544  accuracy =   0.6900  loss =  155.931\n",
      "testing  :  2544  accuracy =   0.6827  loss =  158.462\n",
      "training :  2545  accuracy =   0.7200  loss =  158.026\n",
      "testing  :  2545  accuracy =   0.6840  loss =  158.427\n",
      "training :  2546  accuracy =   0.7200  loss =  156.6\n",
      "testing  :  2546  accuracy =   0.6851  loss =  158.409\n",
      "training :  2547  accuracy =   0.6400  loss =  160.566\n",
      "testing  :  2547  accuracy =   0.6861  loss =  158.414\n",
      "training :  2548  accuracy =   0.6900  loss =  157.488\n",
      "testing  :  2548  accuracy =   0.6864  loss =  158.442\n",
      "training :  2549  accuracy =   0.7400  loss =  156.85\n",
      "testing  :  2549  accuracy =   0.6855  loss =  158.483\n",
      "training :  2550  accuracy =   0.7000  loss =  155.581\n",
      "testing  :  2550  accuracy =   0.6850  loss =  158.539\n",
      "training :  2551  accuracy =   0.6700  loss =  156.12\n",
      "testing  :  2551  accuracy =   0.6850  loss =  158.564\n",
      "training :  2552  accuracy =   0.6700  loss =  160.98\n",
      "testing  :  2552  accuracy =   0.6850  loss =  158.574\n",
      "training :  2553  accuracy =   0.7200  loss =  159.301\n",
      "testing  :  2553  accuracy =   0.6854  loss =  158.539\n",
      "training :  2554  accuracy =   0.6800  loss =  154.54\n",
      "testing  :  2554  accuracy =   0.6854  loss =  158.512\n",
      "training :  2555  accuracy =   0.6700  loss =  159.565\n",
      "testing  :  2555  accuracy =   0.6861  loss =  158.516\n",
      "training :  2556  accuracy =   0.6800  loss =  159.359\n",
      "testing  :  2556  accuracy =   0.6869  loss =  158.481\n",
      "training :  2557  accuracy =   0.7500  loss =  157.974\n",
      "testing  :  2557  accuracy =   0.6876  loss =  158.464\n",
      "training :  2558  accuracy =   0.7500  loss =  158.712\n",
      "testing  :  2558  accuracy =   0.6861  loss =  158.48\n",
      "training :  2559  accuracy =   0.7200  loss =  156.525\n",
      "testing  :  2559  accuracy =   0.6855  loss =  158.601\n",
      "training :  2560  accuracy =   0.6800  loss =  158.308\n",
      "testing  :  2560  accuracy =   0.6829  loss =  158.838\n",
      "training :  2561  accuracy =   0.6700  loss =  159.974\n",
      "testing  :  2561  accuracy =   0.6818  loss =  159.124\n",
      "training :  2562  accuracy =   0.6200  loss =  158.539\n",
      "testing  :  2562  accuracy =   0.6790  loss =  159.397\n",
      "training :  2563  accuracy =   0.6800  loss =  159.222\n",
      "testing  :  2563  accuracy =   0.6756  loss =  159.736\n",
      "training :  2564  accuracy =   0.6300  loss =  161.272\n",
      "testing  :  2564  accuracy =   0.6739  loss =  160.018\n",
      "training :  2565  accuracy =   0.7400  loss =  159.986\n",
      "testing  :  2565  accuracy =   0.6717  loss =  160.14\n",
      "training :  2566  accuracy =   0.7200  loss =  163.103\n",
      "testing  :  2566  accuracy =   0.6709  loss =  160.145\n",
      "training :  2567  accuracy =   0.6300  loss =  159.853\n",
      "testing  :  2567  accuracy =   0.6722  loss =  159.895\n",
      "training :  2568  accuracy =   0.7100  loss =  160.067\n",
      "testing  :  2568  accuracy =   0.6752  loss =  159.626\n",
      "training :  2569  accuracy =   0.6900  loss =  161.537\n",
      "testing  :  2569  accuracy =   0.6786  loss =  159.338\n",
      "training :  2570  accuracy =   0.7100  loss =  159.295\n",
      "testing  :  2570  accuracy =   0.6806  loss =  159.083\n",
      "training :  2571  accuracy =   0.6500  loss =  159.197\n",
      "testing  :  2571  accuracy =   0.6832  loss =  158.719\n",
      "training :  2572  accuracy =   0.7600  loss =  155.604\n",
      "testing  :  2572  accuracy =   0.6857  loss =  158.517\n",
      "training :  2573  accuracy =   0.5700  loss =  160.476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2573  accuracy =   0.6861  loss =  158.411\n",
      "training :  2574  accuracy =   0.7400  loss =  158.036\n",
      "testing  :  2574  accuracy =   0.6876  loss =  158.374\n",
      "training :  2575  accuracy =   0.7100  loss =  158.252\n",
      "testing  :  2575  accuracy =   0.6869  loss =  158.462\n",
      "training :  2576  accuracy =   0.6400  loss =  161.692\n",
      "testing  :  2576  accuracy =   0.6842  loss =  158.709\n",
      "training :  2577  accuracy =   0.6800  loss =  160.111\n",
      "testing  :  2577  accuracy =   0.6794  loss =  159.013\n",
      "training :  2578  accuracy =   0.5700  loss =  157.954\n",
      "testing  :  2578  accuracy =   0.6756  loss =  159.298\n",
      "training :  2579  accuracy =   0.7100  loss =  158.508\n",
      "testing  :  2579  accuracy =   0.6732  loss =  159.52\n",
      "training :  2580  accuracy =   0.6500  loss =  157.513\n",
      "testing  :  2580  accuracy =   0.6742  loss =  159.487\n",
      "training :  2581  accuracy =   0.7000  loss =  161.235\n",
      "testing  :  2581  accuracy =   0.6756  loss =  159.349\n",
      "training :  2582  accuracy =   0.6500  loss =  157.267\n",
      "testing  :  2582  accuracy =   0.6825  loss =  158.931\n",
      "training :  2583  accuracy =   0.6600  loss =  157.217\n",
      "testing  :  2583  accuracy =   0.6865  loss =  158.594\n",
      "training :  2584  accuracy =   0.7500  loss =  155.934\n",
      "testing  :  2584  accuracy =   0.6885  loss =  158.419\n",
      "training :  2585  accuracy =   0.6200  loss =  158.326\n",
      "testing  :  2585  accuracy =   0.6892  loss =  158.339\n",
      "training :  2586  accuracy =   0.6700  loss =  156.855\n",
      "testing  :  2586  accuracy =   0.6879  loss =  158.332\n",
      "training :  2587  accuracy =   0.7400  loss =  156.593\n",
      "testing  :  2587  accuracy =   0.6881  loss =  158.378\n",
      "training :  2588  accuracy =   0.6600  loss =  158.278\n",
      "testing  :  2588  accuracy =   0.6879  loss =  158.446\n",
      "training :  2589  accuracy =   0.6400  loss =  159.055\n",
      "testing  :  2589  accuracy =   0.6877  loss =  158.521\n",
      "training :  2590  accuracy =   0.6900  loss =  159.001\n",
      "testing  :  2590  accuracy =   0.6878  loss =  158.624\n",
      "training :  2591  accuracy =   0.7100  loss =  157.924\n",
      "testing  :  2591  accuracy =   0.6875  loss =  158.668\n",
      "training :  2592  accuracy =   0.6100  loss =  160.062\n",
      "testing  :  2592  accuracy =   0.6867  loss =  158.672\n",
      "training :  2593  accuracy =   0.7500  loss =  156.924\n",
      "testing  :  2593  accuracy =   0.6862  loss =  158.719\n",
      "training :  2594  accuracy =   0.6800  loss =  159.98\n",
      "testing  :  2594  accuracy =   0.6858  loss =  158.773\n",
      "training :  2595  accuracy =   0.7300  loss =  156.656\n",
      "testing  :  2595  accuracy =   0.6861  loss =  158.799\n",
      "training :  2596  accuracy =   0.8200  loss =  155.818\n",
      "testing  :  2596  accuracy =   0.6874  loss =  158.744\n",
      "training :  2597  accuracy =   0.8100  loss =  154.452\n",
      "testing  :  2597  accuracy =   0.6876  loss =  158.655\n",
      "training :  2598  accuracy =   0.6700  loss =  155.997\n",
      "testing  :  2598  accuracy =   0.6875  loss =  158.573\n",
      "training :  2599  accuracy =   0.6700  loss =  157.262\n",
      "testing  :  2599  accuracy =   0.6885  loss =  158.504\n",
      "training :  2600  accuracy =   0.7100  loss =  158.058\n",
      "testing  :  2600  accuracy =   0.6892  loss =  158.49\n",
      "training :  2601  accuracy =   0.6600  loss =  158.443\n",
      "testing  :  2601  accuracy =   0.6894  loss =  158.453\n",
      "training :  2602  accuracy =   0.6800  loss =  157.589\n",
      "testing  :  2602  accuracy =   0.6895  loss =  158.375\n",
      "training :  2603  accuracy =   0.7700  loss =  158.402\n",
      "testing  :  2603  accuracy =   0.6899  loss =  158.308\n",
      "training :  2604  accuracy =   0.7300  loss =  156.063\n",
      "testing  :  2604  accuracy =   0.6908  loss =  158.266\n",
      "training :  2605  accuracy =   0.7000  loss =  156.849\n",
      "testing  :  2605  accuracy =   0.6905  loss =  158.294\n",
      "training :  2606  accuracy =   0.7000  loss =  157.257\n",
      "testing  :  2606  accuracy =   0.6881  loss =  158.416\n",
      "training :  2607  accuracy =   0.6700  loss =  159.093\n",
      "testing  :  2607  accuracy =   0.6847  loss =  158.717\n",
      "training :  2608  accuracy =   0.7000  loss =  155.615\n",
      "testing  :  2608  accuracy =   0.6819  loss =  159.044\n",
      "training :  2609  accuracy =   0.6800  loss =  159.906\n",
      "testing  :  2609  accuracy =   0.6785  loss =  159.294\n",
      "training :  2610  accuracy =   0.7700  loss =  156.034\n",
      "testing  :  2610  accuracy =   0.6811  loss =  159.265\n",
      "training :  2611  accuracy =   0.6700  loss =  158.331\n",
      "testing  :  2611  accuracy =   0.6825  loss =  159.197\n",
      "training :  2612  accuracy =   0.6300  loss =  157.691\n",
      "testing  :  2612  accuracy =   0.6861  loss =  159.054\n",
      "training :  2613  accuracy =   0.6900  loss =  158.868\n",
      "testing  :  2613  accuracy =   0.6871  loss =  158.905\n",
      "training :  2614  accuracy =   0.7300  loss =  158.074\n",
      "testing  :  2614  accuracy =   0.6883  loss =  158.718\n",
      "training :  2615  accuracy =   0.7300  loss =  158.202\n",
      "testing  :  2615  accuracy =   0.6910  loss =  158.579\n",
      "training :  2616  accuracy =   0.6800  loss =  157.204\n",
      "testing  :  2616  accuracy =   0.6927  loss =  158.525\n",
      "training :  2617  accuracy =   0.6400  loss =  158.276\n",
      "testing  :  2617  accuracy =   0.6920  loss =  158.563\n",
      "training :  2618  accuracy =   0.6500  loss =  158.397\n",
      "testing  :  2618  accuracy =   0.6911  loss =  158.698\n",
      "training :  2619  accuracy =   0.7600  loss =  156.548\n",
      "testing  :  2619  accuracy =   0.6909  loss =  158.882\n",
      "training :  2620  accuracy =   0.7000  loss =  156.576\n",
      "testing  :  2620  accuracy =   0.6893  loss =  159.019\n",
      "training :  2621  accuracy =   0.7500  loss =  157.905\n",
      "testing  :  2621  accuracy =   0.6883  loss =  159.113\n",
      "training :  2622  accuracy =   0.7200  loss =  157.363\n",
      "testing  :  2622  accuracy =   0.6888  loss =  159.143\n",
      "training :  2623  accuracy =   0.7700  loss =  157.855\n",
      "testing  :  2623  accuracy =   0.6880  loss =  159.204\n",
      "training :  2624  accuracy =   0.7200  loss =  157.828\n",
      "testing  :  2624  accuracy =   0.6884  loss =  159.176\n",
      "training :  2625  accuracy =   0.7600  loss =  156.946\n",
      "testing  :  2625  accuracy =   0.6899  loss =  159.025\n",
      "training :  2626  accuracy =   0.7400  loss =  157.533\n",
      "testing  :  2626  accuracy =   0.6904  loss =  158.902\n",
      "training :  2627  accuracy =   0.6500  loss =  161.248\n",
      "testing  :  2627  accuracy =   0.6904  loss =  158.774\n",
      "training :  2628  accuracy =   0.6300  loss =  157.845\n",
      "testing  :  2628  accuracy =   0.6910  loss =  158.659\n",
      "training :  2629  accuracy =   0.6300  loss =  161.544\n",
      "testing  :  2629  accuracy =   0.6913  loss =  158.593\n",
      "training :  2630  accuracy =   0.6900  loss =  158.712\n",
      "testing  :  2630  accuracy =   0.6900  loss =  158.547\n",
      "training :  2631  accuracy =   0.6800  loss =  156.826\n",
      "testing  :  2631  accuracy =   0.6910  loss =  158.508\n",
      "training :  2632  accuracy =   0.6100  loss =  159.625\n",
      "testing  :  2632  accuracy =   0.6916  loss =  158.483\n",
      "training :  2633  accuracy =   0.7100  loss =  158.225\n",
      "testing  :  2633  accuracy =   0.6900  loss =  158.469\n",
      "training :  2634  accuracy =   0.6800  loss =  159.351\n",
      "testing  :  2634  accuracy =   0.6894  loss =  158.477\n",
      "training :  2635  accuracy =   0.7500  loss =  158.269\n",
      "testing  :  2635  accuracy =   0.6890  loss =  158.493\n",
      "training :  2636  accuracy =   0.6400  loss =  158.633\n",
      "testing  :  2636  accuracy =   0.6884  loss =  158.526\n",
      "training :  2637  accuracy =   0.7100  loss =  158.069\n",
      "testing  :  2637  accuracy =   0.6884  loss =  158.549\n",
      "training :  2638  accuracy =   0.7700  loss =  157.343\n",
      "testing  :  2638  accuracy =   0.6875  loss =  158.556\n",
      "training :  2639  accuracy =   0.7300  loss =  158.358\n",
      "testing  :  2639  accuracy =   0.6872  loss =  158.552\n",
      "training :  2640  accuracy =   0.6100  loss =  158.343\n",
      "testing  :  2640  accuracy =   0.6873  loss =  158.538\n",
      "training :  2641  accuracy =   0.6300  loss =  158.376\n",
      "testing  :  2641  accuracy =   0.6877  loss =  158.525\n",
      "training :  2642  accuracy =   0.7100  loss =  157.778\n",
      "testing  :  2642  accuracy =   0.6879  loss =  158.522\n",
      "training :  2643  accuracy =   0.7200  loss =  155.5\n",
      "testing  :  2643  accuracy =   0.6877  loss =  158.512\n",
      "training :  2644  accuracy =   0.7100  loss =  156.999\n",
      "testing  :  2644  accuracy =   0.6881  loss =  158.485\n",
      "training :  2645  accuracy =   0.6400  loss =  159.708\n",
      "testing  :  2645  accuracy =   0.6888  loss =  158.453\n",
      "training :  2646  accuracy =   0.6900  loss =  157.112\n",
      "testing  :  2646  accuracy =   0.6884  loss =  158.449\n",
      "training :  2647  accuracy =   0.7800  loss =  155.966\n",
      "testing  :  2647  accuracy =   0.6881  loss =  158.446\n",
      "training :  2648  accuracy =   0.8000  loss =  154.425\n",
      "testing  :  2648  accuracy =   0.6882  loss =  158.444\n",
      "training :  2649  accuracy =   0.6500  loss =  157.429\n",
      "testing  :  2649  accuracy =   0.6886  loss =  158.445\n",
      "training :  2650  accuracy =   0.7200  loss =  157.395\n",
      "testing  :  2650  accuracy =   0.6892  loss =  158.454\n",
      "training :  2651  accuracy =   0.7000  loss =  159.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2651  accuracy =   0.6890  loss =  158.468\n",
      "training :  2652  accuracy =   0.7500  loss =  155.507\n",
      "testing  :  2652  accuracy =   0.6887  loss =  158.442\n",
      "training :  2653  accuracy =   0.7800  loss =  157.156\n",
      "testing  :  2653  accuracy =   0.6886  loss =  158.431\n",
      "training :  2654  accuracy =   0.7300  loss =  158.539\n",
      "testing  :  2654  accuracy =   0.6893  loss =  158.414\n",
      "training :  2655  accuracy =   0.7200  loss =  157.625\n",
      "testing  :  2655  accuracy =   0.6895  loss =  158.394\n",
      "training :  2656  accuracy =   0.7400  loss =  155.606\n",
      "testing  :  2656  accuracy =   0.6899  loss =  158.398\n",
      "training :  2657  accuracy =   0.6600  loss =  157.778\n",
      "testing  :  2657  accuracy =   0.6907  loss =  158.429\n",
      "training :  2658  accuracy =   0.7100  loss =  159.107\n",
      "testing  :  2658  accuracy =   0.6907  loss =  158.477\n",
      "training :  2659  accuracy =   0.6700  loss =  159.72\n",
      "testing  :  2659  accuracy =   0.6906  loss =  158.528\n",
      "training :  2660  accuracy =   0.7100  loss =  156.137\n",
      "testing  :  2660  accuracy =   0.6908  loss =  158.546\n",
      "training :  2661  accuracy =   0.6600  loss =  160.217\n",
      "testing  :  2661  accuracy =   0.6907  loss =  158.557\n",
      "training :  2662  accuracy =   0.7400  loss =  157.585\n",
      "testing  :  2662  accuracy =   0.6904  loss =  158.599\n",
      "training :  2663  accuracy =   0.7400  loss =  157.854\n",
      "testing  :  2663  accuracy =   0.6901  loss =  158.632\n",
      "training :  2664  accuracy =   0.7200  loss =  157.619\n",
      "testing  :  2664  accuracy =   0.6895  loss =  158.656\n",
      "training :  2665  accuracy =   0.7100  loss =  154.877\n",
      "testing  :  2665  accuracy =   0.6899  loss =  158.618\n",
      "training :  2666  accuracy =   0.7100  loss =  155.761\n",
      "testing  :  2666  accuracy =   0.6898  loss =  158.587\n",
      "training :  2667  accuracy =   0.7000  loss =  157.784\n",
      "testing  :  2667  accuracy =   0.6905  loss =  158.568\n",
      "training :  2668  accuracy =   0.6500  loss =  158.714\n",
      "testing  :  2668  accuracy =   0.6898  loss =  158.544\n",
      "training :  2669  accuracy =   0.7600  loss =  157.666\n",
      "testing  :  2669  accuracy =   0.6908  loss =  158.52\n",
      "training :  2670  accuracy =   0.7700  loss =  158.487\n",
      "testing  :  2670  accuracy =   0.6908  loss =  158.502\n",
      "training :  2671  accuracy =   0.8000  loss =  155.448\n",
      "testing  :  2671  accuracy =   0.6905  loss =  158.49\n",
      "training :  2672  accuracy =   0.6800  loss =  158.439\n",
      "testing  :  2672  accuracy =   0.6901  loss =  158.487\n",
      "training :  2673  accuracy =   0.6600  loss =  157.418\n",
      "testing  :  2673  accuracy =   0.6894  loss =  158.48\n",
      "training :  2674  accuracy =   0.7600  loss =  157.956\n",
      "testing  :  2674  accuracy =   0.6889  loss =  158.484\n",
      "training :  2675  accuracy =   0.6300  loss =  161.285\n",
      "testing  :  2675  accuracy =   0.6884  loss =  158.53\n",
      "training :  2676  accuracy =   0.7400  loss =  157.028\n",
      "testing  :  2676  accuracy =   0.6880  loss =  158.543\n",
      "training :  2677  accuracy =   0.7300  loss =  155.01\n",
      "testing  :  2677  accuracy =   0.6880  loss =  158.562\n",
      "training :  2678  accuracy =   0.7200  loss =  156.062\n",
      "testing  :  2678  accuracy =   0.6869  loss =  158.582\n",
      "training :  2679  accuracy =   0.6900  loss =  159.775\n",
      "testing  :  2679  accuracy =   0.6867  loss =  158.574\n",
      "training :  2680  accuracy =   0.6500  loss =  159.399\n",
      "testing  :  2680  accuracy =   0.6869  loss =  158.583\n",
      "training :  2681  accuracy =   0.7500  loss =  158.504\n",
      "testing  :  2681  accuracy =   0.6863  loss =  158.596\n",
      "training :  2682  accuracy =   0.6900  loss =  156.271\n",
      "testing  :  2682  accuracy =   0.6852  loss =  158.576\n",
      "training :  2683  accuracy =   0.7600  loss =  154.885\n",
      "testing  :  2683  accuracy =   0.6842  loss =  158.583\n",
      "training :  2684  accuracy =   0.7200  loss =  157.615\n",
      "testing  :  2684  accuracy =   0.6835  loss =  158.607\n",
      "training :  2685  accuracy =   0.7400  loss =  156.841\n",
      "testing  :  2685  accuracy =   0.6837  loss =  158.596\n",
      "training :  2686  accuracy =   0.7200  loss =  159.924\n",
      "testing  :  2686  accuracy =   0.6845  loss =  158.579\n",
      "training :  2687  accuracy =   0.7200  loss =  159.506\n",
      "testing  :  2687  accuracy =   0.6845  loss =  158.565\n",
      "training :  2688  accuracy =   0.7000  loss =  155.855\n",
      "testing  :  2688  accuracy =   0.6849  loss =  158.517\n",
      "training :  2689  accuracy =   0.6700  loss =  154.82\n",
      "testing  :  2689  accuracy =   0.6855  loss =  158.5\n",
      "training :  2690  accuracy =   0.7200  loss =  159.859\n",
      "testing  :  2690  accuracy =   0.6857  loss =  158.501\n",
      "training :  2691  accuracy =   0.6600  loss =  157.084\n",
      "testing  :  2691  accuracy =   0.6860  loss =  158.519\n",
      "training :  2692  accuracy =   0.6600  loss =  159.198\n",
      "testing  :  2692  accuracy =   0.6847  loss =  158.547\n",
      "training :  2693  accuracy =   0.6900  loss =  158.648\n",
      "testing  :  2693  accuracy =   0.6855  loss =  158.562\n",
      "training :  2694  accuracy =   0.7100  loss =  157.375\n",
      "testing  :  2694  accuracy =   0.6856  loss =  158.573\n",
      "training :  2695  accuracy =   0.7600  loss =  159.134\n",
      "testing  :  2695  accuracy =   0.6858  loss =  158.552\n",
      "training :  2696  accuracy =   0.7200  loss =  154.941\n",
      "testing  :  2696  accuracy =   0.6857  loss =  158.519\n",
      "training :  2697  accuracy =   0.6700  loss =  160.405\n",
      "testing  :  2697  accuracy =   0.6863  loss =  158.498\n",
      "training :  2698  accuracy =   0.6900  loss =  156.701\n",
      "testing  :  2698  accuracy =   0.6874  loss =  158.451\n",
      "training :  2699  accuracy =   0.8000  loss =  155.963\n",
      "testing  :  2699  accuracy =   0.6878  loss =  158.417\n",
      "training :  2700  accuracy =   0.7100  loss =  156.667\n",
      "testing  :  2700  accuracy =   0.6881  loss =  158.391\n",
      "training :  2701  accuracy =   0.6800  loss =  155.992\n",
      "testing  :  2701  accuracy =   0.6884  loss =  158.37\n",
      "training :  2702  accuracy =   0.6900  loss =  157.345\n",
      "testing  :  2702  accuracy =   0.6885  loss =  158.361\n",
      "training :  2703  accuracy =   0.6100  loss =  156.475\n",
      "testing  :  2703  accuracy =   0.6882  loss =  158.343\n",
      "training :  2704  accuracy =   0.6600  loss =  156.281\n",
      "testing  :  2704  accuracy =   0.6884  loss =  158.338\n",
      "training :  2705  accuracy =   0.7500  loss =  156.919\n",
      "testing  :  2705  accuracy =   0.6883  loss =  158.343\n",
      "training :  2706  accuracy =   0.6200  loss =  157.868\n",
      "testing  :  2706  accuracy =   0.6884  loss =  158.352\n",
      "training :  2707  accuracy =   0.6600  loss =  160.239\n",
      "testing  :  2707  accuracy =   0.6880  loss =  158.367\n",
      "training :  2708  accuracy =   0.6400  loss =  157.847\n",
      "testing  :  2708  accuracy =   0.6876  loss =  158.406\n",
      "training :  2709  accuracy =   0.5900  loss =  160.489\n",
      "testing  :  2709  accuracy =   0.6877  loss =  158.45\n",
      "training :  2710  accuracy =   0.7200  loss =  160.126\n",
      "testing  :  2710  accuracy =   0.6874  loss =  158.47\n",
      "training :  2711  accuracy =   0.7000  loss =  156.411\n",
      "testing  :  2711  accuracy =   0.6879  loss =  158.498\n",
      "training :  2712  accuracy =   0.6800  loss =  157.207\n",
      "testing  :  2712  accuracy =   0.6881  loss =  158.518\n",
      "training :  2713  accuracy =   0.6900  loss =  158.759\n",
      "testing  :  2713  accuracy =   0.6879  loss =  158.502\n",
      "training :  2714  accuracy =   0.7000  loss =  159.095\n",
      "testing  :  2714  accuracy =   0.6883  loss =  158.478\n",
      "training :  2715  accuracy =   0.7100  loss =  160.066\n",
      "testing  :  2715  accuracy =   0.6886  loss =  158.432\n",
      "training :  2716  accuracy =   0.6800  loss =  160.295\n",
      "testing  :  2716  accuracy =   0.6881  loss =  158.386\n",
      "training :  2717  accuracy =   0.6200  loss =  157.386\n",
      "testing  :  2717  accuracy =   0.6896  loss =  158.356\n",
      "training :  2718  accuracy =   0.6100  loss =  157.443\n",
      "testing  :  2718  accuracy =   0.6896  loss =  158.349\n",
      "training :  2719  accuracy =   0.6900  loss =  158.639\n",
      "testing  :  2719  accuracy =   0.6895  loss =  158.352\n",
      "training :  2720  accuracy =   0.7900  loss =  157.232\n",
      "testing  :  2720  accuracy =   0.6891  loss =  158.373\n",
      "training :  2721  accuracy =   0.7700  loss =  155.661\n",
      "testing  :  2721  accuracy =   0.6893  loss =  158.397\n",
      "training :  2722  accuracy =   0.7800  loss =  155.029\n",
      "testing  :  2722  accuracy =   0.6891  loss =  158.424\n",
      "training :  2723  accuracy =   0.7600  loss =  157.389\n",
      "testing  :  2723  accuracy =   0.6888  loss =  158.455\n",
      "training :  2724  accuracy =   0.7000  loss =  157.954\n",
      "testing  :  2724  accuracy =   0.6881  loss =  158.495\n",
      "training :  2725  accuracy =   0.7100  loss =  159.483\n",
      "testing  :  2725  accuracy =   0.6877  loss =  158.544\n",
      "training :  2726  accuracy =   0.6400  loss =  159.905\n",
      "testing  :  2726  accuracy =   0.6877  loss =  158.578\n",
      "training :  2727  accuracy =   0.6900  loss =  157.573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2727  accuracy =   0.6880  loss =  158.515\n",
      "training :  2728  accuracy =   0.7300  loss =  156.593\n",
      "testing  :  2728  accuracy =   0.6888  loss =  158.394\n",
      "training :  2729  accuracy =   0.6200  loss =  158.352\n",
      "testing  :  2729  accuracy =   0.6899  loss =  158.311\n",
      "training :  2730  accuracy =   0.7300  loss =  157.922\n",
      "testing  :  2730  accuracy =   0.6904  loss =  158.285\n",
      "training :  2731  accuracy =   0.7300  loss =  158.273\n",
      "testing  :  2731  accuracy =   0.6894  loss =  158.301\n",
      "training :  2732  accuracy =   0.7100  loss =  156.767\n",
      "testing  :  2732  accuracy =   0.6897  loss =  158.355\n",
      "training :  2733  accuracy =   0.6600  loss =  156.844\n",
      "testing  :  2733  accuracy =   0.6891  loss =  158.443\n",
      "training :  2734  accuracy =   0.6800  loss =  161.136\n",
      "testing  :  2734  accuracy =   0.6884  loss =  158.508\n",
      "training :  2735  accuracy =   0.6700  loss =  156.934\n",
      "testing  :  2735  accuracy =   0.6885  loss =  158.567\n",
      "training :  2736  accuracy =   0.6700  loss =  159.644\n",
      "testing  :  2736  accuracy =   0.6882  loss =  158.609\n",
      "training :  2737  accuracy =   0.6900  loss =  157.613\n",
      "testing  :  2737  accuracy =   0.6881  loss =  158.631\n",
      "training :  2738  accuracy =   0.6800  loss =  158.12\n",
      "testing  :  2738  accuracy =   0.6887  loss =  158.635\n",
      "training :  2739  accuracy =   0.7100  loss =  156.329\n",
      "testing  :  2739  accuracy =   0.6882  loss =  158.649\n",
      "training :  2740  accuracy =   0.6200  loss =  162.368\n",
      "testing  :  2740  accuracy =   0.6885  loss =  158.585\n",
      "training :  2741  accuracy =   0.6600  loss =  158.783\n",
      "testing  :  2741  accuracy =   0.6887  loss =  158.548\n",
      "training :  2742  accuracy =   0.6400  loss =  157.259\n",
      "testing  :  2742  accuracy =   0.6884  loss =  158.527\n",
      "training :  2743  accuracy =   0.6200  loss =  158.686\n",
      "testing  :  2743  accuracy =   0.6875  loss =  158.554\n",
      "training :  2744  accuracy =   0.6800  loss =  160.878\n",
      "testing  :  2744  accuracy =   0.6880  loss =  158.514\n",
      "training :  2745  accuracy =   0.6500  loss =  156.87\n",
      "testing  :  2745  accuracy =   0.6876  loss =  158.467\n",
      "training :  2746  accuracy =   0.6900  loss =  157.032\n",
      "testing  :  2746  accuracy =   0.6862  loss =  158.458\n",
      "training :  2747  accuracy =   0.7900  loss =  154.911\n",
      "testing  :  2747  accuracy =   0.6852  loss =  158.465\n",
      "training :  2748  accuracy =   0.6400  loss =  160.764\n",
      "testing  :  2748  accuracy =   0.6853  loss =  158.527\n",
      "training :  2749  accuracy =   0.6800  loss =  158.701\n",
      "testing  :  2749  accuracy =   0.6844  loss =  158.608\n",
      "training :  2750  accuracy =   0.7100  loss =  156.792\n",
      "testing  :  2750  accuracy =   0.6843  loss =  158.648\n",
      "training :  2751  accuracy =   0.6600  loss =  159.561\n",
      "testing  :  2751  accuracy =   0.6842  loss =  158.693\n",
      "training :  2752  accuracy =   0.6400  loss =  157.266\n",
      "testing  :  2752  accuracy =   0.6843  loss =  158.632\n",
      "training :  2753  accuracy =   0.7000  loss =  159.544\n",
      "testing  :  2753  accuracy =   0.6845  loss =  158.596\n",
      "training :  2754  accuracy =   0.6800  loss =  159.898\n",
      "testing  :  2754  accuracy =   0.6841  loss =  158.544\n",
      "training :  2755  accuracy =   0.6200  loss =  159.285\n",
      "testing  :  2755  accuracy =   0.6846  loss =  158.496\n",
      "training :  2756  accuracy =   0.7700  loss =  157.581\n",
      "testing  :  2756  accuracy =   0.6852  loss =  158.443\n",
      "training :  2757  accuracy =   0.8100  loss =  159.182\n",
      "testing  :  2757  accuracy =   0.6856  loss =  158.4\n",
      "training :  2758  accuracy =   0.7200  loss =  158.648\n",
      "testing  :  2758  accuracy =   0.6861  loss =  158.378\n",
      "training :  2759  accuracy =   0.7200  loss =  157.74\n",
      "testing  :  2759  accuracy =   0.6858  loss =  158.364\n",
      "training :  2760  accuracy =   0.7400  loss =  157.692\n",
      "testing  :  2760  accuracy =   0.6868  loss =  158.368\n",
      "training :  2761  accuracy =   0.7600  loss =  154.689\n",
      "testing  :  2761  accuracy =   0.6862  loss =  158.404\n",
      "training :  2762  accuracy =   0.7200  loss =  157.168\n",
      "testing  :  2762  accuracy =   0.6862  loss =  158.458\n",
      "training :  2763  accuracy =   0.6900  loss =  156.964\n",
      "testing  :  2763  accuracy =   0.6862  loss =  158.521\n",
      "training :  2764  accuracy =   0.7400  loss =  157.268\n",
      "testing  :  2764  accuracy =   0.6855  loss =  158.607\n",
      "training :  2765  accuracy =   0.6900  loss =  158.477\n",
      "testing  :  2765  accuracy =   0.6836  loss =  158.687\n",
      "training :  2766  accuracy =   0.6700  loss =  159.936\n",
      "testing  :  2766  accuracy =   0.6835  loss =  158.726\n",
      "training :  2767  accuracy =   0.6600  loss =  156.974\n",
      "testing  :  2767  accuracy =   0.6842  loss =  158.689\n",
      "training :  2768  accuracy =   0.7100  loss =  156.79\n",
      "testing  :  2768  accuracy =   0.6854  loss =  158.638\n",
      "training :  2769  accuracy =   0.6900  loss =  158.486\n",
      "testing  :  2769  accuracy =   0.6866  loss =  158.584\n",
      "training :  2770  accuracy =   0.6500  loss =  158.089\n",
      "testing  :  2770  accuracy =   0.6874  loss =  158.504\n",
      "training :  2771  accuracy =   0.7200  loss =  156.223\n",
      "testing  :  2771  accuracy =   0.6880  loss =  158.406\n",
      "training :  2772  accuracy =   0.7000  loss =  156.483\n",
      "testing  :  2772  accuracy =   0.6876  loss =  158.346\n",
      "training :  2773  accuracy =   0.6800  loss =  159.579\n",
      "testing  :  2773  accuracy =   0.6888  loss =  158.31\n",
      "training :  2774  accuracy =   0.6400  loss =  159.856\n",
      "testing  :  2774  accuracy =   0.6886  loss =  158.304\n",
      "training :  2775  accuracy =   0.7500  loss =  157.185\n",
      "testing  :  2775  accuracy =   0.6888  loss =  158.314\n",
      "training :  2776  accuracy =   0.7000  loss =  158.403\n",
      "testing  :  2776  accuracy =   0.6893  loss =  158.347\n",
      "training :  2777  accuracy =   0.7400  loss =  157.276\n",
      "testing  :  2777  accuracy =   0.6885  loss =  158.387\n",
      "training :  2778  accuracy =   0.7400  loss =  157.749\n",
      "testing  :  2778  accuracy =   0.6882  loss =  158.429\n",
      "training :  2779  accuracy =   0.6600  loss =  160.101\n",
      "testing  :  2779  accuracy =   0.6888  loss =  158.48\n",
      "training :  2780  accuracy =   0.6900  loss =  158.626\n",
      "testing  :  2780  accuracy =   0.6884  loss =  158.543\n",
      "training :  2781  accuracy =   0.7200  loss =  157.806\n",
      "testing  :  2781  accuracy =   0.6875  loss =  158.594\n",
      "training :  2782  accuracy =   0.7700  loss =  157.962\n",
      "testing  :  2782  accuracy =   0.6876  loss =  158.651\n",
      "training :  2783  accuracy =   0.8600  loss =  156.449\n",
      "testing  :  2783  accuracy =   0.6874  loss =  158.693\n",
      "training :  2784  accuracy =   0.6500  loss =  158.534\n",
      "testing  :  2784  accuracy =   0.6873  loss =  158.692\n",
      "training :  2785  accuracy =   0.6800  loss =  158.901\n",
      "testing  :  2785  accuracy =   0.6886  loss =  158.593\n",
      "training :  2786  accuracy =   0.6200  loss =  160.235\n",
      "testing  :  2786  accuracy =   0.6891  loss =  158.52\n",
      "training :  2787  accuracy =   0.6600  loss =  157.268\n",
      "testing  :  2787  accuracy =   0.6898  loss =  158.455\n",
      "training :  2788  accuracy =   0.6800  loss =  157.059\n",
      "testing  :  2788  accuracy =   0.6904  loss =  158.399\n",
      "training :  2789  accuracy =   0.7800  loss =  156.457\n",
      "testing  :  2789  accuracy =   0.6908  loss =  158.367\n",
      "training :  2790  accuracy =   0.7200  loss =  160.44\n",
      "testing  :  2790  accuracy =   0.6909  loss =  158.357\n",
      "training :  2791  accuracy =   0.7100  loss =  157.317\n",
      "testing  :  2791  accuracy =   0.6909  loss =  158.359\n",
      "training :  2792  accuracy =   0.7200  loss =  157.06\n",
      "testing  :  2792  accuracy =   0.6906  loss =  158.37\n",
      "training :  2793  accuracy =   0.6800  loss =  157.004\n",
      "testing  :  2793  accuracy =   0.6896  loss =  158.382\n",
      "training :  2794  accuracy =   0.7500  loss =  154.022\n",
      "testing  :  2794  accuracy =   0.6892  loss =  158.411\n",
      "training :  2795  accuracy =   0.7000  loss =  158.715\n",
      "testing  :  2795  accuracy =   0.6891  loss =  158.451\n",
      "training :  2796  accuracy =   0.6500  loss =  158.448\n",
      "testing  :  2796  accuracy =   0.6887  loss =  158.484\n",
      "training :  2797  accuracy =   0.6900  loss =  156.434\n",
      "testing  :  2797  accuracy =   0.6880  loss =  158.494\n",
      "training :  2798  accuracy =   0.7100  loss =  157.631\n",
      "testing  :  2798  accuracy =   0.6876  loss =  158.505\n",
      "training :  2799  accuracy =   0.7100  loss =  158.415\n",
      "testing  :  2799  accuracy =   0.6872  loss =  158.527\n",
      "training :  2800  accuracy =   0.7200  loss =  157.223\n",
      "testing  :  2800  accuracy =   0.6870  loss =  158.545\n",
      "training :  2801  accuracy =   0.6700  loss =  156.598\n",
      "testing  :  2801  accuracy =   0.6868  loss =  158.56\n",
      "training :  2802  accuracy =   0.7200  loss =  157.846\n",
      "testing  :  2802  accuracy =   0.6867  loss =  158.589\n",
      "training :  2803  accuracy =   0.7600  loss =  155.676\n",
      "testing  :  2803  accuracy =   0.6868  loss =  158.58\n",
      "training :  2804  accuracy =   0.6900  loss =  158.561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2804  accuracy =   0.6865  loss =  158.584\n",
      "training :  2805  accuracy =   0.6900  loss =  157.072\n",
      "testing  :  2805  accuracy =   0.6863  loss =  158.573\n",
      "training :  2806  accuracy =   0.6900  loss =  156.988\n",
      "testing  :  2806  accuracy =   0.6860  loss =  158.574\n",
      "training :  2807  accuracy =   0.6600  loss =  159.674\n",
      "testing  :  2807  accuracy =   0.6859  loss =  158.581\n",
      "training :  2808  accuracy =   0.7500  loss =  156.405\n",
      "testing  :  2808  accuracy =   0.6855  loss =  158.555\n",
      "training :  2809  accuracy =   0.7300  loss =  155.081\n",
      "testing  :  2809  accuracy =   0.6853  loss =  158.539\n",
      "training :  2810  accuracy =   0.7000  loss =  158.521\n",
      "testing  :  2810  accuracy =   0.6860  loss =  158.519\n",
      "training :  2811  accuracy =   0.7000  loss =  155.569\n",
      "testing  :  2811  accuracy =   0.6861  loss =  158.53\n",
      "training :  2812  accuracy =   0.7300  loss =  159.222\n",
      "testing  :  2812  accuracy =   0.6860  loss =  158.534\n",
      "training :  2813  accuracy =   0.7200  loss =  155.564\n",
      "testing  :  2813  accuracy =   0.6854  loss =  158.542\n",
      "training :  2814  accuracy =   0.7200  loss =  157.54\n",
      "testing  :  2814  accuracy =   0.6853  loss =  158.562\n",
      "training :  2815  accuracy =   0.6600  loss =  157.767\n",
      "testing  :  2815  accuracy =   0.6856  loss =  158.543\n",
      "training :  2816  accuracy =   0.6600  loss =  157.018\n",
      "testing  :  2816  accuracy =   0.6855  loss =  158.528\n",
      "training :  2817  accuracy =   0.6900  loss =  157.015\n",
      "testing  :  2817  accuracy =   0.6849  loss =  158.517\n",
      "training :  2818  accuracy =   0.6700  loss =  158.317\n",
      "testing  :  2818  accuracy =   0.6850  loss =  158.505\n",
      "training :  2819  accuracy =   0.7200  loss =  156.277\n",
      "testing  :  2819  accuracy =   0.6860  loss =  158.489\n",
      "training :  2820  accuracy =   0.7000  loss =  159.141\n",
      "testing  :  2820  accuracy =   0.6861  loss =  158.482\n",
      "training :  2821  accuracy =   0.6600  loss =  157.245\n",
      "testing  :  2821  accuracy =   0.6863  loss =  158.475\n",
      "training :  2822  accuracy =   0.6200  loss =  157.811\n",
      "testing  :  2822  accuracy =   0.6858  loss =  158.48\n",
      "training :  2823  accuracy =   0.7000  loss =  158.808\n",
      "testing  :  2823  accuracy =   0.6861  loss =  158.49\n",
      "training :  2824  accuracy =   0.7600  loss =  158.648\n",
      "testing  :  2824  accuracy =   0.6856  loss =  158.496\n",
      "training :  2825  accuracy =   0.6000  loss =  158.563\n",
      "testing  :  2825  accuracy =   0.6851  loss =  158.495\n",
      "training :  2826  accuracy =   0.6800  loss =  158.545\n",
      "testing  :  2826  accuracy =   0.6846  loss =  158.514\n",
      "training :  2827  accuracy =   0.6200  loss =  156.585\n",
      "testing  :  2827  accuracy =   0.6849  loss =  158.556\n",
      "training :  2828  accuracy =   0.6400  loss =  162.378\n",
      "testing  :  2828  accuracy =   0.6843  loss =  158.605\n",
      "training :  2829  accuracy =   0.6600  loss =  156.429\n",
      "testing  :  2829  accuracy =   0.6842  loss =  158.649\n",
      "training :  2830  accuracy =   0.7200  loss =  154.229\n",
      "testing  :  2830  accuracy =   0.6836  loss =  158.695\n",
      "training :  2831  accuracy =   0.6800  loss =  160.023\n",
      "testing  :  2831  accuracy =   0.6838  loss =  158.72\n",
      "training :  2832  accuracy =   0.6700  loss =  160.145\n",
      "testing  :  2832  accuracy =   0.6836  loss =  158.72\n",
      "training :  2833  accuracy =   0.6400  loss =  157.637\n",
      "testing  :  2833  accuracy =   0.6838  loss =  158.724\n",
      "training :  2834  accuracy =   0.6500  loss =  156.507\n",
      "testing  :  2834  accuracy =   0.6838  loss =  158.755\n",
      "training :  2835  accuracy =   0.7200  loss =  158.127\n",
      "testing  :  2835  accuracy =   0.6838  loss =  158.783\n",
      "training :  2836  accuracy =   0.7600  loss =  157.52\n",
      "testing  :  2836  accuracy =   0.6836  loss =  158.765\n",
      "training :  2837  accuracy =   0.6900  loss =  159.328\n",
      "testing  :  2837  accuracy =   0.6838  loss =  158.693\n",
      "training :  2838  accuracy =   0.6800  loss =  157.954\n",
      "testing  :  2838  accuracy =   0.6840  loss =  158.618\n",
      "training :  2839  accuracy =   0.7100  loss =  156.294\n",
      "testing  :  2839  accuracy =   0.6842  loss =  158.542\n",
      "training :  2840  accuracy =   0.7200  loss =  155.937\n",
      "testing  :  2840  accuracy =   0.6854  loss =  158.498\n",
      "training :  2841  accuracy =   0.7400  loss =  155.633\n",
      "testing  :  2841  accuracy =   0.6860  loss =  158.455\n",
      "training :  2842  accuracy =   0.7200  loss =  157.019\n",
      "testing  :  2842  accuracy =   0.6854  loss =  158.467\n",
      "training :  2843  accuracy =   0.7400  loss =  156.214\n",
      "testing  :  2843  accuracy =   0.6849  loss =  158.466\n",
      "training :  2844  accuracy =   0.6600  loss =  158.429\n",
      "testing  :  2844  accuracy =   0.6844  loss =  158.467\n",
      "training :  2845  accuracy =   0.7100  loss =  156.228\n",
      "testing  :  2845  accuracy =   0.6840  loss =  158.417\n",
      "training :  2846  accuracy =   0.6800  loss =  156.995\n",
      "testing  :  2846  accuracy =   0.6841  loss =  158.38\n",
      "training :  2847  accuracy =   0.6800  loss =  158.169\n",
      "testing  :  2847  accuracy =   0.6839  loss =  158.347\n",
      "training :  2848  accuracy =   0.7300  loss =  157.909\n",
      "testing  :  2848  accuracy =   0.6847  loss =  158.285\n",
      "training :  2849  accuracy =   0.7500  loss =  157.347\n",
      "testing  :  2849  accuracy =   0.6842  loss =  158.24\n",
      "training :  2850  accuracy =   0.7300  loss =  155.693\n",
      "testing  :  2850  accuracy =   0.6840  loss =  158.22\n",
      "training :  2851  accuracy =   0.6900  loss =  158.771\n",
      "testing  :  2851  accuracy =   0.6854  loss =  158.21\n",
      "training :  2852  accuracy =   0.5800  loss =  163.22\n",
      "testing  :  2852  accuracy =   0.6857  loss =  158.233\n",
      "training :  2853  accuracy =   0.6600  loss =  156.953\n",
      "testing  :  2853  accuracy =   0.6856  loss =  158.275\n",
      "training :  2854  accuracy =   0.7100  loss =  156.302\n",
      "testing  :  2854  accuracy =   0.6856  loss =  158.332\n",
      "training :  2855  accuracy =   0.6800  loss =  157.364\n",
      "testing  :  2855  accuracy =   0.6849  loss =  158.394\n",
      "training :  2856  accuracy =   0.7400  loss =  158.039\n",
      "testing  :  2856  accuracy =   0.6850  loss =  158.456\n",
      "training :  2857  accuracy =   0.6200  loss =  160.277\n",
      "testing  :  2857  accuracy =   0.6851  loss =  158.485\n",
      "training :  2858  accuracy =   0.7200  loss =  156.781\n",
      "testing  :  2858  accuracy =   0.6856  loss =  158.407\n",
      "training :  2859  accuracy =   0.6700  loss =  160.259\n",
      "testing  :  2859  accuracy =   0.6861  loss =  158.362\n",
      "training :  2860  accuracy =   0.7200  loss =  154.773\n",
      "testing  :  2860  accuracy =   0.6862  loss =  158.382\n",
      "training :  2861  accuracy =   0.6700  loss =  157.308\n",
      "testing  :  2861  accuracy =   0.6863  loss =  158.425\n",
      "training :  2862  accuracy =   0.6600  loss =  158.2\n",
      "testing  :  2862  accuracy =   0.6865  loss =  158.428\n",
      "training :  2863  accuracy =   0.6700  loss =  158.226\n",
      "testing  :  2863  accuracy =   0.6877  loss =  158.384\n",
      "training :  2864  accuracy =   0.6400  loss =  157.569\n",
      "testing  :  2864  accuracy =   0.6880  loss =  158.366\n",
      "training :  2865  accuracy =   0.6900  loss =  159.24\n",
      "testing  :  2865  accuracy =   0.6887  loss =  158.339\n",
      "training :  2866  accuracy =   0.6800  loss =  158.15\n",
      "testing  :  2866  accuracy =   0.6901  loss =  158.288\n",
      "training :  2867  accuracy =   0.7200  loss =  155.681\n",
      "testing  :  2867  accuracy =   0.6908  loss =  158.25\n",
      "training :  2868  accuracy =   0.7400  loss =  157.967\n",
      "testing  :  2868  accuracy =   0.6908  loss =  158.226\n",
      "training :  2869  accuracy =   0.7000  loss =  161.833\n",
      "testing  :  2869  accuracy =   0.6904  loss =  158.225\n",
      "training :  2870  accuracy =   0.7000  loss =  160.609\n",
      "testing  :  2870  accuracy =   0.6909  loss =  158.217\n",
      "training :  2871  accuracy =   0.7300  loss =  157.791\n",
      "testing  :  2871  accuracy =   0.6908  loss =  158.213\n",
      "training :  2872  accuracy =   0.7000  loss =  159.865\n",
      "testing  :  2872  accuracy =   0.6905  loss =  158.211\n",
      "training :  2873  accuracy =   0.6200  loss =  160.765\n",
      "testing  :  2873  accuracy =   0.6904  loss =  158.203\n",
      "training :  2874  accuracy =   0.6500  loss =  155.098\n",
      "testing  :  2874  accuracy =   0.6904  loss =  158.195\n",
      "training :  2875  accuracy =   0.6900  loss =  155.031\n",
      "testing  :  2875  accuracy =   0.6897  loss =  158.195\n",
      "training :  2876  accuracy =   0.6300  loss =  159.293\n",
      "testing  :  2876  accuracy =   0.6895  loss =  158.196\n",
      "training :  2877  accuracy =   0.6700  loss =  157.316\n",
      "testing  :  2877  accuracy =   0.6898  loss =  158.194\n",
      "training :  2878  accuracy =   0.7000  loss =  157.242\n",
      "testing  :  2878  accuracy =   0.6891  loss =  158.179\n",
      "training :  2879  accuracy =   0.6900  loss =  158.834\n",
      "testing  :  2879  accuracy =   0.6885  loss =  158.175\n",
      "training :  2880  accuracy =   0.7200  loss =  159.24\n",
      "testing  :  2880  accuracy =   0.6883  loss =  158.197\n",
      "training :  2881  accuracy =   0.7600  loss =  158.314\n",
      "testing  :  2881  accuracy =   0.6885  loss =  158.249\n",
      "training :  2882  accuracy =   0.7200  loss =  155.093\n",
      "testing  :  2882  accuracy =   0.6879  loss =  158.282\n",
      "training :  2883  accuracy =   0.6500  loss =  157.941\n",
      "testing  :  2883  accuracy =   0.6877  loss =  158.315\n",
      "training :  2884  accuracy =   0.6900  loss =  158.323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2884  accuracy =   0.6868  loss =  158.364\n",
      "training :  2885  accuracy =   0.6800  loss =  157.878\n",
      "testing  :  2885  accuracy =   0.6868  loss =  158.378\n",
      "training :  2886  accuracy =   0.7300  loss =  157.209\n",
      "testing  :  2886  accuracy =   0.6861  loss =  158.379\n",
      "training :  2887  accuracy =   0.7200  loss =  156.481\n",
      "testing  :  2887  accuracy =   0.6864  loss =  158.33\n",
      "training :  2888  accuracy =   0.7100  loss =  159.083\n",
      "testing  :  2888  accuracy =   0.6868  loss =  158.302\n",
      "training :  2889  accuracy =   0.7100  loss =  156.405\n",
      "testing  :  2889  accuracy =   0.6867  loss =  158.239\n",
      "training :  2890  accuracy =   0.6900  loss =  158.235\n",
      "testing  :  2890  accuracy =   0.6871  loss =  158.202\n",
      "training :  2891  accuracy =   0.6000  loss =  159.931\n",
      "testing  :  2891  accuracy =   0.6878  loss =  158.203\n",
      "training :  2892  accuracy =   0.6700  loss =  161.538\n",
      "testing  :  2892  accuracy =   0.6884  loss =  158.221\n",
      "training :  2893  accuracy =   0.6500  loss =  160.625\n",
      "testing  :  2893  accuracy =   0.6883  loss =  158.216\n",
      "training :  2894  accuracy =   0.6900  loss =  158.147\n",
      "testing  :  2894  accuracy =   0.6887  loss =  158.229\n",
      "training :  2895  accuracy =   0.6800  loss =  156.037\n",
      "testing  :  2895  accuracy =   0.6878  loss =  158.259\n",
      "training :  2896  accuracy =   0.7500  loss =  157.089\n",
      "testing  :  2896  accuracy =   0.6876  loss =  158.324\n",
      "training :  2897  accuracy =   0.6600  loss =  159.069\n",
      "testing  :  2897  accuracy =   0.6871  loss =  158.408\n",
      "training :  2898  accuracy =   0.6400  loss =  157.265\n",
      "testing  :  2898  accuracy =   0.6863  loss =  158.465\n",
      "training :  2899  accuracy =   0.6800  loss =  156.724\n",
      "testing  :  2899  accuracy =   0.6863  loss =  158.498\n",
      "training :  2900  accuracy =   0.6500  loss =  158.909\n",
      "testing  :  2900  accuracy =   0.6860  loss =  158.517\n",
      "training :  2901  accuracy =   0.7300  loss =  157.287\n",
      "testing  :  2901  accuracy =   0.6871  loss =  158.488\n",
      "training :  2902  accuracy =   0.6800  loss =  159.906\n",
      "testing  :  2902  accuracy =   0.6871  loss =  158.449\n",
      "training :  2903  accuracy =   0.6500  loss =  161.384\n",
      "testing  :  2903  accuracy =   0.6874  loss =  158.341\n",
      "training :  2904  accuracy =   0.7400  loss =  156.784\n",
      "testing  :  2904  accuracy =   0.6878  loss =  158.241\n",
      "training :  2905  accuracy =   0.7200  loss =  155.777\n",
      "testing  :  2905  accuracy =   0.6888  loss =  158.216\n",
      "training :  2906  accuracy =   0.7300  loss =  156.116\n",
      "testing  :  2906  accuracy =   0.6880  loss =  158.236\n",
      "training :  2907  accuracy =   0.6400  loss =  159.508\n",
      "testing  :  2907  accuracy =   0.6876  loss =  158.277\n",
      "training :  2908  accuracy =   0.6700  loss =  160.867\n",
      "testing  :  2908  accuracy =   0.6872  loss =  158.317\n",
      "training :  2909  accuracy =   0.6600  loss =  156.957\n",
      "testing  :  2909  accuracy =   0.6880  loss =  158.34\n",
      "training :  2910  accuracy =   0.7100  loss =  158.265\n",
      "testing  :  2910  accuracy =   0.6878  loss =  158.389\n",
      "training :  2911  accuracy =   0.6400  loss =  157.135\n",
      "testing  :  2911  accuracy =   0.6878  loss =  158.414\n",
      "training :  2912  accuracy =   0.6600  loss =  157.879\n",
      "testing  :  2912  accuracy =   0.6880  loss =  158.425\n",
      "training :  2913  accuracy =   0.7000  loss =  160.081\n",
      "testing  :  2913  accuracy =   0.6877  loss =  158.41\n",
      "training :  2914  accuracy =   0.6700  loss =  157.078\n",
      "testing  :  2914  accuracy =   0.6880  loss =  158.393\n",
      "training :  2915  accuracy =   0.7400  loss =  158.15\n",
      "testing  :  2915  accuracy =   0.6879  loss =  158.411\n",
      "training :  2916  accuracy =   0.6800  loss =  155.289\n",
      "testing  :  2916  accuracy =   0.6881  loss =  158.383\n",
      "training :  2917  accuracy =   0.6900  loss =  157.281\n",
      "testing  :  2917  accuracy =   0.6880  loss =  158.37\n",
      "training :  2918  accuracy =   0.7900  loss =  157.135\n",
      "testing  :  2918  accuracy =   0.6884  loss =  158.346\n",
      "training :  2919  accuracy =   0.6900  loss =  157.992\n",
      "testing  :  2919  accuracy =   0.6886  loss =  158.322\n",
      "training :  2920  accuracy =   0.6900  loss =  158.511\n",
      "testing  :  2920  accuracy =   0.6907  loss =  158.245\n",
      "training :  2921  accuracy =   0.7000  loss =  159.152\n",
      "testing  :  2921  accuracy =   0.6900  loss =  158.204\n",
      "training :  2922  accuracy =   0.7100  loss =  157.687\n",
      "testing  :  2922  accuracy =   0.6908  loss =  158.175\n",
      "training :  2923  accuracy =   0.6600  loss =  156.822\n",
      "testing  :  2923  accuracy =   0.6906  loss =  158.276\n",
      "training :  2924  accuracy =   0.7900  loss =  154.8\n",
      "testing  :  2924  accuracy =   0.6904  loss =  158.427\n",
      "training :  2925  accuracy =   0.6500  loss =  162.827\n",
      "testing  :  2925  accuracy =   0.6893  loss =  158.558\n",
      "training :  2926  accuracy =   0.6700  loss =  161.303\n",
      "testing  :  2926  accuracy =   0.6886  loss =  158.739\n",
      "training :  2927  accuracy =   0.6200  loss =  157.506\n",
      "testing  :  2927  accuracy =   0.6873  loss =  158.889\n",
      "training :  2928  accuracy =   0.7100  loss =  156.119\n",
      "testing  :  2928  accuracy =   0.6883  loss =  158.819\n",
      "training :  2929  accuracy =   0.6900  loss =  161.935\n",
      "testing  :  2929  accuracy =   0.6891  loss =  158.697\n",
      "training :  2930  accuracy =   0.7100  loss =  157.48\n",
      "testing  :  2930  accuracy =   0.6901  loss =  158.451\n",
      "training :  2931  accuracy =   0.6200  loss =  157.11\n",
      "testing  :  2931  accuracy =   0.6905  loss =  158.298\n",
      "training :  2932  accuracy =   0.7600  loss =  157.666\n",
      "testing  :  2932  accuracy =   0.6906  loss =  158.219\n",
      "training :  2933  accuracy =   0.7100  loss =  159.089\n",
      "testing  :  2933  accuracy =   0.6900  loss =  158.19\n",
      "training :  2934  accuracy =   0.6900  loss =  157.053\n",
      "testing  :  2934  accuracy =   0.6895  loss =  158.2\n",
      "training :  2935  accuracy =   0.7300  loss =  156.072\n",
      "testing  :  2935  accuracy =   0.6893  loss =  158.241\n",
      "training :  2936  accuracy =   0.7100  loss =  157.649\n",
      "testing  :  2936  accuracy =   0.6876  loss =  158.299\n",
      "training :  2937  accuracy =   0.6700  loss =  158.388\n",
      "testing  :  2937  accuracy =   0.6871  loss =  158.381\n",
      "training :  2938  accuracy =   0.6600  loss =  158.779\n",
      "testing  :  2938  accuracy =   0.6863  loss =  158.438\n",
      "training :  2939  accuracy =   0.6800  loss =  156.484\n",
      "testing  :  2939  accuracy =   0.6861  loss =  158.479\n",
      "training :  2940  accuracy =   0.6600  loss =  159.578\n",
      "testing  :  2940  accuracy =   0.6854  loss =  158.516\n",
      "training :  2941  accuracy =   0.6800  loss =  156.306\n",
      "testing  :  2941  accuracy =   0.6858  loss =  158.476\n",
      "training :  2942  accuracy =   0.6600  loss =  160.517\n",
      "testing  :  2942  accuracy =   0.6860  loss =  158.428\n",
      "training :  2943  accuracy =   0.5900  loss =  163.149\n",
      "testing  :  2943  accuracy =   0.6868  loss =  158.39\n",
      "training :  2944  accuracy =   0.7800  loss =  156.327\n",
      "testing  :  2944  accuracy =   0.6870  loss =  158.399\n",
      "training :  2945  accuracy =   0.7000  loss =  158.332\n",
      "testing  :  2945  accuracy =   0.6862  loss =  158.444\n",
      "training :  2946  accuracy =   0.7100  loss =  156.617\n",
      "testing  :  2946  accuracy =   0.6855  loss =  158.5\n",
      "training :  2947  accuracy =   0.7300  loss =  156.657\n",
      "testing  :  2947  accuracy =   0.6841  loss =  158.573\n",
      "training :  2948  accuracy =   0.6600  loss =  158.022\n",
      "testing  :  2948  accuracy =   0.6836  loss =  158.584\n",
      "training :  2949  accuracy =   0.7200  loss =  157.696\n",
      "testing  :  2949  accuracy =   0.6836  loss =  158.587\n",
      "training :  2950  accuracy =   0.7000  loss =  155.332\n",
      "testing  :  2950  accuracy =   0.6851  loss =  158.5\n",
      "training :  2951  accuracy =   0.7400  loss =  156.24\n",
      "testing  :  2951  accuracy =   0.6866  loss =  158.423\n",
      "training :  2952  accuracy =   0.7200  loss =  156.916\n",
      "testing  :  2952  accuracy =   0.6867  loss =  158.37\n",
      "training :  2953  accuracy =   0.5800  loss =  159.473\n",
      "testing  :  2953  accuracy =   0.6876  loss =  158.293\n",
      "training :  2954  accuracy =   0.7000  loss =  156.8\n",
      "testing  :  2954  accuracy =   0.6885  loss =  158.24\n",
      "training :  2955  accuracy =   0.7600  loss =  158.526\n",
      "testing  :  2955  accuracy =   0.6891  loss =  158.2\n",
      "training :  2956  accuracy =   0.7800  loss =  156.962\n",
      "testing  :  2956  accuracy =   0.6895  loss =  158.172\n",
      "training :  2957  accuracy =   0.6900  loss =  156.243\n",
      "testing  :  2957  accuracy =   0.6892  loss =  158.16\n",
      "training :  2958  accuracy =   0.7300  loss =  157.853\n",
      "testing  :  2958  accuracy =   0.6889  loss =  158.158\n",
      "training :  2959  accuracy =   0.6700  loss =  156.381\n",
      "testing  :  2959  accuracy =   0.6886  loss =  158.161\n",
      "training :  2960  accuracy =   0.7300  loss =  160.503\n",
      "testing  :  2960  accuracy =   0.6884  loss =  158.171\n",
      "training :  2961  accuracy =   0.7900  loss =  156.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  2961  accuracy =   0.6880  loss =  158.2\n",
      "training :  2962  accuracy =   0.7500  loss =  157.311\n",
      "testing  :  2962  accuracy =   0.6869  loss =  158.232\n",
      "training :  2963  accuracy =   0.6800  loss =  158.124\n",
      "testing  :  2963  accuracy =   0.6864  loss =  158.259\n",
      "training :  2964  accuracy =   0.7200  loss =  156.537\n",
      "testing  :  2964  accuracy =   0.6854  loss =  158.34\n",
      "training :  2965  accuracy =   0.7300  loss =  158.693\n",
      "testing  :  2965  accuracy =   0.6849  loss =  158.395\n",
      "training :  2966  accuracy =   0.6900  loss =  157.618\n",
      "testing  :  2966  accuracy =   0.6846  loss =  158.389\n",
      "training :  2967  accuracy =   0.7700  loss =  158.214\n",
      "testing  :  2967  accuracy =   0.6846  loss =  158.379\n",
      "training :  2968  accuracy =   0.6900  loss =  157.598\n",
      "testing  :  2968  accuracy =   0.6847  loss =  158.349\n",
      "training :  2969  accuracy =   0.6800  loss =  159.306\n",
      "testing  :  2969  accuracy =   0.6846  loss =  158.294\n",
      "training :  2970  accuracy =   0.6400  loss =  157.873\n",
      "testing  :  2970  accuracy =   0.6847  loss =  158.232\n",
      "training :  2971  accuracy =   0.7600  loss =  157.728\n",
      "testing  :  2971  accuracy =   0.6854  loss =  158.171\n",
      "training :  2972  accuracy =   0.6600  loss =  156.236\n",
      "testing  :  2972  accuracy =   0.6860  loss =  158.1\n",
      "training :  2973  accuracy =   0.6200  loss =  156.809\n",
      "testing  :  2973  accuracy =   0.6862  loss =  158.025\n",
      "training :  2974  accuracy =   0.7200  loss =  158.424\n",
      "testing  :  2974  accuracy =   0.6870  loss =  157.937\n",
      "training :  2975  accuracy =   0.6800  loss =  160.007\n",
      "testing  :  2975  accuracy =   0.6875  loss =  157.844\n",
      "training :  2976  accuracy =   0.6900  loss =  158.092\n",
      "testing  :  2976  accuracy =   0.6880  loss =  157.748\n",
      "training :  2977  accuracy =   0.7100  loss =  156.409\n",
      "testing  :  2977  accuracy =   0.6884  loss =  157.657\n",
      "training :  2978  accuracy =   0.7300  loss =  154.871\n",
      "testing  :  2978  accuracy =   0.6896  loss =  157.558\n",
      "training :  2979  accuracy =   0.7600  loss =  155.155\n",
      "testing  :  2979  accuracy =   0.6901  loss =  157.456\n",
      "training :  2980  accuracy =   0.6200  loss =  157.381\n",
      "testing  :  2980  accuracy =   0.6907  loss =  157.36\n",
      "training :  2981  accuracy =   0.6600  loss =  155.992\n",
      "testing  :  2981  accuracy =   0.6909  loss =  157.286\n",
      "training :  2982  accuracy =   0.7600  loss =  154.47\n",
      "testing  :  2982  accuracy =   0.6908  loss =  157.235\n",
      "training :  2983  accuracy =   0.6500  loss =  156.676\n",
      "testing  :  2983  accuracy =   0.6914  loss =  157.191\n",
      "training :  2984  accuracy =   0.6900  loss =  157.911\n",
      "testing  :  2984  accuracy =   0.6913  loss =  157.129\n",
      "training :  2985  accuracy =   0.8000  loss =  153.971\n",
      "testing  :  2985  accuracy =   0.6917  loss =  157.068\n",
      "training :  2986  accuracy =   0.6600  loss =  160.352\n",
      "testing  :  2986  accuracy =   0.6913  loss =  157.032\n",
      "training :  2987  accuracy =   0.6700  loss =  156.454\n",
      "testing  :  2987  accuracy =   0.6916  loss =  157.005\n",
      "training :  2988  accuracy =   0.7300  loss =  159.834\n",
      "testing  :  2988  accuracy =   0.6918  loss =  156.972\n",
      "training :  2989  accuracy =   0.7600  loss =  155.351\n",
      "testing  :  2989  accuracy =   0.6919  loss =  156.921\n",
      "training :  2990  accuracy =   0.7100  loss =  155.14\n",
      "testing  :  2990  accuracy =   0.6919  loss =  156.854\n",
      "training :  2991  accuracy =   0.7800  loss =  155.719\n",
      "testing  :  2991  accuracy =   0.6921  loss =  156.784\n",
      "training :  2992  accuracy =   0.7400  loss =  158.177\n",
      "testing  :  2992  accuracy =   0.6926  loss =  156.722\n",
      "training :  2993  accuracy =   0.7500  loss =  156.079\n",
      "testing  :  2993  accuracy =   0.6926  loss =  156.662\n",
      "training :  2994  accuracy =   0.6900  loss =  154.882\n",
      "testing  :  2994  accuracy =   0.6933  loss =  156.618\n",
      "training :  2995  accuracy =   0.7500  loss =  155.725\n",
      "testing  :  2995  accuracy =   0.6935  loss =  156.571\n",
      "training :  2996  accuracy =   0.7400  loss =  155.243\n",
      "testing  :  2996  accuracy =   0.6931  loss =  156.53\n",
      "training :  2997  accuracy =   0.6600  loss =  154.944\n",
      "testing  :  2997  accuracy =   0.6934  loss =  156.49\n",
      "training :  2998  accuracy =   0.5800  loss =  157.917\n",
      "testing  :  2998  accuracy =   0.6932  loss =  156.46\n",
      "training :  2999  accuracy =   0.7400  loss =  153.703\n",
      "testing  :  2999  accuracy =   0.6931  loss =  156.43\n",
      "training :  3000  accuracy =   0.6500  loss =  154.589\n",
      "testing  :  3000  accuracy =   0.6932  loss =  156.407\n",
      "training :  3001  accuracy =   0.6900  loss =  154.549\n",
      "testing  :  3001  accuracy =   0.6932  loss =  156.387\n",
      "training :  3002  accuracy =   0.7000  loss =  156.707\n",
      "testing  :  3002  accuracy =   0.6933  loss =  156.391\n",
      "training :  3003  accuracy =   0.7300  loss =  156.252\n",
      "testing  :  3003  accuracy =   0.6936  loss =  156.381\n",
      "training :  3004  accuracy =   0.7100  loss =  155.86\n",
      "testing  :  3004  accuracy =   0.6936  loss =  156.379\n",
      "training :  3005  accuracy =   0.7200  loss =  157.204\n",
      "testing  :  3005  accuracy =   0.6941  loss =  156.373\n",
      "training :  3006  accuracy =   0.6600  loss =  157.337\n",
      "testing  :  3006  accuracy =   0.6944  loss =  156.367\n",
      "training :  3007  accuracy =   0.7200  loss =  154.368\n",
      "testing  :  3007  accuracy =   0.6944  loss =  156.345\n",
      "training :  3008  accuracy =   0.6600  loss =  153.995\n",
      "testing  :  3008  accuracy =   0.6937  loss =  156.319\n",
      "training :  3009  accuracy =   0.6500  loss =  155.785\n",
      "testing  :  3009  accuracy =   0.6937  loss =  156.303\n",
      "training :  3010  accuracy =   0.7400  loss =  153.731\n",
      "testing  :  3010  accuracy =   0.6935  loss =  156.289\n",
      "training :  3011  accuracy =   0.6500  loss =  154.313\n",
      "testing  :  3011  accuracy =   0.6935  loss =  156.277\n",
      "training :  3012  accuracy =   0.7300  loss =  156.045\n",
      "testing  :  3012  accuracy =   0.6928  loss =  156.257\n",
      "training :  3013  accuracy =   0.7100  loss =  156.407\n",
      "testing  :  3013  accuracy =   0.6926  loss =  156.245\n",
      "training :  3014  accuracy =   0.7000  loss =  154.204\n",
      "testing  :  3014  accuracy =   0.6925  loss =  156.213\n",
      "training :  3015  accuracy =   0.6600  loss =  156.136\n",
      "testing  :  3015  accuracy =   0.6925  loss =  156.173\n",
      "training :  3016  accuracy =   0.7000  loss =  154.357\n",
      "testing  :  3016  accuracy =   0.6925  loss =  156.142\n",
      "training :  3017  accuracy =   0.7100  loss =  154.935\n",
      "testing  :  3017  accuracy =   0.6929  loss =  156.125\n",
      "training :  3018  accuracy =   0.6300  loss =  157.453\n",
      "testing  :  3018  accuracy =   0.6928  loss =  156.115\n",
      "training :  3019  accuracy =   0.6600  loss =  155.509\n",
      "testing  :  3019  accuracy =   0.6931  loss =  156.103\n",
      "training :  3020  accuracy =   0.6700  loss =  155.355\n",
      "testing  :  3020  accuracy =   0.6933  loss =  156.065\n",
      "training :  3021  accuracy =   0.6700  loss =  155.598\n",
      "testing  :  3021  accuracy =   0.6926  loss =  156.02\n",
      "training :  3022  accuracy =   0.7000  loss =  154.72\n",
      "testing  :  3022  accuracy =   0.6924  loss =  155.996\n",
      "training :  3023  accuracy =   0.8100  loss =  152.759\n",
      "testing  :  3023  accuracy =   0.6921  loss =  155.992\n",
      "training :  3024  accuracy =   0.8000  loss =  152.841\n",
      "testing  :  3024  accuracy =   0.6909  loss =  155.997\n",
      "training :  3025  accuracy =   0.7000  loss =  154.932\n",
      "testing  :  3025  accuracy =   0.6908  loss =  156.008\n",
      "training :  3026  accuracy =   0.6700  loss =  155.782\n",
      "testing  :  3026  accuracy =   0.6908  loss =  156.018\n",
      "training :  3027  accuracy =   0.6300  loss =  156.223\n",
      "testing  :  3027  accuracy =   0.6910  loss =  156.01\n",
      "training :  3028  accuracy =   0.7000  loss =  154.773\n",
      "testing  :  3028  accuracy =   0.6914  loss =  156.007\n",
      "training :  3029  accuracy =   0.7200  loss =  155.186\n",
      "testing  :  3029  accuracy =   0.6917  loss =  156.007\n",
      "training :  3030  accuracy =   0.6200  loss =  155.415\n",
      "testing  :  3030  accuracy =   0.6913  loss =  156.016\n",
      "training :  3031  accuracy =   0.6700  loss =  154.453\n",
      "testing  :  3031  accuracy =   0.6906  loss =  156.073\n",
      "training :  3032  accuracy =   0.7300  loss =  156.371\n",
      "testing  :  3032  accuracy =   0.6896  loss =  156.152\n",
      "training :  3033  accuracy =   0.8000  loss =  152.97\n",
      "testing  :  3033  accuracy =   0.6891  loss =  156.18\n",
      "training :  3034  accuracy =   0.6400  loss =  157.918\n",
      "testing  :  3034  accuracy =   0.6886  loss =  156.204\n",
      "training :  3035  accuracy =   0.6800  loss =  155.571\n",
      "testing  :  3035  accuracy =   0.6877  loss =  156.29\n",
      "training :  3036  accuracy =   0.6300  loss =  156.978\n",
      "testing  :  3036  accuracy =   0.6877  loss =  156.338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  3037  accuracy =   0.6900  loss =  156.234\n",
      "testing  :  3037  accuracy =   0.6870  loss =  156.383\n",
      "training :  3038  accuracy =   0.6700  loss =  156.166\n",
      "testing  :  3038  accuracy =   0.6878  loss =  156.262\n",
      "training :  3039  accuracy =   0.6900  loss =  154.426\n",
      "testing  :  3039  accuracy =   0.6888  loss =  156.164\n",
      "training :  3040  accuracy =   0.7300  loss =  153.566\n",
      "testing  :  3040  accuracy =   0.6902  loss =  156.085\n",
      "training :  3041  accuracy =   0.7100  loss =  153.661\n",
      "testing  :  3041  accuracy =   0.6905  loss =  156.046\n",
      "training :  3042  accuracy =   0.8000  loss =  152.572\n",
      "testing  :  3042  accuracy =   0.6909  loss =  156.03\n",
      "training :  3043  accuracy =   0.6900  loss =  154.133\n",
      "testing  :  3043  accuracy =   0.6910  loss =  156.042\n",
      "training :  3044  accuracy =   0.8000  loss =  153.693\n",
      "testing  :  3044  accuracy =   0.6909  loss =  156.048\n",
      "training :  3045  accuracy =   0.6500  loss =  154.754\n",
      "testing  :  3045  accuracy =   0.6912  loss =  156.055\n",
      "training :  3046  accuracy =   0.6800  loss =  159.004\n",
      "testing  :  3046  accuracy =   0.6913  loss =  156.065\n",
      "training :  3047  accuracy =   0.6700  loss =  155.413\n",
      "testing  :  3047  accuracy =   0.6906  loss =  156.093\n",
      "training :  3048  accuracy =   0.7500  loss =  154.227\n",
      "testing  :  3048  accuracy =   0.6902  loss =  156.123\n",
      "training :  3049  accuracy =   0.7800  loss =  153.604\n",
      "testing  :  3049  accuracy =   0.6893  loss =  156.164\n",
      "training :  3050  accuracy =   0.7800  loss =  153.953\n",
      "testing  :  3050  accuracy =   0.6895  loss =  156.174\n",
      "training :  3051  accuracy =   0.6900  loss =  155.943\n",
      "testing  :  3051  accuracy =   0.6895  loss =  156.158\n",
      "training :  3052  accuracy =   0.6700  loss =  156.356\n",
      "testing  :  3052  accuracy =   0.6900  loss =  156.118\n",
      "training :  3053  accuracy =   0.6700  loss =  156.811\n",
      "testing  :  3053  accuracy =   0.6903  loss =  156.083\n",
      "training :  3054  accuracy =   0.6700  loss =  157.79\n",
      "testing  :  3054  accuracy =   0.6904  loss =  156.036\n",
      "training :  3055  accuracy =   0.7400  loss =  155.239\n",
      "testing  :  3055  accuracy =   0.6909  loss =  155.973\n",
      "training :  3056  accuracy =   0.7200  loss =  154.526\n",
      "testing  :  3056  accuracy =   0.6918  loss =  155.874\n",
      "training :  3057  accuracy =   0.7800  loss =  152.782\n",
      "testing  :  3057  accuracy =   0.6925  loss =  155.849\n",
      "training :  3058  accuracy =   0.7500  loss =  153.498\n",
      "testing  :  3058  accuracy =   0.6923  loss =  155.861\n",
      "training :  3059  accuracy =   0.7200  loss =  154.505\n",
      "testing  :  3059  accuracy =   0.6923  loss =  155.92\n",
      "training :  3060  accuracy =   0.5900  loss =  159.192\n",
      "testing  :  3060  accuracy =   0.6929  loss =  156.025\n",
      "training :  3061  accuracy =   0.6000  loss =  157.544\n",
      "testing  :  3061  accuracy =   0.6924  loss =  156.121\n",
      "training :  3062  accuracy =   0.7200  loss =  154.603\n",
      "testing  :  3062  accuracy =   0.6918  loss =  156.216\n",
      "training :  3063  accuracy =   0.7200  loss =  153.874\n",
      "testing  :  3063  accuracy =   0.6910  loss =  156.374\n",
      "training :  3064  accuracy =   0.7100  loss =  155.969\n",
      "testing  :  3064  accuracy =   0.6897  loss =  156.599\n",
      "training :  3065  accuracy =   0.6700  loss =  154.024\n",
      "testing  :  3065  accuracy =   0.6883  loss =  156.808\n",
      "training :  3066  accuracy =   0.6700  loss =  157.06\n",
      "testing  :  3066  accuracy =   0.6874  loss =  157.003\n",
      "training :  3067  accuracy =   0.7600  loss =  155.186\n",
      "testing  :  3067  accuracy =   0.6875  loss =  157.066\n",
      "training :  3068  accuracy =   0.6900  loss =  158.101\n",
      "testing  :  3068  accuracy =   0.6874  loss =  157.053\n",
      "training :  3069  accuracy =   0.6800  loss =  156.106\n",
      "testing  :  3069  accuracy =   0.6873  loss =  157.033\n",
      "training :  3070  accuracy =   0.7300  loss =  156.163\n",
      "testing  :  3070  accuracy =   0.6880  loss =  156.91\n",
      "training :  3071  accuracy =   0.7800  loss =  154.576\n",
      "testing  :  3071  accuracy =   0.6877  loss =  156.801\n",
      "training :  3072  accuracy =   0.7500  loss =  156.453\n",
      "testing  :  3072  accuracy =   0.6885  loss =  156.601\n",
      "training :  3073  accuracy =   0.6900  loss =  154.537\n",
      "testing  :  3073  accuracy =   0.6901  loss =  156.368\n",
      "training :  3074  accuracy =   0.6900  loss =  155.241\n",
      "testing  :  3074  accuracy =   0.6910  loss =  156.251\n",
      "training :  3075  accuracy =   0.6000  loss =  157.627\n",
      "testing  :  3075  accuracy =   0.6918  loss =  156.181\n",
      "training :  3076  accuracy =   0.7100  loss =  155.087\n",
      "testing  :  3076  accuracy =   0.6911  loss =  156.138\n",
      "training :  3077  accuracy =   0.7100  loss =  153.923\n",
      "testing  :  3077  accuracy =   0.6913  loss =  156.116\n",
      "training :  3078  accuracy =   0.6700  loss =  155.868\n",
      "testing  :  3078  accuracy =   0.6919  loss =  156.098\n",
      "training :  3079  accuracy =   0.6800  loss =  155.916\n",
      "testing  :  3079  accuracy =   0.6920  loss =  156.104\n",
      "training :  3080  accuracy =   0.6900  loss =  155.987\n",
      "testing  :  3080  accuracy =   0.6911  loss =  156.083\n",
      "training :  3081  accuracy =   0.7400  loss =  154.923\n",
      "testing  :  3081  accuracy =   0.6904  loss =  156.088\n",
      "training :  3082  accuracy =   0.6400  loss =  155.621\n",
      "testing  :  3082  accuracy =   0.6903  loss =  156.101\n",
      "training :  3083  accuracy =   0.6800  loss =  154.917\n",
      "testing  :  3083  accuracy =   0.6892  loss =  156.147\n",
      "training :  3084  accuracy =   0.7300  loss =  156.227\n",
      "testing  :  3084  accuracy =   0.6885  loss =  156.204\n",
      "training :  3085  accuracy =   0.7100  loss =  158.212\n",
      "testing  :  3085  accuracy =   0.6866  loss =  156.268\n",
      "training :  3086  accuracy =   0.6600  loss =  156.463\n",
      "testing  :  3086  accuracy =   0.6865  loss =  156.311\n",
      "training :  3087  accuracy =   0.8000  loss =  153.077\n",
      "testing  :  3087  accuracy =   0.6865  loss =  156.337\n",
      "training :  3088  accuracy =   0.6600  loss =  155.907\n",
      "testing  :  3088  accuracy =   0.6868  loss =  156.362\n",
      "training :  3089  accuracy =   0.6500  loss =  155.124\n",
      "testing  :  3089  accuracy =   0.6869  loss =  156.396\n",
      "training :  3090  accuracy =   0.6700  loss =  156.072\n",
      "testing  :  3090  accuracy =   0.6869  loss =  156.409\n",
      "training :  3091  accuracy =   0.7500  loss =  153.115\n",
      "testing  :  3091  accuracy =   0.6872  loss =  156.391\n",
      "training :  3092  accuracy =   0.7000  loss =  155.609\n",
      "testing  :  3092  accuracy =   0.6875  loss =  156.382\n",
      "training :  3093  accuracy =   0.7300  loss =  155.708\n",
      "testing  :  3093  accuracy =   0.6878  loss =  156.341\n",
      "training :  3094  accuracy =   0.7000  loss =  154.812\n",
      "testing  :  3094  accuracy =   0.6887  loss =  156.284\n",
      "training :  3095  accuracy =   0.7100  loss =  154.069\n",
      "testing  :  3095  accuracy =   0.6887  loss =  156.257\n",
      "training :  3096  accuracy =   0.7200  loss =  157.768\n",
      "testing  :  3096  accuracy =   0.6888  loss =  156.246\n",
      "training :  3097  accuracy =   0.7200  loss =  156.697\n",
      "testing  :  3097  accuracy =   0.6893  loss =  156.253\n",
      "training :  3098  accuracy =   0.6600  loss =  157.438\n",
      "testing  :  3098  accuracy =   0.6898  loss =  156.251\n",
      "training :  3099  accuracy =   0.6700  loss =  157.022\n",
      "testing  :  3099  accuracy =   0.6905  loss =  156.176\n",
      "training :  3100  accuracy =   0.7300  loss =  158.114\n",
      "testing  :  3100  accuracy =   0.6913  loss =  156.072\n",
      "training :  3101  accuracy =   0.7500  loss =  154.472\n",
      "testing  :  3101  accuracy =   0.6908  loss =  155.989\n",
      "training :  3102  accuracy =   0.7000  loss =  158.847\n",
      "testing  :  3102  accuracy =   0.6910  loss =  155.942\n",
      "training :  3103  accuracy =   0.7300  loss =  154.667\n",
      "testing  :  3103  accuracy =   0.6911  loss =  155.922\n",
      "training :  3104  accuracy =   0.6900  loss =  157.42\n",
      "testing  :  3104  accuracy =   0.6911  loss =  155.929\n",
      "training :  3105  accuracy =   0.7000  loss =  157.144\n",
      "testing  :  3105  accuracy =   0.6902  loss =  155.977\n",
      "training :  3106  accuracy =   0.6600  loss =  157.437\n",
      "testing  :  3106  accuracy =   0.6892  loss =  156.041\n",
      "training :  3107  accuracy =   0.7900  loss =  152.313\n",
      "testing  :  3107  accuracy =   0.6889  loss =  156.131\n",
      "training :  3108  accuracy =   0.6700  loss =  154.863\n",
      "testing  :  3108  accuracy =   0.6871  loss =  156.214\n",
      "training :  3109  accuracy =   0.6400  loss =  155.517\n",
      "testing  :  3109  accuracy =   0.6856  loss =  156.29\n",
      "training :  3110  accuracy =   0.6500  loss =  155.875\n",
      "testing  :  3110  accuracy =   0.6860  loss =  156.337\n",
      "training :  3111  accuracy =   0.6900  loss =  154.228\n",
      "testing  :  3111  accuracy =   0.6857  loss =  156.342\n",
      "training :  3112  accuracy =   0.7200  loss =  154.351\n",
      "testing  :  3112  accuracy =   0.6856  loss =  156.334\n",
      "training :  3113  accuracy =   0.7000  loss =  154.441\n",
      "testing  :  3113  accuracy =   0.6866  loss =  156.301\n",
      "training :  3114  accuracy =   0.7300  loss =  155.184\n",
      "testing  :  3114  accuracy =   0.6874  loss =  156.271\n",
      "training :  3115  accuracy =   0.7000  loss =  155.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  3115  accuracy =   0.6884  loss =  156.213\n",
      "training :  3116  accuracy =   0.6400  loss =  156.89\n",
      "testing  :  3116  accuracy =   0.6891  loss =  156.176\n",
      "training :  3117  accuracy =   0.6700  loss =  154.289\n",
      "testing  :  3117  accuracy =   0.6896  loss =  156.159\n",
      "training :  3118  accuracy =   0.6800  loss =  156.719\n",
      "testing  :  3118  accuracy =   0.6906  loss =  156.112\n",
      "training :  3119  accuracy =   0.6900  loss =  155.187\n",
      "testing  :  3119  accuracy =   0.6912  loss =  156.08\n",
      "training :  3120  accuracy =   0.6900  loss =  155.551\n",
      "testing  :  3120  accuracy =   0.6918  loss =  156.051\n",
      "training :  3121  accuracy =   0.7000  loss =  156.359\n",
      "testing  :  3121  accuracy =   0.6919  loss =  156.033\n",
      "training :  3122  accuracy =   0.7500  loss =  157.243\n",
      "testing  :  3122  accuracy =   0.6914  loss =  156.071\n",
      "training :  3123  accuracy =   0.6600  loss =  155.16\n",
      "testing  :  3123  accuracy =   0.6919  loss =  156.114\n",
      "training :  3124  accuracy =   0.6100  loss =  157.61\n",
      "testing  :  3124  accuracy =   0.6917  loss =  156.17\n",
      "training :  3125  accuracy =   0.7100  loss =  154.506\n",
      "testing  :  3125  accuracy =   0.6920  loss =  156.18\n",
      "training :  3126  accuracy =   0.7800  loss =  153.214\n",
      "testing  :  3126  accuracy =   0.6916  loss =  156.194\n",
      "training :  3127  accuracy =   0.7100  loss =  153.419\n",
      "testing  :  3127  accuracy =   0.6920  loss =  156.201\n",
      "training :  3128  accuracy =   0.6400  loss =  157.469\n",
      "testing  :  3128  accuracy =   0.6917  loss =  156.189\n",
      "training :  3129  accuracy =   0.7400  loss =  155.564\n",
      "testing  :  3129  accuracy =   0.6917  loss =  156.124\n",
      "training :  3130  accuracy =   0.7000  loss =  154.714\n",
      "testing  :  3130  accuracy =   0.6917  loss =  156.069\n",
      "training :  3131  accuracy =   0.6600  loss =  155.955\n",
      "testing  :  3131  accuracy =   0.6914  loss =  156.032\n",
      "training :  3132  accuracy =   0.6600  loss =  154.456\n",
      "testing  :  3132  accuracy =   0.6907  loss =  155.981\n",
      "training :  3133  accuracy =   0.6800  loss =  155.716\n",
      "testing  :  3133  accuracy =   0.6912  loss =  155.952\n",
      "training :  3134  accuracy =   0.7500  loss =  154.034\n",
      "testing  :  3134  accuracy =   0.6914  loss =  155.945\n",
      "training :  3135  accuracy =   0.7400  loss =  154.549\n",
      "testing  :  3135  accuracy =   0.6917  loss =  155.914\n",
      "training :  3136  accuracy =   0.6300  loss =  155.772\n",
      "testing  :  3136  accuracy =   0.6914  loss =  155.897\n",
      "training :  3137  accuracy =   0.7400  loss =  155.443\n",
      "testing  :  3137  accuracy =   0.6916  loss =  155.939\n",
      "training :  3138  accuracy =   0.6800  loss =  157.616\n",
      "testing  :  3138  accuracy =   0.6903  loss =  156.001\n",
      "training :  3139  accuracy =   0.6000  loss =  158.865\n",
      "testing  :  3139  accuracy =   0.6899  loss =  156.012\n",
      "training :  3140  accuracy =   0.7500  loss =  155.376\n",
      "testing  :  3140  accuracy =   0.6889  loss =  156.046\n",
      "training :  3141  accuracy =   0.7200  loss =  155.025\n",
      "testing  :  3141  accuracy =   0.6895  loss =  156.025\n",
      "training :  3142  accuracy =   0.6500  loss =  155.315\n",
      "testing  :  3142  accuracy =   0.6902  loss =  155.981\n",
      "training :  3143  accuracy =   0.7900  loss =  153.961\n",
      "testing  :  3143  accuracy =   0.6914  loss =  155.903\n",
      "training :  3144  accuracy =   0.6900  loss =  153.512\n",
      "testing  :  3144  accuracy =   0.6917  loss =  155.844\n",
      "training :  3145  accuracy =   0.7300  loss =  155.607\n",
      "testing  :  3145  accuracy =   0.6918  loss =  155.802\n",
      "training :  3146  accuracy =   0.7300  loss =  152.522\n",
      "testing  :  3146  accuracy =   0.6921  loss =  155.797\n",
      "training :  3147  accuracy =   0.6500  loss =  158.662\n",
      "testing  :  3147  accuracy =   0.6925  loss =  155.828\n",
      "training :  3148  accuracy =   0.6900  loss =  155.669\n",
      "testing  :  3148  accuracy =   0.6924  loss =  155.886\n",
      "training :  3149  accuracy =   0.7500  loss =  153.735\n",
      "testing  :  3149  accuracy =   0.6920  loss =  155.929\n",
      "training :  3150  accuracy =   0.7200  loss =  153.371\n",
      "testing  :  3150  accuracy =   0.6914  loss =  155.981\n",
      "training :  3151  accuracy =   0.6500  loss =  155.103\n",
      "testing  :  3151  accuracy =   0.6911  loss =  156.037\n",
      "training :  3152  accuracy =   0.6700  loss =  158.035\n",
      "testing  :  3152  accuracy =   0.6919  loss =  156.046\n",
      "training :  3153  accuracy =   0.7300  loss =  156.155\n",
      "testing  :  3153  accuracy =   0.6931  loss =  156.041\n",
      "training :  3154  accuracy =   0.7000  loss =  153.281\n",
      "testing  :  3154  accuracy =   0.6973  loss =  156.014\n",
      "training :  3155  accuracy =   0.7300  loss =  156.895\n",
      "testing  :  3155  accuracy =   0.7144  loss =  155.953\n",
      "training :  3156  accuracy =   0.7500  loss =  157.533\n",
      "testing  :  3156  accuracy =   0.7383  loss =  155.856\n",
      "training :  3157  accuracy =   0.7900  loss =  154.075\n",
      "testing  :  3157  accuracy =   0.7475  loss =  155.799\n",
      "training :  3158  accuracy =   0.8100  loss =  154.549\n",
      "testing  :  3158  accuracy =   0.7533  loss =  155.83\n",
      "training :  3159  accuracy =   0.7500  loss =  154.903\n",
      "testing  :  3159  accuracy =   0.7556  loss =  155.947\n",
      "training :  3160  accuracy =   0.7400  loss =  155.602\n",
      "testing  :  3160  accuracy =   0.7558  loss =  156.138\n",
      "training :  3161  accuracy =   0.7500  loss =  157.182\n",
      "testing  :  3161  accuracy =   0.7570  loss =  156.311\n",
      "training :  3162  accuracy =   0.7000  loss =  154.576\n",
      "testing  :  3162  accuracy =   0.7552  loss =  156.445\n",
      "training :  3163  accuracy =   0.7700  loss =  156.835\n",
      "testing  :  3163  accuracy =   0.7519  loss =  156.559\n",
      "training :  3164  accuracy =   0.7200  loss =  158.207\n",
      "testing  :  3164  accuracy =   0.7519  loss =  156.528\n",
      "training :  3165  accuracy =   0.8400  loss =  153.567\n",
      "testing  :  3165  accuracy =   0.7494  loss =  156.419\n",
      "training :  3166  accuracy =   0.8000  loss =  155.836\n",
      "testing  :  3166  accuracy =   0.7473  loss =  156.302\n",
      "training :  3167  accuracy =   0.6800  loss =  157.57\n",
      "testing  :  3167  accuracy =   0.7430  loss =  156.28\n",
      "training :  3168  accuracy =   0.8100  loss =  156.738\n",
      "testing  :  3168  accuracy =   0.7393  loss =  156.173\n",
      "training :  3169  accuracy =   0.6900  loss =  157.319\n",
      "testing  :  3169  accuracy =   0.7388  loss =  156.095\n",
      "training :  3170  accuracy =   0.7800  loss =  153.504\n",
      "testing  :  3170  accuracy =   0.7313  loss =  156.027\n",
      "training :  3171  accuracy =   0.6700  loss =  155.895\n",
      "testing  :  3171  accuracy =   0.7230  loss =  155.964\n",
      "training :  3172  accuracy =   0.8300  loss =  153.867\n",
      "testing  :  3172  accuracy =   0.7274  loss =  155.897\n",
      "training :  3173  accuracy =   0.6500  loss =  158.173\n",
      "testing  :  3173  accuracy =   0.7316  loss =  155.859\n",
      "training :  3174  accuracy =   0.7700  loss =  156.545\n",
      "testing  :  3174  accuracy =   0.7430  loss =  155.846\n",
      "training :  3175  accuracy =   0.7800  loss =  155.613\n",
      "testing  :  3175  accuracy =   0.7517  loss =  155.851\n",
      "training :  3176  accuracy =   0.7200  loss =  158.255\n",
      "testing  :  3176  accuracy =   0.7609  loss =  155.842\n",
      "training :  3177  accuracy =   0.7000  loss =  157.251\n",
      "testing  :  3177  accuracy =   0.7249  loss =  155.821\n",
      "training :  3178  accuracy =   0.6300  loss =  155.799\n",
      "testing  :  3178  accuracy =   0.7146  loss =  155.839\n",
      "training :  3179  accuracy =   0.7600  loss =  155.376\n",
      "testing  :  3179  accuracy =   0.7089  loss =  155.871\n",
      "training :  3180  accuracy =   0.6500  loss =  154.717\n",
      "testing  :  3180  accuracy =   0.7050  loss =  155.902\n",
      "training :  3181  accuracy =   0.7500  loss =  154.073\n",
      "testing  :  3181  accuracy =   0.7015  loss =  155.948\n",
      "training :  3182  accuracy =   0.7100  loss =  154.357\n",
      "testing  :  3182  accuracy =   0.7000  loss =  155.955\n",
      "training :  3183  accuracy =   0.6200  loss =  154.917\n",
      "testing  :  3183  accuracy =   0.6994  loss =  155.955\n",
      "training :  3184  accuracy =   0.6700  loss =  153.198\n",
      "testing  :  3184  accuracy =   0.6990  loss =  155.955\n",
      "training :  3185  accuracy =   0.6200  loss =  154.544\n",
      "testing  :  3185  accuracy =   0.6989  loss =  155.953\n",
      "training :  3186  accuracy =   0.7100  loss =  154.575\n",
      "testing  :  3186  accuracy =   0.6981  loss =  155.948\n",
      "training :  3187  accuracy =   0.7600  loss =  153.852\n",
      "testing  :  3187  accuracy =   0.6981  loss =  155.904\n",
      "training :  3188  accuracy =   0.6400  loss =  155.799\n",
      "testing  :  3188  accuracy =   0.6987  loss =  155.866\n",
      "training :  3189  accuracy =   0.6800  loss =  156.19\n",
      "testing  :  3189  accuracy =   0.6979  loss =  155.849\n",
      "training :  3190  accuracy =   0.7600  loss =  154.414\n",
      "testing  :  3190  accuracy =   0.6982  loss =  155.839\n",
      "training :  3191  accuracy =   0.7300  loss =  154.961\n",
      "testing  :  3191  accuracy =   0.6974  loss =  155.838\n",
      "training :  3192  accuracy =   0.6400  loss =  159.221\n",
      "testing  :  3192  accuracy =   0.6979  loss =  155.833\n",
      "training :  3193  accuracy =   0.7000  loss =  153.908\n",
      "testing  :  3193  accuracy =   0.6981  loss =  155.822\n",
      "training :  3194  accuracy =   0.6800  loss =  155.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  3194  accuracy =   0.6989  loss =  155.826\n",
      "training :  3195  accuracy =   0.7900  loss =  153.777\n",
      "testing  :  3195  accuracy =   0.6994  loss =  155.829\n",
      "training :  3196  accuracy =   0.7600  loss =  152.967\n",
      "testing  :  3196  accuracy =   0.6999  loss =  155.834\n",
      "training :  3197  accuracy =   0.7500  loss =  152.631\n",
      "testing  :  3197  accuracy =   0.7003  loss =  155.83\n",
      "training :  3198  accuracy =   0.7000  loss =  153.891\n",
      "testing  :  3198  accuracy =   0.7002  loss =  155.826\n",
      "training :  3199  accuracy =   0.7100  loss =  152.873\n",
      "testing  :  3199  accuracy =   0.7005  loss =  155.833\n",
      "training :  3200  accuracy =   0.7100  loss =  154.134\n",
      "testing  :  3200  accuracy =   0.7010  loss =  155.834\n",
      "training :  3201  accuracy =   0.7300  loss =  156.455\n",
      "testing  :  3201  accuracy =   0.7008  loss =  155.834\n",
      "training :  3202  accuracy =   0.6800  loss =  155.922\n",
      "testing  :  3202  accuracy =   0.7005  loss =  155.812\n",
      "training :  3203  accuracy =   0.7700  loss =  153.842\n",
      "testing  :  3203  accuracy =   0.6999  loss =  155.77\n",
      "training :  3204  accuracy =   0.7100  loss =  153.99\n",
      "testing  :  3204  accuracy =   0.6991  loss =  155.759\n",
      "training :  3205  accuracy =   0.7500  loss =  153.807\n",
      "testing  :  3205  accuracy =   0.6978  loss =  155.774\n",
      "training :  3206  accuracy =   0.7700  loss =  155.547\n",
      "testing  :  3206  accuracy =   0.6959  loss =  155.809\n",
      "training :  3207  accuracy =   0.7000  loss =  154.85\n",
      "testing  :  3207  accuracy =   0.6948  loss =  155.925\n",
      "training :  3208  accuracy =   0.7000  loss =  152.852\n",
      "testing  :  3208  accuracy =   0.6930  loss =  156.068\n",
      "training :  3209  accuracy =   0.7200  loss =  154.64\n",
      "testing  :  3209  accuracy =   0.6928  loss =  156.165\n",
      "training :  3210  accuracy =   0.8000  loss =  152.97\n",
      "testing  :  3210  accuracy =   0.6919  loss =  156.246\n",
      "training :  3211  accuracy =   0.6800  loss =  157.537\n",
      "testing  :  3211  accuracy =   0.6909  loss =  156.304\n",
      "training :  3212  accuracy =   0.6700  loss =  157.386\n",
      "testing  :  3212  accuracy =   0.6927  loss =  156.212\n",
      "training :  3213  accuracy =   0.7300  loss =  155.59\n",
      "testing  :  3213  accuracy =   0.6943  loss =  156.064\n",
      "training :  3214  accuracy =   0.6900  loss =  154.066\n",
      "testing  :  3214  accuracy =   0.6958  loss =  155.945\n",
      "training :  3215  accuracy =   0.7100  loss =  155.166\n",
      "testing  :  3215  accuracy =   0.6980  loss =  155.866\n",
      "training :  3216  accuracy =   0.7500  loss =  153.346\n",
      "testing  :  3216  accuracy =   0.7015  loss =  155.825\n",
      "training :  3217  accuracy =   0.6400  loss =  155.9\n",
      "testing  :  3217  accuracy =   0.7032  loss =  155.825\n",
      "training :  3218  accuracy =   0.6500  loss =  157.973\n",
      "testing  :  3218  accuracy =   0.7049  loss =  155.861\n",
      "training :  3219  accuracy =   0.7800  loss =  152.776\n",
      "testing  :  3219  accuracy =   0.7064  loss =  155.885\n",
      "training :  3220  accuracy =   0.7400  loss =  153.47\n",
      "testing  :  3220  accuracy =   0.7084  loss =  155.915\n",
      "training :  3221  accuracy =   0.7100  loss =  155.15\n",
      "testing  :  3221  accuracy =   0.7112  loss =  155.946\n",
      "training :  3222  accuracy =   0.7200  loss =  154.6\n",
      "testing  :  3222  accuracy =   0.7137  loss =  155.976\n",
      "training :  3223  accuracy =   0.7700  loss =  153.655\n",
      "testing  :  3223  accuracy =   0.7155  loss =  156.031\n",
      "training :  3224  accuracy =   0.7500  loss =  153.211\n",
      "testing  :  3224  accuracy =   0.7157  loss =  156.08\n",
      "training :  3225  accuracy =   0.8000  loss =  154.518\n",
      "testing  :  3225  accuracy =   0.7154  loss =  156.065\n",
      "training :  3226  accuracy =   0.7700  loss =  154.153\n",
      "testing  :  3226  accuracy =   0.7162  loss =  156.056\n",
      "training :  3227  accuracy =   0.6400  loss =  159.927\n",
      "testing  :  3227  accuracy =   0.7161  loss =  156.047\n",
      "training :  3228  accuracy =   0.7300  loss =  154.86\n",
      "testing  :  3228  accuracy =   0.7169  loss =  156.024\n",
      "training :  3229  accuracy =   0.6300  loss =  160.362\n",
      "testing  :  3229  accuracy =   0.7169  loss =  155.996\n",
      "training :  3230  accuracy =   0.6900  loss =  155.068\n",
      "testing  :  3230  accuracy =   0.7147  loss =  155.92\n",
      "training :  3231  accuracy =   0.6900  loss =  156.353\n",
      "testing  :  3231  accuracy =   0.7115  loss =  155.848\n",
      "training :  3232  accuracy =   0.6300  loss =  156.761\n",
      "testing  :  3232  accuracy =   0.7086  loss =  155.791\n",
      "training :  3233  accuracy =   0.6600  loss =  154.514\n",
      "testing  :  3233  accuracy =   0.7072  loss =  155.754\n",
      "training :  3234  accuracy =   0.6500  loss =  156.161\n",
      "testing  :  3234  accuracy =   0.7047  loss =  155.729\n",
      "training :  3235  accuracy =   0.7600  loss =  153.629\n",
      "testing  :  3235  accuracy =   0.7056  loss =  155.715\n",
      "training :  3236  accuracy =   0.6700  loss =  156.27\n",
      "testing  :  3236  accuracy =   0.7064  loss =  155.706\n",
      "training :  3237  accuracy =   0.7700  loss =  155.373\n",
      "testing  :  3237  accuracy =   0.7062  loss =  155.704\n",
      "training :  3238  accuracy =   0.7400  loss =  154.37\n",
      "testing  :  3238  accuracy =   0.7046  loss =  155.707\n",
      "training :  3239  accuracy =   0.7300  loss =  154.211\n",
      "testing  :  3239  accuracy =   0.7038  loss =  155.711\n",
      "training :  3240  accuracy =   0.6900  loss =  155.466\n",
      "testing  :  3240  accuracy =   0.7024  loss =  155.727\n",
      "training :  3241  accuracy =   0.6300  loss =  156.062\n",
      "testing  :  3241  accuracy =   0.7015  loss =  155.744\n",
      "training :  3242  accuracy =   0.7100  loss =  154.364\n",
      "testing  :  3242  accuracy =   0.7005  loss =  155.757\n",
      "training :  3243  accuracy =   0.8100  loss =  153.145\n",
      "testing  :  3243  accuracy =   0.7001  loss =  155.78\n",
      "training :  3244  accuracy =   0.7400  loss =  153.883\n",
      "testing  :  3244  accuracy =   0.6996  loss =  155.795\n",
      "training :  3245  accuracy =   0.6800  loss =  157.68\n",
      "testing  :  3245  accuracy =   0.6994  loss =  155.809\n",
      "training :  3246  accuracy =   0.7100  loss =  153.471\n",
      "testing  :  3246  accuracy =   0.6997  loss =  155.824\n",
      "training :  3247  accuracy =   0.7500  loss =  154.003\n",
      "testing  :  3247  accuracy =   0.6991  loss =  155.854\n",
      "training :  3248  accuracy =   0.7700  loss =  151.814\n",
      "testing  :  3248  accuracy =   0.6991  loss =  155.896\n",
      "training :  3249  accuracy =   0.6600  loss =  154.868\n",
      "testing  :  3249  accuracy =   0.6993  loss =  155.929\n",
      "training :  3250  accuracy =   0.7300  loss =  155.114\n",
      "testing  :  3250  accuracy =   0.6993  loss =  155.963\n",
      "training :  3251  accuracy =   0.7400  loss =  156.057\n",
      "testing  :  3251  accuracy =   0.7000  loss =  155.94\n",
      "training :  3252  accuracy =   0.7900  loss =  153.998\n",
      "testing  :  3252  accuracy =   0.7011  loss =  155.92\n",
      "training :  3253  accuracy =   0.7300  loss =  154.051\n",
      "testing  :  3253  accuracy =   0.7020  loss =  155.903\n",
      "training :  3254  accuracy =   0.7200  loss =  155.635\n",
      "testing  :  3254  accuracy =   0.7035  loss =  155.892\n",
      "training :  3255  accuracy =   0.6800  loss =  153.998\n",
      "testing  :  3255  accuracy =   0.7049  loss =  155.854\n",
      "training :  3256  accuracy =   0.7700  loss =  153.049\n",
      "testing  :  3256  accuracy =   0.7060  loss =  155.813\n",
      "training :  3257  accuracy =   0.6800  loss =  155.753\n",
      "testing  :  3257  accuracy =   0.7057  loss =  155.789\n",
      "training :  3258  accuracy =   0.7300  loss =  154.883\n",
      "testing  :  3258  accuracy =   0.7052  loss =  155.763\n",
      "training :  3259  accuracy =   0.7100  loss =  155.555\n",
      "testing  :  3259  accuracy =   0.7058  loss =  155.747\n",
      "training :  3260  accuracy =   0.7000  loss =  155.01\n",
      "testing  :  3260  accuracy =   0.7059  loss =  155.732\n",
      "training :  3261  accuracy =   0.6400  loss =  159.136\n",
      "testing  :  3261  accuracy =   0.7061  loss =  155.715\n",
      "training :  3262  accuracy =   0.7200  loss =  155.132\n",
      "testing  :  3262  accuracy =   0.7062  loss =  155.719\n",
      "training :  3263  accuracy =   0.7500  loss =  153.131\n",
      "testing  :  3263  accuracy =   0.7056  loss =  155.744\n",
      "training :  3264  accuracy =   0.7600  loss =  153.719\n",
      "testing  :  3264  accuracy =   0.7050  loss =  155.767\n",
      "training :  3265  accuracy =   0.7600  loss =  152.493\n",
      "testing  :  3265  accuracy =   0.7053  loss =  155.794\n",
      "training :  3266  accuracy =   0.7300  loss =  152.958\n",
      "testing  :  3266  accuracy =   0.7058  loss =  155.822\n",
      "training :  3267  accuracy =   0.7400  loss =  155.223\n",
      "testing  :  3267  accuracy =   0.7053  loss =  155.854\n",
      "training :  3268  accuracy =   0.7100  loss =  155.059\n",
      "testing  :  3268  accuracy =   0.7050  loss =  155.892\n",
      "training :  3269  accuracy =   0.7400  loss =  153.525\n",
      "testing  :  3269  accuracy =   0.7050  loss =  155.901\n",
      "training :  3270  accuracy =   0.7900  loss =  154.569\n",
      "testing  :  3270  accuracy =   0.7048  loss =  155.886\n",
      "training :  3271  accuracy =   0.8100  loss =  152.135\n",
      "testing  :  3271  accuracy =   0.7048  loss =  155.848\n",
      "training :  3272  accuracy =   0.7600  loss =  153.747\n",
      "testing  :  3272  accuracy =   0.7041  loss =  155.821\n",
      "training :  3273  accuracy =   0.7200  loss =  154.061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  3273  accuracy =   0.7046  loss =  155.77\n",
      "training :  3274  accuracy =   0.7900  loss =  153.62\n",
      "testing  :  3274  accuracy =   0.7041  loss =  155.748\n",
      "training :  3275  accuracy =   0.6500  loss =  157.85\n",
      "testing  :  3275  accuracy =   0.7025  loss =  155.732\n",
      "training :  3276  accuracy =   0.7400  loss =  154.015\n",
      "testing  :  3276  accuracy =   0.7028  loss =  155.737\n",
      "training :  3277  accuracy =   0.7500  loss =  152.397\n",
      "testing  :  3277  accuracy =   0.7009  loss =  155.774\n",
      "training :  3278  accuracy =   0.7200  loss =  153.106\n",
      "testing  :  3278  accuracy =   0.7009  loss =  155.797\n",
      "training :  3279  accuracy =   0.7300  loss =  156.832\n",
      "testing  :  3279  accuracy =   0.6996  loss =  155.827\n",
      "training :  3280  accuracy =   0.7000  loss =  157.18\n",
      "testing  :  3280  accuracy =   0.6993  loss =  155.826\n",
      "training :  3281  accuracy =   0.7100  loss =  154.795\n",
      "testing  :  3281  accuracy =   0.7005  loss =  155.808\n",
      "training :  3282  accuracy =   0.7700  loss =  152.787\n",
      "testing  :  3282  accuracy =   0.7003  loss =  155.818\n",
      "training :  3283  accuracy =   0.7700  loss =  152.751\n",
      "testing  :  3283  accuracy =   0.7012  loss =  155.843\n",
      "training :  3284  accuracy =   0.6700  loss =  155.922\n",
      "testing  :  3284  accuracy =   0.7033  loss =  155.861\n",
      "training :  3285  accuracy =   0.7000  loss =  153.306\n",
      "testing  :  3285  accuracy =   0.7053  loss =  155.843\n",
      "training :  3286  accuracy =   0.7300  loss =  156.914\n",
      "testing  :  3286  accuracy =   0.7066  loss =  155.819\n",
      "training :  3287  accuracy =   0.7500  loss =  154.73\n",
      "testing  :  3287  accuracy =   0.7073  loss =  155.774\n",
      "training :  3288  accuracy =   0.7100  loss =  154.749\n",
      "testing  :  3288  accuracy =   0.7077  loss =  155.727\n",
      "training :  3289  accuracy =   0.7500  loss =  153.207\n",
      "testing  :  3289  accuracy =   0.7073  loss =  155.706\n",
      "training :  3290  accuracy =   0.7200  loss =  156.541\n",
      "testing  :  3290  accuracy =   0.7072  loss =  155.709\n",
      "training :  3291  accuracy =   0.6500  loss =  155.097\n",
      "testing  :  3291  accuracy =   0.7076  loss =  155.708\n",
      "training :  3292  accuracy =   0.6800  loss =  158.115\n",
      "testing  :  3292  accuracy =   0.7084  loss =  155.698\n",
      "training :  3293  accuracy =   0.6800  loss =  154.887\n",
      "testing  :  3293  accuracy =   0.7100  loss =  155.701\n",
      "training :  3294  accuracy =   0.7600  loss =  154.09\n",
      "testing  :  3294  accuracy =   0.7114  loss =  155.694\n",
      "training :  3295  accuracy =   0.6900  loss =  156.4\n",
      "testing  :  3295  accuracy =   0.7128  loss =  155.681\n",
      "training :  3296  accuracy =   0.7200  loss =  152.735\n",
      "testing  :  3296  accuracy =   0.7169  loss =  155.652\n",
      "training :  3297  accuracy =   0.6800  loss =  156.51\n",
      "testing  :  3297  accuracy =   0.7193  loss =  155.646\n",
      "training :  3298  accuracy =   0.7400  loss =  154.133\n",
      "testing  :  3298  accuracy =   0.7222  loss =  155.647\n",
      "training :  3299  accuracy =   0.8200  loss =  152.602\n",
      "testing  :  3299  accuracy =   0.7237  loss =  155.673\n",
      "training :  3300  accuracy =   0.7500  loss =  154.492\n",
      "testing  :  3300  accuracy =   0.7234  loss =  155.707\n",
      "training :  3301  accuracy =   0.7000  loss =  153.027\n",
      "testing  :  3301  accuracy =   0.7233  loss =  155.7\n",
      "training :  3302  accuracy =   0.7100  loss =  154.066\n",
      "testing  :  3302  accuracy =   0.7234  loss =  155.702\n",
      "training :  3303  accuracy =   0.6700  loss =  153.607\n",
      "testing  :  3303  accuracy =   0.7223  loss =  155.702\n",
      "training :  3304  accuracy =   0.6700  loss =  155.092\n",
      "testing  :  3304  accuracy =   0.7218  loss =  155.713\n",
      "training :  3305  accuracy =   0.7700  loss =  153.528\n",
      "testing  :  3305  accuracy =   0.7266  loss =  155.714\n",
      "training :  3306  accuracy =   0.6900  loss =  154.681\n",
      "testing  :  3306  accuracy =   0.7336  loss =  155.705\n",
      "training :  3307  accuracy =   0.7400  loss =  155.438\n",
      "testing  :  3307  accuracy =   0.7405  loss =  155.655\n",
      "training :  3308  accuracy =   0.7000  loss =  155.456\n",
      "testing  :  3308  accuracy =   0.7508  loss =  155.632\n",
      "training :  3309  accuracy =   0.6800  loss =  156.391\n",
      "testing  :  3309  accuracy =   0.7618  loss =  155.601\n",
      "training :  3310  accuracy =   0.7700  loss =  156.103\n",
      "testing  :  3310  accuracy =   0.7654  loss =  155.649\n",
      "training :  3311  accuracy =   0.8000  loss =  154.609\n",
      "testing  :  3311  accuracy =   0.7605  loss =  155.738\n",
      "training :  3312  accuracy =   0.7300  loss =  153.541\n",
      "testing  :  3312  accuracy =   0.7573  loss =  155.836\n",
      "training :  3313  accuracy =   0.7500  loss =  154.939\n",
      "testing  :  3313  accuracy =   0.7522  loss =  155.919\n",
      "training :  3314  accuracy =   0.7500  loss =  158.468\n",
      "testing  :  3314  accuracy =   0.7473  loss =  155.975\n",
      "training :  3315  accuracy =   0.7700  loss =  157.721\n",
      "testing  :  3315  accuracy =   0.7487  loss =  155.893\n",
      "training :  3316  accuracy =   0.7700  loss =  157.061\n",
      "testing  :  3316  accuracy =   0.7509  loss =  155.764\n",
      "training :  3317  accuracy =   0.6900  loss =  156.15\n",
      "testing  :  3317  accuracy =   0.7382  loss =  155.656\n",
      "training :  3318  accuracy =   0.6300  loss =  155.85\n",
      "testing  :  3318  accuracy =   0.7164  loss =  155.602\n",
      "training :  3319  accuracy =   0.6900  loss =  155.577\n",
      "testing  :  3319  accuracy =   0.7106  loss =  155.607\n",
      "training :  3320  accuracy =   0.8100  loss =  154.402\n",
      "testing  :  3320  accuracy =   0.7066  loss =  155.635\n",
      "training :  3321  accuracy =   0.8100  loss =  152.936\n",
      "testing  :  3321  accuracy =   0.7172  loss =  155.693\n",
      "training :  3322  accuracy =   0.8000  loss =  152.409\n",
      "testing  :  3322  accuracy =   0.7297  loss =  155.75\n",
      "training :  3323  accuracy =   0.7900  loss =  153.926\n",
      "testing  :  3323  accuracy =   0.7420  loss =  155.802\n",
      "training :  3324  accuracy =   0.7700  loss =  155.842\n",
      "testing  :  3324  accuracy =   0.7497  loss =  155.844\n",
      "training :  3325  accuracy =   0.8000  loss =  156.857\n",
      "testing  :  3325  accuracy =   0.7559  loss =  155.895\n",
      "training :  3326  accuracy =   0.7300  loss =  157.052\n",
      "testing  :  3326  accuracy =   0.7588  loss =  155.895\n",
      "training :  3327  accuracy =   0.7400  loss =  155.091\n",
      "testing  :  3327  accuracy =   0.7607  loss =  155.848\n",
      "training :  3328  accuracy =   0.7400  loss =  153.747\n",
      "testing  :  3328  accuracy =   0.7622  loss =  155.733\n",
      "training :  3329  accuracy =   0.7000  loss =  154.687\n",
      "testing  :  3329  accuracy =   0.7626  loss =  155.694\n",
      "training :  3330  accuracy =   0.8000  loss =  154.169\n",
      "testing  :  3330  accuracy =   0.7617  loss =  155.721\n",
      "training :  3331  accuracy =   0.7600  loss =  153.916\n",
      "testing  :  3331  accuracy =   0.7623  loss =  155.779\n",
      "training :  3332  accuracy =   0.8100  loss =  153.693\n",
      "testing  :  3332  accuracy =   0.7619  loss =  155.863\n",
      "training :  3333  accuracy =   0.7300  loss =  154.787\n",
      "testing  :  3333  accuracy =   0.7598  loss =  155.934\n",
      "training :  3334  accuracy =   0.8000  loss =  156.699\n",
      "testing  :  3334  accuracy =   0.7575  loss =  156.005\n",
      "training :  3335  accuracy =   0.7300  loss =  154.494\n",
      "testing  :  3335  accuracy =   0.7562  loss =  156.015\n",
      "training :  3336  accuracy =   0.6900  loss =  159.472\n",
      "testing  :  3336  accuracy =   0.7366  loss =  155.945\n",
      "training :  3337  accuracy =   0.7700  loss =  154.449\n",
      "testing  :  3337  accuracy =   0.7245  loss =  155.865\n",
      "training :  3338  accuracy =   0.7400  loss =  155.346\n",
      "testing  :  3338  accuracy =   0.7169  loss =  155.831\n",
      "training :  3339  accuracy =   0.7400  loss =  153.683\n",
      "testing  :  3339  accuracy =   0.7127  loss =  155.852\n",
      "training :  3340  accuracy =   0.6200  loss =  158.832\n",
      "testing  :  3340  accuracy =   0.7088  loss =  155.937\n",
      "training :  3341  accuracy =   0.6700  loss =  155.934\n",
      "testing  :  3341  accuracy =   0.7067  loss =  156.05\n",
      "training :  3342  accuracy =   0.7000  loss =  154.378\n",
      "testing  :  3342  accuracy =   0.7061  loss =  156.125\n",
      "training :  3343  accuracy =   0.6600  loss =  155.405\n",
      "testing  :  3343  accuracy =   0.7065  loss =  156.157\n",
      "training :  3344  accuracy =   0.7300  loss =  156.665\n",
      "testing  :  3344  accuracy =   0.7084  loss =  156.173\n",
      "training :  3345  accuracy =   0.6300  loss =  154.925\n",
      "testing  :  3345  accuracy =   0.7091  loss =  156.161\n",
      "training :  3346  accuracy =   0.7400  loss =  155.078\n",
      "testing  :  3346  accuracy =   0.7117  loss =  156.079\n",
      "training :  3347  accuracy =   0.7600  loss =  153.46\n",
      "testing  :  3347  accuracy =   0.7159  loss =  156.017\n",
      "training :  3348  accuracy =   0.6700  loss =  157.373\n",
      "testing  :  3348  accuracy =   0.7186  loss =  155.968\n",
      "training :  3349  accuracy =   0.7000  loss =  154.554\n",
      "testing  :  3349  accuracy =   0.7208  loss =  155.92\n",
      "training :  3350  accuracy =   0.7700  loss =  153.919\n",
      "testing  :  3350  accuracy =   0.7233  loss =  155.866\n",
      "training :  3351  accuracy =   0.6600  loss =  153.747\n",
      "testing  :  3351  accuracy =   0.7247  loss =  155.847\n",
      "training :  3352  accuracy =   0.6800  loss =  155.38\n",
      "testing  :  3352  accuracy =   0.7265  loss =  155.832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  3353  accuracy =   0.7300  loss =  155.307\n",
      "testing  :  3353  accuracy =   0.7333  loss =  155.825\n",
      "training :  3354  accuracy =   0.7300  loss =  157.284\n",
      "testing  :  3354  accuracy =   0.7406  loss =  155.868\n",
      "training :  3355  accuracy =   0.6700  loss =  155.953\n",
      "testing  :  3355  accuracy =   0.7502  loss =  155.934\n",
      "training :  3356  accuracy =   0.7900  loss =  155.505\n",
      "testing  :  3356  accuracy =   0.7585  loss =  155.988\n",
      "training :  3357  accuracy =   0.8300  loss =  156.545\n",
      "testing  :  3357  accuracy =   0.7623  loss =  156.034\n",
      "training :  3358  accuracy =   0.7600  loss =  156.799\n",
      "testing  :  3358  accuracy =   0.7586  loss =  156.054\n",
      "training :  3359  accuracy =   0.7400  loss =  154.093\n",
      "testing  :  3359  accuracy =   0.7583  loss =  156.004\n",
      "training :  3360  accuracy =   0.8100  loss =  154.542\n",
      "testing  :  3360  accuracy =   0.7586  loss =  155.936\n",
      "training :  3361  accuracy =   0.8100  loss =  153.386\n",
      "testing  :  3361  accuracy =   0.7551  loss =  155.928\n",
      "training :  3362  accuracy =   0.8100  loss =  153.184\n",
      "testing  :  3362  accuracy =   0.7498  loss =  155.971\n",
      "training :  3363  accuracy =   0.7400  loss =  153.894\n",
      "testing  :  3363  accuracy =   0.7434  loss =  156.063\n",
      "training :  3364  accuracy =   0.7700  loss =  154.854\n",
      "testing  :  3364  accuracy =   0.7445  loss =  156.217\n",
      "training :  3365  accuracy =   0.7500  loss =  155.818\n",
      "testing  :  3365  accuracy =   0.7450  loss =  156.351\n",
      "training :  3366  accuracy =   0.7100  loss =  157.541\n",
      "testing  :  3366  accuracy =   0.7475  loss =  156.43\n",
      "training :  3367  accuracy =   0.7700  loss =  153.498\n",
      "testing  :  3367  accuracy =   0.7518  loss =  156.282\n",
      "training :  3368  accuracy =   0.8300  loss =  153.918\n",
      "testing  :  3368  accuracy =   0.7546  loss =  156.147\n",
      "training :  3369  accuracy =   0.7400  loss =  155.661\n",
      "testing  :  3369  accuracy =   0.7576  loss =  156.044\n",
      "training :  3370  accuracy =   0.7400  loss =  155.508\n",
      "testing  :  3370  accuracy =   0.7596  loss =  155.91\n",
      "training :  3371  accuracy =   0.8200  loss =  153.126\n",
      "testing  :  3371  accuracy =   0.7597  loss =  155.753\n",
      "training :  3372  accuracy =   0.8300  loss =  154.822\n",
      "testing  :  3372  accuracy =   0.7601  loss =  155.681\n",
      "training :  3373  accuracy =   0.7500  loss =  154.769\n",
      "testing  :  3373  accuracy =   0.7600  loss =  155.652\n",
      "training :  3374  accuracy =   0.7300  loss =  158.909\n",
      "testing  :  3374  accuracy =   0.7589  loss =  155.663\n",
      "training :  3375  accuracy =   0.8300  loss =  154.161\n",
      "testing  :  3375  accuracy =   0.7548  loss =  155.703\n",
      "training :  3376  accuracy =   0.7500  loss =  155.915\n",
      "testing  :  3376  accuracy =   0.7554  loss =  155.755\n",
      "training :  3377  accuracy =   0.7700  loss =  155.479\n",
      "testing  :  3377  accuracy =   0.7547  loss =  155.798\n",
      "training :  3378  accuracy =   0.7900  loss =  154.85\n",
      "testing  :  3378  accuracy =   0.7541  loss =  155.819\n",
      "training :  3379  accuracy =   0.7100  loss =  156.628\n",
      "testing  :  3379  accuracy =   0.7482  loss =  155.807\n",
      "training :  3380  accuracy =   0.7300  loss =  155.021\n",
      "testing  :  3380  accuracy =   0.7361  loss =  155.806\n",
      "training :  3381  accuracy =   0.7500  loss =  155.989\n",
      "testing  :  3381  accuracy =   0.6985  loss =  155.751\n",
      "training :  3382  accuracy =   0.7500  loss =  155.282\n",
      "testing  :  3382  accuracy =   0.6930  loss =  155.738\n",
      "training :  3383  accuracy =   0.8700  loss =  152.885\n",
      "testing  :  3383  accuracy =   0.6907  loss =  155.741\n",
      "training :  3384  accuracy =   0.6600  loss =  155.301\n",
      "testing  :  3384  accuracy =   0.6900  loss =  155.759\n",
      "training :  3385  accuracy =   0.7000  loss =  154.577\n",
      "testing  :  3385  accuracy =   0.6894  loss =  155.775\n",
      "training :  3386  accuracy =   0.6100  loss =  157.979\n",
      "testing  :  3386  accuracy =   0.6887  loss =  155.787\n",
      "training :  3387  accuracy =   0.6600  loss =  156.565\n",
      "testing  :  3387  accuracy =   0.6890  loss =  155.773\n",
      "training :  3388  accuracy =   0.6800  loss =  154.764\n",
      "testing  :  3388  accuracy =   0.6897  loss =  155.76\n",
      "training :  3389  accuracy =   0.7900  loss =  153.628\n",
      "testing  :  3389  accuracy =   0.6892  loss =  155.73\n",
      "training :  3390  accuracy =   0.7200  loss =  156.558\n",
      "testing  :  3390  accuracy =   0.6894  loss =  155.713\n",
      "training :  3391  accuracy =   0.7100  loss =  155.192\n",
      "testing  :  3391  accuracy =   0.6895  loss =  155.694\n",
      "training :  3392  accuracy =   0.7200  loss =  154.824\n",
      "testing  :  3392  accuracy =   0.6898  loss =  155.672\n",
      "training :  3393  accuracy =   0.6900  loss =  155.341\n",
      "testing  :  3393  accuracy =   0.6902  loss =  155.672\n",
      "training :  3394  accuracy =   0.7400  loss =  153.042\n",
      "testing  :  3394  accuracy =   0.6907  loss =  155.663\n",
      "training :  3395  accuracy =   0.7200  loss =  156.715\n",
      "testing  :  3395  accuracy =   0.6905  loss =  155.676\n",
      "training :  3396  accuracy =   0.6600  loss =  155.032\n",
      "testing  :  3396  accuracy =   0.6912  loss =  155.694\n",
      "training :  3397  accuracy =   0.6900  loss =  154.627\n",
      "testing  :  3397  accuracy =   0.6909  loss =  155.716\n",
      "training :  3398  accuracy =   0.7000  loss =  155.87\n",
      "testing  :  3398  accuracy =   0.6905  loss =  155.735\n",
      "training :  3399  accuracy =   0.7200  loss =  156.545\n",
      "testing  :  3399  accuracy =   0.6901  loss =  155.759\n",
      "training :  3400  accuracy =   0.7400  loss =  153.565\n",
      "testing  :  3400  accuracy =   0.6895  loss =  155.789\n",
      "training :  3401  accuracy =   0.6800  loss =  154.593\n",
      "testing  :  3401  accuracy =   0.6898  loss =  155.821\n",
      "training :  3402  accuracy =   0.7300  loss =  153.455\n",
      "testing  :  3402  accuracy =   0.6894  loss =  155.831\n",
      "training :  3403  accuracy =   0.7600  loss =  153.414\n",
      "testing  :  3403  accuracy =   0.6893  loss =  155.838\n",
      "training :  3404  accuracy =   0.6900  loss =  156.805\n",
      "testing  :  3404  accuracy =   0.6893  loss =  155.821\n",
      "training :  3405  accuracy =   0.6900  loss =  152.7\n",
      "testing  :  3405  accuracy =   0.6894  loss =  155.802\n",
      "training :  3406  accuracy =   0.6900  loss =  154.003\n",
      "testing  :  3406  accuracy =   0.6890  loss =  155.805\n",
      "training :  3407  accuracy =   0.6700  loss =  155.058\n",
      "testing  :  3407  accuracy =   0.6881  loss =  155.83\n",
      "training :  3408  accuracy =   0.7400  loss =  153.661\n",
      "testing  :  3408  accuracy =   0.6880  loss =  155.846\n",
      "training :  3409  accuracy =   0.7300  loss =  152.562\n",
      "testing  :  3409  accuracy =   0.6881  loss =  155.851\n",
      "training :  3410  accuracy =   0.7100  loss =  154.481\n",
      "testing  :  3410  accuracy =   0.6884  loss =  155.843\n",
      "training :  3411  accuracy =   0.7000  loss =  153.422\n",
      "testing  :  3411  accuracy =   0.6889  loss =  155.812\n",
      "training :  3412  accuracy =   0.7800  loss =  155.115\n",
      "testing  :  3412  accuracy =   0.6888  loss =  155.779\n",
      "training :  3413  accuracy =   0.7200  loss =  152.958\n",
      "testing  :  3413  accuracy =   0.6886  loss =  155.758\n",
      "training :  3414  accuracy =   0.7300  loss =  155.208\n",
      "testing  :  3414  accuracy =   0.6893  loss =  155.741\n",
      "training :  3415  accuracy =   0.6700  loss =  155.958\n",
      "testing  :  3415  accuracy =   0.6894  loss =  155.727\n",
      "training :  3416  accuracy =   0.6700  loss =  154.629\n",
      "testing  :  3416  accuracy =   0.6897  loss =  155.697\n",
      "training :  3417  accuracy =   0.7000  loss =  154.786\n",
      "testing  :  3417  accuracy =   0.6894  loss =  155.673\n",
      "training :  3418  accuracy =   0.6900  loss =  155.347\n",
      "testing  :  3418  accuracy =   0.6893  loss =  155.65\n",
      "training :  3419  accuracy =   0.7200  loss =  153.75\n",
      "testing  :  3419  accuracy =   0.6890  loss =  155.627\n",
      "training :  3420  accuracy =   0.6800  loss =  157.641\n",
      "testing  :  3420  accuracy =   0.6899  loss =  155.613\n",
      "training :  3421  accuracy =   0.6600  loss =  155.858\n",
      "testing  :  3421  accuracy =   0.6903  loss =  155.634\n",
      "training :  3422  accuracy =   0.6300  loss =  154.293\n",
      "testing  :  3422  accuracy =   0.6902  loss =  155.705\n",
      "training :  3423  accuracy =   0.7000  loss =  155.297\n",
      "testing  :  3423  accuracy =   0.6898  loss =  155.788\n",
      "training :  3424  accuracy =   0.7800  loss =  152.781\n",
      "testing  :  3424  accuracy =   0.6902  loss =  155.841\n",
      "training :  3425  accuracy =   0.6100  loss =  156.839\n",
      "testing  :  3425  accuracy =   0.6920  loss =  155.907\n",
      "training :  3426  accuracy =   0.7100  loss =  154.98\n",
      "testing  :  3426  accuracy =   0.6922  loss =  156.049\n",
      "training :  3427  accuracy =   0.6200  loss =  155.018\n",
      "testing  :  3427  accuracy =   0.6933  loss =  156.224\n",
      "training :  3428  accuracy =   0.6600  loss =  159.087\n",
      "testing  :  3428  accuracy =   0.6920  loss =  156.426\n",
      "training :  3429  accuracy =   0.6600  loss =  155.637\n",
      "testing  :  3429  accuracy =   0.6920  loss =  156.626\n",
      "training :  3430  accuracy =   0.7100  loss =  155.759\n",
      "testing  :  3430  accuracy =   0.6917  loss =  156.825\n",
      "training :  3431  accuracy =   0.6800  loss =  157.652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  3431  accuracy =   0.6910  loss =  156.768\n",
      "training :  3432  accuracy =   0.6900  loss =  157.657\n",
      "testing  :  3432  accuracy =   0.6915  loss =  156.648\n",
      "training :  3433  accuracy =   0.6700  loss =  155.689\n",
      "testing  :  3433  accuracy =   0.6918  loss =  156.56\n",
      "training :  3434  accuracy =   0.6800  loss =  153.208\n",
      "testing  :  3434  accuracy =   0.6915  loss =  156.531\n",
      "training :  3435  accuracy =   0.7300  loss =  155.148\n",
      "testing  :  3435  accuracy =   0.6905  loss =  156.505\n",
      "training :  3436  accuracy =   0.6900  loss =  157.885\n",
      "testing  :  3436  accuracy =   0.6897  loss =  156.5\n",
      "training :  3437  accuracy =   0.7000  loss =  155.994\n",
      "testing  :  3437  accuracy =   0.6901  loss =  156.428\n",
      "training :  3438  accuracy =   0.6900  loss =  156.184\n",
      "testing  :  3438  accuracy =   0.6900  loss =  156.357\n",
      "training :  3439  accuracy =   0.6900  loss =  155.743\n",
      "testing  :  3439  accuracy =   0.6909  loss =  156.292\n",
      "training :  3440  accuracy =   0.7300  loss =  153.721\n",
      "testing  :  3440  accuracy =   0.6896  loss =  156.222\n",
      "training :  3441  accuracy =   0.7400  loss =  153.875\n",
      "testing  :  3441  accuracy =   0.6893  loss =  156.159\n",
      "training :  3442  accuracy =   0.7200  loss =  154.602\n",
      "testing  :  3442  accuracy =   0.6887  loss =  156.124\n",
      "training :  3443  accuracy =   0.7300  loss =  152.849\n",
      "testing  :  3443  accuracy =   0.6882  loss =  156.057\n",
      "training :  3444  accuracy =   0.6600  loss =  156.113\n",
      "testing  :  3444  accuracy =   0.6879  loss =  156.005\n",
      "training :  3445  accuracy =   0.7200  loss =  153.663\n",
      "testing  :  3445  accuracy =   0.6890  loss =  155.925\n",
      "training :  3446  accuracy =   0.6700  loss =  156.69\n",
      "testing  :  3446  accuracy =   0.6894  loss =  155.879\n",
      "training :  3447  accuracy =   0.6900  loss =  156.249\n",
      "testing  :  3447  accuracy =   0.6894  loss =  155.848\n",
      "training :  3448  accuracy =   0.7500  loss =  156.752\n",
      "testing  :  3448  accuracy =   0.6898  loss =  155.84\n",
      "training :  3449  accuracy =   0.7600  loss =  154.236\n",
      "testing  :  3449  accuracy =   0.6902  loss =  155.847\n",
      "training :  3450  accuracy =   0.7400  loss =  153.749\n",
      "testing  :  3450  accuracy =   0.6904  loss =  155.854\n",
      "training :  3451  accuracy =   0.6900  loss =  156.518\n",
      "testing  :  3451  accuracy =   0.6904  loss =  155.841\n",
      "training :  3452  accuracy =   0.5900  loss =  158.271\n",
      "testing  :  3452  accuracy =   0.6901  loss =  155.832\n",
      "training :  3453  accuracy =   0.6800  loss =  154.246\n",
      "testing  :  3453  accuracy =   0.6900  loss =  155.833\n",
      "training :  3454  accuracy =   0.7100  loss =  154.398\n",
      "testing  :  3454  accuracy =   0.6896  loss =  155.851\n",
      "training :  3455  accuracy =   0.6700  loss =  154.656\n",
      "testing  :  3455  accuracy =   0.6890  loss =  155.902\n",
      "training :  3456  accuracy =   0.7300  loss =  155.77\n",
      "testing  :  3456  accuracy =   0.6881  loss =  155.963\n",
      "training :  3457  accuracy =   0.6200  loss =  157.373\n",
      "testing  :  3457  accuracy =   0.6885  loss =  155.973\n",
      "training :  3458  accuracy =   0.7000  loss =  154.644\n",
      "testing  :  3458  accuracy =   0.6893  loss =  155.959\n",
      "training :  3459  accuracy =   0.6800  loss =  156.838\n",
      "testing  :  3459  accuracy =   0.6886  loss =  155.89\n",
      "training :  3460  accuracy =   0.7000  loss =  154.944\n",
      "testing  :  3460  accuracy =   0.6886  loss =  155.821\n",
      "training :  3461  accuracy =   0.6800  loss =  154.637\n",
      "testing  :  3461  accuracy =   0.6891  loss =  155.765\n",
      "training :  3462  accuracy =   0.6600  loss =  156.251\n",
      "testing  :  3462  accuracy =   0.6905  loss =  155.748\n",
      "training :  3463  accuracy =   0.6700  loss =  155.636\n",
      "testing  :  3463  accuracy =   0.6901  loss =  155.738\n",
      "training :  3464  accuracy =   0.6400  loss =  155.155\n",
      "testing  :  3464  accuracy =   0.6901  loss =  155.758\n",
      "training :  3465  accuracy =   0.7000  loss =  155.742\n",
      "testing  :  3465  accuracy =   0.6908  loss =  155.766\n",
      "training :  3466  accuracy =   0.6600  loss =  154.801\n",
      "testing  :  3466  accuracy =   0.6903  loss =  155.783\n",
      "training :  3467  accuracy =   0.7200  loss =  153.149\n",
      "testing  :  3467  accuracy =   0.6908  loss =  155.814\n",
      "training :  3468  accuracy =   0.7400  loss =  155.203\n",
      "testing  :  3468  accuracy =   0.6909  loss =  155.839\n",
      "training :  3469  accuracy =   0.7300  loss =  157.893\n",
      "testing  :  3469  accuracy =   0.6911  loss =  155.858\n",
      "training :  3470  accuracy =   0.7000  loss =  157.243\n",
      "testing  :  3470  accuracy =   0.6910  loss =  155.889\n",
      "training :  3471  accuracy =   0.7200  loss =  155.781\n",
      "testing  :  3471  accuracy =   0.6909  loss =  155.941\n",
      "training :  3472  accuracy =   0.7000  loss =  156.545\n",
      "testing  :  3472  accuracy =   0.6905  loss =  156.0\n",
      "training :  3473  accuracy =   0.6200  loss =  157.586\n",
      "testing  :  3473  accuracy =   0.6896  loss =  156.044\n",
      "training :  3474  accuracy =   0.6500  loss =  153.758\n",
      "testing  :  3474  accuracy =   0.6896  loss =  156.014\n",
      "training :  3475  accuracy =   0.6900  loss =  153.744\n",
      "testing  :  3475  accuracy =   0.6897  loss =  156.003\n",
      "training :  3476  accuracy =   0.6400  loss =  155.828\n",
      "testing  :  3476  accuracy =   0.6903  loss =  155.94\n",
      "training :  3477  accuracy =   0.6900  loss =  154.625\n",
      "testing  :  3477  accuracy =   0.6902  loss =  155.949\n",
      "training :  3478  accuracy =   0.7100  loss =  153.621\n",
      "testing  :  3478  accuracy =   0.6905  loss =  155.995\n",
      "training :  3479  accuracy =   0.7100  loss =  156.763\n",
      "testing  :  3479  accuracy =   0.6898  loss =  156.048\n",
      "training :  3480  accuracy =   0.7100  loss =  156.693\n",
      "testing  :  3480  accuracy =   0.6889  loss =  156.079\n",
      "training :  3481  accuracy =   0.7500  loss =  155.688\n",
      "testing  :  3481  accuracy =   0.6882  loss =  156.127\n",
      "training :  3482  accuracy =   0.7100  loss =  153.504\n",
      "testing  :  3482  accuracy =   0.6880  loss =  156.184\n",
      "training :  3483  accuracy =   0.6500  loss =  157.54\n",
      "testing  :  3483  accuracy =   0.6882  loss =  156.215\n",
      "training :  3484  accuracy =   0.7100  loss =  156.332\n",
      "testing  :  3484  accuracy =   0.6881  loss =  156.216\n",
      "training :  3485  accuracy =   0.6600  loss =  155.665\n",
      "testing  :  3485  accuracy =   0.6883  loss =  156.184\n",
      "training :  3486  accuracy =   0.7400  loss =  155.057\n",
      "testing  :  3486  accuracy =   0.6898  loss =  156.105\n",
      "training :  3487  accuracy =   0.7200  loss =  154.061\n",
      "testing  :  3487  accuracy =   0.6903  loss =  156.033\n",
      "training :  3488  accuracy =   0.7200  loss =  154.97\n",
      "testing  :  3488  accuracy =   0.6909  loss =  155.951\n",
      "training :  3489  accuracy =   0.7100  loss =  153.292\n",
      "testing  :  3489  accuracy =   0.6913  loss =  155.896\n",
      "training :  3490  accuracy =   0.6900  loss =  155.78\n",
      "testing  :  3490  accuracy =   0.6922  loss =  155.863\n",
      "training :  3491  accuracy =   0.6000  loss =  158.151\n",
      "testing  :  3491  accuracy =   0.6926  loss =  155.832\n",
      "training :  3492  accuracy =   0.6700  loss =  158.31\n",
      "testing  :  3492  accuracy =   0.6921  loss =  155.791\n",
      "training :  3493  accuracy =   0.6800  loss =  155.827\n",
      "testing  :  3493  accuracy =   0.6931  loss =  155.713\n",
      "training :  3494  accuracy =   0.7100  loss =  155.26\n",
      "testing  :  3494  accuracy =   0.6932  loss =  155.643\n",
      "training :  3495  accuracy =   0.6700  loss =  154.501\n",
      "testing  :  3495  accuracy =   0.6937  loss =  155.605\n",
      "training :  3496  accuracy =   0.7600  loss =  155.397\n",
      "testing  :  3496  accuracy =   0.6938  loss =  155.581\n",
      "training :  3497  accuracy =   0.6600  loss =  155.208\n",
      "testing  :  3497  accuracy =   0.6945  loss =  155.565\n",
      "training :  3498  accuracy =   0.6400  loss =  156.667\n",
      "testing  :  3498  accuracy =   0.6950  loss =  155.557\n",
      "training :  3499  accuracy =   0.6800  loss =  155.746\n",
      "testing  :  3499  accuracy =   0.6963  loss =  155.555\n",
      "training :  3500  accuracy =   0.6800  loss =  154.723\n",
      "testing  :  3500  accuracy =   0.6982  loss =  155.561\n",
      "training :  3501  accuracy =   0.7400  loss =  156.055\n",
      "testing  :  3501  accuracy =   0.6993  loss =  155.569\n",
      "training :  3502  accuracy =   0.7100  loss =  155.624\n",
      "testing  :  3502  accuracy =   0.6993  loss =  155.578\n",
      "training :  3503  accuracy =   0.6600  loss =  158.245\n",
      "testing  :  3503  accuracy =   0.6997  loss =  155.582\n",
      "training :  3504  accuracy =   0.7500  loss =  154.087\n",
      "testing  :  3504  accuracy =   0.7007  loss =  155.581\n",
      "training :  3505  accuracy =   0.7800  loss =  154.007\n",
      "testing  :  3505  accuracy =   0.7010  loss =  155.587\n",
      "training :  3506  accuracy =   0.7300  loss =  154.805\n",
      "testing  :  3506  accuracy =   0.7017  loss =  155.6\n",
      "training :  3507  accuracy =   0.6600  loss =  155.536\n",
      "testing  :  3507  accuracy =   0.7063  loss =  155.609\n",
      "training :  3508  accuracy =   0.7000  loss =  157.715\n",
      "testing  :  3508  accuracy =   0.7115  loss =  155.623\n",
      "training :  3509  accuracy =   0.6800  loss =  154.548\n",
      "testing  :  3509  accuracy =   0.7180  loss =  155.634\n",
      "training :  3510  accuracy =   0.7700  loss =  155.215\n",
      "testing  :  3510  accuracy =   0.7254  loss =  155.644\n",
      "training :  3511  accuracy =   0.6800  loss =  155.104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  3511  accuracy =   0.7368  loss =  155.66\n",
      "training :  3512  accuracy =   0.7700  loss =  154.12\n",
      "testing  :  3512  accuracy =   0.7282  loss =  155.672\n",
      "training :  3513  accuracy =   0.7600  loss =  156.844\n",
      "testing  :  3513  accuracy =   0.7194  loss =  155.687\n",
      "training :  3514  accuracy =   0.7000  loss =  154.598\n",
      "testing  :  3514  accuracy =   0.7180  loss =  155.694\n",
      "training :  3515  accuracy =   0.7700  loss =  153.611\n",
      "testing  :  3515  accuracy =   0.7139  loss =  155.689\n",
      "training :  3516  accuracy =   0.7300  loss =  155.333\n",
      "testing  :  3516  accuracy =   0.7175  loss =  155.642\n",
      "training :  3517  accuracy =   0.7200  loss =  155.159\n",
      "testing  :  3517  accuracy =   0.7180  loss =  155.626\n",
      "training :  3518  accuracy =   0.8000  loss =  154.451\n",
      "testing  :  3518  accuracy =   0.7082  loss =  155.605\n",
      "training :  3519  accuracy =   0.7300  loss =  153.764\n",
      "testing  :  3519  accuracy =   0.7015  loss =  155.606\n",
      "training :  3520  accuracy =   0.6800  loss =  156.295\n",
      "testing  :  3520  accuracy =   0.6973  loss =  155.614\n",
      "training :  3521  accuracy =   0.7400  loss =  155.129\n",
      "testing  :  3521  accuracy =   0.6958  loss =  155.632\n",
      "training :  3522  accuracy =   0.7000  loss =  156.529\n",
      "testing  :  3522  accuracy =   0.6941  loss =  155.653\n",
      "training :  3523  accuracy =   0.6800  loss =  155.249\n",
      "testing  :  3523  accuracy =   0.6932  loss =  155.672\n",
      "training :  3524  accuracy =   0.8100  loss =  152.37\n",
      "testing  :  3524  accuracy =   0.6934  loss =  155.631\n",
      "training :  3525  accuracy =   0.6500  loss =  161.892\n",
      "testing  :  3525  accuracy =   0.6939  loss =  155.61\n",
      "training :  3526  accuracy =   0.6700  loss =  156.174\n",
      "testing  :  3526  accuracy =   0.6932  loss =  155.598\n",
      "training :  3527  accuracy =   0.6000  loss =  156.045\n",
      "testing  :  3527  accuracy =   0.6930  loss =  155.613\n",
      "training :  3528  accuracy =   0.7200  loss =  153.46\n",
      "testing  :  3528  accuracy =   0.6937  loss =  155.63\n",
      "training :  3529  accuracy =   0.7000  loss =  157.792\n",
      "testing  :  3529  accuracy =   0.6928  loss =  155.669\n",
      "training :  3530  accuracy =   0.7200  loss =  154.121\n",
      "testing  :  3530  accuracy =   0.6925  loss =  155.705\n",
      "training :  3531  accuracy =   0.6400  loss =  154.584\n",
      "testing  :  3531  accuracy =   0.6923  loss =  155.734\n",
      "training :  3532  accuracy =   0.7700  loss =  155.839\n",
      "testing  :  3532  accuracy =   0.6918  loss =  155.773\n",
      "training :  3533  accuracy =   0.7100  loss =  155.912\n",
      "testing  :  3533  accuracy =   0.6922  loss =  155.744\n",
      "training :  3534  accuracy =   0.6900  loss =  155.934\n",
      "testing  :  3534  accuracy =   0.6932  loss =  155.717\n",
      "training :  3535  accuracy =   0.7300  loss =  153.28\n",
      "testing  :  3535  accuracy =   0.6934  loss =  155.686\n",
      "training :  3536  accuracy =   0.7100  loss =  155.185\n",
      "testing  :  3536  accuracy =   0.6929  loss =  155.663\n",
      "training :  3537  accuracy =   0.6900  loss =  154.313\n",
      "testing  :  3537  accuracy =   0.6934  loss =  155.615\n",
      "training :  3538  accuracy =   0.6600  loss =  157.011\n",
      "testing  :  3538  accuracy =   0.6941  loss =  155.594\n",
      "training :  3539  accuracy =   0.6700  loss =  154.507\n",
      "testing  :  3539  accuracy =   0.6935  loss =  155.6\n",
      "training :  3540  accuracy =   0.6800  loss =  155.535\n",
      "testing  :  3540  accuracy =   0.6928  loss =  155.623\n",
      "training :  3541  accuracy =   0.7200  loss =  154.156\n",
      "testing  :  3541  accuracy =   0.6919  loss =  155.651\n",
      "training :  3542  accuracy =   0.6800  loss =  155.36\n",
      "testing  :  3542  accuracy =   0.6915  loss =  155.667\n",
      "training :  3543  accuracy =   0.6000  loss =  159.226\n",
      "testing  :  3543  accuracy =   0.6913  loss =  155.688\n",
      "training :  3544  accuracy =   0.8000  loss =  153.612\n",
      "testing  :  3544  accuracy =   0.6915  loss =  155.705\n",
      "training :  3545  accuracy =   0.7100  loss =  154.6\n",
      "testing  :  3545  accuracy =   0.6912  loss =  155.709\n",
      "training :  3546  accuracy =   0.7200  loss =  152.759\n",
      "testing  :  3546  accuracy =   0.6915  loss =  155.714\n",
      "training :  3547  accuracy =   0.7500  loss =  153.219\n",
      "testing  :  3547  accuracy =   0.6916  loss =  155.709\n",
      "training :  3548  accuracy =   0.6700  loss =  155.743\n",
      "testing  :  3548  accuracy =   0.6912  loss =  155.71\n",
      "training :  3549  accuracy =   0.7500  loss =  152.95\n",
      "testing  :  3549  accuracy =   0.6913  loss =  155.707\n",
      "training :  3550  accuracy =   0.7000  loss =  154.064\n",
      "testing  :  3550  accuracy =   0.6915  loss =  155.71\n",
      "training :  3551  accuracy =   0.7500  loss =  153.105\n",
      "testing  :  3551  accuracy =   0.6908  loss =  155.733\n",
      "training :  3552  accuracy =   0.7200  loss =  153.595\n",
      "testing  :  3552  accuracy =   0.6903  loss =  155.777\n",
      "training :  3553  accuracy =   0.6000  loss =  156.867\n",
      "testing  :  3553  accuracy =   0.6901  loss =  155.8\n",
      "training :  3554  accuracy =   0.7000  loss =  154.295\n",
      "testing  :  3554  accuracy =   0.6900  loss =  155.825\n",
      "training :  3555  accuracy =   0.7700  loss =  153.796\n",
      "testing  :  3555  accuracy =   0.6898  loss =  155.839\n",
      "training :  3556  accuracy =   0.8000  loss =  153.355\n",
      "testing  :  3556  accuracy =   0.6899  loss =  155.831\n",
      "training :  3557  accuracy =   0.7000  loss =  153.459\n",
      "testing  :  3557  accuracy =   0.6902  loss =  155.812\n",
      "training :  3558  accuracy =   0.7300  loss =  155.408\n",
      "testing  :  3558  accuracy =   0.6907  loss =  155.793\n",
      "training :  3559  accuracy =   0.6900  loss =  154.849\n",
      "testing  :  3559  accuracy =   0.6911  loss =  155.773\n",
      "training :  3560  accuracy =   0.7400  loss =  156.514\n",
      "testing  :  3560  accuracy =   0.6906  loss =  155.797\n",
      "training :  3561  accuracy =   0.7900  loss =  153.148\n",
      "testing  :  3561  accuracy =   0.6907  loss =  155.809\n",
      "training :  3562  accuracy =   0.7600  loss =  154.253\n",
      "testing  :  3562  accuracy =   0.6911  loss =  155.808\n",
      "training :  3563  accuracy =   0.6900  loss =  155.957\n",
      "testing  :  3563  accuracy =   0.6910  loss =  155.806\n",
      "training :  3564  accuracy =   0.7200  loss =  152.512\n",
      "testing  :  3564  accuracy =   0.6910  loss =  155.821\n",
      "training :  3565  accuracy =   0.7300  loss =  155.118\n",
      "testing  :  3565  accuracy =   0.6906  loss =  155.84\n",
      "training :  3566  accuracy =   0.6700  loss =  155.467\n",
      "testing  :  3566  accuracy =   0.6897  loss =  155.894\n",
      "training :  3567  accuracy =   0.7600  loss =  156.239\n",
      "testing  :  3567  accuracy =   0.6911  loss =  155.946\n",
      "training :  3568  accuracy =   0.7400  loss =  154.411\n",
      "testing  :  3568  accuracy =   0.6898  loss =  155.999\n",
      "training :  3569  accuracy =   0.7000  loss =  155.276\n",
      "testing  :  3569  accuracy =   0.6889  loss =  156.073\n",
      "training :  3570  accuracy =   0.6700  loss =  155.243\n",
      "testing  :  3570  accuracy =   0.6886  loss =  156.192\n",
      "training :  3571  accuracy =   0.7400  loss =  153.691\n",
      "testing  :  3571  accuracy =   0.6868  loss =  156.312\n",
      "training :  3572  accuracy =   0.6500  loss =  155.693\n",
      "testing  :  3572  accuracy =   0.6855  loss =  156.44\n",
      "training :  3573  accuracy =   0.6100  loss =  156.082\n",
      "testing  :  3573  accuracy =   0.6854  loss =  156.562\n",
      "training :  3574  accuracy =   0.7200  loss =  156.743\n",
      "testing  :  3574  accuracy =   0.6858  loss =  156.665\n",
      "training :  3575  accuracy =   0.7100  loss =  159.919\n",
      "testing  :  3575  accuracy =   0.6862  loss =  156.676\n",
      "training :  3576  accuracy =   0.6700  loss =  156.307\n",
      "testing  :  3576  accuracy =   0.6873  loss =  156.586\n",
      "training :  3577  accuracy =   0.7200  loss =  156.317\n",
      "testing  :  3577  accuracy =   0.6877  loss =  156.49\n",
      "training :  3578  accuracy =   0.7100  loss =  154.985\n",
      "testing  :  3578  accuracy =   0.6881  loss =  156.387\n",
      "training :  3579  accuracy =   0.7500  loss =  152.193\n",
      "testing  :  3579  accuracy =   0.6898  loss =  156.169\n",
      "training :  3580  accuracy =   0.6400  loss =  155.937\n",
      "testing  :  3580  accuracy =   0.6905  loss =  156.026\n",
      "training :  3581  accuracy =   0.6400  loss =  155.116\n",
      "testing  :  3581  accuracy =   0.6911  loss =  155.9\n",
      "training :  3582  accuracy =   0.7700  loss =  153.54\n",
      "testing  :  3582  accuracy =   0.6919  loss =  155.805\n",
      "training :  3583  accuracy =   0.6500  loss =  154.425\n",
      "testing  :  3583  accuracy =   0.6925  loss =  155.75\n",
      "training :  3584  accuracy =   0.6900  loss =  156.323\n",
      "testing  :  3584  accuracy =   0.6929  loss =  155.72\n",
      "training :  3585  accuracy =   0.7900  loss =  152.973\n",
      "testing  :  3585  accuracy =   0.6929  loss =  155.696\n",
      "training :  3586  accuracy =   0.6700  loss =  158.21\n",
      "testing  :  3586  accuracy =   0.6932  loss =  155.662\n",
      "training :  3587  accuracy =   0.6700  loss =  154.631\n",
      "testing  :  3587  accuracy =   0.6931  loss =  155.657\n",
      "training :  3588  accuracy =   0.7500  loss =  156.634\n",
      "testing  :  3588  accuracy =   0.6933  loss =  155.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  3589  accuracy =   0.7600  loss =  153.767\n",
      "testing  :  3589  accuracy =   0.6932  loss =  155.659\n",
      "training :  3590  accuracy =   0.7000  loss =  153.937\n",
      "testing  :  3590  accuracy =   0.6932  loss =  155.667\n",
      "training :  3591  accuracy =   0.8000  loss =  153.463\n",
      "testing  :  3591  accuracy =   0.6932  loss =  155.675\n",
      "training :  3592  accuracy =   0.7600  loss =  156.34\n",
      "testing  :  3592  accuracy =   0.6931  loss =  155.711\n",
      "training :  3593  accuracy =   0.7600  loss =  154.928\n",
      "testing  :  3593  accuracy =   0.6931  loss =  155.751\n",
      "training :  3594  accuracy =   0.6900  loss =  154.301\n",
      "testing  :  3594  accuracy =   0.6929  loss =  155.789\n",
      "training :  3595  accuracy =   0.7300  loss =  155.072\n",
      "testing  :  3595  accuracy =   0.6929  loss =  155.817\n",
      "training :  3596  accuracy =   0.7400  loss =  154.798\n",
      "testing  :  3596  accuracy =   0.6930  loss =  155.835\n",
      "training :  3597  accuracy =   0.6500  loss =  154.689\n",
      "testing  :  3597  accuracy =   0.6933  loss =  155.824\n",
      "training :  3598  accuracy =   0.5900  loss =  156.817\n",
      "testing  :  3598  accuracy =   0.6930  loss =  155.838\n",
      "training :  3599  accuracy =   0.7200  loss =  154.376\n",
      "testing  :  3599  accuracy =   0.6935  loss =  155.84\n",
      "training :  3600  accuracy =   0.6600  loss =  154.571\n",
      "testing  :  3600  accuracy =   0.6940  loss =  155.777\n",
      "training :  3601  accuracy =   0.6800  loss =  153.697\n",
      "testing  :  3601  accuracy =   0.6942  loss =  155.736\n",
      "training :  3602  accuracy =   0.7000  loss =  156.182\n",
      "testing  :  3602  accuracy =   0.6951  loss =  155.708\n",
      "training :  3603  accuracy =   0.7400  loss =  155.221\n",
      "testing  :  3603  accuracy =   0.6966  loss =  155.69\n",
      "training :  3604  accuracy =   0.7300  loss =  154.448\n",
      "testing  :  3604  accuracy =   0.6974  loss =  155.684\n",
      "training :  3605  accuracy =   0.7400  loss =  155.477\n",
      "testing  :  3605  accuracy =   0.6978  loss =  155.677\n",
      "training :  3606  accuracy =   0.7000  loss =  156.314\n",
      "testing  :  3606  accuracy =   0.6994  loss =  155.671\n",
      "training :  3607  accuracy =   0.7200  loss =  154.081\n",
      "testing  :  3607  accuracy =   0.6990  loss =  155.682\n",
      "training :  3608  accuracy =   0.6600  loss =  154.0\n",
      "testing  :  3608  accuracy =   0.6992  loss =  155.712\n",
      "training :  3609  accuracy =   0.6400  loss =  155.218\n",
      "testing  :  3609  accuracy =   0.6992  loss =  155.735\n",
      "training :  3610  accuracy =   0.7500  loss =  154.666\n",
      "testing  :  3610  accuracy =   0.6997  loss =  155.742\n",
      "training :  3611  accuracy =   0.6400  loss =  153.861\n",
      "testing  :  3611  accuracy =   0.6994  loss =  155.718\n",
      "training :  3612  accuracy =   0.7300  loss =  155.04\n",
      "testing  :  3612  accuracy =   0.6992  loss =  155.696\n",
      "training :  3613  accuracy =   0.7400  loss =  154.987\n",
      "testing  :  3613  accuracy =   0.6991  loss =  155.66\n",
      "training :  3614  accuracy =   0.7000  loss =  154.138\n",
      "testing  :  3614  accuracy =   0.6990  loss =  155.633\n",
      "training :  3615  accuracy =   0.6500  loss =  155.143\n",
      "testing  :  3615  accuracy =   0.6989  loss =  155.597\n",
      "training :  3616  accuracy =   0.7000  loss =  153.617\n",
      "testing  :  3616  accuracy =   0.6977  loss =  155.569\n",
      "training :  3617  accuracy =   0.7100  loss =  154.904\n",
      "testing  :  3617  accuracy =   0.6967  loss =  155.551\n",
      "training :  3618  accuracy =   0.6200  loss =  156.591\n",
      "testing  :  3618  accuracy =   0.6963  loss =  155.543\n",
      "training :  3619  accuracy =   0.7000  loss =  154.397\n",
      "testing  :  3619  accuracy =   0.6964  loss =  155.543\n",
      "training :  3620  accuracy =   0.6900  loss =  154.734\n",
      "testing  :  3620  accuracy =   0.6964  loss =  155.55\n",
      "training :  3621  accuracy =   0.6800  loss =  154.928\n",
      "testing  :  3621  accuracy =   0.6963  loss =  155.561\n",
      "training :  3622  accuracy =   0.7000  loss =  154.506\n",
      "testing  :  3622  accuracy =   0.6964  loss =  155.58\n",
      "training :  3623  accuracy =   0.8000  loss =  153.485\n",
      "testing  :  3623  accuracy =   0.6960  loss =  155.594\n",
      "training :  3624  accuracy =   0.7800  loss =  153.002\n",
      "testing  :  3624  accuracy =   0.6950  loss =  155.606\n",
      "training :  3625  accuracy =   0.7100  loss =  153.379\n",
      "testing  :  3625  accuracy =   0.6941  loss =  155.607\n",
      "training :  3626  accuracy =   0.6800  loss =  156.179\n",
      "testing  :  3626  accuracy =   0.6923  loss =  155.612\n",
      "training :  3627  accuracy =   0.6300  loss =  156.133\n",
      "testing  :  3627  accuracy =   0.6914  loss =  155.634\n",
      "training :  3628  accuracy =   0.7000  loss =  154.828\n",
      "testing  :  3628  accuracy =   0.6911  loss =  155.665\n",
      "training :  3629  accuracy =   0.7300  loss =  154.568\n",
      "testing  :  3629  accuracy =   0.6906  loss =  155.682\n",
      "training :  3630  accuracy =   0.6200  loss =  155.034\n",
      "testing  :  3630  accuracy =   0.6902  loss =  155.708\n",
      "training :  3631  accuracy =   0.6700  loss =  153.478\n",
      "testing  :  3631  accuracy =   0.6902  loss =  155.728\n",
      "training :  3632  accuracy =   0.7200  loss =  156.271\n",
      "testing  :  3632  accuracy =   0.6904  loss =  155.683\n",
      "training :  3633  accuracy =   0.8000  loss =  152.859\n",
      "testing  :  3633  accuracy =   0.6908  loss =  155.662\n",
      "training :  3634  accuracy =   0.6700  loss =  156.488\n",
      "testing  :  3634  accuracy =   0.6907  loss =  155.767\n",
      "training :  3635  accuracy =   0.6400  loss =  156.432\n",
      "testing  :  3635  accuracy =   0.6883  loss =  155.97\n",
      "training :  3636  accuracy =   0.6200  loss =  156.754\n",
      "testing  :  3636  accuracy =   0.6863  loss =  156.296\n",
      "training :  3637  accuracy =   0.6600  loss =  157.445\n",
      "testing  :  3637  accuracy =   0.6850  loss =  156.51\n",
      "training :  3638  accuracy =   0.6900  loss =  155.055\n",
      "testing  :  3638  accuracy =   0.6869  loss =  156.351\n",
      "training :  3639  accuracy =   0.6900  loss =  154.975\n",
      "testing  :  3639  accuracy =   0.6875  loss =  156.206\n",
      "training :  3640  accuracy =   0.7300  loss =  152.992\n",
      "testing  :  3640  accuracy =   0.6903  loss =  156.001\n",
      "training :  3641  accuracy =   0.7100  loss =  153.683\n",
      "testing  :  3641  accuracy =   0.6929  loss =  155.859\n",
      "training :  3642  accuracy =   0.8100  loss =  153.049\n",
      "testing  :  3642  accuracy =   0.6946  loss =  155.754\n",
      "training :  3643  accuracy =   0.7100  loss =  153.259\n",
      "testing  :  3643  accuracy =   0.6967  loss =  155.68\n",
      "training :  3644  accuracy =   0.8100  loss =  153.611\n",
      "testing  :  3644  accuracy =   0.6988  loss =  155.626\n",
      "training :  3645  accuracy =   0.6400  loss =  154.022\n",
      "testing  :  3645  accuracy =   0.7011  loss =  155.615\n",
      "training :  3646  accuracy =   0.7200  loss =  157.131\n",
      "testing  :  3646  accuracy =   0.7033  loss =  155.646\n",
      "training :  3647  accuracy =   0.6700  loss =  155.406\n",
      "testing  :  3647  accuracy =   0.7061  loss =  155.681\n",
      "training :  3648  accuracy =   0.7800  loss =  154.083\n",
      "testing  :  3648  accuracy =   0.7182  loss =  155.704\n",
      "training :  3649  accuracy =   0.8100  loss =  154.525\n",
      "testing  :  3649  accuracy =   0.7359  loss =  155.733\n",
      "training :  3650  accuracy =   0.8200  loss =  154.017\n",
      "testing  :  3650  accuracy =   0.7491  loss =  155.765\n",
      "training :  3651  accuracy =   0.7900  loss =  155.524\n",
      "testing  :  3651  accuracy =   0.7571  loss =  155.801\n",
      "training :  3652  accuracy =   0.7400  loss =  156.058\n",
      "testing  :  3652  accuracy =   0.7575  loss =  155.798\n",
      "training :  3653  accuracy =   0.7400  loss =  155.929\n",
      "testing  :  3653  accuracy =   0.7580  loss =  155.792\n",
      "training :  3654  accuracy =   0.7400  loss =  157.163\n",
      "testing  :  3654  accuracy =   0.7574  loss =  155.819\n",
      "training :  3655  accuracy =   0.7900  loss =  152.921\n",
      "testing  :  3655  accuracy =   0.7601  loss =  155.803\n",
      "training :  3656  accuracy =   0.7700  loss =  154.186\n",
      "testing  :  3656  accuracy =   0.7619  loss =  155.749\n",
      "training :  3657  accuracy =   0.8600  loss =  152.728\n",
      "testing  :  3657  accuracy =   0.7636  loss =  155.643\n",
      "training :  3658  accuracy =   0.8000  loss =  153.721\n",
      "testing  :  3658  accuracy =   0.7645  loss =  155.576\n",
      "training :  3659  accuracy =   0.8100  loss =  154.194\n",
      "testing  :  3659  accuracy =   0.7655  loss =  155.537\n",
      "training :  3660  accuracy =   0.6900  loss =  157.399\n",
      "testing  :  3660  accuracy =   0.7660  loss =  155.506\n",
      "training :  3661  accuracy =   0.7000  loss =  157.058\n",
      "testing  :  3661  accuracy =   0.7658  loss =  155.493\n",
      "training :  3662  accuracy =   0.8400  loss =  154.601\n",
      "testing  :  3662  accuracy =   0.7660  loss =  155.502\n",
      "training :  3663  accuracy =   0.8000  loss =  153.912\n",
      "testing  :  3663  accuracy =   0.7657  loss =  155.521\n",
      "training :  3664  accuracy =   0.7900  loss =  155.489\n",
      "testing  :  3664  accuracy =   0.7660  loss =  155.55\n",
      "training :  3665  accuracy =   0.7800  loss =  153.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  3665  accuracy =   0.7655  loss =  155.571\n",
      "training :  3666  accuracy =   0.7500  loss =  155.386\n",
      "testing  :  3666  accuracy =   0.7663  loss =  155.591\n",
      "training :  3667  accuracy =   0.8000  loss =  154.625\n",
      "testing  :  3667  accuracy =   0.7655  loss =  155.577\n",
      "training :  3668  accuracy =   0.7500  loss =  155.851\n",
      "testing  :  3668  accuracy =   0.7634  loss =  155.547\n",
      "training :  3669  accuracy =   0.7700  loss =  154.576\n",
      "testing  :  3669  accuracy =   0.7610  loss =  155.526\n",
      "training :  3670  accuracy =   0.7900  loss =  155.773\n",
      "testing  :  3670  accuracy =   0.7595  loss =  155.493\n",
      "training :  3671  accuracy =   0.8900  loss =  153.139\n",
      "testing  :  3671  accuracy =   0.7618  loss =  155.47\n",
      "training :  3672  accuracy =   0.8000  loss =  155.669\n",
      "testing  :  3672  accuracy =   0.7631  loss =  155.488\n",
      "training :  3673  accuracy =   0.7700  loss =  154.3\n",
      "testing  :  3673  accuracy =   0.7657  loss =  155.508\n",
      "training :  3674  accuracy =   0.7600  loss =  154.487\n",
      "testing  :  3674  accuracy =   0.7647  loss =  155.545\n",
      "training :  3675  accuracy =   0.6900  loss =  157.908\n",
      "testing  :  3675  accuracy =   0.7641  loss =  155.596\n",
      "training :  3676  accuracy =   0.7500  loss =  155.376\n",
      "testing  :  3676  accuracy =   0.7633  loss =  155.601\n",
      "training :  3677  accuracy =   0.8100  loss =  152.733\n",
      "testing  :  3677  accuracy =   0.7592  loss =  155.601\n",
      "training :  3678  accuracy =   0.7500  loss =  155.61\n",
      "testing  :  3678  accuracy =   0.7501  loss =  155.617\n",
      "training :  3679  accuracy =   0.8100  loss =  153.467\n",
      "testing  :  3679  accuracy =   0.7427  loss =  155.626\n",
      "training :  3680  accuracy =   0.7800  loss =  156.24\n",
      "testing  :  3680  accuracy =   0.7410  loss =  155.607\n",
      "training :  3681  accuracy =   0.7700  loss =  155.437\n",
      "testing  :  3681  accuracy =   0.7405  loss =  155.569\n",
      "training :  3682  accuracy =   0.7100  loss =  155.203\n",
      "testing  :  3682  accuracy =   0.7460  loss =  155.491\n",
      "training :  3683  accuracy =   0.8400  loss =  153.963\n",
      "testing  :  3683  accuracy =   0.7643  loss =  155.433\n",
      "training :  3684  accuracy =   0.8200  loss =  155.276\n",
      "testing  :  3684  accuracy =   0.7633  loss =  155.448\n",
      "training :  3685  accuracy =   0.7700  loss =  156.548\n",
      "testing  :  3685  accuracy =   0.7538  loss =  155.542\n",
      "training :  3686  accuracy =   0.7100  loss =  153.551\n",
      "testing  :  3686  accuracy =   0.7337  loss =  155.677\n",
      "training :  3687  accuracy =   0.8200  loss =  152.798\n",
      "testing  :  3687  accuracy =   0.7136  loss =  155.851\n",
      "training :  3688  accuracy =   0.6700  loss =  156.765\n",
      "testing  :  3688  accuracy =   0.6998  loss =  156.049\n",
      "training :  3689  accuracy =   0.6400  loss =  154.648\n",
      "testing  :  3689  accuracy =   0.6948  loss =  155.941\n",
      "training :  3690  accuracy =   0.7000  loss =  154.141\n",
      "testing  :  3690  accuracy =   0.6935  loss =  155.829\n",
      "training :  3691  accuracy =   0.7300  loss =  153.513\n",
      "testing  :  3691  accuracy =   0.6931  loss =  155.769\n",
      "training :  3692  accuracy =   0.7000  loss =  155.751\n",
      "testing  :  3692  accuracy =   0.6932  loss =  155.736\n",
      "training :  3693  accuracy =   0.7300  loss =  153.885\n",
      "testing  :  3693  accuracy =   0.6931  loss =  155.716\n",
      "training :  3694  accuracy =   0.7100  loss =  154.973\n",
      "testing  :  3694  accuracy =   0.6918  loss =  155.722\n",
      "training :  3695  accuracy =   0.7100  loss =  153.133\n",
      "testing  :  3695  accuracy =   0.6914  loss =  155.743\n",
      "training :  3696  accuracy =   0.7100  loss =  156.59\n",
      "testing  :  3696  accuracy =   0.6906  loss =  155.771\n",
      "training :  3697  accuracy =   0.7300  loss =  155.284\n",
      "testing  :  3697  accuracy =   0.6902  loss =  155.799\n",
      "training :  3698  accuracy =   0.6700  loss =  155.632\n",
      "testing  :  3698  accuracy =   0.6896  loss =  155.818\n",
      "training :  3699  accuracy =   0.6600  loss =  156.895\n",
      "testing  :  3699  accuracy =   0.6899  loss =  155.772\n",
      "training :  3700  accuracy =   0.7200  loss =  156.248\n",
      "testing  :  3700  accuracy =   0.6899  loss =  155.706\n",
      "training :  3701  accuracy =   0.7600  loss =  154.17\n",
      "testing  :  3701  accuracy =   0.6897  loss =  155.665\n",
      "training :  3702  accuracy =   0.7000  loss =  158.254\n",
      "testing  :  3702  accuracy =   0.6896  loss =  155.646\n",
      "training :  3703  accuracy =   0.7500  loss =  153.622\n",
      "testing  :  3703  accuracy =   0.6895  loss =  155.656\n",
      "training :  3704  accuracy =   0.7000  loss =  155.893\n",
      "testing  :  3704  accuracy =   0.6893  loss =  155.643\n",
      "training :  3705  accuracy =   0.7100  loss =  155.892\n",
      "testing  :  3705  accuracy =   0.6890  loss =  155.627\n",
      "training :  3706  accuracy =   0.6600  loss =  156.286\n",
      "testing  :  3706  accuracy =   0.6889  loss =  155.61\n",
      "training :  3707  accuracy =   0.7900  loss =  151.859\n",
      "testing  :  3707  accuracy =   0.6891  loss =  155.646\n",
      "training :  3708  accuracy =   0.6700  loss =  155.241\n",
      "testing  :  3708  accuracy =   0.6895  loss =  155.688\n",
      "training :  3709  accuracy =   0.6600  loss =  154.141\n",
      "testing  :  3709  accuracy =   0.6897  loss =  155.677\n",
      "training :  3710  accuracy =   0.6500  loss =  154.438\n",
      "testing  :  3710  accuracy =   0.6907  loss =  155.678\n",
      "training :  3711  accuracy =   0.7100  loss =  153.658\n",
      "testing  :  3711  accuracy =   0.6914  loss =  155.703\n",
      "training :  3712  accuracy =   0.7400  loss =  154.189\n",
      "testing  :  3712  accuracy =   0.6919  loss =  155.732\n",
      "training :  3713  accuracy =   0.7000  loss =  154.559\n",
      "testing  :  3713  accuracy =   0.6915  loss =  155.788\n",
      "training :  3714  accuracy =   0.7400  loss =  153.923\n",
      "testing  :  3714  accuracy =   0.6920  loss =  155.856\n",
      "training :  3715  accuracy =   0.6800  loss =  155.762\n",
      "testing  :  3715  accuracy =   0.6925  loss =  155.91\n",
      "training :  3716  accuracy =   0.6300  loss =  157.406\n",
      "testing  :  3716  accuracy =   0.6929  loss =  155.967\n",
      "training :  3717  accuracy =   0.6700  loss =  153.948\n",
      "testing  :  3717  accuracy =   0.6933  loss =  155.992\n",
      "training :  3718  accuracy =   0.7000  loss =  157.266\n",
      "testing  :  3718  accuracy =   0.6930  loss =  156.007\n",
      "training :  3719  accuracy =   0.7100  loss =  155.703\n",
      "testing  :  3719  accuracy =   0.6930  loss =  156.006\n",
      "training :  3720  accuracy =   0.7200  loss =  153.445\n",
      "testing  :  3720  accuracy =   0.6928  loss =  155.98\n",
      "training :  3721  accuracy =   0.7100  loss =  156.333\n",
      "testing  :  3721  accuracy =   0.6930  loss =  155.971\n",
      "training :  3722  accuracy =   0.7400  loss =  157.446\n",
      "testing  :  3722  accuracy =   0.6936  loss =  155.958\n",
      "training :  3723  accuracy =   0.6900  loss =  154.059\n",
      "testing  :  3723  accuracy =   0.6939  loss =  155.963\n",
      "training :  3724  accuracy =   0.6700  loss =  154.146\n",
      "testing  :  3724  accuracy =   0.6939  loss =  155.976\n",
      "training :  3725  accuracy =   0.7200  loss =  154.817\n",
      "testing  :  3725  accuracy =   0.6939  loss =  155.97\n",
      "training :  3726  accuracy =   0.7800  loss =  152.26\n",
      "testing  :  3726  accuracy =   0.6940  loss =  155.914\n",
      "training :  3727  accuracy =   0.6900  loss =  154.07\n",
      "testing  :  3727  accuracy =   0.6941  loss =  155.878\n",
      "training :  3728  accuracy =   0.6400  loss =  156.453\n",
      "testing  :  3728  accuracy =   0.6935  loss =  155.815\n",
      "training :  3729  accuracy =   0.7300  loss =  156.337\n",
      "testing  :  3729  accuracy =   0.6933  loss =  155.752\n",
      "training :  3730  accuracy =   0.6700  loss =  155.084\n",
      "testing  :  3730  accuracy =   0.6933  loss =  155.683\n",
      "training :  3731  accuracy =   0.7000  loss =  154.559\n",
      "testing  :  3731  accuracy =   0.6927  loss =  155.634\n",
      "training :  3732  accuracy =   0.6400  loss =  155.818\n",
      "testing  :  3732  accuracy =   0.6922  loss =  155.602\n",
      "training :  3733  accuracy =   0.6900  loss =  155.537\n",
      "testing  :  3733  accuracy =   0.6926  loss =  155.583\n",
      "training :  3734  accuracy =   0.7300  loss =  153.74\n",
      "testing  :  3734  accuracy =   0.6929  loss =  155.572\n",
      "training :  3735  accuracy =   0.7400  loss =  153.981\n",
      "testing  :  3735  accuracy =   0.6935  loss =  155.577\n",
      "training :  3736  accuracy =   0.6600  loss =  155.879\n",
      "testing  :  3736  accuracy =   0.6935  loss =  155.586\n",
      "training :  3737  accuracy =   0.7300  loss =  155.608\n",
      "testing  :  3737  accuracy =   0.6933  loss =  155.6\n",
      "training :  3738  accuracy =   0.7000  loss =  155.884\n",
      "testing  :  3738  accuracy =   0.6930  loss =  155.596\n",
      "training :  3739  accuracy =   0.5700  loss =  158.801\n",
      "testing  :  3739  accuracy =   0.6927  loss =  155.596\n",
      "training :  3740  accuracy =   0.7500  loss =  154.581\n",
      "testing  :  3740  accuracy =   0.6927  loss =  155.596\n",
      "training :  3741  accuracy =   0.7500  loss =  153.194\n",
      "testing  :  3741  accuracy =   0.6922  loss =  155.583\n",
      "training :  3742  accuracy =   0.6600  loss =  154.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  3742  accuracy =   0.6921  loss =  155.577\n",
      "training :  3743  accuracy =   0.7900  loss =  153.425\n",
      "testing  :  3743  accuracy =   0.6920  loss =  155.575\n",
      "training :  3744  accuracy =   0.6800  loss =  153.863\n",
      "testing  :  3744  accuracy =   0.6924  loss =  155.57\n",
      "training :  3745  accuracy =   0.7200  loss =  155.376\n",
      "testing  :  3745  accuracy =   0.6924  loss =  155.551\n",
      "training :  3746  accuracy =   0.7300  loss =  152.525\n",
      "testing  :  3746  accuracy =   0.6931  loss =  155.528\n",
      "training :  3747  accuracy =   0.6600  loss =  156.388\n",
      "testing  :  3747  accuracy =   0.6932  loss =  155.519\n",
      "training :  3748  accuracy =   0.7000  loss =  154.981\n",
      "testing  :  3748  accuracy =   0.6937  loss =  155.52\n",
      "training :  3749  accuracy =   0.7400  loss =  153.641\n",
      "testing  :  3749  accuracy =   0.6934  loss =  155.53\n",
      "training :  3750  accuracy =   0.7100  loss =  153.108\n",
      "testing  :  3750  accuracy =   0.6933  loss =  155.548\n",
      "training :  3751  accuracy =   0.6600  loss =  154.337\n",
      "testing  :  3751  accuracy =   0.6928  loss =  155.57\n",
      "training :  3752  accuracy =   0.6700  loss =  157.94\n",
      "testing  :  3752  accuracy =   0.6920  loss =  155.607\n",
      "training :  3753  accuracy =   0.7400  loss =  155.69\n",
      "testing  :  3753  accuracy =   0.6920  loss =  155.634\n",
      "training :  3754  accuracy =   0.6800  loss =  152.526\n",
      "testing  :  3754  accuracy =   0.6919  loss =  155.66\n",
      "training :  3755  accuracy =   0.7000  loss =  155.086\n",
      "testing  :  3755  accuracy =   0.6914  loss =  155.685\n",
      "training :  3756  accuracy =   0.6800  loss =  157.553\n",
      "testing  :  3756  accuracy =   0.6914  loss =  155.744\n",
      "training :  3757  accuracy =   0.7600  loss =  153.83\n",
      "testing  :  3757  accuracy =   0.6914  loss =  155.726\n",
      "training :  3758  accuracy =   0.7400  loss =  155.522\n",
      "testing  :  3758  accuracy =   0.6915  loss =  155.679\n",
      "training :  3759  accuracy =   0.7100  loss =  154.974\n",
      "testing  :  3759  accuracy =   0.6921  loss =  155.59\n",
      "training :  3760  accuracy =   0.6800  loss =  155.017\n",
      "testing  :  3760  accuracy =   0.6919  loss =  155.558\n",
      "training :  3761  accuracy =   0.6900  loss =  156.251\n",
      "testing  :  3761  accuracy =   0.6920  loss =  155.573\n",
      "training :  3762  accuracy =   0.6300  loss =  154.315\n",
      "testing  :  3762  accuracy =   0.6910  loss =  155.618\n",
      "training :  3763  accuracy =   0.7100  loss =  154.04\n",
      "testing  :  3763  accuracy =   0.6909  loss =  155.696\n",
      "training :  3764  accuracy =   0.6400  loss =  156.789\n",
      "testing  :  3764  accuracy =   0.6899  loss =  155.771\n",
      "training :  3765  accuracy =   0.7400  loss =  153.183\n",
      "testing  :  3765  accuracy =   0.6897  loss =  155.826\n",
      "training :  3766  accuracy =   0.7500  loss =  156.67\n",
      "testing  :  3766  accuracy =   0.6891  loss =  155.888\n",
      "training :  3767  accuracy =   0.6400  loss =  155.375\n",
      "testing  :  3767  accuracy =   0.6886  loss =  155.966\n",
      "training :  3768  accuracy =   0.7200  loss =  157.144\n",
      "testing  :  3768  accuracy =   0.6883  loss =  156.068\n",
      "training :  3769  accuracy =   0.6600  loss =  158.196\n",
      "testing  :  3769  accuracy =   0.6876  loss =  156.04\n",
      "training :  3770  accuracy =   0.7400  loss =  154.269\n",
      "testing  :  3770  accuracy =   0.6882  loss =  156.02\n",
      "training :  3771  accuracy =   0.6700  loss =  154.559\n",
      "testing  :  3771  accuracy =   0.6887  loss =  155.836\n",
      "training :  3772  accuracy =   0.7700  loss =  153.454\n",
      "testing  :  3772  accuracy =   0.6891  loss =  155.755\n",
      "training :  3773  accuracy =   0.5900  loss =  157.415\n",
      "testing  :  3773  accuracy =   0.6893  loss =  155.708\n",
      "training :  3774  accuracy =   0.7500  loss =  155.939\n",
      "testing  :  3774  accuracy =   0.6897  loss =  155.667\n",
      "training :  3775  accuracy =   0.7000  loss =  154.872\n",
      "testing  :  3775  accuracy =   0.6904  loss =  155.64\n",
      "training :  3776  accuracy =   0.6600  loss =  157.381\n",
      "testing  :  3776  accuracy =   0.6907  loss =  155.619\n",
      "training :  3777  accuracy =   0.6900  loss =  156.574\n",
      "testing  :  3777  accuracy =   0.6903  loss =  155.605\n",
      "training :  3778  accuracy =   0.5800  loss =  155.759\n",
      "testing  :  3778  accuracy =   0.6906  loss =  155.593\n",
      "training :  3779  accuracy =   0.7500  loss =  152.788\n",
      "testing  :  3779  accuracy =   0.6909  loss =  155.582\n",
      "training :  3780  accuracy =   0.6600  loss =  154.623\n",
      "testing  :  3780  accuracy =   0.6910  loss =  155.597\n",
      "training :  3781  accuracy =   0.7500  loss =  153.715\n",
      "testing  :  3781  accuracy =   0.6910  loss =  155.628\n",
      "training :  3782  accuracy =   0.6500  loss =  154.247\n",
      "testing  :  3782  accuracy =   0.6918  loss =  155.631\n",
      "training :  3783  accuracy =   0.6600  loss =  154.323\n",
      "testing  :  3783  accuracy =   0.6927  loss =  155.62\n",
      "training :  3784  accuracy =   0.7600  loss =  153.046\n",
      "testing  :  3784  accuracy =   0.6923  loss =  155.619\n",
      "training :  3785  accuracy =   0.6300  loss =  154.058\n",
      "testing  :  3785  accuracy =   0.6923  loss =  155.619\n",
      "training :  3786  accuracy =   0.6900  loss =  154.148\n",
      "testing  :  3786  accuracy =   0.6920  loss =  155.632\n",
      "training :  3787  accuracy =   0.7500  loss =  153.54\n",
      "testing  :  3787  accuracy =   0.6922  loss =  155.61\n",
      "training :  3788  accuracy =   0.6800  loss =  155.059\n",
      "testing  :  3788  accuracy =   0.6923  loss =  155.585\n",
      "training :  3789  accuracy =   0.6600  loss =  156.059\n",
      "testing  :  3789  accuracy =   0.6923  loss =  155.548\n",
      "training :  3790  accuracy =   0.7000  loss =  153.967\n",
      "testing  :  3790  accuracy =   0.6928  loss =  155.514\n",
      "training :  3791  accuracy =   0.7100  loss =  155.487\n",
      "testing  :  3791  accuracy =   0.6933  loss =  155.492\n",
      "training :  3792  accuracy =   0.6000  loss =  158.034\n",
      "testing  :  3792  accuracy =   0.6932  loss =  155.465\n",
      "training :  3793  accuracy =   0.7400  loss =  152.646\n",
      "testing  :  3793  accuracy =   0.6939  loss =  155.425\n",
      "training :  3794  accuracy =   0.6900  loss =  154.727\n",
      "testing  :  3794  accuracy =   0.6940  loss =  155.404\n",
      "training :  3795  accuracy =   0.7500  loss =  153.873\n",
      "testing  :  3795  accuracy =   0.6945  loss =  155.403\n",
      "training :  3796  accuracy =   0.8300  loss =  153.236\n",
      "testing  :  3796  accuracy =   0.6945  loss =  155.414\n",
      "training :  3797  accuracy =   0.8200  loss =  151.9\n",
      "testing  :  3797  accuracy =   0.6941  loss =  155.436\n",
      "training :  3798  accuracy =   0.6800  loss =  153.273\n",
      "testing  :  3798  accuracy =   0.6946  loss =  155.458\n",
      "training :  3799  accuracy =   0.6800  loss =  153.251\n",
      "testing  :  3799  accuracy =   0.6949  loss =  155.451\n",
      "training :  3800  accuracy =   0.6900  loss =  154.205\n",
      "testing  :  3800  accuracy =   0.6953  loss =  155.438\n",
      "training :  3801  accuracy =   0.6700  loss =  155.649\n",
      "testing  :  3801  accuracy =   0.6964  loss =  155.431\n",
      "training :  3802  accuracy =   0.6900  loss =  155.087\n",
      "testing  :  3802  accuracy =   0.6964  loss =  155.439\n",
      "training :  3803  accuracy =   0.7900  loss =  153.374\n",
      "testing  :  3803  accuracy =   0.6969  loss =  155.465\n",
      "training :  3804  accuracy =   0.7400  loss =  154.202\n",
      "testing  :  3804  accuracy =   0.6965  loss =  155.476\n",
      "training :  3805  accuracy =   0.7000  loss =  153.432\n",
      "testing  :  3805  accuracy =   0.6963  loss =  155.491\n",
      "training :  3806  accuracy =   0.7000  loss =  155.547\n",
      "testing  :  3806  accuracy =   0.6965  loss =  155.517\n",
      "training :  3807  accuracy =   0.6900  loss =  154.927\n",
      "testing  :  3807  accuracy =   0.6964  loss =  155.55\n",
      "training :  3808  accuracy =   0.7500  loss =  152.319\n",
      "testing  :  3808  accuracy =   0.6967  loss =  155.588\n",
      "training :  3809  accuracy =   0.7000  loss =  154.626\n",
      "testing  :  3809  accuracy =   0.6962  loss =  155.632\n",
      "training :  3810  accuracy =   0.7600  loss =  153.044\n",
      "testing  :  3810  accuracy =   0.6965  loss =  155.647\n",
      "training :  3811  accuracy =   0.6800  loss =  154.273\n",
      "testing  :  3811  accuracy =   0.6963  loss =  155.669\n",
      "training :  3812  accuracy =   0.6400  loss =  156.504\n",
      "testing  :  3812  accuracy =   0.6953  loss =  155.677\n",
      "training :  3813  accuracy =   0.6900  loss =  155.354\n",
      "testing  :  3813  accuracy =   0.6962  loss =  155.67\n",
      "training :  3814  accuracy =   0.7700  loss =  153.454\n",
      "testing  :  3814  accuracy =   0.6955  loss =  155.673\n",
      "training :  3815  accuracy =   0.7300  loss =  155.245\n",
      "testing  :  3815  accuracy =   0.6953  loss =  155.663\n",
      "training :  3816  accuracy =   0.6900  loss =  153.403\n",
      "testing  :  3816  accuracy =   0.6938  loss =  155.631\n",
      "training :  3817  accuracy =   0.6500  loss =  155.748\n",
      "testing  :  3817  accuracy =   0.6931  loss =  155.607\n",
      "training :  3818  accuracy =   0.6600  loss =  156.325\n",
      "testing  :  3818  accuracy =   0.6936  loss =  155.589\n",
      "training :  3819  accuracy =   0.7500  loss =  152.59\n",
      "testing  :  3819  accuracy =   0.6940  loss =  155.574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  3820  accuracy =   0.6900  loss =  153.222\n",
      "testing  :  3820  accuracy =   0.6938  loss =  155.565\n",
      "training :  3821  accuracy =   0.7500  loss =  154.695\n",
      "testing  :  3821  accuracy =   0.6937  loss =  155.559\n",
      "training :  3822  accuracy =   0.7200  loss =  155.038\n",
      "testing  :  3822  accuracy =   0.6944  loss =  155.556\n",
      "training :  3823  accuracy =   0.7700  loss =  153.486\n",
      "testing  :  3823  accuracy =   0.6938  loss =  155.553\n",
      "training :  3824  accuracy =   0.7300  loss =  152.377\n",
      "testing  :  3824  accuracy =   0.6936  loss =  155.552\n",
      "training :  3825  accuracy =   0.7600  loss =  153.933\n",
      "testing  :  3825  accuracy =   0.6934  loss =  155.553\n",
      "training :  3826  accuracy =   0.7300  loss =  153.731\n",
      "testing  :  3826  accuracy =   0.6937  loss =  155.552\n",
      "training :  3827  accuracy =   0.6600  loss =  157.705\n",
      "testing  :  3827  accuracy =   0.6945  loss =  155.55\n",
      "training :  3828  accuracy =   0.6100  loss =  154.954\n",
      "testing  :  3828  accuracy =   0.6945  loss =  155.553\n",
      "training :  3829  accuracy =   0.6200  loss =  159.176\n",
      "testing  :  3829  accuracy =   0.6951  loss =  155.55\n",
      "training :  3830  accuracy =   0.6800  loss =  154.288\n",
      "testing  :  3830  accuracy =   0.6952  loss =  155.544\n",
      "training :  3831  accuracy =   0.6700  loss =  154.652\n",
      "testing  :  3831  accuracy =   0.6955  loss =  155.533\n",
      "training :  3832  accuracy =   0.6100  loss =  156.818\n",
      "testing  :  3832  accuracy =   0.6954  loss =  155.526\n",
      "training :  3833  accuracy =   0.7100  loss =  153.918\n",
      "testing  :  3833  accuracy =   0.6959  loss =  155.519\n",
      "training :  3834  accuracy =   0.7100  loss =  153.873\n",
      "testing  :  3834  accuracy =   0.6957  loss =  155.515\n",
      "training :  3835  accuracy =   0.7700  loss =  153.16\n",
      "testing  :  3835  accuracy =   0.6967  loss =  155.514\n",
      "training :  3836  accuracy =   0.6600  loss =  156.049\n",
      "testing  :  3836  accuracy =   0.6976  loss =  155.513\n",
      "training :  3837  accuracy =   0.7200  loss =  155.344\n",
      "testing  :  3837  accuracy =   0.6979  loss =  155.513\n",
      "training :  3838  accuracy =   0.7600  loss =  153.656\n",
      "testing  :  3838  accuracy =   0.6975  loss =  155.534\n",
      "training :  3839  accuracy =   0.7400  loss =  154.058\n",
      "testing  :  3839  accuracy =   0.6973  loss =  155.578\n",
      "training :  3840  accuracy =   0.6300  loss =  155.864\n",
      "testing  :  3840  accuracy =   0.6977  loss =  155.644\n",
      "training :  3841  accuracy =   0.6500  loss =  155.58\n",
      "testing  :  3841  accuracy =   0.6970  loss =  155.694\n",
      "training :  3842  accuracy =   0.7000  loss =  153.231\n",
      "testing  :  3842  accuracy =   0.6965  loss =  155.744\n",
      "training :  3843  accuracy =   0.7300  loss =  152.152\n",
      "testing  :  3843  accuracy =   0.6963  loss =  155.789\n",
      "training :  3844  accuracy =   0.7300  loss =  154.58\n",
      "testing  :  3844  accuracy =   0.6962  loss =  155.832\n",
      "training :  3845  accuracy =   0.6800  loss =  156.226\n",
      "testing  :  3845  accuracy =   0.6963  loss =  155.821\n",
      "training :  3846  accuracy =   0.7000  loss =  154.33\n",
      "testing  :  3846  accuracy =   0.6963  loss =  155.811\n",
      "training :  3847  accuracy =   0.7700  loss =  154.873\n",
      "testing  :  3847  accuracy =   0.6966  loss =  155.805\n",
      "training :  3848  accuracy =   0.8000  loss =  152.714\n",
      "testing  :  3848  accuracy =   0.6975  loss =  155.744\n",
      "training :  3849  accuracy =   0.6600  loss =  154.732\n",
      "testing  :  3849  accuracy =   0.6969  loss =  155.66\n",
      "training :  3850  accuracy =   0.7000  loss =  155.343\n",
      "testing  :  3850  accuracy =   0.6965  loss =  155.593\n",
      "training :  3851  accuracy =   0.7100  loss =  155.496\n",
      "testing  :  3851  accuracy =   0.6969  loss =  155.54\n",
      "training :  3852  accuracy =   0.7600  loss =  153.604\n",
      "testing  :  3852  accuracy =   0.6975  loss =  155.5\n",
      "training :  3853  accuracy =   0.7700  loss =  153.705\n",
      "testing  :  3853  accuracy =   0.6965  loss =  155.468\n",
      "training :  3854  accuracy =   0.7800  loss =  152.695\n",
      "testing  :  3854  accuracy =   0.6964  loss =  155.42\n",
      "training :  3855  accuracy =   0.7300  loss =  153.834\n",
      "testing  :  3855  accuracy =   0.6963  loss =  155.401\n",
      "training :  3856  accuracy =   0.7400  loss =  152.594\n",
      "testing  :  3856  accuracy =   0.6969  loss =  155.393\n",
      "training :  3857  accuracy =   0.7100  loss =  155.421\n",
      "testing  :  3857  accuracy =   0.6968  loss =  155.394\n",
      "training :  3858  accuracy =   0.7600  loss =  154.653\n",
      "testing  :  3858  accuracy =   0.6967  loss =  155.401\n",
      "training :  3859  accuracy =   0.7000  loss =  154.901\n",
      "testing  :  3859  accuracy =   0.6962  loss =  155.416\n",
      "training :  3860  accuracy =   0.7200  loss =  155.941\n",
      "testing  :  3860  accuracy =   0.6964  loss =  155.433\n",
      "training :  3861  accuracy =   0.6400  loss =  157.346\n",
      "testing  :  3861  accuracy =   0.6968  loss =  155.42\n",
      "training :  3862  accuracy =   0.7300  loss =  155.079\n",
      "testing  :  3862  accuracy =   0.6970  loss =  155.372\n",
      "training :  3863  accuracy =   0.7300  loss =  153.903\n",
      "testing  :  3863  accuracy =   0.6973  loss =  155.347\n",
      "training :  3864  accuracy =   0.7500  loss =  152.603\n",
      "testing  :  3864  accuracy =   0.6970  loss =  155.347\n",
      "training :  3865  accuracy =   0.7600  loss =  153.287\n",
      "testing  :  3865  accuracy =   0.6968  loss =  155.354\n",
      "training :  3866  accuracy =   0.7200  loss =  153.368\n",
      "testing  :  3866  accuracy =   0.6969  loss =  155.363\n",
      "training :  3867  accuracy =   0.7100  loss =  154.645\n",
      "testing  :  3867  accuracy =   0.6967  loss =  155.369\n",
      "training :  3868  accuracy =   0.6600  loss =  154.311\n",
      "testing  :  3868  accuracy =   0.6971  loss =  155.388\n",
      "training :  3869  accuracy =   0.7700  loss =  153.44\n",
      "testing  :  3869  accuracy =   0.6971  loss =  155.414\n",
      "training :  3870  accuracy =   0.7900  loss =  153.639\n",
      "testing  :  3870  accuracy =   0.6969  loss =  155.436\n",
      "training :  3871  accuracy =   0.8100  loss =  152.105\n",
      "testing  :  3871  accuracy =   0.6971  loss =  155.451\n",
      "training :  3872  accuracy =   0.7000  loss =  154.316\n",
      "testing  :  3872  accuracy =   0.6968  loss =  155.475\n",
      "training :  3873  accuracy =   0.6700  loss =  153.409\n",
      "testing  :  3873  accuracy =   0.6973  loss =  155.493\n",
      "training :  3874  accuracy =   0.8000  loss =  154.052\n",
      "testing  :  3874  accuracy =   0.6980  loss =  155.523\n",
      "training :  3875  accuracy =   0.6700  loss =  156.521\n",
      "testing  :  3875  accuracy =   0.6975  loss =  155.529\n",
      "training :  3876  accuracy =   0.7500  loss =  153.47\n",
      "testing  :  3876  accuracy =   0.6982  loss =  155.54\n",
      "training :  3877  accuracy =   0.7400  loss =  151.992\n",
      "testing  :  3877  accuracy =   0.6976  loss =  155.567\n",
      "training :  3878  accuracy =   0.7300  loss =  153.663\n",
      "testing  :  3878  accuracy =   0.6973  loss =  155.583\n",
      "training :  3879  accuracy =   0.7100  loss =  156.971\n",
      "testing  :  3879  accuracy =   0.6982  loss =  155.575\n",
      "training :  3880  accuracy =   0.6600  loss =  155.807\n",
      "testing  :  3880  accuracy =   0.6980  loss =  155.544\n",
      "training :  3881  accuracy =   0.7800  loss =  153.848\n",
      "testing  :  3881  accuracy =   0.7001  loss =  155.489\n",
      "training :  3882  accuracy =   0.7400  loss =  152.687\n",
      "testing  :  3882  accuracy =   0.7024  loss =  155.468\n",
      "training :  3883  accuracy =   0.7500  loss =  152.563\n",
      "testing  :  3883  accuracy =   0.7123  loss =  155.479\n",
      "training :  3884  accuracy =   0.7600  loss =  154.386\n",
      "testing  :  3884  accuracy =   0.7272  loss =  155.5\n",
      "training :  3885  accuracy =   0.7800  loss =  153.274\n",
      "testing  :  3885  accuracy =   0.7486  loss =  155.535\n",
      "training :  3886  accuracy =   0.7800  loss =  157.022\n",
      "testing  :  3886  accuracy =   0.7574  loss =  155.583\n",
      "training :  3887  accuracy =   0.8100  loss =  154.744\n",
      "testing  :  3887  accuracy =   0.7660  loss =  155.631\n",
      "training :  3888  accuracy =   0.7700  loss =  155.973\n",
      "testing  :  3888  accuracy =   0.7592  loss =  155.665\n",
      "training :  3889  accuracy =   0.7700  loss =  153.246\n",
      "testing  :  3889  accuracy =   0.7600  loss =  155.683\n",
      "training :  3890  accuracy =   0.8000  loss =  156.38\n",
      "testing  :  3890  accuracy =   0.7599  loss =  155.689\n",
      "training :  3891  accuracy =   0.7100  loss =  154.447\n",
      "testing  :  3891  accuracy =   0.7567  loss =  155.667\n",
      "training :  3892  accuracy =   0.7200  loss =  156.279\n",
      "testing  :  3892  accuracy =   0.7530  loss =  155.62\n",
      "training :  3893  accuracy =   0.7400  loss =  154.87\n",
      "testing  :  3893  accuracy =   0.7505  loss =  155.595\n",
      "training :  3894  accuracy =   0.7900  loss =  153.153\n",
      "testing  :  3894  accuracy =   0.7468  loss =  155.575\n",
      "training :  3895  accuracy =   0.7100  loss =  154.868\n",
      "testing  :  3895  accuracy =   0.7390  loss =  155.582\n",
      "training :  3896  accuracy =   0.7400  loss =  152.953\n",
      "testing  :  3896  accuracy =   0.7332  loss =  155.576\n",
      "training :  3897  accuracy =   0.7000  loss =  155.735\n",
      "testing  :  3897  accuracy =   0.7279  loss =  155.581\n",
      "training :  3898  accuracy =   0.7700  loss =  153.209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  3898  accuracy =   0.7415  loss =  155.579\n",
      "training :  3899  accuracy =   0.8800  loss =  152.096\n",
      "testing  :  3899  accuracy =   0.7579  loss =  155.582\n",
      "training :  3900  accuracy =   0.7600  loss =  153.818\n",
      "testing  :  3900  accuracy =   0.7649  loss =  155.544\n",
      "training :  3901  accuracy =   0.7400  loss =  154.336\n",
      "testing  :  3901  accuracy =   0.7649  loss =  155.514\n",
      "training :  3902  accuracy =   0.7600  loss =  153.888\n",
      "testing  :  3902  accuracy =   0.7628  loss =  155.461\n",
      "training :  3903  accuracy =   0.6900  loss =  154.051\n",
      "testing  :  3903  accuracy =   0.7560  loss =  155.424\n",
      "training :  3904  accuracy =   0.7100  loss =  154.353\n",
      "testing  :  3904  accuracy =   0.7518  loss =  155.392\n",
      "training :  3905  accuracy =   0.8600  loss =  152.297\n",
      "testing  :  3905  accuracy =   0.7466  loss =  155.375\n",
      "training :  3906  accuracy =   0.7200  loss =  154.409\n",
      "testing  :  3906  accuracy =   0.7397  loss =  155.371\n",
      "training :  3907  accuracy =   0.7600  loss =  153.876\n",
      "testing  :  3907  accuracy =   0.7392  loss =  155.385\n",
      "training :  3908  accuracy =   0.7700  loss =  155.124\n",
      "testing  :  3908  accuracy =   0.7418  loss =  155.406\n",
      "training :  3909  accuracy =   0.6500  loss =  157.314\n",
      "testing  :  3909  accuracy =   0.7465  loss =  155.424\n",
      "training :  3910  accuracy =   0.7400  loss =  156.392\n",
      "testing  :  3910  accuracy =   0.7496  loss =  155.437\n",
      "training :  3911  accuracy =   0.7800  loss =  154.6\n",
      "testing  :  3911  accuracy =   0.7531  loss =  155.431\n",
      "training :  3912  accuracy =   0.7200  loss =  152.788\n",
      "testing  :  3912  accuracy =   0.7561  loss =  155.428\n",
      "training :  3913  accuracy =   0.7400  loss =  154.891\n",
      "testing  :  3913  accuracy =   0.7581  loss =  155.428\n",
      "training :  3914  accuracy =   0.8100  loss =  155.753\n",
      "testing  :  3914  accuracy =   0.7595  loss =  155.421\n",
      "training :  3915  accuracy =   0.7900  loss =  155.226\n",
      "testing  :  3915  accuracy =   0.7642  loss =  155.433\n",
      "training :  3916  accuracy =   0.7800  loss =  155.358\n",
      "testing  :  3916  accuracy =   0.7654  loss =  155.45\n",
      "training :  3917  accuracy =   0.7300  loss =  155.973\n",
      "testing  :  3917  accuracy =   0.7589  loss =  155.468\n",
      "training :  3918  accuracy =   0.6700  loss =  156.365\n",
      "testing  :  3918  accuracy =   0.7461  loss =  155.485\n",
      "training :  3919  accuracy =   0.6800  loss =  154.982\n",
      "testing  :  3919  accuracy =   0.7140  loss =  155.486\n",
      "training :  3920  accuracy =   0.7600  loss =  153.889\n",
      "testing  :  3920  accuracy =   0.7075  loss =  155.486\n",
      "training :  3921  accuracy =   0.7700  loss =  152.411\n",
      "testing  :  3921  accuracy =   0.7034  loss =  155.477\n",
      "training :  3922  accuracy =   0.7600  loss =  153.067\n",
      "testing  :  3922  accuracy =   0.7019  loss =  155.473\n",
      "training :  3923  accuracy =   0.7100  loss =  153.646\n",
      "testing  :  3923  accuracy =   0.7017  loss =  155.412\n",
      "training :  3924  accuracy =   0.7300  loss =  154.983\n",
      "testing  :  3924  accuracy =   0.7029  loss =  155.356\n",
      "training :  3925  accuracy =   0.7700  loss =  155.05\n",
      "testing  :  3925  accuracy =   0.7027  loss =  155.313\n",
      "training :  3926  accuracy =   0.7000  loss =  155.614\n",
      "testing  :  3926  accuracy =   0.7031  loss =  155.279\n",
      "training :  3927  accuracy =   0.7300  loss =  153.776\n",
      "testing  :  3927  accuracy =   0.7037  loss =  155.277\n",
      "training :  3928  accuracy =   0.6800  loss =  154.439\n",
      "testing  :  3928  accuracy =   0.7047  loss =  155.307\n",
      "training :  3929  accuracy =   0.6600  loss =  154.627\n",
      "testing  :  3929  accuracy =   0.7062  loss =  155.363\n",
      "training :  3930  accuracy =   0.7200  loss =  154.203\n",
      "testing  :  3930  accuracy =   0.7071  loss =  155.441\n",
      "training :  3931  accuracy =   0.7000  loss =  153.825\n",
      "testing  :  3931  accuracy =   0.7081  loss =  155.516\n",
      "training :  3932  accuracy =   0.7300  loss =  153.079\n",
      "testing  :  3932  accuracy =   0.7094  loss =  155.588\n",
      "training :  3933  accuracy =   0.6700  loss =  155.133\n",
      "testing  :  3933  accuracy =   0.7109  loss =  155.644\n",
      "training :  3934  accuracy =   0.7800  loss =  156.588\n",
      "testing  :  3934  accuracy =   0.7108  loss =  155.608\n",
      "training :  3935  accuracy =   0.7300  loss =  153.284\n",
      "testing  :  3935  accuracy =   0.7106  loss =  155.58\n",
      "training :  3936  accuracy =   0.6900  loss =  158.303\n",
      "testing  :  3936  accuracy =   0.7116  loss =  155.561\n",
      "training :  3937  accuracy =   0.7600  loss =  154.152\n",
      "testing  :  3937  accuracy =   0.7125  loss =  155.548\n",
      "training :  3938  accuracy =   0.7300  loss =  155.768\n",
      "testing  :  3938  accuracy =   0.7153  loss =  155.529\n",
      "training :  3939  accuracy =   0.7500  loss =  153.796\n",
      "testing  :  3939  accuracy =   0.7144  loss =  155.4\n",
      "training :  3940  accuracy =   0.6400  loss =  156.24\n",
      "testing  :  3940  accuracy =   0.7170  loss =  155.366\n",
      "training :  3941  accuracy =   0.6800  loss =  153.726\n",
      "testing  :  3941  accuracy =   0.7234  loss =  155.402\n",
      "training :  3942  accuracy =   0.7800  loss =  153.742\n",
      "testing  :  3942  accuracy =   0.7527  loss =  155.477\n",
      "training :  3943  accuracy =   0.7000  loss =  155.347\n",
      "testing  :  3943  accuracy =   0.7523  loss =  155.61\n",
      "training :  3944  accuracy =   0.7500  loss =  156.673\n",
      "testing  :  3944  accuracy =   0.7235  loss =  155.718\n",
      "training :  3945  accuracy =   0.6700  loss =  154.685\n",
      "testing  :  3945  accuracy =   0.7024  loss =  155.81\n",
      "training :  3946  accuracy =   0.7200  loss =  154.386\n",
      "testing  :  3946  accuracy =   0.6932  loss =  155.828\n",
      "training :  3947  accuracy =   0.7900  loss =  152.997\n",
      "testing  :  3947  accuracy =   0.6917  loss =  155.813\n",
      "training :  3948  accuracy =   0.6400  loss =  157.197\n",
      "testing  :  3948  accuracy =   0.6911  loss =  155.784\n",
      "training :  3949  accuracy =   0.7000  loss =  155.088\n",
      "testing  :  3949  accuracy =   0.6907  loss =  155.707\n",
      "training :  3950  accuracy =   0.7200  loss =  153.993\n",
      "testing  :  3950  accuracy =   0.6930  loss =  155.511\n",
      "training :  3951  accuracy =   0.7000  loss =  152.934\n",
      "testing  :  3951  accuracy =   0.6951  loss =  155.381\n",
      "training :  3952  accuracy =   0.6600  loss =  153.799\n",
      "testing  :  3952  accuracy =   0.6962  loss =  155.334\n",
      "training :  3953  accuracy =   0.7000  loss =  154.666\n",
      "testing  :  3953  accuracy =   0.6961  loss =  155.339\n",
      "training :  3954  accuracy =   0.6900  loss =  155.919\n",
      "testing  :  3954  accuracy =   0.6958  loss =  155.364\n",
      "training :  3955  accuracy =   0.6500  loss =  155.841\n",
      "testing  :  3955  accuracy =   0.6959  loss =  155.384\n",
      "training :  3956  accuracy =   0.7700  loss =  154.219\n",
      "testing  :  3956  accuracy =   0.6961  loss =  155.408\n",
      "training :  3957  accuracy =   0.8000  loss =  155.546\n",
      "testing  :  3957  accuracy =   0.6963  loss =  155.435\n",
      "training :  3958  accuracy =   0.7000  loss =  155.933\n",
      "testing  :  3958  accuracy =   0.6956  loss =  155.447\n",
      "training :  3959  accuracy =   0.7200  loss =  153.128\n",
      "testing  :  3959  accuracy =   0.6945  loss =  155.395\n",
      "training :  3960  accuracy =   0.7500  loss =  153.76\n",
      "testing  :  3960  accuracy =   0.6942  loss =  155.355\n",
      "training :  3961  accuracy =   0.7600  loss =  153.332\n",
      "testing  :  3961  accuracy =   0.6944  loss =  155.35\n",
      "training :  3962  accuracy =   0.7400  loss =  152.824\n",
      "testing  :  3962  accuracy =   0.6937  loss =  155.372\n",
      "training :  3963  accuracy =   0.7100  loss =  153.547\n",
      "testing  :  3963  accuracy =   0.6928  loss =  155.417\n",
      "training :  3964  accuracy =   0.7500  loss =  154.814\n",
      "testing  :  3964  accuracy =   0.6928  loss =  155.512\n",
      "training :  3965  accuracy =   0.6800  loss =  155.036\n",
      "testing  :  3965  accuracy =   0.6924  loss =  155.622\n",
      "training :  3966  accuracy =   0.6900  loss =  156.104\n",
      "testing  :  3966  accuracy =   0.6918  loss =  155.749\n",
      "training :  3967  accuracy =   0.6900  loss =  153.23\n",
      "testing  :  3967  accuracy =   0.6902  loss =  155.851\n",
      "training :  3968  accuracy =   0.7200  loss =  153.818\n",
      "testing  :  3968  accuracy =   0.6894  loss =  155.961\n",
      "training :  3969  accuracy =   0.7100  loss =  154.377\n",
      "testing  :  3969  accuracy =   0.6888  loss =  156.044\n",
      "training :  3970  accuracy =   0.6500  loss =  156.153\n",
      "testing  :  3970  accuracy =   0.6883  loss =  156.152\n",
      "training :  3971  accuracy =   0.7400  loss =  154.712\n",
      "testing  :  3971  accuracy =   0.6888  loss =  156.177\n",
      "training :  3972  accuracy =   0.7300  loss =  156.116\n",
      "testing  :  3972  accuracy =   0.6913  loss =  156.101\n",
      "training :  3973  accuracy =   0.7000  loss =  154.408\n",
      "testing  :  3973  accuracy =   0.6941  loss =  155.986\n",
      "training :  3974  accuracy =   0.6700  loss =  157.913\n",
      "testing  :  3974  accuracy =   0.6963  loss =  155.928\n",
      "training :  3975  accuracy =   0.7600  loss =  153.776\n",
      "testing  :  3975  accuracy =   0.6992  loss =  155.943\n",
      "training :  3976  accuracy =   0.7100  loss =  155.116\n",
      "testing  :  3976  accuracy =   0.7039  loss =  155.948\n",
      "training :  3977  accuracy =   0.7400  loss =  154.223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  3977  accuracy =   0.7082  loss =  155.96\n",
      "training :  3978  accuracy =   0.7700  loss =  154.392\n",
      "testing  :  3978  accuracy =   0.7141  loss =  155.96\n",
      "training :  3979  accuracy =   0.6800  loss =  155.683\n",
      "testing  :  3979  accuracy =   0.7198  loss =  155.946\n",
      "training :  3980  accuracy =   0.7500  loss =  153.786\n",
      "testing  :  3980  accuracy =   0.7220  loss =  155.86\n",
      "training :  3981  accuracy =   0.8100  loss =  155.422\n",
      "testing  :  3981  accuracy =   0.7201  loss =  155.771\n",
      "training :  3982  accuracy =   0.7400  loss =  154.821\n",
      "testing  :  3982  accuracy =   0.7218  loss =  155.69\n",
      "training :  3983  accuracy =   0.8800  loss =  152.333\n",
      "testing  :  3983  accuracy =   0.7215  loss =  155.609\n",
      "training :  3984  accuracy =   0.7000  loss =  155.321\n",
      "testing  :  3984  accuracy =   0.7217  loss =  155.539\n",
      "training :  3985  accuracy =   0.7000  loss =  153.794\n",
      "testing  :  3985  accuracy =   0.7127  loss =  155.509\n",
      "training :  3986  accuracy =   0.6500  loss =  156.359\n",
      "testing  :  3986  accuracy =   0.6987  loss =  155.494\n",
      "training :  3987  accuracy =   0.6600  loss =  156.532\n",
      "testing  :  3987  accuracy =   0.6967  loss =  155.487\n",
      "training :  3988  accuracy =   0.6900  loss =  152.849\n",
      "testing  :  3988  accuracy =   0.6949  loss =  155.493\n",
      "training :  3989  accuracy =   0.7900  loss =  152.361\n",
      "testing  :  3989  accuracy =   0.6941  loss =  155.504\n",
      "training :  3990  accuracy =   0.7200  loss =  156.852\n",
      "testing  :  3990  accuracy =   0.6922  loss =  155.515\n",
      "training :  3991  accuracy =   0.7100  loss =  155.346\n",
      "testing  :  3991  accuracy =   0.6925  loss =  155.507\n",
      "training :  3992  accuracy =   0.7300  loss =  154.519\n",
      "testing  :  3992  accuracy =   0.6933  loss =  155.488\n",
      "training :  3993  accuracy =   0.6900  loss =  154.424\n",
      "testing  :  3993  accuracy =   0.6936  loss =  155.478\n",
      "training :  3994  accuracy =   0.7400  loss =  152.848\n",
      "testing  :  3994  accuracy =   0.6940  loss =  155.476\n",
      "training :  3995  accuracy =   0.7100  loss =  156.696\n",
      "testing  :  3995  accuracy =   0.6942  loss =  155.474\n",
      "training :  3996  accuracy =   0.6500  loss =  154.877\n",
      "testing  :  3996  accuracy =   0.6942  loss =  155.46\n",
      "training :  3997  accuracy =   0.6900  loss =  154.607\n",
      "testing  :  3997  accuracy =   0.6946  loss =  155.427\n",
      "training :  3998  accuracy =   0.6900  loss =  156.161\n",
      "testing  :  3998  accuracy =   0.6949  loss =  155.4\n",
      "training :  3999  accuracy =   0.7300  loss =  156.695\n",
      "testing  :  3999  accuracy =   0.6948  loss =  155.388\n",
      "training :  4000  accuracy =   0.7200  loss =  153.565\n",
      "testing  :  4000  accuracy =   0.6943  loss =  155.38\n",
      "training :  4001  accuracy =   0.6800  loss =  154.438\n",
      "testing  :  4001  accuracy =   0.6946  loss =  155.376\n",
      "training :  4002  accuracy =   0.7300  loss =  152.584\n",
      "testing  :  4002  accuracy =   0.6946  loss =  155.351\n",
      "training :  4003  accuracy =   0.7600  loss =  152.773\n",
      "testing  :  4003  accuracy =   0.6952  loss =  155.327\n",
      "training :  4004  accuracy =   0.7000  loss =  156.514\n",
      "testing  :  4004  accuracy =   0.6955  loss =  155.308\n",
      "training :  4005  accuracy =   0.6900  loss =  151.832\n",
      "testing  :  4005  accuracy =   0.6965  loss =  155.293\n",
      "training :  4006  accuracy =   0.7000  loss =  153.332\n",
      "testing  :  4006  accuracy =   0.6967  loss =  155.295\n",
      "training :  4007  accuracy =   0.6900  loss =  155.451\n",
      "testing  :  4007  accuracy =   0.6974  loss =  155.304\n",
      "training :  4008  accuracy =   0.7600  loss =  152.403\n",
      "testing  :  4008  accuracy =   0.6972  loss =  155.295\n",
      "training :  4009  accuracy =   0.7200  loss =  152.551\n",
      "testing  :  4009  accuracy =   0.6972  loss =  155.297\n",
      "training :  4010  accuracy =   0.7000  loss =  154.627\n",
      "testing  :  4010  accuracy =   0.6971  loss =  155.309\n",
      "training :  4011  accuracy =   0.6900  loss =  153.671\n",
      "testing  :  4011  accuracy =   0.6969  loss =  155.322\n",
      "training :  4012  accuracy =   0.7700  loss =  155.522\n",
      "testing  :  4012  accuracy =   0.6974  loss =  155.346\n",
      "training :  4013  accuracy =   0.7200  loss =  152.635\n",
      "testing  :  4013  accuracy =   0.6970  loss =  155.368\n",
      "training :  4014  accuracy =   0.7500  loss =  153.432\n",
      "testing  :  4014  accuracy =   0.6967  loss =  155.393\n",
      "training :  4015  accuracy =   0.6700  loss =  154.763\n",
      "testing  :  4015  accuracy =   0.6967  loss =  155.419\n",
      "training :  4016  accuracy =   0.6700  loss =  154.267\n",
      "testing  :  4016  accuracy =   0.6968  loss =  155.439\n",
      "training :  4017  accuracy =   0.6900  loss =  153.995\n",
      "testing  :  4017  accuracy =   0.6957  loss =  155.463\n",
      "training :  4018  accuracy =   0.6800  loss =  154.914\n",
      "testing  :  4018  accuracy =   0.6945  loss =  155.498\n",
      "training :  4019  accuracy =   0.7100  loss =  152.822\n",
      "testing  :  4019  accuracy =   0.6936  loss =  155.534\n",
      "training :  4020  accuracy =   0.7000  loss =  157.354\n",
      "testing  :  4020  accuracy =   0.6929  loss =  155.571\n",
      "training :  4021  accuracy =   0.6600  loss =  155.767\n",
      "testing  :  4021  accuracy =   0.6920  loss =  155.612\n",
      "training :  4022  accuracy =   0.6400  loss =  154.304\n",
      "testing  :  4022  accuracy =   0.6911  loss =  155.629\n",
      "training :  4023  accuracy =   0.7100  loss =  153.972\n",
      "testing  :  4023  accuracy =   0.6914  loss =  155.622\n",
      "training :  4024  accuracy =   0.7600  loss =  153.663\n",
      "testing  :  4024  accuracy =   0.6907  loss =  155.61\n",
      "training :  4025  accuracy =   0.6100  loss =  156.518\n",
      "testing  :  4025  accuracy =   0.6909  loss =  155.562\n",
      "training :  4026  accuracy =   0.6900  loss =  154.862\n",
      "testing  :  4026  accuracy =   0.6912  loss =  155.538\n",
      "training :  4027  accuracy =   0.6200  loss =  154.237\n",
      "testing  :  4027  accuracy =   0.6904  loss =  155.52\n",
      "training :  4028  accuracy =   0.6300  loss =  159.216\n",
      "testing  :  4028  accuracy =   0.6899  loss =  155.51\n",
      "training :  4029  accuracy =   0.6600  loss =  153.66\n",
      "testing  :  4029  accuracy =   0.6892  loss =  155.521\n",
      "training :  4030  accuracy =   0.7300  loss =  152.962\n",
      "testing  :  4030  accuracy =   0.6893  loss =  155.543\n",
      "training :  4031  accuracy =   0.6800  loss =  155.169\n",
      "testing  :  4031  accuracy =   0.6899  loss =  155.559\n",
      "training :  4032  accuracy =   0.6800  loss =  155.271\n",
      "testing  :  4032  accuracy =   0.6897  loss =  155.521\n",
      "training :  4033  accuracy =   0.6600  loss =  153.926\n",
      "testing  :  4033  accuracy =   0.6899  loss =  155.475\n",
      "training :  4034  accuracy =   0.6600  loss =  153.01\n",
      "testing  :  4034  accuracy =   0.6903  loss =  155.445\n",
      "training :  4035  accuracy =   0.7200  loss =  154.466\n",
      "testing  :  4035  accuracy =   0.6911  loss =  155.43\n",
      "training :  4036  accuracy =   0.7400  loss =  154.919\n",
      "testing  :  4036  accuracy =   0.6912  loss =  155.406\n",
      "training :  4037  accuracy =   0.6900  loss =  155.853\n",
      "testing  :  4037  accuracy =   0.6913  loss =  155.396\n",
      "training :  4038  accuracy =   0.6900  loss =  154.483\n",
      "testing  :  4038  accuracy =   0.6920  loss =  155.401\n",
      "training :  4039  accuracy =   0.6900  loss =  155.34\n",
      "testing  :  4039  accuracy =   0.6921  loss =  155.424\n",
      "training :  4040  accuracy =   0.7100  loss =  153.723\n",
      "testing  :  4040  accuracy =   0.6918  loss =  155.446\n",
      "training :  4041  accuracy =   0.7400  loss =  154.554\n",
      "testing  :  4041  accuracy =   0.6918  loss =  155.468\n",
      "training :  4042  accuracy =   0.7100  loss =  154.011\n",
      "testing  :  4042  accuracy =   0.6918  loss =  155.505\n",
      "training :  4043  accuracy =   0.7400  loss =  154.151\n",
      "testing  :  4043  accuracy =   0.6913  loss =  155.541\n",
      "training :  4044  accuracy =   0.6800  loss =  155.202\n",
      "testing  :  4044  accuracy =   0.6913  loss =  155.542\n",
      "training :  4045  accuracy =   0.7100  loss =  153.471\n",
      "testing  :  4045  accuracy =   0.6912  loss =  155.545\n",
      "training :  4046  accuracy =   0.7000  loss =  153.589\n",
      "testing  :  4046  accuracy =   0.6909  loss =  155.549\n",
      "training :  4047  accuracy =   0.6900  loss =  155.676\n",
      "testing  :  4047  accuracy =   0.6907  loss =  155.559\n",
      "training :  4048  accuracy =   0.7100  loss =  156.674\n",
      "testing  :  4048  accuracy =   0.6907  loss =  155.572\n",
      "training :  4049  accuracy =   0.7400  loss =  155.295\n",
      "testing  :  4049  accuracy =   0.6906  loss =  155.583\n",
      "training :  4050  accuracy =   0.7300  loss =  152.078\n",
      "testing  :  4050  accuracy =   0.6906  loss =  155.541\n",
      "training :  4051  accuracy =   0.6900  loss =  156.109\n",
      "testing  :  4051  accuracy =   0.6907  loss =  155.517\n",
      "training :  4052  accuracy =   0.6000  loss =  157.168\n",
      "testing  :  4052  accuracy =   0.6905  loss =  155.493\n",
      "training :  4053  accuracy =   0.6600  loss =  154.031\n",
      "testing  :  4053  accuracy =   0.6913  loss =  155.48\n",
      "training :  4054  accuracy =   0.7200  loss =  154.303\n",
      "testing  :  4054  accuracy =   0.6905  loss =  155.501\n",
      "training :  4055  accuracy =   0.6700  loss =  154.448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4055  accuracy =   0.6900  loss =  155.531\n",
      "training :  4056  accuracy =   0.7400  loss =  155.269\n",
      "testing  :  4056  accuracy =   0.6903  loss =  155.548\n",
      "training :  4057  accuracy =   0.6300  loss =  156.332\n",
      "testing  :  4057  accuracy =   0.6906  loss =  155.573\n",
      "training :  4058  accuracy =   0.7100  loss =  153.556\n",
      "testing  :  4058  accuracy =   0.6900  loss =  155.61\n",
      "training :  4059  accuracy =   0.6800  loss =  157.37\n",
      "testing  :  4059  accuracy =   0.6886  loss =  155.645\n",
      "training :  4060  accuracy =   0.7100  loss =  153.573\n",
      "testing  :  4060  accuracy =   0.6891  loss =  155.695\n",
      "training :  4061  accuracy =   0.6600  loss =  154.679\n",
      "testing  :  4061  accuracy =   0.6896  loss =  155.747\n",
      "training :  4062  accuracy =   0.6700  loss =  156.404\n",
      "testing  :  4062  accuracy =   0.6894  loss =  155.792\n",
      "training :  4063  accuracy =   0.7100  loss =  154.994\n",
      "testing  :  4063  accuracy =   0.6885  loss =  155.866\n",
      "training :  4064  accuracy =   0.6400  loss =  156.95\n",
      "testing  :  4064  accuracy =   0.6881  loss =  155.941\n",
      "training :  4065  accuracy =   0.6900  loss =  156.699\n",
      "testing  :  4065  accuracy =   0.6894  loss =  155.882\n",
      "training :  4066  accuracy =   0.6700  loss =  153.746\n",
      "testing  :  4066  accuracy =   0.6895  loss =  155.782\n",
      "training :  4067  accuracy =   0.7200  loss =  153.408\n",
      "testing  :  4067  accuracy =   0.6901  loss =  155.717\n",
      "training :  4068  accuracy =   0.7500  loss =  154.432\n",
      "testing  :  4068  accuracy =   0.6904  loss =  155.657\n",
      "training :  4069  accuracy =   0.7000  loss =  160.114\n",
      "testing  :  4069  accuracy =   0.6906  loss =  155.611\n",
      "training :  4070  accuracy =   0.6900  loss =  157.341\n",
      "testing  :  4070  accuracy =   0.6904  loss =  155.512\n",
      "training :  4071  accuracy =   0.7300  loss =  156.073\n",
      "testing  :  4071  accuracy =   0.6917  loss =  155.406\n",
      "training :  4072  accuracy =   0.7000  loss =  156.97\n",
      "testing  :  4072  accuracy =   0.6919  loss =  155.354\n",
      "training :  4073  accuracy =   0.6200  loss =  158.757\n",
      "testing  :  4073  accuracy =   0.6927  loss =  155.34\n",
      "training :  4074  accuracy =   0.6500  loss =  153.706\n",
      "testing  :  4074  accuracy =   0.6924  loss =  155.359\n",
      "training :  4075  accuracy =   0.6900  loss =  153.172\n",
      "testing  :  4075  accuracy =   0.6917  loss =  155.397\n",
      "training :  4076  accuracy =   0.6400  loss =  156.239\n",
      "testing  :  4076  accuracy =   0.6904  loss =  155.452\n",
      "training :  4077  accuracy =   0.6800  loss =  154.598\n",
      "testing  :  4077  accuracy =   0.6894  loss =  155.551\n",
      "training :  4078  accuracy =   0.7000  loss =  153.819\n",
      "testing  :  4078  accuracy =   0.6881  loss =  155.694\n",
      "training :  4079  accuracy =   0.7000  loss =  156.718\n",
      "testing  :  4079  accuracy =   0.6859  loss =  155.901\n",
      "training :  4080  accuracy =   0.6900  loss =  157.545\n",
      "testing  :  4080  accuracy =   0.6846  loss =  156.1\n",
      "training :  4081  accuracy =   0.7500  loss =  155.862\n",
      "testing  :  4081  accuracy =   0.6838  loss =  156.159\n",
      "training :  4082  accuracy =   0.7100  loss =  153.218\n",
      "testing  :  4082  accuracy =   0.6841  loss =  156.121\n",
      "training :  4083  accuracy =   0.6400  loss =  157.271\n",
      "testing  :  4083  accuracy =   0.6852  loss =  156.034\n",
      "training :  4084  accuracy =   0.6900  loss =  156.188\n",
      "testing  :  4084  accuracy =   0.6859  loss =  155.943\n",
      "training :  4085  accuracy =   0.6400  loss =  156.624\n",
      "testing  :  4085  accuracy =   0.6867  loss =  155.837\n",
      "training :  4086  accuracy =   0.7300  loss =  152.926\n",
      "testing  :  4086  accuracy =   0.6889  loss =  155.68\n",
      "training :  4087  accuracy =   0.7200  loss =  153.702\n",
      "testing  :  4087  accuracy =   0.6900  loss =  155.586\n",
      "training :  4088  accuracy =   0.7200  loss =  154.557\n",
      "testing  :  4088  accuracy =   0.6902  loss =  155.51\n",
      "training :  4089  accuracy =   0.7100  loss =  153.283\n",
      "testing  :  4089  accuracy =   0.6904  loss =  155.455\n",
      "training :  4090  accuracy =   0.6900  loss =  154.986\n",
      "testing  :  4090  accuracy =   0.6905  loss =  155.434\n",
      "training :  4091  accuracy =   0.6000  loss =  156.971\n",
      "testing  :  4091  accuracy =   0.6916  loss =  155.432\n",
      "training :  4092  accuracy =   0.6900  loss =  157.409\n",
      "testing  :  4092  accuracy =   0.6919  loss =  155.474\n",
      "training :  4093  accuracy =   0.6800  loss =  156.322\n",
      "testing  :  4093  accuracy =   0.6912  loss =  155.503\n",
      "training :  4094  accuracy =   0.7000  loss =  154.726\n",
      "testing  :  4094  accuracy =   0.6903  loss =  155.51\n",
      "training :  4095  accuracy =   0.6600  loss =  154.622\n",
      "testing  :  4095  accuracy =   0.6898  loss =  155.518\n",
      "training :  4096  accuracy =   0.7500  loss =  154.729\n",
      "testing  :  4096  accuracy =   0.6895  loss =  155.554\n",
      "training :  4097  accuracy =   0.6500  loss =  155.285\n",
      "testing  :  4097  accuracy =   0.6894  loss =  155.6\n",
      "training :  4098  accuracy =   0.6400  loss =  157.323\n",
      "testing  :  4098  accuracy =   0.6900  loss =  155.65\n",
      "training :  4099  accuracy =   0.6300  loss =  156.5\n",
      "testing  :  4099  accuracy =   0.6901  loss =  155.58\n",
      "training :  4100  accuracy =   0.6600  loss =  154.978\n",
      "testing  :  4100  accuracy =   0.6906  loss =  155.462\n",
      "training :  4101  accuracy =   0.7300  loss =  155.146\n",
      "testing  :  4101  accuracy =   0.6916  loss =  155.369\n",
      "training :  4102  accuracy =   0.6900  loss =  155.011\n",
      "testing  :  4102  accuracy =   0.6914  loss =  155.346\n",
      "training :  4103  accuracy =   0.6700  loss =  157.086\n",
      "testing  :  4103  accuracy =   0.6908  loss =  155.379\n",
      "training :  4104  accuracy =   0.7300  loss =  154.085\n",
      "testing  :  4104  accuracy =   0.6909  loss =  155.446\n",
      "training :  4105  accuracy =   0.7100  loss =  154.175\n",
      "testing  :  4105  accuracy =   0.6908  loss =  155.555\n",
      "training :  4106  accuracy =   0.7400  loss =  154.518\n",
      "testing  :  4106  accuracy =   0.6896  loss =  155.688\n",
      "training :  4107  accuracy =   0.6600  loss =  155.17\n",
      "testing  :  4107  accuracy =   0.6873  loss =  155.822\n",
      "training :  4108  accuracy =   0.6700  loss =  158.2\n",
      "testing  :  4108  accuracy =   0.6865  loss =  155.972\n",
      "training :  4109  accuracy =   0.6300  loss =  154.89\n",
      "testing  :  4109  accuracy =   0.6870  loss =  155.916\n",
      "training :  4110  accuracy =   0.7300  loss =  154.458\n",
      "testing  :  4110  accuracy =   0.6880  loss =  155.826\n",
      "training :  4111  accuracy =   0.6400  loss =  156.191\n",
      "testing  :  4111  accuracy =   0.6886  loss =  155.696\n",
      "training :  4112  accuracy =   0.6800  loss =  154.748\n",
      "testing  :  4112  accuracy =   0.6900  loss =  155.577\n",
      "training :  4113  accuracy =   0.7200  loss =  155.911\n",
      "testing  :  4113  accuracy =   0.6903  loss =  155.442\n",
      "training :  4114  accuracy =   0.6600  loss =  155.586\n",
      "testing  :  4114  accuracy =   0.6905  loss =  155.368\n",
      "training :  4115  accuracy =   0.7300  loss =  152.681\n",
      "testing  :  4115  accuracy =   0.6915  loss =  155.351\n",
      "training :  4116  accuracy =   0.6800  loss =  154.787\n",
      "testing  :  4116  accuracy =   0.6908  loss =  155.386\n",
      "training :  4117  accuracy =   0.6500  loss =  157.974\n",
      "testing  :  4117  accuracy =   0.6903  loss =  155.441\n",
      "training :  4118  accuracy =   0.7900  loss =  153.843\n",
      "testing  :  4118  accuracy =   0.6900  loss =  155.477\n",
      "training :  4119  accuracy =   0.7000  loss =  154.749\n",
      "testing  :  4119  accuracy =   0.6903  loss =  155.477\n",
      "training :  4120  accuracy =   0.7000  loss =  154.994\n",
      "testing  :  4120  accuracy =   0.6904  loss =  155.494\n",
      "training :  4121  accuracy =   0.7300  loss =  155.445\n",
      "testing  :  4121  accuracy =   0.6903  loss =  155.514\n",
      "training :  4122  accuracy =   0.7200  loss =  155.697\n",
      "testing  :  4122  accuracy =   0.6904  loss =  155.525\n",
      "training :  4123  accuracy =   0.6600  loss =  154.21\n",
      "testing  :  4123  accuracy =   0.6898  loss =  155.534\n",
      "training :  4124  accuracy =   0.8000  loss =  152.123\n",
      "testing  :  4124  accuracy =   0.6906  loss =  155.526\n",
      "training :  4125  accuracy =   0.6900  loss =  158.831\n",
      "testing  :  4125  accuracy =   0.6910  loss =  155.52\n",
      "training :  4126  accuracy =   0.6700  loss =  155.493\n",
      "testing  :  4126  accuracy =   0.6916  loss =  155.532\n",
      "training :  4127  accuracy =   0.6300  loss =  154.496\n",
      "testing  :  4127  accuracy =   0.6908  loss =  155.547\n",
      "training :  4128  accuracy =   0.7400  loss =  153.458\n",
      "testing  :  4128  accuracy =   0.6911  loss =  155.548\n",
      "training :  4129  accuracy =   0.6700  loss =  157.186\n",
      "testing  :  4129  accuracy =   0.6913  loss =  155.528\n",
      "training :  4130  accuracy =   0.7200  loss =  154.476\n",
      "testing  :  4130  accuracy =   0.6920  loss =  155.486\n",
      "training :  4131  accuracy =   0.6100  loss =  155.307\n",
      "testing  :  4131  accuracy =   0.6915  loss =  155.446\n",
      "training :  4132  accuracy =   0.7900  loss =  154.513\n",
      "testing  :  4132  accuracy =   0.6911  loss =  155.42\n",
      "training :  4133  accuracy =   0.7200  loss =  155.094\n",
      "testing  :  4133  accuracy =   0.6904  loss =  155.42\n",
      "training :  4134  accuracy =   0.7000  loss =  155.074\n",
      "testing  :  4134  accuracy =   0.6905  loss =  155.438\n",
      "training :  4135  accuracy =   0.7300  loss =  152.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4135  accuracy =   0.6897  loss =  155.463\n",
      "training :  4136  accuracy =   0.7000  loss =  154.401\n",
      "testing  :  4136  accuracy =   0.6895  loss =  155.522\n",
      "training :  4137  accuracy =   0.6800  loss =  154.74\n",
      "testing  :  4137  accuracy =   0.6888  loss =  155.579\n",
      "training :  4138  accuracy =   0.6700  loss =  156.26\n",
      "testing  :  4138  accuracy =   0.6880  loss =  155.651\n",
      "training :  4139  accuracy =   0.6800  loss =  153.813\n",
      "testing  :  4139  accuracy =   0.6874  loss =  155.685\n",
      "training :  4140  accuracy =   0.6800  loss =  155.852\n",
      "testing  :  4140  accuracy =   0.6874  loss =  155.729\n",
      "training :  4141  accuracy =   0.7000  loss =  153.729\n",
      "testing  :  4141  accuracy =   0.6865  loss =  155.763\n",
      "training :  4142  accuracy =   0.6800  loss =  156.27\n",
      "testing  :  4142  accuracy =   0.6878  loss =  155.71\n",
      "training :  4143  accuracy =   0.6100  loss =  158.403\n",
      "testing  :  4143  accuracy =   0.6883  loss =  155.677\n",
      "training :  4144  accuracy =   0.8100  loss =  153.076\n",
      "testing  :  4144  accuracy =   0.6894  loss =  155.639\n",
      "training :  4145  accuracy =   0.7200  loss =  153.939\n",
      "testing  :  4145  accuracy =   0.6901  loss =  155.597\n",
      "training :  4146  accuracy =   0.7100  loss =  153.887\n",
      "testing  :  4146  accuracy =   0.6896  loss =  155.577\n",
      "training :  4147  accuracy =   0.7400  loss =  153.454\n",
      "testing  :  4147  accuracy =   0.6897  loss =  155.577\n",
      "training :  4148  accuracy =   0.6800  loss =  154.902\n",
      "testing  :  4148  accuracy =   0.6896  loss =  155.58\n",
      "training :  4149  accuracy =   0.7500  loss =  152.613\n",
      "testing  :  4149  accuracy =   0.6901  loss =  155.598\n",
      "training :  4150  accuracy =   0.6900  loss =  154.431\n",
      "testing  :  4150  accuracy =   0.6903  loss =  155.612\n",
      "training :  4151  accuracy =   0.7400  loss =  152.847\n",
      "testing  :  4151  accuracy =   0.6898  loss =  155.615\n",
      "training :  4152  accuracy =   0.7200  loss =  153.572\n",
      "testing  :  4152  accuracy =   0.6899  loss =  155.629\n",
      "training :  4153  accuracy =   0.6000  loss =  157.522\n",
      "testing  :  4153  accuracy =   0.6905  loss =  155.633\n",
      "training :  4154  accuracy =   0.7100  loss =  153.048\n",
      "testing  :  4154  accuracy =   0.6904  loss =  155.627\n",
      "training :  4155  accuracy =   0.7700  loss =  153.47\n",
      "testing  :  4155  accuracy =   0.6904  loss =  155.63\n",
      "training :  4156  accuracy =   0.8000  loss =  153.143\n",
      "testing  :  4156  accuracy =   0.6908  loss =  155.637\n",
      "training :  4157  accuracy =   0.6900  loss =  154.318\n",
      "testing  :  4157  accuracy =   0.6912  loss =  155.64\n",
      "training :  4158  accuracy =   0.7200  loss =  155.502\n",
      "testing  :  4158  accuracy =   0.6916  loss =  155.651\n",
      "training :  4159  accuracy =   0.6700  loss =  155.398\n",
      "testing  :  4159  accuracy =   0.6920  loss =  155.606\n",
      "training :  4160  accuracy =   0.7300  loss =  155.708\n",
      "testing  :  4160  accuracy =   0.6919  loss =  155.545\n",
      "training :  4161  accuracy =   0.7700  loss =  153.183\n",
      "testing  :  4161  accuracy =   0.6923  loss =  155.482\n",
      "training :  4162  accuracy =   0.7500  loss =  153.965\n",
      "testing  :  4162  accuracy =   0.6927  loss =  155.434\n",
      "training :  4163  accuracy =   0.6900  loss =  156.523\n",
      "testing  :  4163  accuracy =   0.6929  loss =  155.397\n",
      "training :  4164  accuracy =   0.7100  loss =  152.515\n",
      "testing  :  4164  accuracy =   0.6924  loss =  155.368\n",
      "training :  4165  accuracy =   0.7300  loss =  153.916\n",
      "testing  :  4165  accuracy =   0.6924  loss =  155.357\n",
      "training :  4166  accuracy =   0.6900  loss =  154.23\n",
      "testing  :  4166  accuracy =   0.6913  loss =  155.344\n",
      "training :  4167  accuracy =   0.7800  loss =  156.225\n",
      "testing  :  4167  accuracy =   0.6909  loss =  155.351\n",
      "training :  4168  accuracy =   0.7200  loss =  154.475\n",
      "testing  :  4168  accuracy =   0.6909  loss =  155.4\n",
      "training :  4169  accuracy =   0.6900  loss =  157.062\n",
      "testing  :  4169  accuracy =   0.6915  loss =  155.455\n",
      "training :  4170  accuracy =   0.6400  loss =  155.281\n",
      "testing  :  4170  accuracy =   0.6917  loss =  155.52\n",
      "training :  4171  accuracy =   0.7400  loss =  153.564\n",
      "testing  :  4171  accuracy =   0.6921  loss =  155.586\n",
      "training :  4172  accuracy =   0.6400  loss =  155.235\n",
      "testing  :  4172  accuracy =   0.6918  loss =  155.65\n",
      "training :  4173  accuracy =   0.6200  loss =  154.712\n",
      "testing  :  4173  accuracy =   0.6917  loss =  155.721\n",
      "training :  4174  accuracy =   0.7400  loss =  155.015\n",
      "testing  :  4174  accuracy =   0.6913  loss =  155.814\n",
      "training :  4175  accuracy =   0.6700  loss =  158.8\n",
      "testing  :  4175  accuracy =   0.6909  loss =  155.923\n",
      "training :  4176  accuracy =   0.6600  loss =  157.644\n",
      "testing  :  4176  accuracy =   0.6912  loss =  156.028\n",
      "training :  4177  accuracy =   0.7100  loss =  155.314\n",
      "testing  :  4177  accuracy =   0.6910  loss =  156.066\n",
      "training :  4178  accuracy =   0.7500  loss =  154.147\n",
      "testing  :  4178  accuracy =   0.6902  loss =  156.088\n",
      "training :  4179  accuracy =   0.7700  loss =  152.992\n",
      "testing  :  4179  accuracy =   0.6901  loss =  156.084\n",
      "training :  4180  accuracy =   0.6300  loss =  155.492\n",
      "testing  :  4180  accuracy =   0.6906  loss =  156.024\n",
      "training :  4181  accuracy =   0.6500  loss =  154.822\n",
      "testing  :  4181  accuracy =   0.6911  loss =  155.968\n",
      "training :  4182  accuracy =   0.7600  loss =  153.492\n",
      "testing  :  4182  accuracy =   0.6919  loss =  155.878\n",
      "training :  4183  accuracy =   0.6500  loss =  154.352\n",
      "testing  :  4183  accuracy =   0.6922  loss =  155.811\n",
      "training :  4184  accuracy =   0.6800  loss =  157.433\n",
      "testing  :  4184  accuracy =   0.6923  loss =  155.754\n",
      "training :  4185  accuracy =   0.7900  loss =  152.745\n",
      "testing  :  4185  accuracy =   0.6928  loss =  155.702\n",
      "training :  4186  accuracy =   0.6500  loss =  158.783\n",
      "testing  :  4186  accuracy =   0.6937  loss =  155.632\n",
      "training :  4187  accuracy =   0.6700  loss =  155.449\n",
      "testing  :  4187  accuracy =   0.6937  loss =  155.581\n",
      "training :  4188  accuracy =   0.7400  loss =  156.27\n",
      "testing  :  4188  accuracy =   0.6944  loss =  155.551\n",
      "training :  4189  accuracy =   0.7500  loss =  153.898\n",
      "testing  :  4189  accuracy =   0.6940  loss =  155.537\n",
      "training :  4190  accuracy =   0.7100  loss =  153.602\n",
      "testing  :  4190  accuracy =   0.6941  loss =  155.534\n",
      "training :  4191  accuracy =   0.8000  loss =  152.905\n",
      "testing  :  4191  accuracy =   0.6944  loss =  155.538\n",
      "training :  4192  accuracy =   0.7600  loss =  155.133\n",
      "testing  :  4192  accuracy =   0.6939  loss =  155.546\n",
      "training :  4193  accuracy =   0.7600  loss =  154.575\n",
      "testing  :  4193  accuracy =   0.6937  loss =  155.556\n",
      "training :  4194  accuracy =   0.6900  loss =  153.791\n",
      "testing  :  4194  accuracy =   0.6933  loss =  155.566\n",
      "training :  4195  accuracy =   0.7400  loss =  154.149\n",
      "testing  :  4195  accuracy =   0.6927  loss =  155.58\n",
      "training :  4196  accuracy =   0.7500  loss =  154.0\n",
      "testing  :  4196  accuracy =   0.6932  loss =  155.591\n",
      "training :  4197  accuracy =   0.6500  loss =  153.96\n",
      "testing  :  4197  accuracy =   0.6930  loss =  155.591\n",
      "training :  4198  accuracy =   0.5900  loss =  156.484\n",
      "testing  :  4198  accuracy =   0.6927  loss =  155.583\n",
      "training :  4199  accuracy =   0.7200  loss =  153.166\n",
      "testing  :  4199  accuracy =   0.6928  loss =  155.576\n",
      "training :  4200  accuracy =   0.6500  loss =  154.527\n",
      "testing  :  4200  accuracy =   0.6925  loss =  155.571\n",
      "training :  4201  accuracy =   0.7000  loss =  153.34\n",
      "testing  :  4201  accuracy =   0.6919  loss =  155.568\n",
      "training :  4202  accuracy =   0.7100  loss =  155.776\n",
      "testing  :  4202  accuracy =   0.6918  loss =  155.572\n",
      "training :  4203  accuracy =   0.7300  loss =  154.792\n",
      "testing  :  4203  accuracy =   0.6916  loss =  155.585\n",
      "training :  4204  accuracy =   0.7100  loss =  154.019\n",
      "testing  :  4204  accuracy =   0.6918  loss =  155.596\n",
      "training :  4205  accuracy =   0.7500  loss =  154.401\n",
      "testing  :  4205  accuracy =   0.6918  loss =  155.594\n",
      "training :  4206  accuracy =   0.6900  loss =  155.753\n",
      "testing  :  4206  accuracy =   0.6916  loss =  155.577\n",
      "training :  4207  accuracy =   0.7100  loss =  153.206\n",
      "testing  :  4207  accuracy =   0.6918  loss =  155.563\n",
      "training :  4208  accuracy =   0.6500  loss =  153.958\n",
      "testing  :  4208  accuracy =   0.6916  loss =  155.555\n",
      "training :  4209  accuracy =   0.6500  loss =  154.038\n",
      "testing  :  4209  accuracy =   0.6922  loss =  155.533\n",
      "training :  4210  accuracy =   0.7500  loss =  153.615\n",
      "testing  :  4210  accuracy =   0.6920  loss =  155.51\n",
      "training :  4211  accuracy =   0.6500  loss =  154.099\n",
      "testing  :  4211  accuracy =   0.6925  loss =  155.48\n",
      "training :  4212  accuracy =   0.7200  loss =  154.229\n",
      "testing  :  4212  accuracy =   0.6932  loss =  155.433\n",
      "training :  4213  accuracy =   0.7100  loss =  155.315\n",
      "testing  :  4213  accuracy =   0.6932  loss =  155.421\n",
      "training :  4214  accuracy =   0.7000  loss =  154.54\n",
      "testing  :  4214  accuracy =   0.6936  loss =  155.421\n",
      "training :  4215  accuracy =   0.6600  loss =  155.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4215  accuracy =   0.6935  loss =  155.424\n",
      "training :  4216  accuracy =   0.6800  loss =  155.265\n",
      "testing  :  4216  accuracy =   0.6932  loss =  155.439\n",
      "training :  4217  accuracy =   0.7000  loss =  154.084\n",
      "testing  :  4217  accuracy =   0.6928  loss =  155.475\n",
      "training :  4218  accuracy =   0.6300  loss =  157.017\n",
      "testing  :  4218  accuracy =   0.6918  loss =  155.49\n",
      "training :  4219  accuracy =   0.6500  loss =  155.584\n",
      "testing  :  4219  accuracy =   0.6912  loss =  155.548\n",
      "training :  4220  accuracy =   0.6700  loss =  154.714\n",
      "testing  :  4220  accuracy =   0.6908  loss =  155.567\n",
      "training :  4221  accuracy =   0.6800  loss =  155.307\n",
      "testing  :  4221  accuracy =   0.6911  loss =  155.573\n",
      "training :  4222  accuracy =   0.7000  loss =  153.732\n",
      "testing  :  4222  accuracy =   0.6922  loss =  155.567\n",
      "training :  4223  accuracy =   0.7900  loss =  153.425\n",
      "testing  :  4223  accuracy =   0.6904  loss =  155.576\n",
      "training :  4224  accuracy =   0.7900  loss =  153.687\n",
      "testing  :  4224  accuracy =   0.6911  loss =  155.512\n",
      "training :  4225  accuracy =   0.6900  loss =  153.81\n",
      "testing  :  4225  accuracy =   0.6912  loss =  155.471\n",
      "training :  4226  accuracy =   0.6700  loss =  155.182\n",
      "testing  :  4226  accuracy =   0.6910  loss =  155.418\n",
      "training :  4227  accuracy =   0.6300  loss =  155.996\n",
      "testing  :  4227  accuracy =   0.6905  loss =  155.369\n",
      "training :  4228  accuracy =   0.7000  loss =  154.366\n",
      "testing  :  4228  accuracy =   0.6906  loss =  155.346\n",
      "training :  4229  accuracy =   0.7300  loss =  154.451\n",
      "testing  :  4229  accuracy =   0.6908  loss =  155.337\n",
      "training :  4230  accuracy =   0.6300  loss =  154.189\n",
      "testing  :  4230  accuracy =   0.6907  loss =  155.328\n",
      "training :  4231  accuracy =   0.6800  loss =  153.345\n",
      "testing  :  4231  accuracy =   0.6913  loss =  155.301\n",
      "training :  4232  accuracy =   0.7400  loss =  154.504\n",
      "testing  :  4232  accuracy =   0.6923  loss =  155.278\n",
      "training :  4233  accuracy =   0.7900  loss =  153.21\n",
      "testing  :  4233  accuracy =   0.6932  loss =  155.263\n",
      "training :  4234  accuracy =   0.6600  loss =  155.9\n",
      "testing  :  4234  accuracy =   0.6936  loss =  155.25\n",
      "training :  4235  accuracy =   0.6700  loss =  155.192\n",
      "testing  :  4235  accuracy =   0.6937  loss =  155.246\n",
      "training :  4236  accuracy =   0.6300  loss =  156.256\n",
      "testing  :  4236  accuracy =   0.6935  loss =  155.271\n",
      "training :  4237  accuracy =   0.7000  loss =  154.74\n",
      "testing  :  4237  accuracy =   0.6939  loss =  155.325\n",
      "training :  4238  accuracy =   0.6800  loss =  155.242\n",
      "testing  :  4238  accuracy =   0.6940  loss =  155.37\n",
      "training :  4239  accuracy =   0.7100  loss =  153.867\n",
      "testing  :  4239  accuracy =   0.6936  loss =  155.409\n",
      "training :  4240  accuracy =   0.7400  loss =  152.243\n",
      "testing  :  4240  accuracy =   0.6932  loss =  155.436\n",
      "training :  4241  accuracy =   0.7000  loss =  153.64\n",
      "testing  :  4241  accuracy =   0.6934  loss =  155.461\n",
      "training :  4242  accuracy =   0.7900  loss =  152.597\n",
      "testing  :  4242  accuracy =   0.6935  loss =  155.475\n",
      "training :  4243  accuracy =   0.7000  loss =  153.381\n",
      "testing  :  4243  accuracy =   0.6931  loss =  155.479\n",
      "training :  4244  accuracy =   0.8000  loss =  152.922\n",
      "testing  :  4244  accuracy =   0.6927  loss =  155.496\n",
      "training :  4245  accuracy =   0.6500  loss =  154.119\n",
      "testing  :  4245  accuracy =   0.6920  loss =  155.498\n",
      "training :  4246  accuracy =   0.7100  loss =  155.818\n",
      "testing  :  4246  accuracy =   0.6924  loss =  155.469\n",
      "training :  4247  accuracy =   0.6800  loss =  153.786\n",
      "testing  :  4247  accuracy =   0.6915  loss =  155.472\n",
      "training :  4248  accuracy =   0.7500  loss =  153.988\n",
      "testing  :  4248  accuracy =   0.6921  loss =  155.483\n",
      "training :  4249  accuracy =   0.7700  loss =  153.344\n",
      "testing  :  4249  accuracy =   0.6918  loss =  155.504\n",
      "training :  4250  accuracy =   0.7800  loss =  152.906\n",
      "testing  :  4250  accuracy =   0.6916  loss =  155.529\n",
      "training :  4251  accuracy =   0.7000  loss =  155.512\n",
      "testing  :  4251  accuracy =   0.6912  loss =  155.553\n",
      "training :  4252  accuracy =   0.6800  loss =  155.092\n",
      "testing  :  4252  accuracy =   0.6909  loss =  155.578\n",
      "training :  4253  accuracy =   0.6400  loss =  157.229\n",
      "testing  :  4253  accuracy =   0.6910  loss =  155.605\n",
      "training :  4254  accuracy =   0.6600  loss =  157.199\n",
      "testing  :  4254  accuracy =   0.6912  loss =  155.601\n",
      "training :  4255  accuracy =   0.7500  loss =  153.469\n",
      "testing  :  4255  accuracy =   0.6916  loss =  155.582\n",
      "training :  4256  accuracy =   0.7300  loss =  153.122\n",
      "testing  :  4256  accuracy =   0.6918  loss =  155.578\n",
      "training :  4257  accuracy =   0.7800  loss =  152.721\n",
      "testing  :  4257  accuracy =   0.6917  loss =  155.503\n",
      "training :  4258  accuracy =   0.7400  loss =  153.646\n",
      "testing  :  4258  accuracy =   0.6913  loss =  155.463\n",
      "training :  4259  accuracy =   0.7200  loss =  154.203\n",
      "testing  :  4259  accuracy =   0.6923  loss =  155.464\n",
      "training :  4260  accuracy =   0.6100  loss =  157.041\n",
      "testing  :  4260  accuracy =   0.6925  loss =  155.489\n",
      "training :  4261  accuracy =   0.6000  loss =  156.481\n",
      "testing  :  4261  accuracy =   0.6913  loss =  155.547\n",
      "training :  4262  accuracy =   0.7500  loss =  153.441\n",
      "testing  :  4262  accuracy =   0.6919  loss =  155.643\n",
      "training :  4263  accuracy =   0.7200  loss =  154.318\n",
      "testing  :  4263  accuracy =   0.6908  loss =  155.75\n",
      "training :  4264  accuracy =   0.6700  loss =  156.233\n",
      "testing  :  4264  accuracy =   0.6903  loss =  155.886\n",
      "training :  4265  accuracy =   0.6700  loss =  153.856\n",
      "testing  :  4265  accuracy =   0.6910  loss =  156.006\n",
      "training :  4266  accuracy =   0.6600  loss =  157.539\n",
      "testing  :  4266  accuracy =   0.6914  loss =  156.099\n",
      "training :  4267  accuracy =   0.7600  loss =  155.419\n",
      "testing  :  4267  accuracy =   0.6919  loss =  156.062\n",
      "training :  4268  accuracy =   0.7100  loss =  155.087\n",
      "testing  :  4268  accuracy =   0.6928  loss =  155.96\n",
      "training :  4269  accuracy =   0.7000  loss =  155.407\n",
      "testing  :  4269  accuracy =   0.6940  loss =  155.84\n",
      "training :  4270  accuracy =   0.7100  loss =  155.948\n",
      "testing  :  4270  accuracy =   0.6947  loss =  155.725\n",
      "training :  4271  accuracy =   0.7900  loss =  153.165\n",
      "testing  :  4271  accuracy =   0.6947  loss =  155.638\n",
      "training :  4272  accuracy =   0.7800  loss =  155.252\n",
      "testing  :  4272  accuracy =   0.6955  loss =  155.557\n",
      "training :  4273  accuracy =   0.7000  loss =  154.463\n",
      "testing  :  4273  accuracy =   0.6961  loss =  155.503\n",
      "training :  4274  accuracy =   0.6900  loss =  154.607\n",
      "testing  :  4274  accuracy =   0.6968  loss =  155.466\n",
      "training :  4275  accuracy =   0.6100  loss =  157.672\n",
      "testing  :  4275  accuracy =   0.6972  loss =  155.437\n",
      "training :  4276  accuracy =   0.7200  loss =  154.834\n",
      "testing  :  4276  accuracy =   0.6967  loss =  155.388\n",
      "training :  4277  accuracy =   0.7000  loss =  152.365\n",
      "testing  :  4277  accuracy =   0.6956  loss =  155.357\n",
      "training :  4278  accuracy =   0.6600  loss =  156.382\n",
      "testing  :  4278  accuracy =   0.6950  loss =  155.352\n",
      "training :  4279  accuracy =   0.7000  loss =  153.151\n",
      "testing  :  4279  accuracy =   0.6952  loss =  155.343\n",
      "training :  4280  accuracy =   0.6900  loss =  155.268\n",
      "testing  :  4280  accuracy =   0.6948  loss =  155.35\n",
      "training :  4281  accuracy =   0.7200  loss =  154.229\n",
      "testing  :  4281  accuracy =   0.6945  loss =  155.361\n",
      "training :  4282  accuracy =   0.6600  loss =  154.451\n",
      "testing  :  4282  accuracy =   0.6945  loss =  155.377\n",
      "training :  4283  accuracy =   0.6900  loss =  154.749\n",
      "testing  :  4283  accuracy =   0.6947  loss =  155.395\n",
      "training :  4284  accuracy =   0.7400  loss =  155.45\n",
      "testing  :  4284  accuracy =   0.6937  loss =  155.415\n",
      "training :  4285  accuracy =   0.7100  loss =  157.13\n",
      "testing  :  4285  accuracy =   0.6930  loss =  155.466\n",
      "training :  4286  accuracy =   0.6700  loss =  155.449\n",
      "testing  :  4286  accuracy =   0.6930  loss =  155.509\n",
      "training :  4287  accuracy =   0.8000  loss =  152.604\n",
      "testing  :  4287  accuracy =   0.6925  loss =  155.551\n",
      "training :  4288  accuracy =   0.6800  loss =  154.951\n",
      "testing  :  4288  accuracy =   0.6920  loss =  155.597\n",
      "training :  4289  accuracy =   0.6400  loss =  153.6\n",
      "testing  :  4289  accuracy =   0.6920  loss =  155.64\n",
      "training :  4290  accuracy =   0.6900  loss =  154.656\n",
      "testing  :  4290  accuracy =   0.6922  loss =  155.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  4291  accuracy =   0.7300  loss =  153.031\n",
      "testing  :  4291  accuracy =   0.6918  loss =  155.68\n",
      "training :  4292  accuracy =   0.6800  loss =  155.981\n",
      "testing  :  4292  accuracy =   0.6913  loss =  155.68\n",
      "training :  4293  accuracy =   0.7400  loss =  153.654\n",
      "testing  :  4293  accuracy =   0.6915  loss =  155.637\n",
      "training :  4294  accuracy =   0.7000  loss =  154.183\n",
      "testing  :  4294  accuracy =   0.6919  loss =  155.61\n",
      "training :  4295  accuracy =   0.7000  loss =  153.274\n",
      "testing  :  4295  accuracy =   0.6925  loss =  155.583\n",
      "training :  4296  accuracy =   0.7200  loss =  155.805\n",
      "testing  :  4296  accuracy =   0.6929  loss =  155.551\n",
      "training :  4297  accuracy =   0.7300  loss =  155.196\n",
      "testing  :  4297  accuracy =   0.6930  loss =  155.497\n",
      "training :  4298  accuracy =   0.6900  loss =  154.734\n",
      "testing  :  4298  accuracy =   0.6935  loss =  155.461\n",
      "training :  4299  accuracy =   0.6800  loss =  155.682\n",
      "testing  :  4299  accuracy =   0.6933  loss =  155.432\n",
      "training :  4300  accuracy =   0.7300  loss =  155.672\n",
      "testing  :  4300  accuracy =   0.6935  loss =  155.432\n",
      "training :  4301  accuracy =   0.7700  loss =  153.378\n",
      "testing  :  4301  accuracy =   0.6930  loss =  155.444\n",
      "training :  4302  accuracy =   0.7100  loss =  157.777\n",
      "testing  :  4302  accuracy =   0.6935  loss =  155.473\n",
      "training :  4303  accuracy =   0.7600  loss =  152.418\n",
      "testing  :  4303  accuracy =   0.6935  loss =  155.496\n",
      "training :  4304  accuracy =   0.6900  loss =  155.246\n",
      "testing  :  4304  accuracy =   0.6939  loss =  155.513\n",
      "training :  4305  accuracy =   0.7100  loss =  155.612\n",
      "testing  :  4305  accuracy =   0.6936  loss =  155.51\n",
      "training :  4306  accuracy =   0.6900  loss =  156.889\n",
      "testing  :  4306  accuracy =   0.6928  loss =  155.536\n",
      "training :  4307  accuracy =   0.7900  loss =  151.853\n",
      "testing  :  4307  accuracy =   0.6917  loss =  155.566\n",
      "training :  4308  accuracy =   0.6800  loss =  155.094\n",
      "testing  :  4308  accuracy =   0.6911  loss =  155.602\n",
      "training :  4309  accuracy =   0.6400  loss =  155.462\n",
      "testing  :  4309  accuracy =   0.6907  loss =  155.594\n",
      "training :  4310  accuracy =   0.6600  loss =  155.216\n",
      "testing  :  4310  accuracy =   0.6909  loss =  155.564\n",
      "training :  4311  accuracy =   0.7100  loss =  153.546\n",
      "testing  :  4311  accuracy =   0.6916  loss =  155.546\n",
      "training :  4312  accuracy =   0.7400  loss =  154.127\n",
      "testing  :  4312  accuracy =   0.6919  loss =  155.536\n",
      "training :  4313  accuracy =   0.7000  loss =  153.713\n",
      "testing  :  4313  accuracy =   0.6921  loss =  155.518\n",
      "training :  4314  accuracy =   0.7300  loss =  154.311\n",
      "testing  :  4314  accuracy =   0.6911  loss =  155.573\n",
      "training :  4315  accuracy =   0.6900  loss =  154.764\n",
      "testing  :  4315  accuracy =   0.6925  loss =  155.6\n",
      "training :  4316  accuracy =   0.6400  loss =  156.721\n",
      "testing  :  4316  accuracy =   0.6928  loss =  155.633\n",
      "training :  4317  accuracy =   0.6800  loss =  153.925\n",
      "testing  :  4317  accuracy =   0.6929  loss =  155.669\n",
      "training :  4318  accuracy =   0.7100  loss =  156.232\n",
      "testing  :  4318  accuracy =   0.6923  loss =  155.691\n",
      "training :  4319  accuracy =   0.7200  loss =  154.381\n",
      "testing  :  4319  accuracy =   0.6920  loss =  155.714\n",
      "training :  4320  accuracy =   0.6900  loss =  153.62\n",
      "testing  :  4320  accuracy =   0.6928  loss =  155.715\n",
      "training :  4321  accuracy =   0.6900  loss =  155.967\n",
      "testing  :  4321  accuracy =   0.6931  loss =  155.69\n",
      "training :  4322  accuracy =   0.7300  loss =  156.732\n",
      "testing  :  4322  accuracy =   0.6934  loss =  155.589\n",
      "training :  4323  accuracy =   0.6500  loss =  155.657\n",
      "testing  :  4323  accuracy =   0.6938  loss =  155.501\n",
      "training :  4324  accuracy =   0.6400  loss =  153.84\n",
      "testing  :  4324  accuracy =   0.6941  loss =  155.437\n",
      "training :  4325  accuracy =   0.7100  loss =  154.18\n",
      "testing  :  4325  accuracy =   0.6946  loss =  155.393\n",
      "training :  4326  accuracy =   0.7700  loss =  151.937\n",
      "testing  :  4326  accuracy =   0.6951  loss =  155.374\n",
      "training :  4327  accuracy =   0.7100  loss =  153.279\n",
      "testing  :  4327  accuracy =   0.6950  loss =  155.382\n",
      "training :  4328  accuracy =   0.6400  loss =  155.863\n",
      "testing  :  4328  accuracy =   0.6946  loss =  155.37\n",
      "training :  4329  accuracy =   0.7600  loss =  155.482\n",
      "testing  :  4329  accuracy =   0.6942  loss =  155.355\n",
      "training :  4330  accuracy =   0.7000  loss =  155.256\n",
      "testing  :  4330  accuracy =   0.6944  loss =  155.341\n",
      "training :  4331  accuracy =   0.7000  loss =  154.288\n",
      "testing  :  4331  accuracy =   0.6940  loss =  155.323\n",
      "training :  4332  accuracy =   0.6400  loss =  155.599\n",
      "testing  :  4332  accuracy =   0.6941  loss =  155.31\n",
      "training :  4333  accuracy =   0.6900  loss =  156.42\n",
      "testing  :  4333  accuracy =   0.6940  loss =  155.288\n",
      "training :  4334  accuracy =   0.7300  loss =  153.757\n",
      "testing  :  4334  accuracy =   0.6945  loss =  155.274\n",
      "training :  4335  accuracy =   0.7600  loss =  153.531\n",
      "testing  :  4335  accuracy =   0.6938  loss =  155.275\n",
      "training :  4336  accuracy =   0.6500  loss =  154.592\n",
      "testing  :  4336  accuracy =   0.6941  loss =  155.286\n",
      "training :  4337  accuracy =   0.7600  loss =  154.326\n",
      "testing  :  4337  accuracy =   0.6943  loss =  155.302\n",
      "training :  4338  accuracy =   0.6800  loss =  156.233\n",
      "testing  :  4338  accuracy =   0.6946  loss =  155.323\n",
      "training :  4339  accuracy =   0.6000  loss =  158.612\n",
      "testing  :  4339  accuracy =   0.6943  loss =  155.348\n",
      "training :  4340  accuracy =   0.7400  loss =  153.834\n",
      "testing  :  4340  accuracy =   0.6942  loss =  155.365\n",
      "training :  4341  accuracy =   0.7400  loss =  154.156\n",
      "testing  :  4341  accuracy =   0.6945  loss =  155.388\n",
      "training :  4342  accuracy =   0.6600  loss =  154.092\n",
      "testing  :  4342  accuracy =   0.6944  loss =  155.405\n",
      "training :  4343  accuracy =   0.7800  loss =  154.136\n",
      "testing  :  4343  accuracy =   0.6936  loss =  155.433\n",
      "training :  4344  accuracy =   0.6900  loss =  153.766\n",
      "testing  :  4344  accuracy =   0.6935  loss =  155.446\n",
      "training :  4345  accuracy =   0.7300  loss =  154.624\n",
      "testing  :  4345  accuracy =   0.6940  loss =  155.437\n",
      "training :  4346  accuracy =   0.7400  loss =  152.922\n",
      "testing  :  4346  accuracy =   0.6938  loss =  155.415\n",
      "training :  4347  accuracy =   0.6800  loss =  156.492\n",
      "testing  :  4347  accuracy =   0.6939  loss =  155.364\n",
      "training :  4348  accuracy =   0.7000  loss =  154.885\n",
      "testing  :  4348  accuracy =   0.6941  loss =  155.317\n",
      "training :  4349  accuracy =   0.7500  loss =  153.77\n",
      "testing  :  4349  accuracy =   0.6940  loss =  155.285\n",
      "training :  4350  accuracy =   0.7100  loss =  153.035\n",
      "testing  :  4350  accuracy =   0.6940  loss =  155.263\n",
      "training :  4351  accuracy =   0.6500  loss =  154.018\n",
      "testing  :  4351  accuracy =   0.6941  loss =  155.256\n",
      "training :  4352  accuracy =   0.6800  loss =  157.09\n",
      "testing  :  4352  accuracy =   0.6944  loss =  155.25\n",
      "training :  4353  accuracy =   0.7400  loss =  155.621\n",
      "testing  :  4353  accuracy =   0.6945  loss =  155.251\n",
      "training :  4354  accuracy =   0.6800  loss =  152.47\n",
      "testing  :  4354  accuracy =   0.6940  loss =  155.256\n",
      "training :  4355  accuracy =   0.7000  loss =  155.251\n",
      "testing  :  4355  accuracy =   0.6939  loss =  155.265\n",
      "training :  4356  accuracy =   0.6900  loss =  155.836\n",
      "testing  :  4356  accuracy =   0.6933  loss =  155.274\n",
      "training :  4357  accuracy =   0.7700  loss =  153.268\n",
      "testing  :  4357  accuracy =   0.6930  loss =  155.273\n",
      "training :  4358  accuracy =   0.7500  loss =  153.749\n",
      "testing  :  4358  accuracy =   0.6924  loss =  155.278\n",
      "training :  4359  accuracy =   0.7200  loss =  154.793\n",
      "testing  :  4359  accuracy =   0.6930  loss =  155.28\n",
      "training :  4360  accuracy =   0.6900  loss =  154.727\n",
      "testing  :  4360  accuracy =   0.6935  loss =  155.29\n",
      "training :  4361  accuracy =   0.7100  loss =  155.936\n",
      "testing  :  4361  accuracy =   0.6937  loss =  155.277\n",
      "training :  4362  accuracy =   0.6400  loss =  155.316\n",
      "testing  :  4362  accuracy =   0.6938  loss =  155.256\n",
      "training :  4363  accuracy =   0.7100  loss =  153.864\n",
      "testing  :  4363  accuracy =   0.6936  loss =  155.253\n",
      "training :  4364  accuracy =   0.6400  loss =  155.87\n",
      "testing  :  4364  accuracy =   0.6938  loss =  155.265\n",
      "training :  4365  accuracy =   0.7400  loss =  152.753\n",
      "testing  :  4365  accuracy =   0.6935  loss =  155.309\n",
      "training :  4366  accuracy =   0.7600  loss =  155.643\n",
      "testing  :  4366  accuracy =   0.6925  loss =  155.354\n",
      "training :  4367  accuracy =   0.6500  loss =  156.095\n",
      "testing  :  4367  accuracy =   0.6924  loss =  155.408\n",
      "training :  4368  accuracy =   0.7300  loss =  156.54\n",
      "testing  :  4368  accuracy =   0.6920  loss =  155.44\n",
      "training :  4369  accuracy =   0.6700  loss =  157.084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4369  accuracy =   0.6912  loss =  155.469\n",
      "training :  4370  accuracy =   0.7500  loss =  153.443\n",
      "testing  :  4370  accuracy =   0.6908  loss =  155.464\n",
      "training :  4371  accuracy =   0.6700  loss =  154.102\n",
      "testing  :  4371  accuracy =   0.6907  loss =  155.449\n",
      "training :  4372  accuracy =   0.7700  loss =  153.893\n",
      "testing  :  4372  accuracy =   0.6915  loss =  155.407\n",
      "training :  4373  accuracy =   0.5800  loss =  157.617\n",
      "testing  :  4373  accuracy =   0.6914  loss =  155.391\n",
      "training :  4374  accuracy =   0.7400  loss =  156.102\n",
      "testing  :  4374  accuracy =   0.6918  loss =  155.405\n",
      "training :  4375  accuracy =   0.6900  loss =  154.258\n",
      "testing  :  4375  accuracy =   0.6922  loss =  155.419\n",
      "training :  4376  accuracy =   0.6600  loss =  155.989\n",
      "testing  :  4376  accuracy =   0.6912  loss =  155.485\n",
      "training :  4377  accuracy =   0.6900  loss =  156.396\n",
      "testing  :  4377  accuracy =   0.6904  loss =  155.589\n",
      "training :  4378  accuracy =   0.5800  loss =  155.81\n",
      "testing  :  4378  accuracy =   0.6892  loss =  155.685\n",
      "training :  4379  accuracy =   0.7400  loss =  153.046\n",
      "testing  :  4379  accuracy =   0.6886  loss =  155.781\n",
      "training :  4380  accuracy =   0.6600  loss =  154.692\n",
      "testing  :  4380  accuracy =   0.6880  loss =  155.832\n",
      "training :  4381  accuracy =   0.7400  loss =  154.73\n",
      "testing  :  4381  accuracy =   0.6884  loss =  155.873\n",
      "training :  4382  accuracy =   0.6600  loss =  154.129\n",
      "testing  :  4382  accuracy =   0.6882  loss =  155.83\n",
      "training :  4383  accuracy =   0.6600  loss =  154.295\n",
      "testing  :  4383  accuracy =   0.6887  loss =  155.787\n",
      "training :  4384  accuracy =   0.7600  loss =  153.157\n",
      "testing  :  4384  accuracy =   0.6890  loss =  155.758\n",
      "training :  4385  accuracy =   0.6200  loss =  156.001\n",
      "testing  :  4385  accuracy =   0.6894  loss =  155.714\n",
      "training :  4386  accuracy =   0.6600  loss =  154.44\n",
      "testing  :  4386  accuracy =   0.6905  loss =  155.623\n",
      "training :  4387  accuracy =   0.7400  loss =  153.293\n",
      "testing  :  4387  accuracy =   0.6920  loss =  155.515\n",
      "training :  4388  accuracy =   0.6800  loss =  155.034\n",
      "testing  :  4388  accuracy =   0.6926  loss =  155.438\n",
      "training :  4389  accuracy =   0.6400  loss =  155.892\n",
      "testing  :  4389  accuracy =   0.6927  loss =  155.383\n",
      "training :  4390  accuracy =   0.7100  loss =  154.118\n",
      "testing  :  4390  accuracy =   0.6927  loss =  155.367\n",
      "training :  4391  accuracy =   0.7200  loss =  153.897\n",
      "testing  :  4391  accuracy =   0.6935  loss =  155.377\n",
      "training :  4392  accuracy =   0.6100  loss =  157.994\n",
      "testing  :  4392  accuracy =   0.6934  loss =  155.392\n",
      "training :  4393  accuracy =   0.7600  loss =  152.682\n",
      "testing  :  4393  accuracy =   0.6927  loss =  155.395\n",
      "training :  4394  accuracy =   0.7100  loss =  154.923\n",
      "testing  :  4394  accuracy =   0.6928  loss =  155.424\n",
      "training :  4395  accuracy =   0.7500  loss =  153.361\n",
      "testing  :  4395  accuracy =   0.6920  loss =  155.453\n",
      "training :  4396  accuracy =   0.8300  loss =  152.717\n",
      "testing  :  4396  accuracy =   0.6912  loss =  155.508\n",
      "training :  4397  accuracy =   0.8400  loss =  152.122\n",
      "testing  :  4397  accuracy =   0.6906  loss =  155.565\n",
      "training :  4398  accuracy =   0.6700  loss =  154.416\n",
      "testing  :  4398  accuracy =   0.6906  loss =  155.586\n",
      "training :  4399  accuracy =   0.6900  loss =  152.477\n",
      "testing  :  4399  accuracy =   0.6911  loss =  155.557\n",
      "training :  4400  accuracy =   0.7200  loss =  153.693\n",
      "testing  :  4400  accuracy =   0.6921  loss =  155.532\n",
      "training :  4401  accuracy =   0.6600  loss =  156.032\n",
      "testing  :  4401  accuracy =   0.6931  loss =  155.523\n",
      "training :  4402  accuracy =   0.6700  loss =  154.93\n",
      "testing  :  4402  accuracy =   0.6941  loss =  155.453\n",
      "training :  4403  accuracy =   0.8000  loss =  153.423\n",
      "testing  :  4403  accuracy =   0.6949  loss =  155.4\n",
      "training :  4404  accuracy =   0.7400  loss =  153.829\n",
      "testing  :  4404  accuracy =   0.6952  loss =  155.36\n",
      "training :  4405  accuracy =   0.7000  loss =  153.321\n",
      "testing  :  4405  accuracy =   0.6949  loss =  155.333\n",
      "training :  4406  accuracy =   0.7000  loss =  155.908\n",
      "testing  :  4406  accuracy =   0.6956  loss =  155.31\n",
      "training :  4407  accuracy =   0.6800  loss =  154.668\n",
      "testing  :  4407  accuracy =   0.6951  loss =  155.312\n",
      "training :  4408  accuracy =   0.7300  loss =  152.374\n",
      "testing  :  4408  accuracy =   0.6945  loss =  155.34\n",
      "training :  4409  accuracy =   0.7100  loss =  153.965\n",
      "testing  :  4409  accuracy =   0.6946  loss =  155.38\n",
      "training :  4410  accuracy =   0.7700  loss =  152.793\n",
      "testing  :  4410  accuracy =   0.6945  loss =  155.419\n",
      "training :  4411  accuracy =   0.6700  loss =  154.687\n",
      "testing  :  4411  accuracy =   0.6944  loss =  155.458\n",
      "training :  4412  accuracy =   0.6400  loss =  156.526\n",
      "testing  :  4412  accuracy =   0.6950  loss =  155.456\n",
      "training :  4413  accuracy =   0.6800  loss =  155.619\n",
      "testing  :  4413  accuracy =   0.6949  loss =  155.504\n",
      "training :  4414  accuracy =   0.7800  loss =  153.666\n",
      "testing  :  4414  accuracy =   0.6944  loss =  155.552\n",
      "training :  4415  accuracy =   0.7300  loss =  155.149\n",
      "testing  :  4415  accuracy =   0.6937  loss =  155.59\n",
      "training :  4416  accuracy =   0.6900  loss =  154.093\n",
      "testing  :  4416  accuracy =   0.6934  loss =  155.61\n",
      "training :  4417  accuracy =   0.6600  loss =  154.963\n",
      "testing  :  4417  accuracy =   0.6935  loss =  155.59\n",
      "training :  4418  accuracy =   0.6600  loss =  156.073\n",
      "testing  :  4418  accuracy =   0.6933  loss =  155.56\n",
      "training :  4419  accuracy =   0.7800  loss =  151.899\n",
      "testing  :  4419  accuracy =   0.6933  loss =  155.535\n",
      "training :  4420  accuracy =   0.6900  loss =  153.426\n",
      "testing  :  4420  accuracy =   0.6939  loss =  155.495\n",
      "training :  4421  accuracy =   0.7400  loss =  154.812\n",
      "testing  :  4421  accuracy =   0.6940  loss =  155.456\n",
      "training :  4422  accuracy =   0.7200  loss =  155.164\n",
      "testing  :  4422  accuracy =   0.6936  loss =  155.42\n",
      "training :  4423  accuracy =   0.7900  loss =  153.446\n",
      "testing  :  4423  accuracy =   0.6936  loss =  155.372\n",
      "training :  4424  accuracy =   0.7400  loss =  152.358\n",
      "testing  :  4424  accuracy =   0.6929  loss =  155.348\n",
      "training :  4425  accuracy =   0.7500  loss =  154.269\n",
      "testing  :  4425  accuracy =   0.6934  loss =  155.336\n",
      "training :  4426  accuracy =   0.7500  loss =  152.063\n",
      "testing  :  4426  accuracy =   0.6939  loss =  155.338\n",
      "training :  4427  accuracy =   0.6600  loss =  159.046\n",
      "testing  :  4427  accuracy =   0.6938  loss =  155.346\n",
      "training :  4428  accuracy =   0.6200  loss =  154.42\n",
      "testing  :  4428  accuracy =   0.6938  loss =  155.344\n",
      "training :  4429  accuracy =   0.6100  loss =  159.097\n",
      "testing  :  4429  accuracy =   0.6940  loss =  155.318\n",
      "training :  4430  accuracy =   0.6800  loss =  155.243\n",
      "testing  :  4430  accuracy =   0.6942  loss =  155.299\n",
      "training :  4431  accuracy =   0.6500  loss =  154.256\n",
      "testing  :  4431  accuracy =   0.6943  loss =  155.288\n",
      "training :  4432  accuracy =   0.6000  loss =  156.485\n",
      "testing  :  4432  accuracy =   0.6946  loss =  155.253\n",
      "training :  4433  accuracy =   0.7200  loss =  153.953\n",
      "testing  :  4433  accuracy =   0.6950  loss =  155.227\n",
      "training :  4434  accuracy =   0.6900  loss =  153.938\n",
      "testing  :  4434  accuracy =   0.6955  loss =  155.213\n",
      "training :  4435  accuracy =   0.7700  loss =  153.339\n",
      "testing  :  4435  accuracy =   0.6961  loss =  155.201\n",
      "training :  4436  accuracy =   0.6600  loss =  156.02\n",
      "testing  :  4436  accuracy =   0.6966  loss =  155.193\n",
      "training :  4437  accuracy =   0.7400  loss =  153.406\n",
      "testing  :  4437  accuracy =   0.6979  loss =  155.195\n",
      "training :  4438  accuracy =   0.7400  loss =  153.682\n",
      "testing  :  4438  accuracy =   0.7013  loss =  155.205\n",
      "training :  4439  accuracy =   0.7700  loss =  153.729\n",
      "testing  :  4439  accuracy =   0.7056  loss =  155.241\n",
      "training :  4440  accuracy =   0.6800  loss =  154.719\n",
      "testing  :  4440  accuracy =   0.7163  loss =  155.282\n",
      "training :  4441  accuracy =   0.6600  loss =  154.606\n",
      "testing  :  4441  accuracy =   0.7282  loss =  155.293\n",
      "training :  4442  accuracy =   0.7800  loss =  154.099\n",
      "testing  :  4442  accuracy =   0.7424  loss =  155.298\n",
      "training :  4443  accuracy =   0.7900  loss =  152.59\n",
      "testing  :  4443  accuracy =   0.7544  loss =  155.293\n",
      "training :  4444  accuracy =   0.8000  loss =  153.839\n",
      "testing  :  4444  accuracy =   0.7617  loss =  155.292\n",
      "training :  4445  accuracy =   0.7500  loss =  154.274\n",
      "testing  :  4445  accuracy =   0.7647  loss =  155.277\n",
      "training :  4446  accuracy =   0.7200  loss =  153.474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4446  accuracy =   0.7564  loss =  155.26\n",
      "training :  4447  accuracy =   0.8000  loss =  152.151\n",
      "testing  :  4447  accuracy =   0.7386  loss =  155.253\n",
      "training :  4448  accuracy =   0.7600  loss =  151.631\n",
      "testing  :  4448  accuracy =   0.7332  loss =  155.251\n",
      "training :  4449  accuracy =   0.7100  loss =  154.037\n",
      "testing  :  4449  accuracy =   0.7275  loss =  155.23\n",
      "training :  4450  accuracy =   0.7600  loss =  154.578\n",
      "testing  :  4450  accuracy =   0.7249  loss =  155.209\n",
      "training :  4451  accuracy =   0.7600  loss =  155.318\n",
      "testing  :  4451  accuracy =   0.7223  loss =  155.174\n",
      "training :  4452  accuracy =   0.8100  loss =  153.489\n",
      "testing  :  4452  accuracy =   0.7211  loss =  155.156\n",
      "training :  4453  accuracy =   0.7600  loss =  152.793\n",
      "testing  :  4453  accuracy =   0.7214  loss =  155.16\n",
      "training :  4454  accuracy =   0.7600  loss =  153.75\n",
      "testing  :  4454  accuracy =   0.7224  loss =  155.174\n",
      "training :  4455  accuracy =   0.7100  loss =  152.958\n",
      "testing  :  4455  accuracy =   0.7218  loss =  155.173\n",
      "training :  4456  accuracy =   0.7500  loss =  152.649\n",
      "testing  :  4456  accuracy =   0.7174  loss =  155.172\n",
      "training :  4457  accuracy =   0.6900  loss =  155.178\n",
      "testing  :  4457  accuracy =   0.7125  loss =  155.181\n",
      "training :  4458  accuracy =   0.6900  loss =  156.757\n",
      "testing  :  4458  accuracy =   0.7099  loss =  155.196\n",
      "training :  4459  accuracy =   0.7100  loss =  154.709\n",
      "testing  :  4459  accuracy =   0.7064  loss =  155.188\n",
      "training :  4460  accuracy =   0.6900  loss =  154.7\n",
      "testing  :  4460  accuracy =   0.7048  loss =  155.187\n",
      "training :  4461  accuracy =   0.6400  loss =  157.042\n",
      "testing  :  4461  accuracy =   0.7056  loss =  155.183\n",
      "training :  4462  accuracy =   0.7200  loss =  154.96\n",
      "testing  :  4462  accuracy =   0.7058  loss =  155.188\n",
      "training :  4463  accuracy =   0.7300  loss =  153.353\n",
      "testing  :  4463  accuracy =   0.7078  loss =  155.185\n",
      "training :  4464  accuracy =   0.7600  loss =  153.43\n",
      "testing  :  4464  accuracy =   0.7087  loss =  155.174\n",
      "training :  4465  accuracy =   0.7300  loss =  152.466\n",
      "testing  :  4465  accuracy =   0.7092  loss =  155.171\n",
      "training :  4466  accuracy =   0.7500  loss =  152.618\n",
      "testing  :  4466  accuracy =   0.7102  loss =  155.175\n",
      "training :  4467  accuracy =   0.7300  loss =  154.454\n",
      "testing  :  4467  accuracy =   0.7119  loss =  155.185\n",
      "training :  4468  accuracy =   0.7200  loss =  152.235\n",
      "testing  :  4468  accuracy =   0.7111  loss =  155.182\n",
      "training :  4469  accuracy =   0.7400  loss =  153.067\n",
      "testing  :  4469  accuracy =   0.7108  loss =  155.199\n",
      "training :  4470  accuracy =   0.8200  loss =  153.548\n",
      "testing  :  4470  accuracy =   0.7103  loss =  155.244\n",
      "training :  4471  accuracy =   0.8100  loss =  152.451\n",
      "testing  :  4471  accuracy =   0.7091  loss =  155.312\n",
      "training :  4472  accuracy =   0.7400  loss =  153.4\n",
      "testing  :  4472  accuracy =   0.7095  loss =  155.359\n",
      "training :  4473  accuracy =   0.7200  loss =  153.567\n",
      "testing  :  4473  accuracy =   0.7093  loss =  155.393\n",
      "training :  4474  accuracy =   0.8100  loss =  153.509\n",
      "testing  :  4474  accuracy =   0.7098  loss =  155.421\n",
      "training :  4475  accuracy =   0.6900  loss =  156.468\n",
      "testing  :  4475  accuracy =   0.7078  loss =  155.449\n",
      "training :  4476  accuracy =   0.7200  loss =  153.86\n",
      "testing  :  4476  accuracy =   0.7056  loss =  155.477\n",
      "training :  4477  accuracy =   0.7500  loss =  152.324\n",
      "testing  :  4477  accuracy =   0.7052  loss =  155.503\n",
      "training :  4478  accuracy =   0.7400  loss =  152.879\n",
      "testing  :  4478  accuracy =   0.7054  loss =  155.429\n",
      "training :  4479  accuracy =   0.7400  loss =  156.433\n",
      "testing  :  4479  accuracy =   0.7048  loss =  155.344\n",
      "training :  4480  accuracy =   0.7000  loss =  155.009\n",
      "testing  :  4480  accuracy =   0.7062  loss =  155.299\n",
      "training :  4481  accuracy =   0.7300  loss =  153.524\n",
      "testing  :  4481  accuracy =   0.7074  loss =  155.201\n",
      "training :  4482  accuracy =   0.7400  loss =  152.65\n",
      "testing  :  4482  accuracy =   0.7082  loss =  155.176\n",
      "training :  4483  accuracy =   0.8100  loss =  152.569\n",
      "testing  :  4483  accuracy =   0.7090  loss =  155.162\n",
      "training :  4484  accuracy =   0.6800  loss =  154.44\n",
      "testing  :  4484  accuracy =   0.7089  loss =  155.16\n",
      "training :  4485  accuracy =   0.7100  loss =  152.929\n",
      "testing  :  4485  accuracy =   0.7091  loss =  155.171\n",
      "training :  4486  accuracy =   0.7100  loss =  155.826\n",
      "testing  :  4486  accuracy =   0.7098  loss =  155.189\n",
      "training :  4487  accuracy =   0.7400  loss =  154.502\n",
      "testing  :  4487  accuracy =   0.7095  loss =  155.182\n",
      "training :  4488  accuracy =   0.7200  loss =  154.238\n",
      "testing  :  4488  accuracy =   0.7096  loss =  155.181\n",
      "training :  4489  accuracy =   0.7500  loss =  153.072\n",
      "testing  :  4489  accuracy =   0.7095  loss =  155.189\n",
      "training :  4490  accuracy =   0.7500  loss =  155.695\n",
      "testing  :  4490  accuracy =   0.7091  loss =  155.201\n",
      "training :  4491  accuracy =   0.6800  loss =  153.698\n",
      "testing  :  4491  accuracy =   0.7084  loss =  155.194\n",
      "training :  4492  accuracy =   0.6900  loss =  155.111\n",
      "testing  :  4492  accuracy =   0.7073  loss =  155.184\n",
      "training :  4493  accuracy =   0.7000  loss =  153.564\n",
      "testing  :  4493  accuracy =   0.7077  loss =  155.16\n",
      "training :  4494  accuracy =   0.7700  loss =  153.052\n",
      "testing  :  4494  accuracy =   0.7068  loss =  155.146\n",
      "training :  4495  accuracy =   0.6900  loss =  154.653\n",
      "testing  :  4495  accuracy =   0.7064  loss =  155.143\n",
      "training :  4496  accuracy =   0.7000  loss =  152.514\n",
      "testing  :  4496  accuracy =   0.7063  loss =  155.147\n",
      "training :  4497  accuracy =   0.6600  loss =  155.873\n",
      "testing  :  4497  accuracy =   0.7063  loss =  155.162\n",
      "training :  4498  accuracy =   0.7300  loss =  153.791\n",
      "testing  :  4498  accuracy =   0.7056  loss =  155.176\n",
      "training :  4499  accuracy =   0.8100  loss =  151.54\n",
      "testing  :  4499  accuracy =   0.7055  loss =  155.195\n",
      "training :  4500  accuracy =   0.7600  loss =  153.607\n",
      "testing  :  4500  accuracy =   0.7058  loss =  155.215\n",
      "training :  4501  accuracy =   0.6800  loss =  153.945\n",
      "testing  :  4501  accuracy =   0.7062  loss =  155.236\n",
      "training :  4502  accuracy =   0.7000  loss =  153.693\n",
      "testing  :  4502  accuracy =   0.7063  loss =  155.246\n",
      "training :  4503  accuracy =   0.6400  loss =  153.435\n",
      "testing  :  4503  accuracy =   0.7069  loss =  155.255\n",
      "training :  4504  accuracy =   0.6600  loss =  154.081\n",
      "testing  :  4504  accuracy =   0.7090  loss =  155.264\n",
      "training :  4505  accuracy =   0.7400  loss =  153.224\n",
      "testing  :  4505  accuracy =   0.7108  loss =  155.275\n",
      "training :  4506  accuracy =   0.6900  loss =  154.0\n",
      "testing  :  4506  accuracy =   0.7133  loss =  155.286\n",
      "training :  4507  accuracy =   0.7500  loss =  154.092\n",
      "testing  :  4507  accuracy =   0.7161  loss =  155.298\n",
      "training :  4508  accuracy =   0.7100  loss =  154.148\n",
      "testing  :  4508  accuracy =   0.7181  loss =  155.307\n",
      "training :  4509  accuracy =   0.6100  loss =  156.958\n",
      "testing  :  4509  accuracy =   0.7194  loss =  155.307\n",
      "training :  4510  accuracy =   0.7100  loss =  155.615\n",
      "testing  :  4510  accuracy =   0.7203  loss =  155.317\n",
      "training :  4511  accuracy =   0.6900  loss =  154.558\n",
      "testing  :  4511  accuracy =   0.7199  loss =  155.321\n",
      "training :  4512  accuracy =   0.7200  loss =  152.964\n",
      "testing  :  4512  accuracy =   0.7199  loss =  155.313\n",
      "training :  4513  accuracy =   0.7000  loss =  154.733\n",
      "testing  :  4513  accuracy =   0.7213  loss =  155.298\n",
      "training :  4514  accuracy =   0.7700  loss =  155.252\n",
      "testing  :  4514  accuracy =   0.7235  loss =  155.279\n",
      "training :  4515  accuracy =   0.7500  loss =  155.209\n",
      "testing  :  4515  accuracy =   0.7233  loss =  155.252\n",
      "training :  4516  accuracy =   0.7300  loss =  154.284\n",
      "testing  :  4516  accuracy =   0.7236  loss =  155.232\n",
      "training :  4517  accuracy =   0.6900  loss =  156.811\n",
      "testing  :  4517  accuracy =   0.7251  loss =  155.202\n",
      "training :  4518  accuracy =   0.6600  loss =  154.611\n",
      "testing  :  4518  accuracy =   0.7264  loss =  155.181\n",
      "training :  4519  accuracy =   0.6900  loss =  154.826\n",
      "testing  :  4519  accuracy =   0.7263  loss =  155.172\n",
      "training :  4520  accuracy =   0.8100  loss =  153.504\n",
      "testing  :  4520  accuracy =   0.7237  loss =  155.171\n",
      "training :  4521  accuracy =   0.8000  loss =  153.136\n",
      "testing  :  4521  accuracy =   0.7227  loss =  155.178\n",
      "training :  4522  accuracy =   0.8100  loss =  152.384\n",
      "testing  :  4522  accuracy =   0.7217  loss =  155.179\n",
      "training :  4523  accuracy =   0.7600  loss =  153.309\n",
      "testing  :  4523  accuracy =   0.7220  loss =  155.179\n",
      "training :  4524  accuracy =   0.7400  loss =  154.459\n",
      "testing  :  4524  accuracy =   0.7222  loss =  155.18\n",
      "training :  4525  accuracy =   0.7900  loss =  153.878\n",
      "testing  :  4525  accuracy =   0.7269  loss =  155.189\n",
      "training :  4526  accuracy =   0.7200  loss =  156.291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4526  accuracy =   0.7357  loss =  155.192\n",
      "training :  4527  accuracy =   0.7700  loss =  152.356\n",
      "testing  :  4527  accuracy =   0.7613  loss =  155.16\n",
      "training :  4528  accuracy =   0.7300  loss =  153.905\n",
      "testing  :  4528  accuracy =   0.7210  loss =  155.178\n",
      "training :  4529  accuracy =   0.6400  loss =  154.112\n",
      "testing  :  4529  accuracy =   0.6992  loss =  155.195\n",
      "training :  4530  accuracy =   0.7400  loss =  154.06\n",
      "testing  :  4530  accuracy =   0.6948  loss =  155.245\n",
      "training :  4531  accuracy =   0.7200  loss =  153.51\n",
      "testing  :  4531  accuracy =   0.6934  loss =  155.329\n",
      "training :  4532  accuracy =   0.7200  loss =  153.602\n",
      "testing  :  4532  accuracy =   0.6923  loss =  155.487\n",
      "training :  4533  accuracy =   0.6600  loss =  153.697\n",
      "testing  :  4533  accuracy =   0.6906  loss =  155.681\n",
      "training :  4534  accuracy =   0.7000  loss =  155.376\n",
      "testing  :  4534  accuracy =   0.6885  loss =  155.924\n",
      "training :  4535  accuracy =   0.6600  loss =  155.31\n",
      "testing  :  4535  accuracy =   0.6884  loss =  156.178\n",
      "training :  4536  accuracy =   0.6600  loss =  159.182\n",
      "testing  :  4536  accuracy =   0.6868  loss =  156.397\n",
      "training :  4537  accuracy =   0.6700  loss =  156.894\n",
      "testing  :  4537  accuracy =   0.6862  loss =  156.362\n",
      "training :  4538  accuracy =   0.6800  loss =  154.779\n",
      "testing  :  4538  accuracy =   0.6870  loss =  156.092\n",
      "training :  4539  accuracy =   0.7200  loss =  153.064\n",
      "testing  :  4539  accuracy =   0.6893  loss =  155.905\n",
      "training :  4540  accuracy =   0.6400  loss =  155.846\n",
      "testing  :  4540  accuracy =   0.6910  loss =  155.782\n",
      "training :  4541  accuracy =   0.6900  loss =  153.869\n",
      "testing  :  4541  accuracy =   0.6911  loss =  155.634\n",
      "training :  4542  accuracy =   0.6500  loss =  154.124\n",
      "testing  :  4542  accuracy =   0.6917  loss =  155.451\n",
      "training :  4543  accuracy =   0.6300  loss =  155.615\n",
      "testing  :  4543  accuracy =   0.6915  loss =  155.37\n",
      "training :  4544  accuracy =   0.7000  loss =  154.808\n",
      "testing  :  4544  accuracy =   0.6913  loss =  155.347\n",
      "training :  4545  accuracy =   0.6700  loss =  154.077\n",
      "testing  :  4545  accuracy =   0.6909  loss =  155.36\n",
      "training :  4546  accuracy =   0.7100  loss =  153.181\n",
      "testing  :  4546  accuracy =   0.6909  loss =  155.397\n",
      "training :  4547  accuracy =   0.7900  loss =  152.896\n",
      "testing  :  4547  accuracy =   0.6904  loss =  155.437\n",
      "training :  4548  accuracy =   0.6300  loss =  156.605\n",
      "testing  :  4548  accuracy =   0.6907  loss =  155.474\n",
      "training :  4549  accuracy =   0.7100  loss =  153.504\n",
      "testing  :  4549  accuracy =   0.6913  loss =  155.489\n",
      "training :  4550  accuracy =   0.7000  loss =  154.406\n",
      "testing  :  4550  accuracy =   0.6911  loss =  155.508\n",
      "training :  4551  accuracy =   0.6900  loss =  154.122\n",
      "testing  :  4551  accuracy =   0.6912  loss =  155.53\n",
      "training :  4552  accuracy =   0.6500  loss =  153.755\n",
      "testing  :  4552  accuracy =   0.6909  loss =  155.529\n",
      "training :  4553  accuracy =   0.6600  loss =  157.11\n",
      "testing  :  4553  accuracy =   0.6904  loss =  155.517\n",
      "training :  4554  accuracy =   0.6900  loss =  156.326\n",
      "testing  :  4554  accuracy =   0.6905  loss =  155.467\n",
      "training :  4555  accuracy =   0.6400  loss =  155.896\n",
      "testing  :  4555  accuracy =   0.6913  loss =  155.456\n",
      "training :  4556  accuracy =   0.7600  loss =  154.386\n",
      "testing  :  4556  accuracy =   0.6912  loss =  155.44\n",
      "training :  4557  accuracy =   0.7900  loss =  156.134\n",
      "testing  :  4557  accuracy =   0.6914  loss =  155.4\n",
      "training :  4558  accuracy =   0.7000  loss =  153.972\n",
      "testing  :  4558  accuracy =   0.6917  loss =  155.35\n",
      "training :  4559  accuracy =   0.7000  loss =  153.227\n",
      "testing  :  4559  accuracy =   0.6917  loss =  155.337\n",
      "training :  4560  accuracy =   0.7400  loss =  153.736\n",
      "testing  :  4560  accuracy =   0.6922  loss =  155.317\n",
      "training :  4561  accuracy =   0.7600  loss =  153.006\n",
      "testing  :  4561  accuracy =   0.6922  loss =  155.299\n",
      "training :  4562  accuracy =   0.7300  loss =  152.922\n",
      "testing  :  4562  accuracy =   0.6920  loss =  155.301\n",
      "training :  4563  accuracy =   0.7200  loss =  153.155\n",
      "testing  :  4563  accuracy =   0.6924  loss =  155.318\n",
      "training :  4564  accuracy =   0.7500  loss =  154.785\n",
      "testing  :  4564  accuracy =   0.6921  loss =  155.354\n",
      "training :  4565  accuracy =   0.6800  loss =  154.563\n",
      "testing  :  4565  accuracy =   0.6919  loss =  155.41\n",
      "training :  4566  accuracy =   0.6900  loss =  156.059\n",
      "testing  :  4566  accuracy =   0.6921  loss =  155.477\n",
      "training :  4567  accuracy =   0.6800  loss =  153.164\n",
      "testing  :  4567  accuracy =   0.6916  loss =  155.54\n",
      "training :  4568  accuracy =   0.7100  loss =  153.598\n",
      "testing  :  4568  accuracy =   0.6909  loss =  155.606\n",
      "training :  4569  accuracy =   0.6800  loss =  156.611\n",
      "testing  :  4569  accuracy =   0.6900  loss =  155.675\n",
      "training :  4570  accuracy =   0.6500  loss =  154.721\n",
      "testing  :  4570  accuracy =   0.6911  loss =  155.544\n",
      "training :  4571  accuracy =   0.7300  loss =  153.397\n",
      "testing  :  4571  accuracy =   0.6919  loss =  155.413\n",
      "training :  4572  accuracy =   0.7100  loss =  154.665\n",
      "testing  :  4572  accuracy =   0.6921  loss =  155.362\n",
      "training :  4573  accuracy =   0.6900  loss =  154.982\n",
      "testing  :  4573  accuracy =   0.6922  loss =  155.356\n",
      "training :  4574  accuracy =   0.6400  loss =  157.456\n",
      "testing  :  4574  accuracy =   0.6923  loss =  155.378\n",
      "training :  4575  accuracy =   0.7700  loss =  153.495\n",
      "testing  :  4575  accuracy =   0.6917  loss =  155.417\n",
      "training :  4576  accuracy =   0.6900  loss =  154.795\n",
      "testing  :  4576  accuracy =   0.6913  loss =  155.478\n",
      "training :  4577  accuracy =   0.7300  loss =  153.937\n",
      "testing  :  4577  accuracy =   0.6916  loss =  155.506\n",
      "training :  4578  accuracy =   0.7500  loss =  154.249\n",
      "testing  :  4578  accuracy =   0.6907  loss =  155.533\n",
      "training :  4579  accuracy =   0.6700  loss =  154.191\n",
      "testing  :  4579  accuracy =   0.6908  loss =  155.557\n",
      "training :  4580  accuracy =   0.6800  loss =  154.181\n",
      "testing  :  4580  accuracy =   0.6906  loss =  155.576\n",
      "training :  4581  accuracy =   0.7100  loss =  155.386\n",
      "testing  :  4581  accuracy =   0.6906  loss =  155.573\n",
      "training :  4582  accuracy =   0.7500  loss =  154.253\n",
      "testing  :  4582  accuracy =   0.6904  loss =  155.555\n",
      "training :  4583  accuracy =   0.8700  loss =  152.737\n",
      "testing  :  4583  accuracy =   0.6903  loss =  155.569\n",
      "training :  4584  accuracy =   0.6400  loss =  155.29\n",
      "testing  :  4584  accuracy =   0.6904  loss =  155.574\n",
      "training :  4585  accuracy =   0.6900  loss =  153.774\n",
      "testing  :  4585  accuracy =   0.6904  loss =  155.545\n",
      "training :  4586  accuracy =   0.6100  loss =  156.676\n",
      "testing  :  4586  accuracy =   0.6909  loss =  155.496\n",
      "training :  4587  accuracy =   0.6700  loss =  155.482\n",
      "testing  :  4587  accuracy =   0.6909  loss =  155.449\n",
      "training :  4588  accuracy =   0.7100  loss =  152.355\n",
      "testing  :  4588  accuracy =   0.6906  loss =  155.397\n",
      "training :  4589  accuracy =   0.7800  loss =  152.808\n",
      "testing  :  4589  accuracy =   0.6906  loss =  155.365\n",
      "training :  4590  accuracy =   0.7200  loss =  155.622\n",
      "testing  :  4590  accuracy =   0.6911  loss =  155.36\n",
      "training :  4591  accuracy =   0.7100  loss =  154.909\n",
      "testing  :  4591  accuracy =   0.6915  loss =  155.362\n",
      "training :  4592  accuracy =   0.7300  loss =  154.796\n",
      "testing  :  4592  accuracy =   0.6910  loss =  155.385\n",
      "training :  4593  accuracy =   0.6800  loss =  154.416\n",
      "testing  :  4593  accuracy =   0.6910  loss =  155.384\n",
      "training :  4594  accuracy =   0.7400  loss =  153.059\n",
      "testing  :  4594  accuracy =   0.6916  loss =  155.363\n",
      "training :  4595  accuracy =   0.7100  loss =  156.473\n",
      "testing  :  4595  accuracy =   0.6914  loss =  155.359\n",
      "training :  4596  accuracy =   0.6800  loss =  154.43\n",
      "testing  :  4596  accuracy =   0.6920  loss =  155.363\n",
      "training :  4597  accuracy =   0.7000  loss =  154.289\n",
      "testing  :  4597  accuracy =   0.6916  loss =  155.373\n",
      "training :  4598  accuracy =   0.6900  loss =  156.552\n",
      "testing  :  4598  accuracy =   0.6919  loss =  155.389\n",
      "training :  4599  accuracy =   0.7600  loss =  154.54\n",
      "testing  :  4599  accuracy =   0.6914  loss =  155.361\n",
      "training :  4600  accuracy =   0.7200  loss =  153.416\n",
      "testing  :  4600  accuracy =   0.6915  loss =  155.369\n",
      "training :  4601  accuracy =   0.6600  loss =  154.918\n",
      "testing  :  4601  accuracy =   0.6908  loss =  155.375\n",
      "training :  4602  accuracy =   0.7200  loss =  152.273\n",
      "testing  :  4602  accuracy =   0.6901  loss =  155.38\n",
      "training :  4603  accuracy =   0.7800  loss =  153.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4603  accuracy =   0.6891  loss =  155.397\n",
      "training :  4604  accuracy =   0.7000  loss =  156.833\n",
      "testing  :  4604  accuracy =   0.6884  loss =  155.41\n",
      "training :  4605  accuracy =   0.7000  loss =  151.8\n",
      "testing  :  4605  accuracy =   0.6887  loss =  155.426\n",
      "training :  4606  accuracy =   0.6900  loss =  153.985\n",
      "testing  :  4606  accuracy =   0.6881  loss =  155.45\n",
      "training :  4607  accuracy =   0.6600  loss =  155.195\n",
      "testing  :  4607  accuracy =   0.6885  loss =  155.52\n",
      "training :  4608  accuracy =   0.7300  loss =  153.917\n",
      "testing  :  4608  accuracy =   0.6889  loss =  155.616\n",
      "training :  4609  accuracy =   0.7300  loss =  152.482\n",
      "testing  :  4609  accuracy =   0.6882  loss =  155.718\n",
      "training :  4610  accuracy =   0.6900  loss =  155.139\n",
      "testing  :  4610  accuracy =   0.6877  loss =  155.831\n",
      "training :  4611  accuracy =   0.6900  loss =  153.558\n",
      "testing  :  4611  accuracy =   0.6871  loss =  155.89\n",
      "training :  4612  accuracy =   0.7400  loss =  155.815\n",
      "testing  :  4612  accuracy =   0.6868  loss =  155.927\n",
      "training :  4613  accuracy =   0.7300  loss =  152.841\n",
      "testing  :  4613  accuracy =   0.6857  loss =  155.975\n",
      "training :  4614  accuracy =   0.7300  loss =  154.14\n",
      "testing  :  4614  accuracy =   0.6850  loss =  155.987\n",
      "training :  4615  accuracy =   0.6500  loss =  156.695\n",
      "testing  :  4615  accuracy =   0.6861  loss =  155.963\n",
      "training :  4616  accuracy =   0.6700  loss =  154.249\n",
      "testing  :  4616  accuracy =   0.6865  loss =  155.867\n",
      "training :  4617  accuracy =   0.7000  loss =  154.857\n",
      "testing  :  4617  accuracy =   0.6862  loss =  155.773\n",
      "training :  4618  accuracy =   0.6800  loss =  155.764\n",
      "testing  :  4618  accuracy =   0.6870  loss =  155.715\n",
      "training :  4619  accuracy =   0.7200  loss =  153.417\n",
      "testing  :  4619  accuracy =   0.6879  loss =  155.667\n",
      "training :  4620  accuracy =   0.7100  loss =  157.079\n",
      "testing  :  4620  accuracy =   0.6878  loss =  155.585\n",
      "training :  4621  accuracy =   0.6700  loss =  155.616\n",
      "testing  :  4621  accuracy =   0.6884  loss =  155.52\n",
      "training :  4622  accuracy =   0.6200  loss =  153.24\n",
      "testing  :  4622  accuracy =   0.6890  loss =  155.477\n",
      "training :  4623  accuracy =   0.7100  loss =  154.245\n",
      "testing  :  4623  accuracy =   0.6889  loss =  155.456\n",
      "training :  4624  accuracy =   0.7600  loss =  154.304\n",
      "testing  :  4624  accuracy =   0.6899  loss =  155.446\n",
      "training :  4625  accuracy =   0.5800  loss =  156.223\n",
      "testing  :  4625  accuracy =   0.6897  loss =  155.445\n",
      "training :  4626  accuracy =   0.7000  loss =  153.746\n",
      "testing  :  4626  accuracy =   0.6895  loss =  155.468\n",
      "training :  4627  accuracy =   0.6000  loss =  154.454\n",
      "testing  :  4627  accuracy =   0.6898  loss =  155.523\n",
      "training :  4628  accuracy =   0.6200  loss =  159.486\n",
      "testing  :  4628  accuracy =   0.6898  loss =  155.595\n",
      "training :  4629  accuracy =   0.6600  loss =  153.956\n",
      "testing  :  4629  accuracy =   0.6902  loss =  155.623\n",
      "training :  4630  accuracy =   0.7200  loss =  152.812\n",
      "testing  :  4630  accuracy =   0.6904  loss =  155.623\n",
      "training :  4631  accuracy =   0.6700  loss =  156.398\n",
      "testing  :  4631  accuracy =   0.6901  loss =  155.613\n",
      "training :  4632  accuracy =   0.7100  loss =  154.745\n",
      "testing  :  4632  accuracy =   0.6898  loss =  155.603\n",
      "training :  4633  accuracy =   0.6500  loss =  154.122\n",
      "testing  :  4633  accuracy =   0.6898  loss =  155.596\n",
      "training :  4634  accuracy =   0.6500  loss =  153.141\n",
      "testing  :  4634  accuracy =   0.6901  loss =  155.606\n",
      "training :  4635  accuracy =   0.7300  loss =  153.45\n",
      "testing  :  4635  accuracy =   0.6899  loss =  155.63\n",
      "training :  4636  accuracy =   0.7600  loss =  154.22\n",
      "testing  :  4636  accuracy =   0.6909  loss =  155.591\n",
      "training :  4637  accuracy =   0.6900  loss =  155.523\n",
      "testing  :  4637  accuracy =   0.6909  loss =  155.555\n",
      "training :  4638  accuracy =   0.7000  loss =  154.452\n",
      "testing  :  4638  accuracy =   0.6910  loss =  155.53\n",
      "training :  4639  accuracy =   0.6900  loss =  153.918\n",
      "testing  :  4639  accuracy =   0.6907  loss =  155.506\n",
      "training :  4640  accuracy =   0.7200  loss =  153.646\n",
      "testing  :  4640  accuracy =   0.6905  loss =  155.497\n",
      "training :  4641  accuracy =   0.7400  loss =  153.438\n",
      "testing  :  4641  accuracy =   0.6904  loss =  155.496\n",
      "training :  4642  accuracy =   0.7200  loss =  153.96\n",
      "testing  :  4642  accuracy =   0.6902  loss =  155.489\n",
      "training :  4643  accuracy =   0.7500  loss =  152.612\n",
      "testing  :  4643  accuracy =   0.6902  loss =  155.486\n",
      "training :  4644  accuracy =   0.6300  loss =  157.29\n",
      "testing  :  4644  accuracy =   0.6903  loss =  155.484\n",
      "training :  4645  accuracy =   0.7100  loss =  153.462\n",
      "testing  :  4645  accuracy =   0.6909  loss =  155.43\n",
      "training :  4646  accuracy =   0.6800  loss =  155.334\n",
      "testing  :  4646  accuracy =   0.6911  loss =  155.393\n",
      "training :  4647  accuracy =   0.6800  loss =  155.726\n",
      "testing  :  4647  accuracy =   0.6918  loss =  155.343\n",
      "training :  4648  accuracy =   0.7300  loss =  154.533\n",
      "testing  :  4648  accuracy =   0.6924  loss =  155.306\n",
      "training :  4649  accuracy =   0.7500  loss =  154.802\n",
      "testing  :  4649  accuracy =   0.6927  loss =  155.277\n",
      "training :  4650  accuracy =   0.7400  loss =  154.16\n",
      "testing  :  4650  accuracy =   0.6932  loss =  155.259\n",
      "training :  4651  accuracy =   0.7000  loss =  155.551\n",
      "testing  :  4651  accuracy =   0.6931  loss =  155.246\n",
      "training :  4652  accuracy =   0.6000  loss =  156.749\n",
      "testing  :  4652  accuracy =   0.6936  loss =  155.238\n",
      "training :  4653  accuracy =   0.6600  loss =  154.504\n",
      "testing  :  4653  accuracy =   0.6935  loss =  155.235\n",
      "training :  4654  accuracy =   0.7200  loss =  154.201\n",
      "testing  :  4654  accuracy =   0.6934  loss =  155.24\n",
      "training :  4655  accuracy =   0.6700  loss =  154.206\n",
      "testing  :  4655  accuracy =   0.6934  loss =  155.257\n",
      "training :  4656  accuracy =   0.7500  loss =  154.155\n",
      "testing  :  4656  accuracy =   0.6938  loss =  155.287\n",
      "training :  4657  accuracy =   0.6300  loss =  156.341\n",
      "testing  :  4657  accuracy =   0.6940  loss =  155.313\n",
      "training :  4658  accuracy =   0.6900  loss =  154.24\n",
      "testing  :  4658  accuracy =   0.6932  loss =  155.342\n",
      "training :  4659  accuracy =   0.6800  loss =  156.857\n",
      "testing  :  4659  accuracy =   0.6925  loss =  155.375\n",
      "training :  4660  accuracy =   0.7100  loss =  153.73\n",
      "testing  :  4660  accuracy =   0.6925  loss =  155.39\n",
      "training :  4661  accuracy =   0.6700  loss =  153.967\n",
      "testing  :  4661  accuracy =   0.6928  loss =  155.415\n",
      "training :  4662  accuracy =   0.6700  loss =  154.257\n",
      "testing  :  4662  accuracy =   0.6927  loss =  155.457\n",
      "training :  4663  accuracy =   0.6800  loss =  155.307\n",
      "testing  :  4663  accuracy =   0.6917  loss =  155.496\n",
      "training :  4664  accuracy =   0.6500  loss =  155.547\n",
      "testing  :  4664  accuracy =   0.6907  loss =  155.55\n",
      "training :  4665  accuracy =   0.7000  loss =  155.284\n",
      "testing  :  4665  accuracy =   0.6900  loss =  155.605\n",
      "training :  4666  accuracy =   0.6700  loss =  153.722\n",
      "testing  :  4666  accuracy =   0.6895  loss =  155.643\n",
      "training :  4667  accuracy =   0.7300  loss =  153.393\n",
      "testing  :  4667  accuracy =   0.6890  loss =  155.688\n",
      "training :  4668  accuracy =   0.7400  loss =  154.156\n",
      "testing  :  4668  accuracy =   0.6884  loss =  155.749\n",
      "training :  4669  accuracy =   0.7100  loss =  159.784\n",
      "testing  :  4669  accuracy =   0.6878  loss =  155.825\n",
      "training :  4670  accuracy =   0.7000  loss =  156.277\n",
      "testing  :  4670  accuracy =   0.6878  loss =  155.805\n",
      "training :  4671  accuracy =   0.7300  loss =  155.375\n",
      "testing  :  4671  accuracy =   0.6877  loss =  155.823\n",
      "training :  4672  accuracy =   0.7000  loss =  156.783\n",
      "testing  :  4672  accuracy =   0.6873  loss =  155.841\n",
      "training :  4673  accuracy =   0.6000  loss =  160.205\n",
      "testing  :  4673  accuracy =   0.6869  loss =  155.86\n",
      "training :  4674  accuracy =   0.6400  loss =  153.931\n",
      "testing  :  4674  accuracy =   0.6868  loss =  155.879\n",
      "training :  4675  accuracy =   0.6900  loss =  153.969\n",
      "testing  :  4675  accuracy =   0.6870  loss =  155.862\n",
      "training :  4676  accuracy =   0.6400  loss =  156.539\n",
      "testing  :  4676  accuracy =   0.6872  loss =  155.809\n",
      "training :  4677  accuracy =   0.6700  loss =  155.627\n",
      "testing  :  4677  accuracy =   0.6878  loss =  155.763\n",
      "training :  4678  accuracy =   0.7200  loss =  152.612\n",
      "testing  :  4678  accuracy =   0.6883  loss =  155.703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  4679  accuracy =   0.6900  loss =  155.985\n",
      "testing  :  4679  accuracy =   0.6891  loss =  155.658\n",
      "training :  4680  accuracy =   0.7200  loss =  155.914\n",
      "testing  :  4680  accuracy =   0.6896  loss =  155.653\n",
      "training :  4681  accuracy =   0.7600  loss =  155.488\n",
      "testing  :  4681  accuracy =   0.6896  loss =  155.636\n",
      "training :  4682  accuracy =   0.7200  loss =  152.901\n",
      "testing  :  4682  accuracy =   0.6901  loss =  155.614\n",
      "training :  4683  accuracy =   0.6600  loss =  156.912\n",
      "testing  :  4683  accuracy =   0.6902  loss =  155.587\n",
      "training :  4684  accuracy =   0.7000  loss =  154.685\n",
      "testing  :  4684  accuracy =   0.6900  loss =  155.546\n",
      "training :  4685  accuracy =   0.6700  loss =  155.338\n",
      "testing  :  4685  accuracy =   0.6905  loss =  155.504\n",
      "training :  4686  accuracy =   0.7300  loss =  153.755\n",
      "testing  :  4686  accuracy =   0.6907  loss =  155.46\n",
      "training :  4687  accuracy =   0.7200  loss =  154.0\n",
      "testing  :  4687  accuracy =   0.6913  loss =  155.42\n",
      "training :  4688  accuracy =   0.7200  loss =  153.854\n",
      "testing  :  4688  accuracy =   0.6918  loss =  155.383\n",
      "training :  4689  accuracy =   0.7100  loss =  153.231\n",
      "testing  :  4689  accuracy =   0.6923  loss =  155.359\n",
      "training :  4690  accuracy =   0.7000  loss =  153.926\n",
      "testing  :  4690  accuracy =   0.6923  loss =  155.343\n",
      "training :  4691  accuracy =   0.6000  loss =  156.387\n",
      "testing  :  4691  accuracy =   0.6930  loss =  155.328\n",
      "training :  4692  accuracy =   0.7000  loss =  156.123\n",
      "testing  :  4692  accuracy =   0.6934  loss =  155.331\n",
      "training :  4693  accuracy =   0.7000  loss =  155.13\n",
      "testing  :  4693  accuracy =   0.6934  loss =  155.344\n",
      "training :  4694  accuracy =   0.6900  loss =  154.552\n",
      "testing  :  4694  accuracy =   0.6931  loss =  155.357\n",
      "training :  4695  accuracy =   0.6700  loss =  154.977\n",
      "testing  :  4695  accuracy =   0.6937  loss =  155.354\n",
      "training :  4696  accuracy =   0.7500  loss =  155.358\n",
      "testing  :  4696  accuracy =   0.6935  loss =  155.353\n",
      "training :  4697  accuracy =   0.6500  loss =  154.891\n",
      "testing  :  4697  accuracy =   0.6929  loss =  155.383\n",
      "training :  4698  accuracy =   0.6300  loss =  157.246\n",
      "testing  :  4698  accuracy =   0.6925  loss =  155.492\n",
      "training :  4699  accuracy =   0.6800  loss =  155.639\n",
      "testing  :  4699  accuracy =   0.6916  loss =  155.595\n",
      "training :  4700  accuracy =   0.6700  loss =  154.535\n",
      "testing  :  4700  accuracy =   0.6907  loss =  155.664\n",
      "training :  4701  accuracy =   0.7200  loss =  156.409\n",
      "testing  :  4701  accuracy =   0.6902  loss =  155.711\n",
      "training :  4702  accuracy =   0.7000  loss =  155.723\n",
      "testing  :  4702  accuracy =   0.6917  loss =  155.536\n",
      "training :  4703  accuracy =   0.6900  loss =  156.704\n",
      "testing  :  4703  accuracy =   0.6926  loss =  155.407\n",
      "training :  4704  accuracy =   0.7500  loss =  153.876\n",
      "testing  :  4704  accuracy =   0.6934  loss =  155.313\n",
      "training :  4705  accuracy =   0.7200  loss =  154.744\n",
      "testing  :  4705  accuracy =   0.6932  loss =  155.254\n",
      "training :  4706  accuracy =   0.7300  loss =  154.036\n",
      "testing  :  4706  accuracy =   0.6937  loss =  155.232\n",
      "training :  4707  accuracy =   0.6600  loss =  155.119\n",
      "testing  :  4707  accuracy =   0.6936  loss =  155.232\n",
      "training :  4708  accuracy =   0.6900  loss =  156.633\n",
      "testing  :  4708  accuracy =   0.6938  loss =  155.237\n",
      "training :  4709  accuracy =   0.6500  loss =  153.697\n",
      "testing  :  4709  accuracy =   0.6931  loss =  155.26\n",
      "training :  4710  accuracy =   0.7100  loss =  154.521\n",
      "testing  :  4710  accuracy =   0.6926  loss =  155.315\n",
      "training :  4711  accuracy =   0.6400  loss =  155.995\n",
      "testing  :  4711  accuracy =   0.6922  loss =  155.383\n",
      "training :  4712  accuracy =   0.6800  loss =  153.9\n",
      "testing  :  4712  accuracy =   0.6914  loss =  155.451\n",
      "training :  4713  accuracy =   0.7200  loss =  156.227\n",
      "testing  :  4713  accuracy =   0.6907  loss =  155.557\n",
      "training :  4714  accuracy =   0.6600  loss =  154.723\n",
      "testing  :  4714  accuracy =   0.6904  loss =  155.559\n",
      "training :  4715  accuracy =   0.7400  loss =  153.462\n",
      "testing  :  4715  accuracy =   0.6901  loss =  155.494\n",
      "training :  4716  accuracy =   0.6600  loss =  154.522\n",
      "testing  :  4716  accuracy =   0.6910  loss =  155.437\n",
      "training :  4717  accuracy =   0.6900  loss =  154.76\n",
      "testing  :  4717  accuracy =   0.6909  loss =  155.408\n",
      "training :  4718  accuracy =   0.8000  loss =  153.254\n",
      "testing  :  4718  accuracy =   0.6909  loss =  155.398\n",
      "training :  4719  accuracy =   0.6900  loss =  154.06\n",
      "testing  :  4719  accuracy =   0.6908  loss =  155.388\n",
      "training :  4720  accuracy =   0.6900  loss =  154.717\n",
      "testing  :  4720  accuracy =   0.6910  loss =  155.383\n",
      "training :  4721  accuracy =   0.7300  loss =  153.939\n",
      "testing  :  4721  accuracy =   0.6918  loss =  155.384\n",
      "training :  4722  accuracy =   0.7100  loss =  156.722\n",
      "testing  :  4722  accuracy =   0.6910  loss =  155.384\n",
      "training :  4723  accuracy =   0.6500  loss =  153.958\n",
      "testing  :  4723  accuracy =   0.6912  loss =  155.369\n",
      "training :  4724  accuracy =   0.8000  loss =  151.969\n",
      "testing  :  4724  accuracy =   0.6916  loss =  155.339\n",
      "training :  4725  accuracy =   0.6400  loss =  161.47\n",
      "testing  :  4725  accuracy =   0.6921  loss =  155.312\n",
      "training :  4726  accuracy =   0.6500  loss =  154.328\n",
      "testing  :  4726  accuracy =   0.6912  loss =  155.315\n",
      "training :  4727  accuracy =   0.6400  loss =  153.969\n",
      "testing  :  4727  accuracy =   0.6898  loss =  155.458\n",
      "training :  4728  accuracy =   0.7300  loss =  153.309\n",
      "testing  :  4728  accuracy =   0.6875  loss =  155.752\n",
      "training :  4729  accuracy =   0.6900  loss =  156.922\n",
      "testing  :  4729  accuracy =   0.6843  loss =  156.139\n",
      "training :  4730  accuracy =   0.6800  loss =  154.639\n",
      "testing  :  4730  accuracy =   0.6809  loss =  156.493\n",
      "training :  4731  accuracy =   0.6100  loss =  155.262\n",
      "testing  :  4731  accuracy =   0.6833  loss =  156.277\n",
      "training :  4732  accuracy =   0.7700  loss =  156.049\n",
      "testing  :  4732  accuracy =   0.6853  loss =  156.113\n",
      "training :  4733  accuracy =   0.7100  loss =  156.405\n",
      "testing  :  4733  accuracy =   0.6875  loss =  155.891\n",
      "training :  4734  accuracy =   0.6800  loss =  155.526\n",
      "testing  :  4734  accuracy =   0.6886  loss =  155.718\n",
      "training :  4735  accuracy =   0.7500  loss =  152.123\n",
      "testing  :  4735  accuracy =   0.6893  loss =  155.615\n",
      "training :  4736  accuracy =   0.7000  loss =  154.115\n",
      "testing  :  4736  accuracy =   0.6900  loss =  155.576\n",
      "training :  4737  accuracy =   0.6900  loss =  153.962\n",
      "testing  :  4737  accuracy =   0.6905  loss =  155.59\n",
      "training :  4738  accuracy =   0.6600  loss =  157.336\n",
      "testing  :  4738  accuracy =   0.6905  loss =  155.612\n",
      "training :  4739  accuracy =   0.6800  loss =  154.105\n",
      "testing  :  4739  accuracy =   0.6906  loss =  155.593\n",
      "training :  4740  accuracy =   0.6800  loss =  155.524\n",
      "testing  :  4740  accuracy =   0.6906  loss =  155.556\n",
      "training :  4741  accuracy =   0.7000  loss =  154.839\n",
      "testing  :  4741  accuracy =   0.6901  loss =  155.512\n",
      "training :  4742  accuracy =   0.6900  loss =  155.431\n",
      "testing  :  4742  accuracy =   0.6907  loss =  155.479\n",
      "training :  4743  accuracy =   0.6100  loss =  159.966\n",
      "testing  :  4743  accuracy =   0.6905  loss =  155.446\n",
      "training :  4744  accuracy =   0.8100  loss =  152.991\n",
      "testing  :  4744  accuracy =   0.6902  loss =  155.4\n",
      "training :  4745  accuracy =   0.7200  loss =  153.776\n",
      "testing  :  4745  accuracy =   0.6905  loss =  155.346\n",
      "training :  4746  accuracy =   0.7100  loss =  153.059\n",
      "testing  :  4746  accuracy =   0.6913  loss =  155.31\n",
      "training :  4747  accuracy =   0.7400  loss =  152.997\n",
      "testing  :  4747  accuracy =   0.6919  loss =  155.289\n",
      "training :  4748  accuracy =   0.6800  loss =  155.078\n",
      "testing  :  4748  accuracy =   0.6920  loss =  155.285\n",
      "training :  4749  accuracy =   0.7400  loss =  153.258\n",
      "testing  :  4749  accuracy =   0.6923  loss =  155.286\n",
      "training :  4750  accuracy =   0.6800  loss =  154.884\n",
      "testing  :  4750  accuracy =   0.6924  loss =  155.277\n",
      "training :  4751  accuracy =   0.7300  loss =  154.015\n",
      "testing  :  4751  accuracy =   0.6919  loss =  155.262\n",
      "training :  4752  accuracy =   0.7200  loss =  153.248\n",
      "testing  :  4752  accuracy =   0.6919  loss =  155.253\n",
      "training :  4753  accuracy =   0.6000  loss =  156.655\n",
      "testing  :  4753  accuracy =   0.6917  loss =  155.248\n",
      "training :  4754  accuracy =   0.7100  loss =  152.915\n",
      "testing  :  4754  accuracy =   0.6924  loss =  155.26\n",
      "training :  4755  accuracy =   0.7600  loss =  154.002\n",
      "testing  :  4755  accuracy =   0.6929  loss =  155.278\n",
      "training :  4756  accuracy =   0.7900  loss =  153.909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4756  accuracy =   0.6933  loss =  155.266\n",
      "training :  4757  accuracy =   0.6900  loss =  153.289\n",
      "testing  :  4757  accuracy =   0.6932  loss =  155.249\n",
      "training :  4758  accuracy =   0.7300  loss =  154.143\n",
      "testing  :  4758  accuracy =   0.6933  loss =  155.233\n",
      "training :  4759  accuracy =   0.6600  loss =  156.255\n",
      "testing  :  4759  accuracy =   0.6929  loss =  155.202\n",
      "training :  4760  accuracy =   0.7400  loss =  156.073\n",
      "testing  :  4760  accuracy =   0.6929  loss =  155.181\n",
      "training :  4761  accuracy =   0.7800  loss =  152.507\n",
      "testing  :  4761  accuracy =   0.6925  loss =  155.161\n",
      "training :  4762  accuracy =   0.7500  loss =  154.046\n",
      "testing  :  4762  accuracy =   0.6919  loss =  155.155\n",
      "training :  4763  accuracy =   0.6900  loss =  156.186\n",
      "testing  :  4763  accuracy =   0.6922  loss =  155.16\n",
      "training :  4764  accuracy =   0.7000  loss =  152.495\n",
      "testing  :  4764  accuracy =   0.6932  loss =  155.157\n",
      "training :  4765  accuracy =   0.7500  loss =  153.569\n",
      "testing  :  4765  accuracy =   0.6931  loss =  155.153\n",
      "training :  4766  accuracy =   0.6900  loss =  154.369\n",
      "testing  :  4766  accuracy =   0.6934  loss =  155.145\n",
      "training :  4767  accuracy =   0.7800  loss =  155.886\n",
      "testing  :  4767  accuracy =   0.6933  loss =  155.135\n",
      "training :  4768  accuracy =   0.7000  loss =  154.925\n",
      "testing  :  4768  accuracy =   0.6935  loss =  155.114\n",
      "training :  4769  accuracy =   0.6900  loss =  156.192\n",
      "testing  :  4769  accuracy =   0.6940  loss =  155.061\n",
      "training :  4770  accuracy =   0.6400  loss =  154.844\n",
      "testing  :  4770  accuracy =   0.6945  loss =  155.028\n",
      "training :  4771  accuracy =   0.7300  loss =  153.515\n",
      "testing  :  4771  accuracy =   0.6943  loss =  155.025\n",
      "training :  4772  accuracy =   0.6600  loss =  154.491\n",
      "testing  :  4772  accuracy =   0.6943  loss =  155.023\n",
      "training :  4773  accuracy =   0.6300  loss =  153.661\n",
      "testing  :  4773  accuracy =   0.6945  loss =  155.026\n",
      "training :  4774  accuracy =   0.7300  loss =  154.786\n",
      "testing  :  4774  accuracy =   0.6940  loss =  155.033\n",
      "training :  4775  accuracy =   0.6900  loss =  157.293\n",
      "testing  :  4775  accuracy =   0.6941  loss =  155.056\n",
      "training :  4776  accuracy =   0.6800  loss =  154.938\n",
      "testing  :  4776  accuracy =   0.6948  loss =  155.069\n",
      "training :  4777  accuracy =   0.7100  loss =  154.351\n",
      "testing  :  4777  accuracy =   0.6949  loss =  155.084\n",
      "training :  4778  accuracy =   0.7300  loss =  152.887\n",
      "testing  :  4778  accuracy =   0.6948  loss =  155.108\n",
      "training :  4779  accuracy =   0.7700  loss =  151.818\n",
      "testing  :  4779  accuracy =   0.6944  loss =  155.118\n",
      "training :  4780  accuracy =   0.6400  loss =  153.31\n",
      "testing  :  4780  accuracy =   0.6944  loss =  155.126\n",
      "training :  4781  accuracy =   0.6500  loss =  153.727\n",
      "testing  :  4781  accuracy =   0.6943  loss =  155.14\n",
      "training :  4782  accuracy =   0.7600  loss =  153.357\n",
      "testing  :  4782  accuracy =   0.6940  loss =  155.157\n",
      "training :  4783  accuracy =   0.6600  loss =  154.05\n",
      "testing  :  4783  accuracy =   0.6943  loss =  155.176\n",
      "training :  4784  accuracy =   0.6900  loss =  155.292\n",
      "testing  :  4784  accuracy =   0.6940  loss =  155.184\n",
      "training :  4785  accuracy =   0.8000  loss =  153.435\n",
      "testing  :  4785  accuracy =   0.6942  loss =  155.193\n",
      "training :  4786  accuracy =   0.6500  loss =  159.362\n",
      "testing  :  4786  accuracy =   0.6942  loss =  155.184\n",
      "training :  4787  accuracy =   0.6700  loss =  155.297\n",
      "testing  :  4787  accuracy =   0.6939  loss =  155.173\n",
      "training :  4788  accuracy =   0.7300  loss =  155.745\n",
      "testing  :  4788  accuracy =   0.6939  loss =  155.153\n",
      "training :  4789  accuracy =   0.7600  loss =  154.115\n",
      "testing  :  4789  accuracy =   0.6939  loss =  155.131\n",
      "training :  4790  accuracy =   0.7000  loss =  152.939\n",
      "testing  :  4790  accuracy =   0.6942  loss =  155.074\n",
      "training :  4791  accuracy =   0.7900  loss =  152.492\n",
      "testing  :  4791  accuracy =   0.6943  loss =  155.003\n",
      "training :  4792  accuracy =   0.7400  loss =  154.629\n",
      "testing  :  4792  accuracy =   0.6947  loss =  154.925\n",
      "training :  4793  accuracy =   0.7500  loss =  154.234\n",
      "testing  :  4793  accuracy =   0.6946  loss =  154.88\n",
      "training :  4794  accuracy =   0.6900  loss =  153.879\n",
      "testing  :  4794  accuracy =   0.6946  loss =  154.842\n",
      "training :  4795  accuracy =   0.7500  loss =  153.275\n",
      "testing  :  4795  accuracy =   0.6947  loss =  154.786\n",
      "training :  4796  accuracy =   0.7400  loss =  153.56\n",
      "testing  :  4796  accuracy =   0.6948  loss =  154.731\n",
      "training :  4797  accuracy =   0.6600  loss =  153.122\n",
      "testing  :  4797  accuracy =   0.6944  loss =  154.719\n",
      "training :  4798  accuracy =   0.5800  loss =  156.029\n",
      "testing  :  4798  accuracy =   0.6935  loss =  154.759\n",
      "training :  4799  accuracy =   0.7200  loss =  152.484\n",
      "testing  :  4799  accuracy =   0.6925  loss =  154.849\n",
      "training :  4800  accuracy =   0.6600  loss =  153.479\n",
      "testing  :  4800  accuracy =   0.6915  loss =  155.002\n",
      "training :  4801  accuracy =   0.6900  loss =  152.664\n",
      "testing  :  4801  accuracy =   0.6912  loss =  155.016\n",
      "training :  4802  accuracy =   0.7100  loss =  154.584\n",
      "testing  :  4802  accuracy =   0.6908  loss =  155.025\n",
      "training :  4803  accuracy =   0.7200  loss =  154.006\n",
      "testing  :  4803  accuracy =   0.6905  loss =  154.994\n",
      "training :  4804  accuracy =   0.7100  loss =  154.289\n",
      "testing  :  4804  accuracy =   0.6909  loss =  154.933\n",
      "training :  4805  accuracy =   0.7600  loss =  153.072\n",
      "testing  :  4805  accuracy =   0.6911  loss =  154.885\n",
      "training :  4806  accuracy =   0.6800  loss =  155.903\n",
      "testing  :  4806  accuracy =   0.6908  loss =  154.859\n",
      "training :  4807  accuracy =   0.7000  loss =  152.826\n",
      "testing  :  4807  accuracy =   0.6908  loss =  154.832\n",
      "training :  4808  accuracy =   0.6500  loss =  152.965\n",
      "testing  :  4808  accuracy =   0.6917  loss =  154.818\n",
      "training :  4809  accuracy =   0.6400  loss =  153.887\n",
      "testing  :  4809  accuracy =   0.6918  loss =  154.8\n",
      "training :  4810  accuracy =   0.7400  loss =  152.801\n",
      "testing  :  4810  accuracy =   0.6920  loss =  154.771\n",
      "training :  4811  accuracy =   0.6400  loss =  153.031\n",
      "testing  :  4811  accuracy =   0.6925  loss =  154.755\n",
      "training :  4812  accuracy =   0.6900  loss =  154.23\n",
      "testing  :  4812  accuracy =   0.6929  loss =  154.727\n",
      "training :  4813  accuracy =   0.7200  loss =  154.068\n",
      "testing  :  4813  accuracy =   0.6941  loss =  154.695\n",
      "training :  4814  accuracy =   0.7100  loss =  152.843\n",
      "testing  :  4814  accuracy =   0.6945  loss =  154.711\n",
      "training :  4815  accuracy =   0.6600  loss =  153.176\n",
      "testing  :  4815  accuracy =   0.6942  loss =  154.757\n",
      "training :  4816  accuracy =   0.7100  loss =  152.817\n",
      "testing  :  4816  accuracy =   0.6943  loss =  154.838\n",
      "training :  4817  accuracy =   0.7100  loss =  152.945\n",
      "testing  :  4817  accuracy =   0.6954  loss =  154.938\n",
      "training :  4818  accuracy =   0.6400  loss =  154.903\n",
      "testing  :  4818  accuracy =   0.6973  loss =  155.031\n",
      "training :  4819  accuracy =   0.6800  loss =  154.58\n",
      "testing  :  4819  accuracy =   0.6993  loss =  155.101\n",
      "training :  4820  accuracy =   0.6900  loss =  154.46\n",
      "testing  :  4820  accuracy =   0.7021  loss =  155.06\n",
      "training :  4821  accuracy =   0.7100  loss =  154.35\n",
      "testing  :  4821  accuracy =   0.7045  loss =  154.971\n",
      "training :  4822  accuracy =   0.7300  loss =  153.541\n",
      "testing  :  4822  accuracy =   0.7099  loss =  154.884\n",
      "training :  4823  accuracy =   0.8200  loss =  151.488\n",
      "testing  :  4823  accuracy =   0.7176  loss =  154.762\n",
      "training :  4824  accuracy =   0.8300  loss =  152.217\n",
      "testing  :  4824  accuracy =   0.7251  loss =  154.689\n",
      "training :  4825  accuracy =   0.7400  loss =  153.289\n",
      "testing  :  4825  accuracy =   0.7342  loss =  154.666\n",
      "training :  4826  accuracy =   0.7500  loss =  153.297\n",
      "testing  :  4826  accuracy =   0.7443  loss =  154.643\n",
      "training :  4827  accuracy =   0.7100  loss =  154.284\n",
      "testing  :  4827  accuracy =   0.7618  loss =  154.633\n",
      "training :  4828  accuracy =   0.8100  loss =  152.572\n",
      "testing  :  4828  accuracy =   0.7699  loss =  154.644\n",
      "training :  4829  accuracy =   0.8100  loss =  153.422\n",
      "testing  :  4829  accuracy =   0.7724  loss =  154.65\n",
      "training :  4830  accuracy =   0.7900  loss =  153.056\n",
      "testing  :  4830  accuracy =   0.7746  loss =  154.656\n",
      "training :  4831  accuracy =   0.7700  loss =  152.455\n",
      "testing  :  4831  accuracy =   0.7767  loss =  154.643\n",
      "training :  4832  accuracy =   0.8200  loss =  153.179\n",
      "testing  :  4832  accuracy =   0.7799  loss =  154.586\n",
      "training :  4833  accuracy =   0.8900  loss =  152.172\n",
      "testing  :  4833  accuracy =   0.7823  loss =  154.513\n",
      "training :  4834  accuracy =   0.7500  loss =  155.321\n",
      "testing  :  4834  accuracy =   0.7824  loss =  154.481\n",
      "training :  4835  accuracy =   0.7600  loss =  154.784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4835  accuracy =   0.7835  loss =  154.471\n",
      "training :  4836  accuracy =   0.7600  loss =  156.483\n",
      "testing  :  4836  accuracy =   0.7838  loss =  154.5\n",
      "training :  4837  accuracy =   0.8000  loss =  153.808\n",
      "testing  :  4837  accuracy =   0.7837  loss =  154.569\n",
      "training :  4838  accuracy =   0.7200  loss =  154.133\n",
      "testing  :  4838  accuracy =   0.7838  loss =  154.644\n",
      "training :  4839  accuracy =   0.7600  loss =  153.816\n",
      "testing  :  4839  accuracy =   0.7828  loss =  154.719\n",
      "training :  4840  accuracy =   0.8200  loss =  151.834\n",
      "testing  :  4840  accuracy =   0.7823  loss =  154.789\n",
      "training :  4841  accuracy =   0.8100  loss =  152.506\n",
      "testing  :  4841  accuracy =   0.7823  loss =  154.819\n",
      "training :  4842  accuracy =   0.8400  loss =  151.837\n",
      "testing  :  4842  accuracy =   0.7824  loss =  154.822\n",
      "training :  4843  accuracy =   0.8200  loss =  153.632\n",
      "testing  :  4843  accuracy =   0.7834  loss =  154.77\n",
      "training :  4844  accuracy =   0.8600  loss =  151.799\n",
      "testing  :  4844  accuracy =   0.7842  loss =  154.684\n",
      "training :  4845  accuracy =   0.7300  loss =  154.009\n",
      "testing  :  4845  accuracy =   0.7835  loss =  154.585\n",
      "training :  4846  accuracy =   0.7600  loss =  155.305\n",
      "testing  :  4846  accuracy =   0.7826  loss =  154.549\n",
      "training :  4847  accuracy =   0.7400  loss =  154.187\n",
      "testing  :  4847  accuracy =   0.7817  loss =  154.569\n",
      "training :  4848  accuracy =   0.8000  loss =  152.79\n",
      "testing  :  4848  accuracy =   0.7797  loss =  154.642\n",
      "training :  4849  accuracy =   0.7900  loss =  152.588\n",
      "testing  :  4849  accuracy =   0.7780  loss =  154.74\n",
      "training :  4850  accuracy =   0.8700  loss =  152.01\n",
      "testing  :  4850  accuracy =   0.7758  loss =  154.825\n",
      "training :  4851  accuracy =   0.7700  loss =  154.95\n",
      "testing  :  4851  accuracy =   0.7740  loss =  154.937\n",
      "training :  4852  accuracy =   0.7600  loss =  155.012\n",
      "testing  :  4852  accuracy =   0.7717  loss =  154.989\n",
      "training :  4853  accuracy =   0.7500  loss =  155.243\n",
      "testing  :  4853  accuracy =   0.7707  loss =  154.988\n",
      "training :  4854  accuracy =   0.7600  loss =  155.982\n",
      "testing  :  4854  accuracy =   0.7694  loss =  154.995\n",
      "training :  4855  accuracy =   0.8400  loss =  151.747\n",
      "testing  :  4855  accuracy =   0.7710  loss =  154.926\n",
      "training :  4856  accuracy =   0.8100  loss =  152.079\n",
      "testing  :  4856  accuracy =   0.7729  loss =  154.848\n",
      "training :  4857  accuracy =   0.8200  loss =  151.463\n",
      "testing  :  4857  accuracy =   0.7735  loss =  154.808\n",
      "training :  4858  accuracy =   0.8500  loss =  154.301\n",
      "testing  :  4858  accuracy =   0.7741  loss =  154.758\n",
      "training :  4859  accuracy =   0.8400  loss =  153.063\n",
      "testing  :  4859  accuracy =   0.7754  loss =  154.642\n",
      "training :  4860  accuracy =   0.7000  loss =  156.412\n",
      "testing  :  4860  accuracy =   0.7766  loss =  154.544\n",
      "training :  4861  accuracy =   0.7400  loss =  157.051\n",
      "testing  :  4861  accuracy =   0.7775  loss =  154.454\n",
      "training :  4862  accuracy =   0.8300  loss =  151.829\n",
      "testing  :  4862  accuracy =   0.7782  loss =  154.406\n",
      "training :  4863  accuracy =   0.8100  loss =  152.638\n",
      "testing  :  4863  accuracy =   0.7781  loss =  154.388\n",
      "training :  4864  accuracy =   0.8100  loss =  153.288\n",
      "testing  :  4864  accuracy =   0.7776  loss =  154.404\n",
      "training :  4865  accuracy =   0.7800  loss =  152.867\n",
      "testing  :  4865  accuracy =   0.7769  loss =  154.452\n",
      "training :  4866  accuracy =   0.7500  loss =  154.982\n",
      "testing  :  4866  accuracy =   0.7747  loss =  154.498\n",
      "training :  4867  accuracy =   0.8300  loss =  154.063\n",
      "testing  :  4867  accuracy =   0.7727  loss =  154.556\n",
      "training :  4868  accuracy =   0.8100  loss =  153.377\n",
      "testing  :  4868  accuracy =   0.7675  loss =  154.622\n",
      "training :  4869  accuracy =   0.7300  loss =  153.069\n",
      "testing  :  4869  accuracy =   0.7549  loss =  154.705\n",
      "training :  4870  accuracy =   0.7400  loss =  154.623\n",
      "testing  :  4870  accuracy =   0.7440  loss =  154.77\n",
      "training :  4871  accuracy =   0.7900  loss =  152.498\n",
      "testing  :  4871  accuracy =   0.7362  loss =  154.812\n",
      "training :  4872  accuracy =   0.8000  loss =  153.847\n",
      "testing  :  4872  accuracy =   0.7313  loss =  154.752\n",
      "training :  4873  accuracy =   0.7200  loss =  153.187\n",
      "testing  :  4873  accuracy =   0.7268  loss =  154.688\n",
      "training :  4874  accuracy =   0.6900  loss =  154.75\n",
      "testing  :  4874  accuracy =   0.7250  loss =  154.631\n",
      "training :  4875  accuracy =   0.6800  loss =  156.355\n",
      "testing  :  4875  accuracy =   0.7228  loss =  154.584\n",
      "training :  4876  accuracy =   0.7600  loss =  153.37\n",
      "testing  :  4876  accuracy =   0.7254  loss =  154.535\n",
      "training :  4877  accuracy =   0.7600  loss =  151.304\n",
      "testing  :  4877  accuracy =   0.7275  loss =  154.512\n",
      "training :  4878  accuracy =   0.7200  loss =  155.058\n",
      "testing  :  4878  accuracy =   0.7294  loss =  154.493\n",
      "training :  4879  accuracy =   0.7500  loss =  152.939\n",
      "testing  :  4879  accuracy =   0.7384  loss =  154.469\n",
      "training :  4880  accuracy =   0.7600  loss =  154.06\n",
      "testing  :  4880  accuracy =   0.7490  loss =  154.448\n",
      "training :  4881  accuracy =   0.8100  loss =  155.022\n",
      "testing  :  4881  accuracy =   0.7605  loss =  154.45\n",
      "training :  4882  accuracy =   0.7200  loss =  153.384\n",
      "testing  :  4882  accuracy =   0.7699  loss =  154.472\n",
      "training :  4883  accuracy =   0.7500  loss =  154.74\n",
      "testing  :  4883  accuracy =   0.7743  loss =  154.493\n",
      "training :  4884  accuracy =   0.8200  loss =  154.877\n",
      "testing  :  4884  accuracy =   0.7754  loss =  154.517\n",
      "training :  4885  accuracy =   0.7600  loss =  155.941\n",
      "testing  :  4885  accuracy =   0.7774  loss =  154.516\n",
      "training :  4886  accuracy =   0.7800  loss =  155.753\n",
      "testing  :  4886  accuracy =   0.7778  loss =  154.525\n",
      "training :  4887  accuracy =   0.8600  loss =  150.499\n",
      "testing  :  4887  accuracy =   0.7792  loss =  154.495\n",
      "training :  4888  accuracy =   0.8100  loss =  152.406\n",
      "testing  :  4888  accuracy =   0.7802  loss =  154.483\n",
      "training :  4889  accuracy =   0.7700  loss =  154.519\n",
      "testing  :  4889  accuracy =   0.7804  loss =  154.481\n",
      "training :  4890  accuracy =   0.8200  loss =  153.788\n",
      "testing  :  4890  accuracy =   0.7805  loss =  154.454\n",
      "training :  4891  accuracy =   0.8300  loss =  151.85\n",
      "testing  :  4891  accuracy =   0.7803  loss =  154.466\n",
      "training :  4892  accuracy =   0.8100  loss =  154.587\n",
      "testing  :  4892  accuracy =   0.7804  loss =  154.472\n",
      "training :  4893  accuracy =   0.7900  loss =  152.764\n",
      "testing  :  4893  accuracy =   0.7795  loss =  154.454\n",
      "training :  4894  accuracy =   0.7800  loss =  154.136\n",
      "testing  :  4894  accuracy =   0.7794  loss =  154.455\n",
      "training :  4895  accuracy =   0.7800  loss =  151.959\n",
      "testing  :  4895  accuracy =   0.7800  loss =  154.453\n",
      "training :  4896  accuracy =   0.7700  loss =  154.866\n",
      "testing  :  4896  accuracy =   0.7807  loss =  154.453\n",
      "training :  4897  accuracy =   0.8000  loss =  154.13\n",
      "testing  :  4897  accuracy =   0.7811  loss =  154.463\n",
      "training :  4898  accuracy =   0.7600  loss =  153.148\n",
      "testing  :  4898  accuracy =   0.7818  loss =  154.464\n",
      "training :  4899  accuracy =   0.7300  loss =  156.424\n",
      "testing  :  4899  accuracy =   0.7822  loss =  154.467\n",
      "training :  4900  accuracy =   0.7900  loss =  153.451\n",
      "testing  :  4900  accuracy =   0.7833  loss =  154.446\n",
      "training :  4901  accuracy =   0.8100  loss =  152.963\n",
      "testing  :  4901  accuracy =   0.7831  loss =  154.418\n",
      "training :  4902  accuracy =   0.7700  loss =  156.581\n",
      "testing  :  4902  accuracy =   0.7834  loss =  154.402\n",
      "training :  4903  accuracy =   0.8600  loss =  152.962\n",
      "testing  :  4903  accuracy =   0.7830  loss =  154.378\n",
      "training :  4904  accuracy =   0.7800  loss =  152.526\n",
      "testing  :  4904  accuracy =   0.7830  loss =  154.368\n",
      "training :  4905  accuracy =   0.7900  loss =  154.678\n",
      "testing  :  4905  accuracy =   0.7826  loss =  154.353\n",
      "training :  4906  accuracy =   0.7300  loss =  156.566\n",
      "testing  :  4906  accuracy =   0.7823  loss =  154.34\n",
      "training :  4907  accuracy =   0.8600  loss =  151.055\n",
      "testing  :  4907  accuracy =   0.7815  loss =  154.329\n",
      "training :  4908  accuracy =   0.8000  loss =  153.062\n",
      "testing  :  4908  accuracy =   0.7810  loss =  154.36\n",
      "training :  4909  accuracy =   0.7600  loss =  153.233\n",
      "testing  :  4909  accuracy =   0.7799  loss =  154.412\n",
      "training :  4910  accuracy =   0.7500  loss =  155.175\n",
      "testing  :  4910  accuracy =   0.7800  loss =  154.416\n",
      "training :  4911  accuracy =   0.7600  loss =  152.208\n",
      "testing  :  4911  accuracy =   0.7794  loss =  154.441\n",
      "training :  4912  accuracy =   0.7600  loss =  154.339\n",
      "testing  :  4912  accuracy =   0.7792  loss =  154.484\n",
      "training :  4913  accuracy =   0.8300  loss =  154.762\n",
      "testing  :  4913  accuracy =   0.7790  loss =  154.423\n",
      "training :  4914  accuracy =   0.8200  loss =  153.424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4914  accuracy =   0.7800  loss =  154.314\n",
      "training :  4915  accuracy =   0.8000  loss =  153.591\n",
      "testing  :  4915  accuracy =   0.7799  loss =  154.314\n",
      "training :  4916  accuracy =   0.7400  loss =  155.598\n",
      "testing  :  4916  accuracy =   0.7795  loss =  154.344\n",
      "training :  4917  accuracy =   0.8100  loss =  153.746\n",
      "testing  :  4917  accuracy =   0.7789  loss =  154.404\n",
      "training :  4918  accuracy =   0.7500  loss =  155.226\n",
      "testing  :  4918  accuracy =   0.7786  loss =  154.479\n",
      "training :  4919  accuracy =   0.7700  loss =  153.376\n",
      "testing  :  4919  accuracy =   0.7780  loss =  154.547\n",
      "training :  4920  accuracy =   0.7900  loss =  151.919\n",
      "testing  :  4920  accuracy =   0.7773  loss =  154.6\n",
      "training :  4921  accuracy =   0.8400  loss =  153.713\n",
      "testing  :  4921  accuracy =   0.7769  loss =  154.651\n",
      "training :  4922  accuracy =   0.7900  loss =  153.558\n",
      "testing  :  4922  accuracy =   0.7767  loss =  154.678\n",
      "training :  4923  accuracy =   0.7800  loss =  154.242\n",
      "testing  :  4923  accuracy =   0.7766  loss =  154.723\n",
      "training :  4924  accuracy =   0.7300  loss =  154.901\n",
      "testing  :  4924  accuracy =   0.7760  loss =  154.732\n",
      "training :  4925  accuracy =   0.8300  loss =  153.191\n",
      "testing  :  4925  accuracy =   0.7765  loss =  154.683\n",
      "training :  4926  accuracy =   0.8300  loss =  150.682\n",
      "testing  :  4926  accuracy =   0.7771  loss =  154.64\n",
      "training :  4927  accuracy =   0.7700  loss =  153.845\n",
      "testing  :  4927  accuracy =   0.7777  loss =  154.606\n",
      "training :  4928  accuracy =   0.7700  loss =  155.004\n",
      "testing  :  4928  accuracy =   0.7798  loss =  154.556\n",
      "training :  4929  accuracy =   0.7900  loss =  152.015\n",
      "testing  :  4929  accuracy =   0.7811  loss =  154.491\n",
      "training :  4930  accuracy =   0.7300  loss =  153.524\n",
      "testing  :  4930  accuracy =   0.7822  loss =  154.446\n",
      "training :  4931  accuracy =   0.7900  loss =  152.69\n",
      "testing  :  4931  accuracy =   0.7818  loss =  154.423\n",
      "training :  4932  accuracy =   0.7400  loss =  153.973\n",
      "testing  :  4932  accuracy =   0.7812  loss =  154.423\n",
      "training :  4933  accuracy =   0.8100  loss =  153.542\n",
      "testing  :  4933  accuracy =   0.7815  loss =  154.441\n",
      "training :  4934  accuracy =   0.7900  loss =  152.937\n",
      "testing  :  4934  accuracy =   0.7815  loss =  154.467\n",
      "training :  4935  accuracy =   0.8200  loss =  153.532\n",
      "testing  :  4935  accuracy =   0.7803  loss =  154.489\n",
      "training :  4936  accuracy =   0.7400  loss =  155.369\n",
      "testing  :  4936  accuracy =   0.7802  loss =  154.49\n",
      "training :  4937  accuracy =   0.8500  loss =  153.648\n",
      "testing  :  4937  accuracy =   0.7803  loss =  154.442\n",
      "training :  4938  accuracy =   0.7500  loss =  154.239\n",
      "testing  :  4938  accuracy =   0.7812  loss =  154.41\n",
      "training :  4939  accuracy =   0.7100  loss =  157.307\n",
      "testing  :  4939  accuracy =   0.7815  loss =  154.394\n",
      "training :  4940  accuracy =   0.8400  loss =  151.816\n",
      "testing  :  4940  accuracy =   0.7814  loss =  154.396\n",
      "training :  4941  accuracy =   0.7800  loss =  152.259\n",
      "testing  :  4941  accuracy =   0.7813  loss =  154.404\n",
      "training :  4942  accuracy =   0.7500  loss =  153.963\n",
      "testing  :  4942  accuracy =   0.7819  loss =  154.399\n",
      "training :  4943  accuracy =   0.8500  loss =  152.816\n",
      "testing  :  4943  accuracy =   0.7819  loss =  154.391\n",
      "training :  4944  accuracy =   0.7800  loss =  152.741\n",
      "testing  :  4944  accuracy =   0.7827  loss =  154.362\n",
      "training :  4945  accuracy =   0.8300  loss =  153.24\n",
      "testing  :  4945  accuracy =   0.7834  loss =  154.347\n",
      "training :  4946  accuracy =   0.7900  loss =  151.572\n",
      "testing  :  4946  accuracy =   0.7834  loss =  154.338\n",
      "training :  4947  accuracy =   0.7300  loss =  154.98\n",
      "testing  :  4947  accuracy =   0.7838  loss =  154.336\n",
      "training :  4948  accuracy =   0.8200  loss =  153.387\n",
      "testing  :  4948  accuracy =   0.7839  loss =  154.339\n",
      "training :  4949  accuracy =   0.8400  loss =  152.493\n",
      "testing  :  4949  accuracy =   0.7840  loss =  154.346\n",
      "training :  4950  accuracy =   0.8200  loss =  152.121\n",
      "testing  :  4950  accuracy =   0.7840  loss =  154.345\n",
      "training :  4951  accuracy =   0.8000  loss =  152.819\n",
      "testing  :  4951  accuracy =   0.7835  loss =  154.351\n",
      "training :  4952  accuracy =   0.7800  loss =  155.511\n",
      "testing  :  4952  accuracy =   0.7827  loss =  154.359\n",
      "training :  4953  accuracy =   0.8000  loss =  154.585\n",
      "testing  :  4953  accuracy =   0.7831  loss =  154.347\n",
      "training :  4954  accuracy =   0.7500  loss =  151.659\n",
      "testing  :  4954  accuracy =   0.7835  loss =  154.334\n",
      "training :  4955  accuracy =   0.7700  loss =  153.205\n",
      "testing  :  4955  accuracy =   0.7840  loss =  154.327\n",
      "training :  4956  accuracy =   0.7900  loss =  154.413\n",
      "testing  :  4956  accuracy =   0.7839  loss =  154.334\n",
      "training :  4957  accuracy =   0.8700  loss =  151.128\n",
      "testing  :  4957  accuracy =   0.7840  loss =  154.348\n",
      "training :  4958  accuracy =   0.8100  loss =  152.469\n",
      "testing  :  4958  accuracy =   0.7843  loss =  154.341\n",
      "training :  4959  accuracy =   0.8200  loss =  153.668\n",
      "testing  :  4959  accuracy =   0.7844  loss =  154.332\n",
      "training :  4960  accuracy =   0.7700  loss =  153.32\n",
      "testing  :  4960  accuracy =   0.7841  loss =  154.327\n",
      "training :  4961  accuracy =   0.7600  loss =  154.513\n",
      "testing  :  4961  accuracy =   0.7842  loss =  154.326\n",
      "training :  4962  accuracy =   0.7700  loss =  154.46\n",
      "testing  :  4962  accuracy =   0.7845  loss =  154.328\n",
      "training :  4963  accuracy =   0.7900  loss =  152.773\n",
      "testing  :  4963  accuracy =   0.7839  loss =  154.337\n",
      "training :  4964  accuracy =   0.7200  loss =  154.38\n",
      "testing  :  4964  accuracy =   0.7839  loss =  154.34\n",
      "training :  4965  accuracy =   0.7800  loss =  151.433\n",
      "testing  :  4965  accuracy =   0.7841  loss =  154.331\n",
      "training :  4966  accuracy =   0.8500  loss =  153.258\n",
      "testing  :  4966  accuracy =   0.7843  loss =  154.33\n",
      "training :  4967  accuracy =   0.7700  loss =  154.73\n",
      "testing  :  4967  accuracy =   0.7840  loss =  154.294\n",
      "training :  4968  accuracy =   0.7200  loss =  156.082\n",
      "testing  :  4968  accuracy =   0.7836  loss =  154.254\n",
      "training :  4969  accuracy =   0.8300  loss =  155.257\n",
      "testing  :  4969  accuracy =   0.7840  loss =  154.236\n",
      "training :  4970  accuracy =   0.8000  loss =  152.214\n",
      "testing  :  4970  accuracy =   0.7835  loss =  154.226\n",
      "training :  4971  accuracy =   0.8100  loss =  153.042\n",
      "testing  :  4971  accuracy =   0.7830  loss =  154.22\n",
      "training :  4972  accuracy =   0.7600  loss =  152.481\n",
      "testing  :  4972  accuracy =   0.7823  loss =  154.221\n",
      "training :  4973  accuracy =   0.7400  loss =  156.678\n",
      "testing  :  4973  accuracy =   0.7816  loss =  154.229\n",
      "training :  4974  accuracy =   0.8600  loss =  154.744\n",
      "testing  :  4974  accuracy =   0.7802  loss =  154.242\n",
      "training :  4975  accuracy =   0.7600  loss =  152.381\n",
      "testing  :  4975  accuracy =   0.7792  loss =  154.255\n",
      "training :  4976  accuracy =   0.7600  loss =  155.189\n",
      "testing  :  4976  accuracy =   0.7778  loss =  154.257\n",
      "training :  4977  accuracy =   0.7800  loss =  153.666\n",
      "testing  :  4977  accuracy =   0.7776  loss =  154.265\n",
      "training :  4978  accuracy =   0.7000  loss =  154.491\n",
      "testing  :  4978  accuracy =   0.7773  loss =  154.259\n",
      "training :  4979  accuracy =   0.8000  loss =  151.217\n",
      "testing  :  4979  accuracy =   0.7763  loss =  154.263\n",
      "training :  4980  accuracy =   0.7600  loss =  153.099\n",
      "testing  :  4980  accuracy =   0.7760  loss =  154.277\n",
      "training :  4981  accuracy =   0.8000  loss =  153.528\n",
      "testing  :  4981  accuracy =   0.7760  loss =  154.294\n",
      "training :  4982  accuracy =   0.7600  loss =  152.09\n",
      "testing  :  4982  accuracy =   0.7755  loss =  154.312\n",
      "training :  4983  accuracy =   0.7700  loss =  153.497\n",
      "testing  :  4983  accuracy =   0.7754  loss =  154.328\n",
      "training :  4984  accuracy =   0.8200  loss =  152.251\n",
      "testing  :  4984  accuracy =   0.7755  loss =  154.336\n",
      "training :  4985  accuracy =   0.7200  loss =  154.616\n",
      "testing  :  4985  accuracy =   0.7751  loss =  154.338\n",
      "training :  4986  accuracy =   0.7500  loss =  152.388\n",
      "testing  :  4986  accuracy =   0.7760  loss =  154.293\n",
      "training :  4987  accuracy =   0.8300  loss =  151.749\n",
      "testing  :  4987  accuracy =   0.7768  loss =  154.251\n",
      "training :  4988  accuracy =   0.7800  loss =  153.698\n",
      "testing  :  4988  accuracy =   0.7776  loss =  154.22\n",
      "training :  4989  accuracy =   0.7100  loss =  155.668\n",
      "testing  :  4989  accuracy =   0.7785  loss =  154.183\n",
      "training :  4990  accuracy =   0.7500  loss =  151.868\n",
      "testing  :  4990  accuracy =   0.7791  loss =  154.185\n",
      "training :  4991  accuracy =   0.8200  loss =  153.184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  4991  accuracy =   0.7804  loss =  154.192\n",
      "training :  4992  accuracy =   0.7400  loss =  155.461\n",
      "testing  :  4992  accuracy =   0.7808  loss =  154.206\n",
      "training :  4993  accuracy =   0.8300  loss =  152.185\n",
      "testing  :  4993  accuracy =   0.7807  loss =  154.233\n",
      "training :  4994  accuracy =   0.8000  loss =  153.321\n",
      "testing  :  4994  accuracy =   0.7813  loss =  154.227\n",
      "training :  4995  accuracy =   0.8000  loss =  152.772\n",
      "testing  :  4995  accuracy =   0.7819  loss =  154.173\n",
      "training :  4996  accuracy =   0.8900  loss =  152.103\n",
      "testing  :  4996  accuracy =   0.7826  loss =  154.135\n",
      "training :  4997  accuracy =   0.9200  loss =  150.549\n",
      "testing  :  4997  accuracy =   0.7826  loss =  154.134\n",
      "training :  4998  accuracy =   0.7700  loss =  152.908\n",
      "testing  :  4998  accuracy =   0.7831  loss =  154.134\n",
      "training :  4999  accuracy =   0.7500  loss =  152.161\n",
      "testing  :  4999  accuracy =   0.7836  loss =  154.119\n",
      "training :  5000  accuracy =   0.8300  loss =  151.434\n",
      "testing  :  5000  accuracy =   0.7838  loss =  154.111\n",
      "training :  5001  accuracy =   0.7600  loss =  154.723\n",
      "testing  :  5001  accuracy =   0.7832  loss =  154.105\n",
      "training :  5002  accuracy =   0.8000  loss =  153.757\n",
      "testing  :  5002  accuracy =   0.7834  loss =  154.112\n",
      "training :  5003  accuracy =   0.8000  loss =  153.79\n",
      "testing  :  5003  accuracy =   0.7829  loss =  154.132\n",
      "training :  5004  accuracy =   0.8500  loss =  152.172\n",
      "testing  :  5004  accuracy =   0.7835  loss =  154.113\n",
      "training :  5005  accuracy =   0.7800  loss =  152.539\n",
      "testing  :  5005  accuracy =   0.7841  loss =  154.086\n",
      "training :  5006  accuracy =   0.7800  loss =  153.905\n",
      "testing  :  5006  accuracy =   0.7846  loss =  154.085\n",
      "training :  5007  accuracy =   0.8200  loss =  153.548\n",
      "testing  :  5007  accuracy =   0.7854  loss =  154.119\n",
      "training :  5008  accuracy =   0.8100  loss =  151.413\n",
      "testing  :  5008  accuracy =   0.7849  loss =  154.181\n",
      "training :  5009  accuracy =   0.8000  loss =  152.158\n",
      "testing  :  5009  accuracy =   0.7845  loss =  154.241\n",
      "training :  5010  accuracy =   0.8600  loss =  150.805\n",
      "testing  :  5010  accuracy =   0.7849  loss =  154.309\n",
      "training :  5011  accuracy =   0.7800  loss =  153.138\n",
      "testing  :  5011  accuracy =   0.7845  loss =  154.374\n",
      "training :  5012  accuracy =   0.7300  loss =  153.967\n",
      "testing  :  5012  accuracy =   0.7841  loss =  154.385\n",
      "training :  5013  accuracy =   0.7800  loss =  153.321\n",
      "testing  :  5013  accuracy =   0.7840  loss =  154.388\n",
      "training :  5014  accuracy =   0.8500  loss =  151.948\n",
      "testing  :  5014  accuracy =   0.7842  loss =  154.395\n",
      "training :  5015  accuracy =   0.8300  loss =  153.669\n",
      "testing  :  5015  accuracy =   0.7844  loss =  154.354\n",
      "training :  5016  accuracy =   0.7800  loss =  153.874\n",
      "testing  :  5016  accuracy =   0.7846  loss =  154.305\n",
      "training :  5017  accuracy =   0.8000  loss =  152.877\n",
      "testing  :  5017  accuracy =   0.7854  loss =  154.269\n",
      "training :  5018  accuracy =   0.7500  loss =  155.701\n",
      "testing  :  5018  accuracy =   0.7844  loss =  154.26\n",
      "training :  5019  accuracy =   0.8600  loss =  150.382\n",
      "testing  :  5019  accuracy =   0.7839  loss =  154.284\n",
      "training :  5020  accuracy =   0.8000  loss =  151.837\n",
      "testing  :  5020  accuracy =   0.7834  loss =  154.331\n",
      "training :  5021  accuracy =   0.8500  loss =  152.55\n",
      "testing  :  5021  accuracy =   0.7830  loss =  154.386\n",
      "training :  5022  accuracy =   0.7900  loss =  153.022\n",
      "testing  :  5022  accuracy =   0.7829  loss =  154.426\n",
      "training :  5023  accuracy =   0.8600  loss =  151.527\n",
      "testing  :  5023  accuracy =   0.7826  loss =  154.447\n",
      "training :  5024  accuracy =   0.8100  loss =  151.542\n",
      "testing  :  5024  accuracy =   0.7825  loss =  154.459\n",
      "training :  5025  accuracy =   0.7900  loss =  152.467\n",
      "testing  :  5025  accuracy =   0.7822  loss =  154.467\n",
      "training :  5026  accuracy =   0.7900  loss =  151.887\n",
      "testing  :  5026  accuracy =   0.7816  loss =  154.48\n",
      "training :  5027  accuracy =   0.7500  loss =  156.7\n",
      "testing  :  5027  accuracy =   0.7815  loss =  154.465\n",
      "training :  5028  accuracy =   0.7600  loss =  153.728\n",
      "testing  :  5028  accuracy =   0.7817  loss =  154.447\n",
      "training :  5029  accuracy =   0.7300  loss =  158.419\n",
      "testing  :  5029  accuracy =   0.7817  loss =  154.416\n",
      "training :  5030  accuracy =   0.7700  loss =  153.775\n",
      "testing  :  5030  accuracy =   0.7818  loss =  154.373\n",
      "training :  5031  accuracy =   0.7700  loss =  152.889\n",
      "testing  :  5031  accuracy =   0.7816  loss =  154.355\n",
      "training :  5032  accuracy =   0.6800  loss =  155.583\n",
      "testing  :  5032  accuracy =   0.7822  loss =  154.325\n",
      "training :  5033  accuracy =   0.7800  loss =  154.893\n",
      "testing  :  5033  accuracy =   0.7823  loss =  154.305\n",
      "training :  5034  accuracy =   0.8400  loss =  152.975\n",
      "testing  :  5034  accuracy =   0.7828  loss =  154.272\n",
      "training :  5035  accuracy =   0.8000  loss =  152.202\n",
      "testing  :  5035  accuracy =   0.7839  loss =  154.239\n",
      "training :  5036  accuracy =   0.7900  loss =  154.746\n",
      "testing  :  5036  accuracy =   0.7844  loss =  154.232\n",
      "training :  5037  accuracy =   0.7700  loss =  152.631\n",
      "testing  :  5037  accuracy =   0.7856  loss =  154.255\n",
      "training :  5038  accuracy =   0.8400  loss =  152.956\n",
      "testing  :  5038  accuracy =   0.7862  loss =  154.319\n",
      "training :  5039  accuracy =   0.8200  loss =  153.362\n",
      "testing  :  5039  accuracy =   0.7864  loss =  154.401\n",
      "training :  5040  accuracy =   0.7400  loss =  153.101\n",
      "testing  :  5040  accuracy =   0.7865  loss =  154.51\n",
      "training :  5041  accuracy =   0.8300  loss =  153.891\n",
      "testing  :  5041  accuracy =   0.7858  loss =  154.61\n",
      "training :  5042  accuracy =   0.8000  loss =  154.796\n",
      "testing  :  5042  accuracy =   0.7856  loss =  154.676\n",
      "training :  5043  accuracy =   0.8100  loss =  152.044\n",
      "testing  :  5043  accuracy =   0.7860  loss =  154.587\n",
      "training :  5044  accuracy =   0.8100  loss =  152.583\n",
      "testing  :  5044  accuracy =   0.7862  loss =  154.433\n",
      "training :  5045  accuracy =   0.7900  loss =  154.34\n",
      "testing  :  5045  accuracy =   0.7869  loss =  154.308\n",
      "training :  5046  accuracy =   0.8000  loss =  152.622\n",
      "testing  :  5046  accuracy =   0.7877  loss =  154.228\n",
      "training :  5047  accuracy =   0.8500  loss =  152.287\n",
      "testing  :  5047  accuracy =   0.7875  loss =  154.18\n",
      "training :  5048  accuracy =   0.8800  loss =  151.102\n",
      "testing  :  5048  accuracy =   0.7875  loss =  154.159\n",
      "training :  5049  accuracy =   0.7300  loss =  153.29\n",
      "testing  :  5049  accuracy =   0.7882  loss =  154.144\n",
      "training :  5050  accuracy =   0.8000  loss =  152.749\n",
      "testing  :  5050  accuracy =   0.7869  loss =  154.133\n",
      "training :  5051  accuracy =   0.7800  loss =  153.832\n",
      "testing  :  5051  accuracy =   0.7866  loss =  154.136\n",
      "training :  5052  accuracy =   0.7800  loss =  152.379\n",
      "testing  :  5052  accuracy =   0.7858  loss =  154.176\n",
      "training :  5053  accuracy =   0.8600  loss =  151.416\n",
      "testing  :  5053  accuracy =   0.7850  loss =  154.215\n",
      "training :  5054  accuracy =   0.8700  loss =  151.68\n",
      "testing  :  5054  accuracy =   0.7841  loss =  154.23\n",
      "training :  5055  accuracy =   0.8300  loss =  151.823\n",
      "testing  :  5055  accuracy =   0.7838  loss =  154.237\n",
      "training :  5056  accuracy =   0.8100  loss =  151.631\n",
      "testing  :  5056  accuracy =   0.7829  loss =  154.241\n",
      "training :  5057  accuracy =   0.7800  loss =  154.149\n",
      "testing  :  5057  accuracy =   0.7831  loss =  154.283\n",
      "training :  5058  accuracy =   0.7800  loss =  153.38\n",
      "testing  :  5058  accuracy =   0.7828  loss =  154.352\n",
      "training :  5059  accuracy =   0.8200  loss =  152.373\n",
      "testing  :  5059  accuracy =   0.7827  loss =  154.433\n",
      "training :  5060  accuracy =   0.7900  loss =  153.609\n",
      "testing  :  5060  accuracy =   0.7823  loss =  154.524\n",
      "training :  5061  accuracy =   0.7500  loss =  156.18\n",
      "testing  :  5061  accuracy =   0.7816  loss =  154.576\n",
      "training :  5062  accuracy =   0.8200  loss =  153.648\n",
      "testing  :  5062  accuracy =   0.7807  loss =  154.655\n",
      "training :  5063  accuracy =   0.8200  loss =  153.437\n",
      "testing  :  5063  accuracy =   0.7808  loss =  154.652\n",
      "training :  5064  accuracy =   0.7900  loss =  152.868\n",
      "testing  :  5064  accuracy =   0.7811  loss =  154.614\n",
      "training :  5065  accuracy =   0.7900  loss =  152.275\n",
      "testing  :  5065  accuracy =   0.7821  loss =  154.538\n",
      "training :  5066  accuracy =   0.8200  loss =  151.719\n",
      "testing  :  5066  accuracy =   0.7840  loss =  154.389\n",
      "training :  5067  accuracy =   0.8100  loss =  153.676\n",
      "testing  :  5067  accuracy =   0.7877  loss =  154.316\n",
      "training :  5068  accuracy =   0.7900  loss =  152.685\n",
      "testing  :  5068  accuracy =   0.7915  loss =  154.274\n",
      "training :  5069  accuracy =   0.8500  loss =  151.372\n",
      "testing  :  5069  accuracy =   0.8028  loss =  154.253\n",
      "training :  5070  accuracy =   0.8500  loss =  152.453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5070  accuracy =   0.8093  loss =  154.258\n",
      "training :  5071  accuracy =   0.8700  loss =  150.268\n",
      "testing  :  5071  accuracy =   0.8185  loss =  154.283\n",
      "training :  5072  accuracy =   0.8300  loss =  152.909\n",
      "testing  :  5072  accuracy =   0.8254  loss =  154.341\n",
      "training :  5073  accuracy =   0.8100  loss =  152.659\n",
      "testing  :  5073  accuracy =   0.8316  loss =  154.423\n",
      "training :  5074  accuracy =   0.8900  loss =  151.869\n",
      "testing  :  5074  accuracy =   0.8392  loss =  154.464\n",
      "training :  5075  accuracy =   0.7800  loss =  157.416\n",
      "testing  :  5075  accuracy =   0.8156  loss =  154.516\n",
      "training :  5076  accuracy =   0.7800  loss =  152.538\n",
      "testing  :  5076  accuracy =   0.8085  loss =  154.524\n",
      "training :  5077  accuracy =   0.9100  loss =  151.003\n",
      "testing  :  5077  accuracy =   0.8049  loss =  154.526\n",
      "training :  5078  accuracy =   0.8300  loss =  152.261\n",
      "testing  :  5078  accuracy =   0.8023  loss =  154.489\n",
      "training :  5079  accuracy =   0.8200  loss =  154.281\n",
      "testing  :  5079  accuracy =   0.7997  loss =  154.461\n",
      "training :  5080  accuracy =   0.8200  loss =  153.929\n",
      "testing  :  5080  accuracy =   0.7984  loss =  154.461\n",
      "training :  5081  accuracy =   0.8200  loss =  154.021\n",
      "testing  :  5081  accuracy =   0.7981  loss =  154.392\n",
      "training :  5082  accuracy =   0.8700  loss =  152.397\n",
      "testing  :  5082  accuracy =   0.7983  loss =  154.337\n",
      "training :  5083  accuracy =   0.8300  loss =  151.103\n",
      "testing  :  5083  accuracy =   0.8009  loss =  154.269\n",
      "training :  5084  accuracy =   0.7400  loss =  153.995\n",
      "testing  :  5084  accuracy =   0.8059  loss =  154.234\n",
      "training :  5085  accuracy =   0.8300  loss =  151.143\n",
      "testing  :  5085  accuracy =   0.8185  loss =  154.206\n",
      "training :  5086  accuracy =   0.8800  loss =  153.863\n",
      "testing  :  5086  accuracy =   0.8519  loss =  154.194\n",
      "training :  5087  accuracy =   0.8600  loss =  154.284\n",
      "testing  :  5087  accuracy =   0.8346  loss =  154.194\n",
      "training :  5088  accuracy =   0.8100  loss =  152.952\n",
      "testing  :  5088  accuracy =   0.8088  loss =  154.217\n",
      "training :  5089  accuracy =   0.7600  loss =  153.082\n",
      "testing  :  5089  accuracy =   0.7937  loss =  154.257\n",
      "training :  5090  accuracy =   0.7900  loss =  153.985\n",
      "testing  :  5090  accuracy =   0.7868  loss =  154.3\n",
      "training :  5091  accuracy =   0.7800  loss =  154.224\n",
      "testing  :  5091  accuracy =   0.7842  loss =  154.335\n",
      "training :  5092  accuracy =   0.7800  loss =  154.481\n",
      "testing  :  5092  accuracy =   0.7827  loss =  154.385\n",
      "training :  5093  accuracy =   0.8200  loss =  152.028\n",
      "testing  :  5093  accuracy =   0.7820  loss =  154.422\n",
      "training :  5094  accuracy =   0.7900  loss =  151.854\n",
      "testing  :  5094  accuracy =   0.7817  loss =  154.44\n",
      "training :  5095  accuracy =   0.8200  loss =  153.853\n",
      "testing  :  5095  accuracy =   0.7815  loss =  154.414\n",
      "training :  5096  accuracy =   0.8300  loss =  152.334\n",
      "testing  :  5096  accuracy =   0.7812  loss =  154.386\n",
      "training :  5097  accuracy =   0.7900  loss =  153.879\n",
      "testing  :  5097  accuracy =   0.7812  loss =  154.358\n",
      "training :  5098  accuracy =   0.7700  loss =  152.18\n",
      "testing  :  5098  accuracy =   0.7820  loss =  154.293\n",
      "training :  5099  accuracy =   0.8700  loss =  151.346\n",
      "testing  :  5099  accuracy =   0.7824  loss =  154.234\n",
      "training :  5100  accuracy =   0.8100  loss =  152.542\n",
      "testing  :  5100  accuracy =   0.7840  loss =  154.179\n",
      "training :  5101  accuracy =   0.8000  loss =  153.08\n",
      "testing  :  5101  accuracy =   0.7845  loss =  154.153\n",
      "training :  5102  accuracy =   0.8300  loss =  151.953\n",
      "testing  :  5102  accuracy =   0.7846  loss =  154.162\n",
      "training :  5103  accuracy =   0.8300  loss =  153.219\n",
      "testing  :  5103  accuracy =   0.7844  loss =  154.194\n",
      "training :  5104  accuracy =   0.7400  loss =  153.291\n",
      "testing  :  5104  accuracy =   0.7841  loss =  154.238\n",
      "training :  5105  accuracy =   0.8500  loss =  152.336\n",
      "testing  :  5105  accuracy =   0.7843  loss =  154.25\n",
      "training :  5106  accuracy =   0.7400  loss =  153.785\n",
      "testing  :  5106  accuracy =   0.7848  loss =  154.22\n",
      "training :  5107  accuracy =   0.7900  loss =  153.14\n",
      "testing  :  5107  accuracy =   0.7844  loss =  154.129\n",
      "training :  5108  accuracy =   0.7100  loss =  153.357\n",
      "testing  :  5108  accuracy =   0.7841  loss =  154.079\n",
      "training :  5109  accuracy =   0.7400  loss =  155.55\n",
      "testing  :  5109  accuracy =   0.7841  loss =  154.059\n",
      "training :  5110  accuracy =   0.7900  loss =  153.716\n",
      "testing  :  5110  accuracy =   0.7844  loss =  154.064\n",
      "training :  5111  accuracy =   0.7900  loss =  153.979\n",
      "testing  :  5111  accuracy =   0.7844  loss =  154.076\n",
      "training :  5112  accuracy =   0.7700  loss =  152.785\n",
      "testing  :  5112  accuracy =   0.7847  loss =  154.099\n",
      "training :  5113  accuracy =   0.8100  loss =  153.279\n",
      "testing  :  5113  accuracy =   0.7848  loss =  154.124\n",
      "training :  5114  accuracy =   0.7700  loss =  154.229\n",
      "testing  :  5114  accuracy =   0.7853  loss =  154.153\n",
      "training :  5115  accuracy =   0.7800  loss =  153.936\n",
      "testing  :  5115  accuracy =   0.7859  loss =  154.179\n",
      "training :  5116  accuracy =   0.7900  loss =  153.567\n",
      "testing  :  5116  accuracy =   0.7865  loss =  154.193\n",
      "training :  5117  accuracy =   0.7300  loss =  154.98\n",
      "testing  :  5117  accuracy =   0.7871  loss =  154.171\n",
      "training :  5118  accuracy =   0.7000  loss =  154.452\n",
      "testing  :  5118  accuracy =   0.7867  loss =  154.122\n",
      "training :  5119  accuracy =   0.7700  loss =  154.205\n",
      "testing  :  5119  accuracy =   0.7865  loss =  154.084\n",
      "training :  5120  accuracy =   0.8500  loss =  151.684\n",
      "testing  :  5120  accuracy =   0.7864  loss =  154.077\n",
      "training :  5121  accuracy =   0.8500  loss =  151.318\n",
      "testing  :  5121  accuracy =   0.7866  loss =  154.079\n",
      "training :  5122  accuracy =   0.8700  loss =  150.587\n",
      "testing  :  5122  accuracy =   0.7860  loss =  154.096\n",
      "training :  5123  accuracy =   0.8200  loss =  152.834\n",
      "testing  :  5123  accuracy =   0.7859  loss =  154.131\n",
      "training :  5124  accuracy =   0.8300  loss =  152.711\n",
      "testing  :  5124  accuracy =   0.7851  loss =  154.145\n",
      "training :  5125  accuracy =   0.8000  loss =  152.105\n",
      "testing  :  5125  accuracy =   0.7848  loss =  154.175\n",
      "training :  5126  accuracy =   0.8100  loss =  153.816\n",
      "testing  :  5126  accuracy =   0.7843  loss =  154.203\n",
      "training :  5127  accuracy =   0.7600  loss =  152.386\n",
      "testing  :  5127  accuracy =   0.7838  loss =  154.229\n",
      "training :  5128  accuracy =   0.8200  loss =  152.66\n",
      "testing  :  5128  accuracy =   0.7843  loss =  154.251\n",
      "training :  5129  accuracy =   0.7800  loss =  153.815\n",
      "testing  :  5129  accuracy =   0.7853  loss =  154.266\n",
      "training :  5130  accuracy =   0.8500  loss =  152.114\n",
      "testing  :  5130  accuracy =   0.7861  loss =  154.294\n",
      "training :  5131  accuracy =   0.8300  loss =  152.794\n",
      "testing  :  5131  accuracy =   0.7860  loss =  154.321\n",
      "training :  5132  accuracy =   0.8200  loss =  152.835\n",
      "testing  :  5132  accuracy =   0.7866  loss =  154.319\n",
      "training :  5133  accuracy =   0.8100  loss =  152.864\n",
      "testing  :  5133  accuracy =   0.7878  loss =  154.316\n",
      "training :  5134  accuracy =   0.7700  loss =  154.623\n",
      "testing  :  5134  accuracy =   0.7894  loss =  154.319\n",
      "training :  5135  accuracy =   0.8200  loss =  152.457\n",
      "testing  :  5135  accuracy =   0.8026  loss =  154.3\n",
      "training :  5136  accuracy =   0.7800  loss =  155.592\n",
      "testing  :  5136  accuracy =   0.8287  loss =  154.329\n",
      "training :  5137  accuracy =   0.9000  loss =  154.212\n",
      "testing  :  5137  accuracy =   0.8594  loss =  154.375\n",
      "training :  5138  accuracy =   0.8500  loss =  153.26\n",
      "testing  :  5138  accuracy =   0.8254  loss =  154.385\n",
      "training :  5139  accuracy =   0.8700  loss =  151.779\n",
      "testing  :  5139  accuracy =   0.8075  loss =  154.349\n",
      "training :  5140  accuracy =   0.7200  loss =  156.312\n",
      "testing  :  5140  accuracy =   0.8003  loss =  154.318\n",
      "training :  5141  accuracy =   0.8000  loss =  153.082\n",
      "testing  :  5141  accuracy =   0.7959  loss =  154.298\n",
      "training :  5142  accuracy =   0.7900  loss =  153.341\n",
      "testing  :  5142  accuracy =   0.7951  loss =  154.266\n",
      "training :  5143  accuracy =   0.7200  loss =  154.233\n",
      "testing  :  5143  accuracy =   0.7942  loss =  154.24\n",
      "training :  5144  accuracy =   0.7800  loss =  153.46\n",
      "testing  :  5144  accuracy =   0.7944  loss =  154.23\n",
      "training :  5145  accuracy =   0.7200  loss =  153.303\n",
      "testing  :  5145  accuracy =   0.7938  loss =  154.229\n",
      "training :  5146  accuracy =   0.8200  loss =  152.696\n",
      "testing  :  5146  accuracy =   0.7933  loss =  154.235\n",
      "training :  5147  accuracy =   0.7800  loss =  151.053\n",
      "testing  :  5147  accuracy =   0.7933  loss =  154.239\n",
      "training :  5148  accuracy =   0.7400  loss =  155.09\n",
      "testing  :  5148  accuracy =   0.7934  loss =  154.247\n",
      "training :  5149  accuracy =   0.8000  loss =  152.466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5149  accuracy =   0.7930  loss =  154.253\n",
      "training :  5150  accuracy =   0.8000  loss =  152.601\n",
      "testing  :  5150  accuracy =   0.7928  loss =  154.261\n",
      "training :  5151  accuracy =   0.7700  loss =  154.933\n",
      "testing  :  5151  accuracy =   0.7930  loss =  154.264\n",
      "training :  5152  accuracy =   0.8000  loss =  152.354\n",
      "testing  :  5152  accuracy =   0.7931  loss =  154.264\n",
      "training :  5153  accuracy =   0.8000  loss =  153.532\n",
      "testing  :  5153  accuracy =   0.7932  loss =  154.26\n",
      "training :  5154  accuracy =   0.7700  loss =  153.809\n",
      "testing  :  5154  accuracy =   0.7933  loss =  154.264\n",
      "training :  5155  accuracy =   0.7900  loss =  153.95\n",
      "testing  :  5155  accuracy =   0.7936  loss =  154.272\n",
      "training :  5156  accuracy =   0.7900  loss =  153.044\n",
      "testing  :  5156  accuracy =   0.7936  loss =  154.282\n",
      "training :  5157  accuracy =   0.7800  loss =  153.471\n",
      "testing  :  5157  accuracy =   0.7940  loss =  154.294\n",
      "training :  5158  accuracy =   0.8100  loss =  152.83\n",
      "testing  :  5158  accuracy =   0.7933  loss =  154.306\n",
      "training :  5159  accuracy =   0.8100  loss =  152.863\n",
      "testing  :  5159  accuracy =   0.7932  loss =  154.321\n",
      "training :  5160  accuracy =   0.8600  loss =  151.781\n",
      "testing  :  5160  accuracy =   0.7930  loss =  154.32\n",
      "training :  5161  accuracy =   0.7600  loss =  152.032\n",
      "testing  :  5161  accuracy =   0.7916  loss =  154.336\n",
      "training :  5162  accuracy =   0.8300  loss =  151.967\n",
      "testing  :  5162  accuracy =   0.7919  loss =  154.325\n",
      "training :  5163  accuracy =   0.8200  loss =  151.817\n",
      "testing  :  5163  accuracy =   0.7925  loss =  154.32\n",
      "training :  5164  accuracy =   0.8000  loss =  153.425\n",
      "testing  :  5164  accuracy =   0.7926  loss =  154.315\n",
      "training :  5165  accuracy =   0.7500  loss =  153.52\n",
      "testing  :  5165  accuracy =   0.7917  loss =  154.313\n",
      "training :  5166  accuracy =   0.7200  loss =  154.442\n",
      "testing  :  5166  accuracy =   0.7908  loss =  154.327\n",
      "training :  5167  accuracy =   0.8000  loss =  151.975\n",
      "testing  :  5167  accuracy =   0.7915  loss =  154.31\n",
      "training :  5168  accuracy =   0.8500  loss =  152.171\n",
      "testing  :  5168  accuracy =   0.7907  loss =  154.302\n",
      "training :  5169  accuracy =   0.8600  loss =  151.997\n",
      "testing  :  5169  accuracy =   0.7903  loss =  154.288\n",
      "training :  5170  accuracy =   0.8000  loss =  152.478\n",
      "testing  :  5170  accuracy =   0.7905  loss =  154.267\n",
      "training :  5171  accuracy =   0.8600  loss =  151.696\n",
      "testing  :  5171  accuracy =   0.7904  loss =  154.248\n",
      "training :  5172  accuracy =   0.7700  loss =  152.694\n",
      "testing  :  5172  accuracy =   0.7909  loss =  154.223\n",
      "training :  5173  accuracy =   0.7900  loss =  153.294\n",
      "testing  :  5173  accuracy =   0.7913  loss =  154.198\n",
      "training :  5174  accuracy =   0.7300  loss =  156.99\n",
      "testing  :  5174  accuracy =   0.7919  loss =  154.161\n",
      "training :  5175  accuracy =   0.8000  loss =  151.562\n",
      "testing  :  5175  accuracy =   0.7924  loss =  154.105\n",
      "training :  5176  accuracy =   0.7900  loss =  152.649\n",
      "testing  :  5176  accuracy =   0.7933  loss =  154.074\n",
      "training :  5177  accuracy =   0.7900  loss =  151.984\n",
      "testing  :  5177  accuracy =   0.7924  loss =  154.072\n",
      "training :  5178  accuracy =   0.8100  loss =  152.63\n",
      "testing  :  5178  accuracy =   0.7922  loss =  154.081\n",
      "training :  5179  accuracy =   0.7800  loss =  154.346\n",
      "testing  :  5179  accuracy =   0.7923  loss =  154.083\n",
      "training :  5180  accuracy =   0.8200  loss =  153.543\n",
      "testing  :  5180  accuracy =   0.7923  loss =  154.083\n",
      "training :  5181  accuracy =   0.8500  loss =  154.029\n",
      "testing  :  5181  accuracy =   0.7925  loss =  154.091\n",
      "training :  5182  accuracy =   0.7800  loss =  154.348\n",
      "testing  :  5182  accuracy =   0.7917  loss =  154.086\n",
      "training :  5183  accuracy =   0.8300  loss =  151.034\n",
      "testing  :  5183  accuracy =   0.7922  loss =  154.071\n",
      "training :  5184  accuracy =   0.7700  loss =  153.621\n",
      "testing  :  5184  accuracy =   0.7925  loss =  154.071\n",
      "training :  5185  accuracy =   0.7700  loss =  152.075\n",
      "testing  :  5185  accuracy =   0.7923  loss =  154.093\n",
      "training :  5186  accuracy =   0.7700  loss =  155.76\n",
      "testing  :  5186  accuracy =   0.7923  loss =  154.129\n",
      "training :  5187  accuracy =   0.7600  loss =  154.694\n",
      "testing  :  5187  accuracy =   0.7914  loss =  154.2\n",
      "training :  5188  accuracy =   0.8900  loss =  151.107\n",
      "testing  :  5188  accuracy =   0.7909  loss =  154.264\n",
      "training :  5189  accuracy =   0.8300  loss =  151.005\n",
      "testing  :  5189  accuracy =   0.7899  loss =  154.334\n",
      "training :  5190  accuracy =   0.8000  loss =  155.068\n",
      "testing  :  5190  accuracy =   0.7889  loss =  154.375\n",
      "training :  5191  accuracy =   0.7700  loss =  154.235\n",
      "testing  :  5191  accuracy =   0.7901  loss =  154.27\n",
      "training :  5192  accuracy =   0.7600  loss =  154.046\n",
      "testing  :  5192  accuracy =   0.7916  loss =  154.196\n",
      "training :  5193  accuracy =   0.7900  loss =  152.248\n",
      "testing  :  5193  accuracy =   0.7911  loss =  154.179\n",
      "training :  5194  accuracy =   0.7600  loss =  152.223\n",
      "testing  :  5194  accuracy =   0.7913  loss =  154.227\n",
      "training :  5195  accuracy =   0.8000  loss =  154.478\n",
      "testing  :  5195  accuracy =   0.7914  loss =  154.3\n",
      "training :  5196  accuracy =   0.7900  loss =  153.694\n",
      "testing  :  5196  accuracy =   0.7904  loss =  154.384\n",
      "training :  5197  accuracy =   0.7400  loss =  153.564\n",
      "testing  :  5197  accuracy =   0.7899  loss =  154.472\n",
      "training :  5198  accuracy =   0.7700  loss =  155.685\n",
      "testing  :  5198  accuracy =   0.7897  loss =  154.565\n",
      "training :  5199  accuracy =   0.8700  loss =  155.221\n",
      "testing  :  5199  accuracy =   0.7887  loss =  154.653\n",
      "training :  5200  accuracy =   0.8100  loss =  151.993\n",
      "testing  :  5200  accuracy =   0.7872  loss =  154.679\n",
      "training :  5201  accuracy =   0.8300  loss =  153.044\n",
      "testing  :  5201  accuracy =   0.7860  loss =  154.689\n",
      "training :  5202  accuracy =   0.8500  loss =  151.937\n",
      "testing  :  5202  accuracy =   0.7851  loss =  154.698\n",
      "training :  5203  accuracy =   0.8000  loss =  152.696\n",
      "testing  :  5203  accuracy =   0.7840  loss =  154.706\n",
      "training :  5204  accuracy =   0.8200  loss =  155.794\n",
      "testing  :  5204  accuracy =   0.7819  loss =  154.693\n",
      "training :  5205  accuracy =   0.8300  loss =  151.178\n",
      "testing  :  5205  accuracy =   0.7810  loss =  154.698\n",
      "training :  5206  accuracy =   0.8100  loss =  152.234\n",
      "testing  :  5206  accuracy =   0.7799  loss =  154.732\n",
      "training :  5207  accuracy =   0.7500  loss =  155.567\n",
      "testing  :  5207  accuracy =   0.7784  loss =  154.815\n",
      "training :  5208  accuracy =   0.8200  loss =  152.569\n",
      "testing  :  5208  accuracy =   0.7768  loss =  154.965\n",
      "training :  5209  accuracy =   0.8000  loss =  151.706\n",
      "testing  :  5209  accuracy =   0.7777  loss =  155.036\n",
      "training :  5210  accuracy =   0.8200  loss =  155.758\n",
      "testing  :  5210  accuracy =   0.7776  loss =  155.031\n",
      "training :  5211  accuracy =   0.8000  loss =  152.016\n",
      "testing  :  5211  accuracy =   0.7795  loss =  154.899\n",
      "training :  5212  accuracy =   0.7600  loss =  153.852\n",
      "testing  :  5212  accuracy =   0.7806  loss =  154.756\n",
      "training :  5213  accuracy =   0.8900  loss =  150.961\n",
      "testing  :  5213  accuracy =   0.7818  loss =  154.643\n",
      "training :  5214  accuracy =   0.8200  loss =  152.882\n",
      "testing  :  5214  accuracy =   0.7829  loss =  154.542\n",
      "training :  5215  accuracy =   0.7100  loss =  153.745\n",
      "testing  :  5215  accuracy =   0.7842  loss =  154.374\n",
      "training :  5216  accuracy =   0.8100  loss =  153.339\n",
      "testing  :  5216  accuracy =   0.7865  loss =  154.222\n",
      "training :  5217  accuracy =   0.7500  loss =  152.772\n",
      "testing  :  5217  accuracy =   0.7874  loss =  154.143\n",
      "training :  5218  accuracy =   0.8100  loss =  153.94\n",
      "testing  :  5218  accuracy =   0.7883  loss =  154.112\n",
      "training :  5219  accuracy =   0.8200  loss =  151.746\n",
      "testing  :  5219  accuracy =   0.7898  loss =  154.126\n",
      "training :  5220  accuracy =   0.8000  loss =  155.289\n",
      "testing  :  5220  accuracy =   0.7912  loss =  154.163\n",
      "training :  5221  accuracy =   0.7600  loss =  153.997\n",
      "testing  :  5221  accuracy =   0.7920  loss =  154.264\n",
      "training :  5222  accuracy =   0.8300  loss =  152.843\n",
      "testing  :  5222  accuracy =   0.7929  loss =  154.398\n",
      "training :  5223  accuracy =   0.8300  loss =  153.554\n",
      "testing  :  5223  accuracy =   0.7942  loss =  154.542\n",
      "training :  5224  accuracy =   0.8300  loss =  151.326\n",
      "testing  :  5224  accuracy =   0.7942  loss =  154.545\n",
      "training :  5225  accuracy =   0.8200  loss =  154.295\n",
      "testing  :  5225  accuracy =   0.7947  loss =  154.551\n",
      "training :  5226  accuracy =   0.8200  loss =  152.447\n",
      "testing  :  5226  accuracy =   0.7947  loss =  154.571\n",
      "training :  5227  accuracy =   0.8400  loss =  153.738\n",
      "testing  :  5227  accuracy =   0.7946  loss =  154.58\n",
      "training :  5228  accuracy =   0.8000  loss =  156.844\n",
      "testing  :  5228  accuracy =   0.7943  loss =  154.516\n",
      "training :  5229  accuracy =   0.7700  loss =  153.563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5229  accuracy =   0.7946  loss =  154.464\n",
      "training :  5230  accuracy =   0.8400  loss =  151.607\n",
      "testing  :  5230  accuracy =   0.7929  loss =  154.327\n",
      "training :  5231  accuracy =   0.7500  loss =  154.956\n",
      "testing  :  5231  accuracy =   0.7918  loss =  154.241\n",
      "training :  5232  accuracy =   0.7300  loss =  154.017\n",
      "testing  :  5232  accuracy =   0.7913  loss =  154.175\n",
      "training :  5233  accuracy =   0.8000  loss =  152.46\n",
      "testing  :  5233  accuracy =   0.7911  loss =  154.135\n",
      "training :  5234  accuracy =   0.7100  loss =  152.195\n",
      "testing  :  5234  accuracy =   0.7901  loss =  154.115\n",
      "training :  5235  accuracy =   0.8200  loss =  153.326\n",
      "testing  :  5235  accuracy =   0.7893  loss =  154.11\n",
      "training :  5236  accuracy =   0.7600  loss =  152.984\n",
      "testing  :  5236  accuracy =   0.7887  loss =  154.118\n",
      "training :  5237  accuracy =   0.7600  loss =  154.019\n",
      "testing  :  5237  accuracy =   0.7879  loss =  154.123\n",
      "training :  5238  accuracy =   0.8500  loss =  153.601\n",
      "testing  :  5238  accuracy =   0.7873  loss =  154.136\n",
      "training :  5239  accuracy =   0.8000  loss =  153.214\n",
      "testing  :  5239  accuracy =   0.7868  loss =  154.135\n",
      "training :  5240  accuracy =   0.7900  loss =  152.559\n",
      "testing  :  5240  accuracy =   0.7869  loss =  154.126\n",
      "training :  5241  accuracy =   0.7700  loss =  153.169\n",
      "testing  :  5241  accuracy =   0.7858  loss =  154.12\n",
      "training :  5242  accuracy =   0.7600  loss =  152.512\n",
      "testing  :  5242  accuracy =   0.7846  loss =  154.115\n",
      "training :  5243  accuracy =   0.8500  loss =  150.879\n",
      "testing  :  5243  accuracy =   0.7839  loss =  154.111\n",
      "training :  5244  accuracy =   0.8200  loss =  153.877\n",
      "testing  :  5244  accuracy =   0.7834  loss =  154.109\n",
      "training :  5245  accuracy =   0.8100  loss =  151.505\n",
      "testing  :  5245  accuracy =   0.7833  loss =  154.11\n",
      "training :  5246  accuracy =   0.8400  loss =  152.536\n",
      "testing  :  5246  accuracy =   0.7836  loss =  154.112\n",
      "training :  5247  accuracy =   0.7400  loss =  154.248\n",
      "testing  :  5247  accuracy =   0.7835  loss =  154.109\n",
      "training :  5248  accuracy =   0.7700  loss =  152.826\n",
      "testing  :  5248  accuracy =   0.7834  loss =  154.108\n",
      "training :  5249  accuracy =   0.8200  loss =  153.051\n",
      "testing  :  5249  accuracy =   0.7837  loss =  154.11\n",
      "training :  5250  accuracy =   0.8900  loss =  150.324\n",
      "testing  :  5250  accuracy =   0.7836  loss =  154.121\n",
      "training :  5251  accuracy =   0.7900  loss =  153.861\n",
      "testing  :  5251  accuracy =   0.7820  loss =  154.133\n",
      "training :  5252  accuracy =   0.7200  loss =  155.422\n",
      "testing  :  5252  accuracy =   0.7802  loss =  154.149\n",
      "training :  5253  accuracy =   0.8100  loss =  153.68\n",
      "testing  :  5253  accuracy =   0.7770  loss =  154.168\n",
      "training :  5254  accuracy =   0.7800  loss =  152.285\n",
      "testing  :  5254  accuracy =   0.7748  loss =  154.2\n",
      "training :  5255  accuracy =   0.8300  loss =  152.876\n",
      "testing  :  5255  accuracy =   0.7738  loss =  154.238\n",
      "training :  5256  accuracy =   0.7800  loss =  152.249\n",
      "testing  :  5256  accuracy =   0.7709  loss =  154.276\n",
      "training :  5257  accuracy =   0.7300  loss =  154.942\n",
      "testing  :  5257  accuracy =   0.7694  loss =  154.316\n",
      "training :  5258  accuracy =   0.7900  loss =  151.882\n",
      "testing  :  5258  accuracy =   0.7690  loss =  154.34\n",
      "training :  5259  accuracy =   0.7600  loss =  156.295\n",
      "testing  :  5259  accuracy =   0.7686  loss =  154.356\n",
      "training :  5260  accuracy =   0.8400  loss =  151.894\n",
      "testing  :  5260  accuracy =   0.7672  loss =  154.375\n",
      "training :  5261  accuracy =   0.7000  loss =  156.552\n",
      "testing  :  5261  accuracy =   0.7655  loss =  154.399\n",
      "training :  5262  accuracy =   0.7900  loss =  153.647\n",
      "testing  :  5262  accuracy =   0.7654  loss =  154.374\n",
      "training :  5263  accuracy =   0.7300  loss =  155.881\n",
      "testing  :  5263  accuracy =   0.7615  loss =  154.375\n",
      "training :  5264  accuracy =   0.7600  loss =  154.669\n",
      "testing  :  5264  accuracy =   0.7568  loss =  154.35\n",
      "training :  5265  accuracy =   0.7200  loss =  153.677\n",
      "testing  :  5265  accuracy =   0.7515  loss =  154.336\n",
      "training :  5266  accuracy =   0.7700  loss =  152.162\n",
      "testing  :  5266  accuracy =   0.7474  loss =  154.329\n",
      "training :  5267  accuracy =   0.7600  loss =  151.429\n",
      "testing  :  5267  accuracy =   0.7414  loss =  154.323\n",
      "training :  5268  accuracy =   0.7300  loss =  153.963\n",
      "testing  :  5268  accuracy =   0.7353  loss =  154.321\n",
      "training :  5269  accuracy =   0.7100  loss =  156.928\n",
      "testing  :  5269  accuracy =   0.7308  loss =  154.327\n",
      "training :  5270  accuracy =   0.7900  loss =  154.644\n",
      "testing  :  5270  accuracy =   0.7285  loss =  154.35\n",
      "training :  5271  accuracy =   0.7400  loss =  154.083\n",
      "testing  :  5271  accuracy =   0.7240  loss =  154.394\n",
      "training :  5272  accuracy =   0.7100  loss =  156.153\n",
      "testing  :  5272  accuracy =   0.7198  loss =  154.464\n",
      "training :  5273  accuracy =   0.6900  loss =  157.249\n",
      "testing  :  5273  accuracy =   0.7167  loss =  154.599\n",
      "training :  5274  accuracy =   0.7800  loss =  152.327\n",
      "testing  :  5274  accuracy =   0.7141  loss =  154.741\n",
      "training :  5275  accuracy =   0.7300  loss =  151.808\n",
      "testing  :  5275  accuracy =   0.7112  loss =  154.896\n",
      "training :  5276  accuracy =   0.6900  loss =  154.358\n",
      "testing  :  5276  accuracy =   0.7093  loss =  155.027\n",
      "training :  5277  accuracy =   0.6700  loss =  153.5\n",
      "testing  :  5277  accuracy =   0.7085  loss =  155.077\n",
      "training :  5278  accuracy =   0.7900  loss =  152.609\n",
      "testing  :  5278  accuracy =   0.7059  loss =  155.105\n",
      "training :  5279  accuracy =   0.6600  loss =  154.864\n",
      "testing  :  5279  accuracy =   0.7043  loss =  155.109\n",
      "training :  5280  accuracy =   0.6700  loss =  155.083\n",
      "testing  :  5280  accuracy =   0.7025  loss =  155.154\n",
      "training :  5281  accuracy =   0.6800  loss =  156.009\n",
      "testing  :  5281  accuracy =   0.7014  loss =  155.145\n",
      "training :  5282  accuracy =   0.7100  loss =  152.049\n",
      "testing  :  5282  accuracy =   0.7007  loss =  155.114\n",
      "training :  5283  accuracy =   0.6800  loss =  154.427\n",
      "testing  :  5283  accuracy =   0.6994  loss =  155.068\n",
      "training :  5284  accuracy =   0.6700  loss =  153.897\n",
      "testing  :  5284  accuracy =   0.6989  loss =  155.026\n",
      "training :  5285  accuracy =   0.7100  loss =  153.726\n",
      "testing  :  5285  accuracy =   0.6993  loss =  154.999\n",
      "training :  5286  accuracy =   0.7300  loss =  153.531\n",
      "testing  :  5286  accuracy =   0.6998  loss =  154.988\n",
      "training :  5287  accuracy =   0.7300  loss =  152.113\n",
      "testing  :  5287  accuracy =   0.7001  loss =  154.9\n",
      "training :  5288  accuracy =   0.7200  loss =  152.199\n",
      "testing  :  5288  accuracy =   0.7012  loss =  154.828\n",
      "training :  5289  accuracy =   0.7400  loss =  151.898\n",
      "testing  :  5289  accuracy =   0.7025  loss =  154.765\n",
      "training :  5290  accuracy =   0.6800  loss =  154.054\n",
      "testing  :  5290  accuracy =   0.7036  loss =  154.717\n",
      "training :  5291  accuracy =   0.6900  loss =  155.218\n",
      "testing  :  5291  accuracy =   0.7061  loss =  154.626\n",
      "training :  5292  accuracy =   0.6900  loss =  154.282\n",
      "testing  :  5292  accuracy =   0.7086  loss =  154.533\n",
      "training :  5293  accuracy =   0.7100  loss =  154.02\n",
      "testing  :  5293  accuracy =   0.7115  loss =  154.489\n",
      "training :  5294  accuracy =   0.7200  loss =  151.438\n",
      "testing  :  5294  accuracy =   0.7184  loss =  154.399\n",
      "training :  5295  accuracy =   0.7600  loss =  153.506\n",
      "testing  :  5295  accuracy =   0.7283  loss =  154.329\n",
      "training :  5296  accuracy =   0.7700  loss =  151.993\n",
      "testing  :  5296  accuracy =   0.7400  loss =  154.274\n",
      "training :  5297  accuracy =   0.7500  loss =  153.858\n",
      "testing  :  5297  accuracy =   0.7499  loss =  154.219\n",
      "training :  5298  accuracy =   0.6600  loss =  154.976\n",
      "testing  :  5298  accuracy =   0.7568  loss =  154.223\n",
      "training :  5299  accuracy =   0.6900  loss =  154.732\n",
      "testing  :  5299  accuracy =   0.7639  loss =  154.255\n",
      "training :  5300  accuracy =   0.7400  loss =  153.68\n",
      "testing  :  5300  accuracy =   0.7709  loss =  154.213\n",
      "training :  5301  accuracy =   0.7500  loss =  153.248\n",
      "testing  :  5301  accuracy =   0.7783  loss =  154.176\n",
      "training :  5302  accuracy =   0.8000  loss =  152.539\n",
      "testing  :  5302  accuracy =   0.7833  loss =  154.143\n",
      "training :  5303  accuracy =   0.7700  loss =  154.784\n",
      "testing  :  5303  accuracy =   0.7852  loss =  154.11\n",
      "training :  5304  accuracy =   0.8300  loss =  152.247\n",
      "testing  :  5304  accuracy =   0.7873  loss =  154.108\n",
      "training :  5305  accuracy =   0.7900  loss =  153.105\n",
      "testing  :  5305  accuracy =   0.7903  loss =  154.116\n",
      "training :  5306  accuracy =   0.7400  loss =  153.145\n",
      "testing  :  5306  accuracy =   0.7907  loss =  154.123\n",
      "training :  5307  accuracy =   0.6900  loss =  154.533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5307  accuracy =   0.7914  loss =  154.145\n",
      "training :  5308  accuracy =   0.8400  loss =  154.689\n",
      "testing  :  5308  accuracy =   0.7913  loss =  154.173\n",
      "training :  5309  accuracy =   0.8000  loss =  153.113\n",
      "testing  :  5309  accuracy =   0.7902  loss =  154.202\n",
      "training :  5310  accuracy =   0.8000  loss =  152.866\n",
      "testing  :  5310  accuracy =   0.7896  loss =  154.231\n",
      "training :  5311  accuracy =   0.7500  loss =  155.041\n",
      "testing  :  5311  accuracy =   0.7904  loss =  154.272\n",
      "training :  5312  accuracy =   0.7800  loss =  153.33\n",
      "testing  :  5312  accuracy =   0.7914  loss =  154.328\n",
      "training :  5313  accuracy =   0.8300  loss =  155.467\n",
      "testing  :  5313  accuracy =   0.7915  loss =  154.391\n",
      "training :  5314  accuracy =   0.8300  loss =  153.221\n",
      "testing  :  5314  accuracy =   0.7918  loss =  154.429\n",
      "training :  5315  accuracy =   0.8800  loss =  151.718\n",
      "testing  :  5315  accuracy =   0.7912  loss =  154.446\n",
      "training :  5316  accuracy =   0.8000  loss =  153.325\n",
      "testing  :  5316  accuracy =   0.7914  loss =  154.448\n",
      "training :  5317  accuracy =   0.8200  loss =  153.649\n",
      "testing  :  5317  accuracy =   0.7910  loss =  154.431\n",
      "training :  5318  accuracy =   0.8000  loss =  152.173\n",
      "testing  :  5318  accuracy =   0.7915  loss =  154.39\n",
      "training :  5319  accuracy =   0.8000  loss =  152.626\n",
      "testing  :  5319  accuracy =   0.7933  loss =  154.339\n",
      "training :  5320  accuracy =   0.7600  loss =  153.695\n",
      "testing  :  5320  accuracy =   0.7927  loss =  154.282\n",
      "training :  5321  accuracy =   0.7400  loss =  152.744\n",
      "testing  :  5321  accuracy =   0.7924  loss =  154.247\n",
      "training :  5322  accuracy =   0.8200  loss =  153.713\n",
      "testing  :  5322  accuracy =   0.7930  loss =  154.196\n",
      "training :  5323  accuracy =   0.8400  loss =  152.196\n",
      "testing  :  5323  accuracy =   0.7934  loss =  154.158\n",
      "training :  5324  accuracy =   0.8700  loss =  150.798\n",
      "testing  :  5324  accuracy =   0.7933  loss =  154.142\n",
      "training :  5325  accuracy =   0.7100  loss =  157.791\n",
      "testing  :  5325  accuracy =   0.7922  loss =  154.105\n",
      "training :  5326  accuracy =   0.8200  loss =  152.712\n",
      "testing  :  5326  accuracy =   0.7911  loss =  154.098\n",
      "training :  5327  accuracy =   0.7400  loss =  153.548\n",
      "testing  :  5327  accuracy =   0.7905  loss =  154.11\n",
      "training :  5328  accuracy =   0.8500  loss =  151.172\n",
      "testing  :  5328  accuracy =   0.7906  loss =  154.145\n",
      "training :  5329  accuracy =   0.7600  loss =  155.453\n",
      "testing  :  5329  accuracy =   0.7898  loss =  154.219\n",
      "training :  5330  accuracy =   0.7800  loss =  152.411\n",
      "testing  :  5330  accuracy =   0.7891  loss =  154.317\n",
      "training :  5331  accuracy =   0.8100  loss =  154.186\n",
      "testing  :  5331  accuracy =   0.7889  loss =  154.42\n",
      "training :  5332  accuracy =   0.8400  loss =  151.043\n",
      "testing  :  5332  accuracy =   0.7884  loss =  154.529\n",
      "training :  5333  accuracy =   0.8300  loss =  153.607\n",
      "testing  :  5333  accuracy =   0.7882  loss =  154.63\n",
      "training :  5334  accuracy =   0.7400  loss =  153.97\n",
      "testing  :  5334  accuracy =   0.7874  loss =  154.671\n",
      "training :  5335  accuracy =   0.8100  loss =  152.183\n",
      "testing  :  5335  accuracy =   0.7862  loss =  154.707\n",
      "training :  5336  accuracy =   0.8000  loss =  152.868\n",
      "testing  :  5336  accuracy =   0.7844  loss =  154.712\n",
      "training :  5337  accuracy =   0.8200  loss =  152.249\n",
      "testing  :  5337  accuracy =   0.7817  loss =  154.74\n",
      "training :  5338  accuracy =   0.8000  loss =  155.387\n",
      "testing  :  5338  accuracy =   0.7794  loss =  154.751\n",
      "training :  5339  accuracy =   0.7400  loss =  153.628\n",
      "testing  :  5339  accuracy =   0.7772  loss =  154.772\n",
      "training :  5340  accuracy =   0.8100  loss =  155.613\n",
      "testing  :  5340  accuracy =   0.7740  loss =  154.789\n",
      "training :  5341  accuracy =   0.8000  loss =  151.82\n",
      "testing  :  5341  accuracy =   0.7715  loss =  154.795\n",
      "training :  5342  accuracy =   0.7700  loss =  155.278\n",
      "testing  :  5342  accuracy =   0.7695  loss =  154.785\n",
      "training :  5343  accuracy =   0.7500  loss =  159.225\n",
      "testing  :  5343  accuracy =   0.7660  loss =  154.74\n",
      "training :  5344  accuracy =   0.8400  loss =  151.952\n",
      "testing  :  5344  accuracy =   0.7624  loss =  154.699\n",
      "training :  5345  accuracy =   0.7700  loss =  153.682\n",
      "testing  :  5345  accuracy =   0.7591  loss =  154.565\n",
      "training :  5346  accuracy =   0.8000  loss =  152.674\n",
      "testing  :  5346  accuracy =   0.7567  loss =  154.455\n",
      "training :  5347  accuracy =   0.7500  loss =  151.913\n",
      "testing  :  5347  accuracy =   0.7544  loss =  154.394\n",
      "training :  5348  accuracy =   0.7700  loss =  154.201\n",
      "testing  :  5348  accuracy =   0.7534  loss =  154.366\n",
      "training :  5349  accuracy =   0.7400  loss =  151.598\n",
      "testing  :  5349  accuracy =   0.7530  loss =  154.36\n",
      "training :  5350  accuracy =   0.7100  loss =  152.81\n",
      "testing  :  5350  accuracy =   0.7526  loss =  154.358\n",
      "training :  5351  accuracy =   0.6800  loss =  152.495\n",
      "testing  :  5351  accuracy =   0.7517  loss =  154.356\n",
      "training :  5352  accuracy =   0.7700  loss =  152.953\n",
      "testing  :  5352  accuracy =   0.7527  loss =  154.398\n",
      "training :  5353  accuracy =   0.7500  loss =  157.45\n",
      "testing  :  5353  accuracy =   0.7538  loss =  154.454\n",
      "training :  5354  accuracy =   0.8500  loss =  151.369\n",
      "testing  :  5354  accuracy =   0.7663  loss =  154.382\n",
      "training :  5355  accuracy =   0.8500  loss =  151.926\n",
      "testing  :  5355  accuracy =   0.7750  loss =  154.349\n",
      "training :  5356  accuracy =   0.7800  loss =  152.696\n",
      "testing  :  5356  accuracy =   0.7807  loss =  154.326\n",
      "training :  5357  accuracy =   0.8200  loss =  152.661\n",
      "testing  :  5357  accuracy =   0.7855  loss =  154.297\n",
      "training :  5358  accuracy =   0.8000  loss =  153.004\n",
      "testing  :  5358  accuracy =   0.7872  loss =  154.287\n",
      "training :  5359  accuracy =   0.8300  loss =  155.079\n",
      "testing  :  5359  accuracy =   0.7885  loss =  154.292\n",
      "training :  5360  accuracy =   0.7400  loss =  154.002\n",
      "testing  :  5360  accuracy =   0.7901  loss =  154.284\n",
      "training :  5361  accuracy =   0.7500  loss =  151.69\n",
      "testing  :  5361  accuracy =   0.7901  loss =  154.284\n",
      "training :  5362  accuracy =   0.8600  loss =  152.93\n",
      "testing  :  5362  accuracy =   0.7906  loss =  154.291\n",
      "training :  5363  accuracy =   0.7700  loss =  154.329\n",
      "testing  :  5363  accuracy =   0.7914  loss =  154.302\n",
      "training :  5364  accuracy =   0.8200  loss =  151.609\n",
      "testing  :  5364  accuracy =   0.7919  loss =  154.284\n",
      "training :  5365  accuracy =   0.8200  loss =  152.869\n",
      "testing  :  5365  accuracy =   0.7926  loss =  154.252\n",
      "training :  5366  accuracy =   0.8000  loss =  153.128\n",
      "testing  :  5366  accuracy =   0.7930  loss =  154.212\n",
      "training :  5367  accuracy =   0.7800  loss =  153.945\n",
      "testing  :  5367  accuracy =   0.7934  loss =  154.19\n",
      "training :  5368  accuracy =   0.8300  loss =  152.174\n",
      "testing  :  5368  accuracy =   0.7934  loss =  154.181\n",
      "training :  5369  accuracy =   0.8500  loss =  153.564\n",
      "testing  :  5369  accuracy =   0.7939  loss =  154.181\n",
      "training :  5370  accuracy =   0.8000  loss =  153.897\n",
      "testing  :  5370  accuracy =   0.7936  loss =  154.189\n",
      "training :  5371  accuracy =   0.8300  loss =  152.865\n",
      "testing  :  5371  accuracy =   0.7930  loss =  154.21\n",
      "training :  5372  accuracy =   0.8000  loss =  153.181\n",
      "testing  :  5372  accuracy =   0.7924  loss =  154.234\n",
      "training :  5373  accuracy =   0.7900  loss =  154.634\n",
      "testing  :  5373  accuracy =   0.7917  loss =  154.251\n",
      "training :  5374  accuracy =   0.7900  loss =  153.953\n",
      "testing  :  5374  accuracy =   0.7914  loss =  154.259\n",
      "training :  5375  accuracy =   0.7900  loss =  156.304\n",
      "testing  :  5375  accuracy =   0.7902  loss =  154.254\n",
      "training :  5376  accuracy =   0.7800  loss =  154.342\n",
      "testing  :  5376  accuracy =   0.7890  loss =  154.254\n",
      "training :  5377  accuracy =   0.7900  loss =  153.667\n",
      "testing  :  5377  accuracy =   0.7882  loss =  154.269\n",
      "training :  5378  accuracy =   0.8800  loss =  151.767\n",
      "testing  :  5378  accuracy =   0.7881  loss =  154.303\n",
      "training :  5379  accuracy =   0.8500  loss =  152.114\n",
      "testing  :  5379  accuracy =   0.7881  loss =  154.329\n",
      "training :  5380  accuracy =   0.7400  loss =  152.651\n",
      "testing  :  5380  accuracy =   0.7880  loss =  154.335\n",
      "training :  5381  accuracy =   0.7300  loss =  153.619\n",
      "testing  :  5381  accuracy =   0.7879  loss =  154.332\n",
      "training :  5382  accuracy =   0.7500  loss =  152.532\n",
      "testing  :  5382  accuracy =   0.7884  loss =  154.289\n",
      "training :  5383  accuracy =   0.7400  loss =  152.751\n",
      "testing  :  5383  accuracy =   0.7887  loss =  154.26\n",
      "training :  5384  accuracy =   0.7300  loss =  154.67\n",
      "testing  :  5384  accuracy =   0.7890  loss =  154.249\n",
      "training :  5385  accuracy =   0.8200  loss =  150.798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5385  accuracy =   0.7896  loss =  154.216\n",
      "training :  5386  accuracy =   0.7600  loss =  157.185\n",
      "testing  :  5386  accuracy =   0.7909  loss =  154.176\n",
      "training :  5387  accuracy =   0.7700  loss =  154.076\n",
      "testing  :  5387  accuracy =   0.7922  loss =  154.148\n",
      "training :  5388  accuracy =   0.7700  loss =  155.464\n",
      "testing  :  5388  accuracy =   0.7933  loss =  154.148\n",
      "training :  5389  accuracy =   0.8000  loss =  152.911\n",
      "testing  :  5389  accuracy =   0.7939  loss =  154.18\n",
      "training :  5390  accuracy =   0.8400  loss =  151.951\n",
      "testing  :  5390  accuracy =   0.7947  loss =  154.183\n",
      "training :  5391  accuracy =   0.8300  loss =  151.299\n",
      "testing  :  5391  accuracy =   0.7943  loss =  154.192\n",
      "training :  5392  accuracy =   0.7600  loss =  153.737\n",
      "testing  :  5392  accuracy =   0.7947  loss =  154.206\n",
      "training :  5393  accuracy =   0.7200  loss =  154.253\n",
      "testing  :  5393  accuracy =   0.7952  loss =  154.22\n",
      "training :  5394  accuracy =   0.8200  loss =  153.224\n",
      "testing  :  5394  accuracy =   0.7953  loss =  154.243\n",
      "training :  5395  accuracy =   0.8500  loss =  151.797\n",
      "testing  :  5395  accuracy =   0.7959  loss =  154.265\n",
      "training :  5396  accuracy =   0.7900  loss =  152.33\n",
      "testing  :  5396  accuracy =   0.7967  loss =  154.267\n",
      "training :  5397  accuracy =   0.7800  loss =  152.628\n",
      "testing  :  5397  accuracy =   0.7958  loss =  154.267\n",
      "training :  5398  accuracy =   0.7100  loss =  155.346\n",
      "testing  :  5398  accuracy =   0.7956  loss =  154.271\n",
      "training :  5399  accuracy =   0.8100  loss =  151.368\n",
      "testing  :  5399  accuracy =   0.7958  loss =  154.264\n",
      "training :  5400  accuracy =   0.7900  loss =  152.366\n",
      "testing  :  5400  accuracy =   0.7952  loss =  154.254\n",
      "training :  5401  accuracy =   0.8100  loss =  153.073\n",
      "testing  :  5401  accuracy =   0.7950  loss =  154.248\n",
      "training :  5402  accuracy =   0.7300  loss =  155.026\n",
      "testing  :  5402  accuracy =   0.7947  loss =  154.257\n",
      "training :  5403  accuracy =   0.7800  loss =  153.368\n",
      "testing  :  5403  accuracy =   0.7950  loss =  154.253\n",
      "training :  5404  accuracy =   0.8300  loss =  151.928\n",
      "testing  :  5404  accuracy =   0.7944  loss =  154.251\n",
      "training :  5405  accuracy =   0.8300  loss =  154.482\n",
      "testing  :  5405  accuracy =   0.7938  loss =  154.257\n",
      "training :  5406  accuracy =   0.7500  loss =  154.756\n",
      "testing  :  5406  accuracy =   0.7938  loss =  154.26\n",
      "training :  5407  accuracy =   0.8000  loss =  151.53\n",
      "testing  :  5407  accuracy =   0.7931  loss =  154.278\n",
      "training :  5408  accuracy =   0.7800  loss =  152.596\n",
      "testing  :  5408  accuracy =   0.7923  loss =  154.302\n",
      "training :  5409  accuracy =   0.8400  loss =  153.816\n",
      "testing  :  5409  accuracy =   0.7915  loss =  154.299\n",
      "training :  5410  accuracy =   0.8200  loss =  152.532\n",
      "testing  :  5410  accuracy =   0.7921  loss =  154.255\n",
      "training :  5411  accuracy =   0.7700  loss =  153.225\n",
      "testing  :  5411  accuracy =   0.7925  loss =  154.212\n",
      "training :  5412  accuracy =   0.8000  loss =  153.026\n",
      "testing  :  5412  accuracy =   0.7939  loss =  154.155\n",
      "training :  5413  accuracy =   0.7700  loss =  152.928\n",
      "testing  :  5413  accuracy =   0.7948  loss =  154.126\n",
      "training :  5414  accuracy =   0.8000  loss =  151.895\n",
      "testing  :  5414  accuracy =   0.7949  loss =  154.124\n",
      "training :  5415  accuracy =   0.7600  loss =  154.185\n",
      "testing  :  5415  accuracy =   0.7959  loss =  154.134\n",
      "training :  5416  accuracy =   0.8000  loss =  152.335\n",
      "testing  :  5416  accuracy =   0.7987  loss =  154.167\n",
      "training :  5417  accuracy =   0.8200  loss =  152.745\n",
      "testing  :  5417  accuracy =   0.8023  loss =  154.207\n",
      "training :  5418  accuracy =   0.8300  loss =  153.75\n",
      "testing  :  5418  accuracy =   0.8097  loss =  154.245\n",
      "training :  5419  accuracy =   0.8300  loss =  152.916\n",
      "testing  :  5419  accuracy =   0.8179  loss =  154.313\n",
      "training :  5420  accuracy =   0.8300  loss =  153.518\n",
      "testing  :  5420  accuracy =   0.8285  loss =  154.381\n",
      "training :  5421  accuracy =   0.8700  loss =  153.272\n",
      "testing  :  5421  accuracy =   0.8421  loss =  154.408\n",
      "training :  5422  accuracy =   0.8800  loss =  151.796\n",
      "testing  :  5422  accuracy =   0.8449  loss =  154.423\n",
      "training :  5423  accuracy =   0.9000  loss =  152.182\n",
      "testing  :  5423  accuracy =   0.8405  loss =  154.472\n",
      "training :  5424  accuracy =   0.9000  loss =  151.715\n",
      "testing  :  5424  accuracy =   0.8341  loss =  154.474\n",
      "training :  5425  accuracy =   0.8700  loss =  152.805\n",
      "testing  :  5425  accuracy =   0.8291  loss =  154.439\n",
      "training :  5426  accuracy =   0.8600  loss =  152.621\n",
      "testing  :  5426  accuracy =   0.8219  loss =  154.384\n",
      "training :  5427  accuracy =   0.8000  loss =  154.047\n",
      "testing  :  5427  accuracy =   0.8184  loss =  154.34\n",
      "training :  5428  accuracy =   0.8500  loss =  152.526\n",
      "testing  :  5428  accuracy =   0.8148  loss =  154.308\n",
      "training :  5429  accuracy =   0.8400  loss =  152.926\n",
      "testing  :  5429  accuracy =   0.8120  loss =  154.279\n",
      "training :  5430  accuracy =   0.8400  loss =  153.753\n",
      "testing  :  5430  accuracy =   0.8098  loss =  154.253\n",
      "training :  5431  accuracy =   0.8200  loss =  152.452\n",
      "testing  :  5431  accuracy =   0.8090  loss =  154.225\n",
      "training :  5432  accuracy =   0.8600  loss =  152.255\n",
      "testing  :  5432  accuracy =   0.8108  loss =  154.186\n",
      "training :  5433  accuracy =   0.8700  loss =  152.124\n",
      "testing  :  5433  accuracy =   0.8120  loss =  154.158\n",
      "training :  5434  accuracy =   0.8000  loss =  155.213\n",
      "testing  :  5434  accuracy =   0.8145  loss =  154.137\n",
      "training :  5435  accuracy =   0.7900  loss =  154.791\n",
      "testing  :  5435  accuracy =   0.8145  loss =  154.175\n",
      "training :  5436  accuracy =   0.8100  loss =  156.245\n",
      "testing  :  5436  accuracy =   0.8108  loss =  154.197\n",
      "training :  5437  accuracy =   0.7900  loss =  154.083\n",
      "testing  :  5437  accuracy =   0.8032  loss =  154.183\n",
      "training :  5438  accuracy =   0.7400  loss =  153.596\n",
      "testing  :  5438  accuracy =   0.7985  loss =  154.178\n",
      "training :  5439  accuracy =   0.7700  loss =  153.382\n",
      "testing  :  5439  accuracy =   0.7955  loss =  154.178\n",
      "training :  5440  accuracy =   0.8200  loss =  152.279\n",
      "testing  :  5440  accuracy =   0.7933  loss =  154.177\n",
      "training :  5441  accuracy =   0.8000  loss =  151.826\n",
      "testing  :  5441  accuracy =   0.7921  loss =  154.173\n",
      "training :  5442  accuracy =   0.8400  loss =  151.133\n",
      "testing  :  5442  accuracy =   0.7912  loss =  154.17\n",
      "training :  5443  accuracy =   0.8400  loss =  152.702\n",
      "testing  :  5443  accuracy =   0.7910  loss =  154.166\n",
      "training :  5444  accuracy =   0.8600  loss =  151.242\n",
      "testing  :  5444  accuracy =   0.7904  loss =  154.164\n",
      "training :  5445  accuracy =   0.7400  loss =  152.696\n",
      "testing  :  5445  accuracy =   0.7900  loss =  154.164\n",
      "training :  5446  accuracy =   0.7800  loss =  155.726\n",
      "testing  :  5446  accuracy =   0.7898  loss =  154.167\n",
      "training :  5447  accuracy =   0.7600  loss =  152.133\n",
      "testing  :  5447  accuracy =   0.7904  loss =  154.146\n",
      "training :  5448  accuracy =   0.8300  loss =  152.732\n",
      "testing  :  5448  accuracy =   0.7947  loss =  154.135\n",
      "training :  5449  accuracy =   0.8500  loss =  150.847\n",
      "testing  :  5449  accuracy =   0.8040  loss =  154.141\n",
      "training :  5450  accuracy =   0.9300  loss =  150.975\n",
      "testing  :  5450  accuracy =   0.8224  loss =  154.138\n",
      "training :  5451  accuracy =   0.8600  loss =  154.992\n",
      "testing  :  5451  accuracy =   0.8422  loss =  154.135\n",
      "training :  5452  accuracy =   0.8400  loss =  153.505\n",
      "testing  :  5452  accuracy =   0.8517  loss =  154.12\n",
      "training :  5453  accuracy =   0.8100  loss =  155.618\n",
      "testing  :  5453  accuracy =   0.8400  loss =  154.108\n",
      "training :  5454  accuracy =   0.8600  loss =  155.364\n",
      "testing  :  5454  accuracy =   0.8247  loss =  154.079\n",
      "training :  5455  accuracy =   0.8400  loss =  151.32\n",
      "testing  :  5455  accuracy =   0.8116  loss =  154.064\n",
      "training :  5456  accuracy =   0.8400  loss =  151.433\n",
      "testing  :  5456  accuracy =   0.8062  loss =  154.069\n",
      "training :  5457  accuracy =   0.8500  loss =  151.01\n",
      "testing  :  5457  accuracy =   0.8029  loss =  154.095\n",
      "training :  5458  accuracy =   0.8500  loss =  152.357\n",
      "testing  :  5458  accuracy =   0.8009  loss =  154.143\n",
      "training :  5459  accuracy =   0.8500  loss =  152.898\n",
      "testing  :  5459  accuracy =   0.8003  loss =  154.2\n",
      "training :  5460  accuracy =   0.7700  loss =  155.175\n",
      "testing  :  5460  accuracy =   0.7998  loss =  154.222\n",
      "training :  5461  accuracy =   0.7700  loss =  154.884\n",
      "testing  :  5461  accuracy =   0.7989  loss =  154.249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  5462  accuracy =   0.8200  loss =  151.105\n",
      "testing  :  5462  accuracy =   0.7978  loss =  154.282\n",
      "training :  5463  accuracy =   0.8600  loss =  152.118\n",
      "testing  :  5463  accuracy =   0.7966  loss =  154.314\n",
      "training :  5464  accuracy =   0.8100  loss =  152.523\n",
      "testing  :  5464  accuracy =   0.7958  loss =  154.345\n",
      "training :  5465  accuracy =   0.8500  loss =  152.849\n",
      "testing  :  5465  accuracy =   0.7952  loss =  154.378\n",
      "training :  5466  accuracy =   0.8000  loss =  154.682\n",
      "testing  :  5466  accuracy =   0.7951  loss =  154.414\n",
      "training :  5467  accuracy =   0.8100  loss =  154.634\n",
      "testing  :  5467  accuracy =   0.7945  loss =  154.435\n",
      "training :  5468  accuracy =   0.7700  loss =  153.728\n",
      "testing  :  5468  accuracy =   0.7942  loss =  154.403\n",
      "training :  5469  accuracy =   0.7900  loss =  151.741\n",
      "testing  :  5469  accuracy =   0.7937  loss =  154.394\n",
      "training :  5470  accuracy =   0.7900  loss =  153.049\n",
      "testing  :  5470  accuracy =   0.7936  loss =  154.394\n",
      "training :  5471  accuracy =   0.8500  loss =  151.239\n",
      "testing  :  5471  accuracy =   0.7925  loss =  154.444\n",
      "training :  5472  accuracy =   0.7800  loss =  154.069\n",
      "testing  :  5472  accuracy =   0.7914  loss =  154.517\n",
      "training :  5473  accuracy =   0.7400  loss =  153.068\n",
      "testing  :  5473  accuracy =   0.7907  loss =  154.56\n",
      "training :  5474  accuracy =   0.7800  loss =  154.372\n",
      "testing  :  5474  accuracy =   0.7898  loss =  154.592\n",
      "training :  5475  accuracy =   0.7500  loss =  155.861\n",
      "testing  :  5475  accuracy =   0.7896  loss =  154.612\n",
      "training :  5476  accuracy =   0.7800  loss =  154.435\n",
      "testing  :  5476  accuracy =   0.7882  loss =  154.606\n",
      "training :  5477  accuracy =   0.8700  loss =  151.398\n",
      "testing  :  5477  accuracy =   0.7871  loss =  154.622\n",
      "training :  5478  accuracy =   0.7800  loss =  155.376\n",
      "testing  :  5478  accuracy =   0.7856  loss =  154.648\n",
      "training :  5479  accuracy =   0.8600  loss =  151.804\n",
      "testing  :  5479  accuracy =   0.7856  loss =  154.631\n",
      "training :  5480  accuracy =   0.8100  loss =  155.121\n",
      "testing  :  5480  accuracy =   0.7851  loss =  154.617\n",
      "training :  5481  accuracy =   0.8300  loss =  153.339\n",
      "testing  :  5481  accuracy =   0.7849  loss =  154.543\n",
      "training :  5482  accuracy =   0.7800  loss =  152.774\n",
      "testing  :  5482  accuracy =   0.7850  loss =  154.477\n",
      "training :  5483  accuracy =   0.8500  loss =  153.505\n",
      "testing  :  5483  accuracy =   0.7861  loss =  154.43\n",
      "training :  5484  accuracy =   0.8200  loss =  153.994\n",
      "testing  :  5484  accuracy =   0.7872  loss =  154.397\n",
      "training :  5485  accuracy =   0.7600  loss =  154.668\n",
      "testing  :  5485  accuracy =   0.7890  loss =  154.36\n",
      "training :  5486  accuracy =   0.8100  loss =  154.449\n",
      "testing  :  5486  accuracy =   0.7907  loss =  154.345\n",
      "training :  5487  accuracy =   0.8400  loss =  150.385\n",
      "testing  :  5487  accuracy =   0.7912  loss =  154.34\n",
      "training :  5488  accuracy =   0.8000  loss =  152.506\n",
      "testing  :  5488  accuracy =   0.7928  loss =  154.34\n",
      "training :  5489  accuracy =   0.7900  loss =  152.736\n",
      "testing  :  5489  accuracy =   0.7941  loss =  154.334\n",
      "training :  5490  accuracy =   0.8300  loss =  152.355\n",
      "testing  :  5490  accuracy =   0.7965  loss =  154.336\n",
      "training :  5491  accuracy =   0.8700  loss =  150.951\n",
      "testing  :  5491  accuracy =   0.7995  loss =  154.333\n",
      "training :  5492  accuracy =   0.8400  loss =  153.597\n",
      "testing  :  5492  accuracy =   0.8016  loss =  154.339\n",
      "training :  5493  accuracy =   0.8700  loss =  152.335\n",
      "testing  :  5493  accuracy =   0.8083  loss =  154.329\n",
      "training :  5494  accuracy =   0.8600  loss =  154.003\n",
      "testing  :  5494  accuracy =   0.8183  loss =  154.344\n",
      "training :  5495  accuracy =   0.8600  loss =  151.736\n",
      "testing  :  5495  accuracy =   0.8382  loss =  154.309\n",
      "training :  5496  accuracy =   0.8600  loss =  154.704\n",
      "testing  :  5496  accuracy =   0.8475  loss =  154.304\n",
      "training :  5497  accuracy =   0.8300  loss =  152.619\n",
      "testing  :  5497  accuracy =   0.8424  loss =  154.313\n",
      "training :  5498  accuracy =   0.8300  loss =  153.589\n",
      "testing  :  5498  accuracy =   0.8271  loss =  154.331\n",
      "training :  5499  accuracy =   0.7600  loss =  156.477\n",
      "testing  :  5499  accuracy =   0.8073  loss =  154.341\n",
      "training :  5500  accuracy =   0.8100  loss =  153.473\n",
      "testing  :  5500  accuracy =   0.7988  loss =  154.343\n",
      "training :  5501  accuracy =   0.8200  loss =  153.153\n",
      "testing  :  5501  accuracy =   0.7953  loss =  154.326\n",
      "training :  5502  accuracy =   0.7800  loss =  156.421\n",
      "testing  :  5502  accuracy =   0.7928  loss =  154.307\n",
      "training :  5503  accuracy =   0.8700  loss =  153.746\n",
      "testing  :  5503  accuracy =   0.7917  loss =  154.277\n",
      "training :  5504  accuracy =   0.7500  loss =  154.699\n",
      "testing  :  5504  accuracy =   0.7904  loss =  154.256\n",
      "training :  5505  accuracy =   0.8100  loss =  154.062\n",
      "testing  :  5505  accuracy =   0.7899  loss =  154.181\n",
      "training :  5506  accuracy =   0.7600  loss =  153.999\n",
      "testing  :  5506  accuracy =   0.7892  loss =  154.103\n",
      "training :  5507  accuracy =   0.8600  loss =  150.733\n",
      "testing  :  5507  accuracy =   0.7878  loss =  154.088\n",
      "training :  5508  accuracy =   0.8200  loss =  152.887\n",
      "testing  :  5508  accuracy =   0.7867  loss =  154.1\n",
      "training :  5509  accuracy =   0.7800  loss =  151.992\n",
      "testing  :  5509  accuracy =   0.7852  loss =  154.127\n",
      "training :  5510  accuracy =   0.7600  loss =  153.929\n",
      "testing  :  5510  accuracy =   0.7842  loss =  154.167\n",
      "training :  5511  accuracy =   0.7800  loss =  151.881\n",
      "testing  :  5511  accuracy =   0.7834  loss =  154.224\n",
      "training :  5512  accuracy =   0.7800  loss =  152.95\n",
      "testing  :  5512  accuracy =   0.7826  loss =  154.28\n",
      "training :  5513  accuracy =   0.8400  loss =  152.378\n",
      "testing  :  5513  accuracy =   0.7820  loss =  154.324\n",
      "training :  5514  accuracy =   0.8200  loss =  152.547\n",
      "testing  :  5514  accuracy =   0.7815  loss =  154.333\n",
      "training :  5515  accuracy =   0.8100  loss =  153.512\n",
      "testing  :  5515  accuracy =   0.7816  loss =  154.34\n",
      "training :  5516  accuracy =   0.7600  loss =  155.502\n",
      "testing  :  5516  accuracy =   0.7816  loss =  154.336\n",
      "training :  5517  accuracy =   0.8000  loss =  152.946\n",
      "testing  :  5517  accuracy =   0.7819  loss =  154.338\n",
      "training :  5518  accuracy =   0.7700  loss =  153.838\n",
      "testing  :  5518  accuracy =   0.7819  loss =  154.341\n",
      "training :  5519  accuracy =   0.7600  loss =  154.361\n",
      "testing  :  5519  accuracy =   0.7823  loss =  154.339\n",
      "training :  5520  accuracy =   0.8000  loss =  151.836\n",
      "testing  :  5520  accuracy =   0.7826  loss =  154.333\n",
      "training :  5521  accuracy =   0.8400  loss =  152.507\n",
      "testing  :  5521  accuracy =   0.7827  loss =  154.326\n",
      "training :  5522  accuracy =   0.8000  loss =  154.047\n",
      "testing  :  5522  accuracy =   0.7828  loss =  154.322\n",
      "training :  5523  accuracy =   0.7800  loss =  153.181\n",
      "testing  :  5523  accuracy =   0.7828  loss =  154.326\n",
      "training :  5524  accuracy =   0.7600  loss =  153.64\n",
      "testing  :  5524  accuracy =   0.7835  loss =  154.297\n",
      "training :  5525  accuracy =   0.8300  loss =  153.157\n",
      "testing  :  5525  accuracy =   0.7836  loss =  154.27\n",
      "training :  5526  accuracy =   0.8300  loss =  150.576\n",
      "testing  :  5526  accuracy =   0.7839  loss =  154.249\n",
      "training :  5527  accuracy =   0.8000  loss =  151.664\n",
      "testing  :  5527  accuracy =   0.7849  loss =  154.236\n",
      "training :  5528  accuracy =   0.7600  loss =  154.03\n",
      "testing  :  5528  accuracy =   0.7849  loss =  154.227\n",
      "training :  5529  accuracy =   0.7800  loss =  152.632\n",
      "testing  :  5529  accuracy =   0.7848  loss =  154.219\n",
      "training :  5530  accuracy =   0.7200  loss =  153.037\n",
      "testing  :  5530  accuracy =   0.7851  loss =  154.221\n",
      "training :  5531  accuracy =   0.7900  loss =  151.985\n",
      "testing  :  5531  accuracy =   0.7856  loss =  154.224\n",
      "training :  5532  accuracy =   0.7400  loss =  153.991\n",
      "testing  :  5532  accuracy =   0.7856  loss =  154.222\n",
      "training :  5533  accuracy =   0.8000  loss =  153.439\n",
      "testing  :  5533  accuracy =   0.7861  loss =  154.217\n",
      "training :  5534  accuracy =   0.8000  loss =  152.576\n",
      "testing  :  5534  accuracy =   0.7864  loss =  154.187\n",
      "training :  5535  accuracy =   0.8400  loss =  152.042\n",
      "testing  :  5535  accuracy =   0.7870  loss =  154.172\n",
      "training :  5536  accuracy =   0.7700  loss =  153.964\n",
      "testing  :  5536  accuracy =   0.7876  loss =  154.159\n",
      "training :  5537  accuracy =   0.8600  loss =  152.665\n",
      "testing  :  5537  accuracy =   0.7877  loss =  154.15\n",
      "training :  5538  accuracy =   0.7700  loss =  155.02\n",
      "testing  :  5538  accuracy =   0.7878  loss =  154.16\n",
      "training :  5539  accuracy =   0.7100  loss =  157.317\n",
      "testing  :  5539  accuracy =   0.7878  loss =  154.122\n",
      "training :  5540  accuracy =   0.8400  loss =  151.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5540  accuracy =   0.7876  loss =  154.08\n",
      "training :  5541  accuracy =   0.7600  loss =  153.509\n",
      "testing  :  5541  accuracy =   0.7872  loss =  154.057\n",
      "training :  5542  accuracy =   0.7400  loss =  153.298\n",
      "testing  :  5542  accuracy =   0.7862  loss =  154.038\n",
      "training :  5543  accuracy =   0.8600  loss =  151.966\n",
      "testing  :  5543  accuracy =   0.7853  loss =  154.052\n",
      "training :  5544  accuracy =   0.7800  loss =  152.559\n",
      "testing  :  5544  accuracy =   0.7850  loss =  154.093\n",
      "training :  5545  accuracy =   0.8400  loss =  153.121\n",
      "testing  :  5545  accuracy =   0.7840  loss =  154.129\n",
      "training :  5546  accuracy =   0.7900  loss =  151.372\n",
      "testing  :  5546  accuracy =   0.7832  loss =  154.168\n",
      "training :  5547  accuracy =   0.7300  loss =  154.921\n",
      "testing  :  5547  accuracy =   0.7824  loss =  154.21\n",
      "training :  5548  accuracy =   0.8300  loss =  153.12\n",
      "testing  :  5548  accuracy =   0.7809  loss =  154.285\n",
      "training :  5549  accuracy =   0.8300  loss =  152.179\n",
      "testing  :  5549  accuracy =   0.7795  loss =  154.371\n",
      "training :  5550  accuracy =   0.8300  loss =  151.218\n",
      "testing  :  5550  accuracy =   0.7787  loss =  154.457\n",
      "training :  5551  accuracy =   0.7900  loss =  153.538\n",
      "testing  :  5551  accuracy =   0.7777  loss =  154.523\n",
      "training :  5552  accuracy =   0.7900  loss =  156.48\n",
      "testing  :  5552  accuracy =   0.7769  loss =  154.559\n",
      "training :  5553  accuracy =   0.8000  loss =  154.52\n",
      "testing  :  5553  accuracy =   0.7783  loss =  154.499\n",
      "training :  5554  accuracy =   0.7400  loss =  151.223\n",
      "testing  :  5554  accuracy =   0.7788  loss =  154.434\n",
      "training :  5555  accuracy =   0.7500  loss =  153.597\n",
      "testing  :  5555  accuracy =   0.7794  loss =  154.396\n",
      "training :  5556  accuracy =   0.7600  loss =  155.172\n",
      "testing  :  5556  accuracy =   0.7799  loss =  154.422\n",
      "training :  5557  accuracy =   0.8400  loss =  152.292\n",
      "testing  :  5557  accuracy =   0.7816  loss =  154.416\n",
      "training :  5558  accuracy =   0.8200  loss =  152.271\n",
      "testing  :  5558  accuracy =   0.7829  loss =  154.447\n",
      "training :  5559  accuracy =   0.8100  loss =  154.584\n",
      "testing  :  5559  accuracy =   0.7840  loss =  154.537\n",
      "training :  5560  accuracy =   0.7700  loss =  152.787\n",
      "testing  :  5560  accuracy =   0.7840  loss =  154.615\n",
      "training :  5561  accuracy =   0.7800  loss =  155.047\n",
      "testing  :  5561  accuracy =   0.7840  loss =  154.797\n",
      "training :  5562  accuracy =   0.7700  loss =  153.336\n",
      "testing  :  5562  accuracy =   0.7825  loss =  154.978\n",
      "training :  5563  accuracy =   0.7900  loss =  152.805\n",
      "testing  :  5563  accuracy =   0.7802  loss =  155.287\n",
      "training :  5564  accuracy =   0.7100  loss =  156.699\n",
      "testing  :  5564  accuracy =   0.7777  loss =  155.577\n",
      "training :  5565  accuracy =   0.7900  loss =  151.803\n",
      "testing  :  5565  accuracy =   0.7778  loss =  155.498\n",
      "training :  5566  accuracy =   0.8100  loss =  155.698\n",
      "testing  :  5566  accuracy =   0.7788  loss =  155.358\n",
      "training :  5567  accuracy =   0.7800  loss =  154.228\n",
      "testing  :  5567  accuracy =   0.7811  loss =  155.111\n",
      "training :  5568  accuracy =   0.7300  loss =  155.586\n",
      "testing  :  5568  accuracy =   0.7829  loss =  154.875\n",
      "training :  5569  accuracy =   0.8200  loss =  155.454\n",
      "testing  :  5569  accuracy =   0.7841  loss =  154.715\n",
      "training :  5570  accuracy =   0.8100  loss =  152.27\n",
      "testing  :  5570  accuracy =   0.7848  loss =  154.535\n",
      "training :  5571  accuracy =   0.8000  loss =  152.943\n",
      "testing  :  5571  accuracy =   0.7850  loss =  154.395\n",
      "training :  5572  accuracy =   0.8100  loss =  152.097\n",
      "testing  :  5572  accuracy =   0.7844  loss =  154.272\n",
      "training :  5573  accuracy =   0.7500  loss =  155.242\n",
      "testing  :  5573  accuracy =   0.7845  loss =  154.203\n",
      "training :  5574  accuracy =   0.8700  loss =  152.417\n",
      "testing  :  5574  accuracy =   0.7847  loss =  154.181\n",
      "training :  5575  accuracy =   0.7500  loss =  152.859\n",
      "testing  :  5575  accuracy =   0.7832  loss =  154.197\n",
      "training :  5576  accuracy =   0.7600  loss =  156.337\n",
      "testing  :  5576  accuracy =   0.7812  loss =  154.25\n",
      "training :  5577  accuracy =   0.7900  loss =  153.157\n",
      "testing  :  5577  accuracy =   0.7799  loss =  154.307\n",
      "training :  5578  accuracy =   0.6900  loss =  155.074\n",
      "testing  :  5578  accuracy =   0.7783  loss =  154.429\n",
      "training :  5579  accuracy =   0.7900  loss =  151.86\n",
      "testing  :  5579  accuracy =   0.7768  loss =  154.54\n",
      "training :  5580  accuracy =   0.7500  loss =  153.251\n",
      "testing  :  5580  accuracy =   0.7757  loss =  154.585\n",
      "training :  5581  accuracy =   0.8000  loss =  154.063\n",
      "testing  :  5581  accuracy =   0.7751  loss =  154.629\n",
      "training :  5582  accuracy =   0.7800  loss =  153.115\n",
      "testing  :  5582  accuracy =   0.7756  loss =  154.614\n",
      "training :  5583  accuracy =   0.7800  loss =  154.298\n",
      "testing  :  5583  accuracy =   0.7753  loss =  154.571\n",
      "training :  5584  accuracy =   0.8000  loss =  153.348\n",
      "testing  :  5584  accuracy =   0.7759  loss =  154.525\n",
      "training :  5585  accuracy =   0.7200  loss =  153.959\n",
      "testing  :  5585  accuracy =   0.7744  loss =  154.514\n",
      "training :  5586  accuracy =   0.7300  loss =  153.076\n",
      "testing  :  5586  accuracy =   0.7740  loss =  154.525\n",
      "training :  5587  accuracy =   0.8300  loss =  152.078\n",
      "testing  :  5587  accuracy =   0.7744  loss =  154.498\n",
      "training :  5588  accuracy =   0.7700  loss =  153.253\n",
      "testing  :  5588  accuracy =   0.7750  loss =  154.431\n",
      "training :  5589  accuracy =   0.7000  loss =  156.295\n",
      "testing  :  5589  accuracy =   0.7756  loss =  154.351\n",
      "training :  5590  accuracy =   0.7600  loss =  151.608\n",
      "testing  :  5590  accuracy =   0.7787  loss =  154.24\n",
      "training :  5591  accuracy =   0.8000  loss =  153.778\n",
      "testing  :  5591  accuracy =   0.7809  loss =  154.172\n",
      "training :  5592  accuracy =   0.7500  loss =  155.547\n",
      "testing  :  5592  accuracy =   0.7839  loss =  154.117\n",
      "training :  5593  accuracy =   0.8200  loss =  153.332\n",
      "testing  :  5593  accuracy =   0.7874  loss =  154.096\n",
      "training :  5594  accuracy =   0.8100  loss =  152.57\n",
      "testing  :  5594  accuracy =   0.7913  loss =  154.082\n",
      "training :  5595  accuracy =   0.8100  loss =  153.203\n",
      "testing  :  5595  accuracy =   0.7950  loss =  154.093\n",
      "training :  5596  accuracy =   0.9100  loss =  152.426\n",
      "testing  :  5596  accuracy =   0.7992  loss =  154.126\n",
      "training :  5597  accuracy =   0.9300  loss =  150.648\n",
      "testing  :  5597  accuracy =   0.8062  loss =  154.161\n",
      "training :  5598  accuracy =   0.8100  loss =  152.251\n",
      "testing  :  5598  accuracy =   0.8099  loss =  154.181\n",
      "training :  5599  accuracy =   0.7900  loss =  152.071\n",
      "testing  :  5599  accuracy =   0.8154  loss =  154.194\n",
      "training :  5600  accuracy =   0.8900  loss =  151.723\n",
      "testing  :  5600  accuracy =   0.8202  loss =  154.2\n",
      "training :  5601  accuracy =   0.8100  loss =  155.457\n",
      "testing  :  5601  accuracy =   0.8296  loss =  154.2\n",
      "training :  5602  accuracy =   0.8900  loss =  153.65\n",
      "testing  :  5602  accuracy =   0.8407  loss =  154.21\n",
      "training :  5603  accuracy =   0.8800  loss =  151.269\n",
      "testing  :  5603  accuracy =   0.8474  loss =  154.231\n",
      "training :  5604  accuracy =   0.8900  loss =  152.154\n",
      "testing  :  5604  accuracy =   0.8497  loss =  154.223\n",
      "training :  5605  accuracy =   0.9100  loss =  151.246\n",
      "testing  :  5605  accuracy =   0.8533  loss =  154.214\n",
      "training :  5606  accuracy =   0.8600  loss =  153.59\n",
      "testing  :  5606  accuracy =   0.8522  loss =  154.207\n",
      "training :  5607  accuracy =   0.8900  loss =  154.527\n",
      "testing  :  5607  accuracy =   0.8422  loss =  154.219\n",
      "training :  5608  accuracy =   0.8200  loss =  151.415\n",
      "testing  :  5608  accuracy =   0.8288  loss =  154.211\n",
      "training :  5609  accuracy =   0.8200  loss =  152.155\n",
      "testing  :  5609  accuracy =   0.8177  loss =  154.207\n",
      "training :  5610  accuracy =   0.8700  loss =  150.837\n",
      "testing  :  5610  accuracy =   0.8124  loss =  154.201\n",
      "training :  5611  accuracy =   0.8400  loss =  152.222\n",
      "testing  :  5611  accuracy =   0.8055  loss =  154.201\n",
      "training :  5612  accuracy =   0.8100  loss =  153.925\n",
      "testing  :  5612  accuracy =   0.8024  loss =  154.203\n",
      "training :  5613  accuracy =   0.8300  loss =  153.291\n",
      "testing  :  5613  accuracy =   0.7967  loss =  154.205\n",
      "training :  5614  accuracy =   0.8100  loss =  151.447\n",
      "testing  :  5614  accuracy =   0.7961  loss =  154.212\n",
      "training :  5615  accuracy =   0.8400  loss =  152.997\n",
      "testing  :  5615  accuracy =   0.7950  loss =  154.221\n",
      "training :  5616  accuracy =   0.8500  loss =  152.057\n",
      "testing  :  5616  accuracy =   0.7947  loss =  154.23\n",
      "training :  5617  accuracy =   0.7700  loss =  153.51\n",
      "testing  :  5617  accuracy =   0.7938  loss =  154.239\n",
      "training :  5618  accuracy =   0.7400  loss =  155.762\n",
      "testing  :  5618  accuracy =   0.7936  loss =  154.249\n",
      "training :  5619  accuracy =   0.9000  loss =  150.277\n",
      "testing  :  5619  accuracy =   0.7927  loss =  154.243\n",
      "training :  5620  accuracy =   0.8300  loss =  151.623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5620  accuracy =   0.7918  loss =  154.242\n",
      "training :  5621  accuracy =   0.8100  loss =  151.91\n",
      "testing  :  5621  accuracy =   0.7906  loss =  154.242\n",
      "training :  5622  accuracy =   0.7800  loss =  152.904\n",
      "testing  :  5622  accuracy =   0.7905  loss =  154.262\n",
      "training :  5623  accuracy =   0.8200  loss =  152.387\n",
      "testing  :  5623  accuracy =   0.7901  loss =  154.28\n",
      "training :  5624  accuracy =   0.8500  loss =  151.553\n",
      "testing  :  5624  accuracy =   0.7897  loss =  154.271\n",
      "training :  5625  accuracy =   0.8200  loss =  150.789\n",
      "testing  :  5625  accuracy =   0.7897  loss =  154.258\n",
      "training :  5626  accuracy =   0.8100  loss =  151.004\n",
      "testing  :  5626  accuracy =   0.7888  loss =  154.242\n",
      "training :  5627  accuracy =   0.6800  loss =  157.128\n",
      "testing  :  5627  accuracy =   0.7884  loss =  154.23\n",
      "training :  5628  accuracy =   0.8600  loss =  153.848\n",
      "testing  :  5628  accuracy =   0.7879  loss =  154.219\n",
      "training :  5629  accuracy =   0.7200  loss =  158.339\n",
      "testing  :  5629  accuracy =   0.7871  loss =  154.214\n",
      "training :  5630  accuracy =   0.8000  loss =  153.873\n",
      "testing  :  5630  accuracy =   0.7870  loss =  154.215\n",
      "training :  5631  accuracy =   0.7900  loss =  152.37\n",
      "testing  :  5631  accuracy =   0.7874  loss =  154.212\n",
      "training :  5632  accuracy =   0.7100  loss =  156.015\n",
      "testing  :  5632  accuracy =   0.7876  loss =  154.224\n",
      "training :  5633  accuracy =   0.7900  loss =  153.286\n",
      "testing  :  5633  accuracy =   0.7881  loss =  154.216\n",
      "training :  5634  accuracy =   0.7700  loss =  154.431\n",
      "testing  :  5634  accuracy =   0.7888  loss =  154.236\n",
      "training :  5635  accuracy =   0.7500  loss =  153.715\n",
      "testing  :  5635  accuracy =   0.7891  loss =  154.217\n",
      "training :  5636  accuracy =   0.7900  loss =  155.181\n",
      "testing  :  5636  accuracy =   0.7897  loss =  154.203\n",
      "training :  5637  accuracy =   0.8100  loss =  152.208\n",
      "testing  :  5637  accuracy =   0.7890  loss =  154.21\n",
      "training :  5638  accuracy =   0.8400  loss =  151.199\n",
      "testing  :  5638  accuracy =   0.7885  loss =  154.229\n",
      "training :  5639  accuracy =   0.8100  loss =  152.833\n",
      "testing  :  5639  accuracy =   0.7887  loss =  154.236\n",
      "training :  5640  accuracy =   0.8200  loss =  153.152\n",
      "testing  :  5640  accuracy =   0.7883  loss =  154.245\n",
      "training :  5641  accuracy =   0.8200  loss =  153.755\n",
      "testing  :  5641  accuracy =   0.7879  loss =  154.246\n",
      "training :  5642  accuracy =   0.7900  loss =  152.25\n",
      "testing  :  5642  accuracy =   0.7883  loss =  154.248\n",
      "training :  5643  accuracy =   0.8700  loss =  152.136\n",
      "testing  :  5643  accuracy =   0.7884  loss =  154.244\n",
      "training :  5644  accuracy =   0.8400  loss =  151.634\n",
      "testing  :  5644  accuracy =   0.7887  loss =  154.225\n",
      "training :  5645  accuracy =   0.8100  loss =  153.516\n",
      "testing  :  5645  accuracy =   0.7891  loss =  154.205\n",
      "training :  5646  accuracy =   0.8100  loss =  152.01\n",
      "testing  :  5646  accuracy =   0.7890  loss =  154.186\n",
      "training :  5647  accuracy =   0.8300  loss =  151.838\n",
      "testing  :  5647  accuracy =   0.7890  loss =  154.176\n",
      "training :  5648  accuracy =   0.8300  loss =  150.565\n",
      "testing  :  5648  accuracy =   0.7892  loss =  154.165\n",
      "training :  5649  accuracy =   0.7500  loss =  152.848\n",
      "testing  :  5649  accuracy =   0.7891  loss =  154.159\n",
      "training :  5650  accuracy =   0.8300  loss =  152.59\n",
      "testing  :  5650  accuracy =   0.7892  loss =  154.155\n",
      "training :  5651  accuracy =   0.8100  loss =  154.125\n",
      "testing  :  5651  accuracy =   0.7891  loss =  154.154\n",
      "training :  5652  accuracy =   0.8200  loss =  151.968\n",
      "testing  :  5652  accuracy =   0.7893  loss =  154.122\n",
      "training :  5653  accuracy =   0.8000  loss =  151.257\n",
      "testing  :  5653  accuracy =   0.7892  loss =  154.092\n",
      "training :  5654  accuracy =   0.8300  loss =  152.461\n",
      "testing  :  5654  accuracy =   0.7886  loss =  154.081\n",
      "training :  5655  accuracy =   0.7400  loss =  152.517\n",
      "testing  :  5655  accuracy =   0.7887  loss =  154.068\n",
      "training :  5656  accuracy =   0.8500  loss =  150.723\n",
      "testing  :  5656  accuracy =   0.7885  loss =  154.049\n",
      "training :  5657  accuracy =   0.8000  loss =  154.352\n",
      "testing  :  5657  accuracy =   0.7884  loss =  154.056\n",
      "training :  5658  accuracy =   0.7600  loss =  152.899\n",
      "testing  :  5658  accuracy =   0.7887  loss =  154.077\n",
      "training :  5659  accuracy =   0.8400  loss =  151.836\n",
      "testing  :  5659  accuracy =   0.7886  loss =  154.119\n",
      "training :  5660  accuracy =   0.7800  loss =  153.388\n",
      "testing  :  5660  accuracy =   0.7894  loss =  154.165\n",
      "training :  5661  accuracy =   0.7300  loss =  157.172\n",
      "testing  :  5661  accuracy =   0.7897  loss =  154.234\n",
      "training :  5662  accuracy =   0.7800  loss =  154.625\n",
      "testing  :  5662  accuracy =   0.7894  loss =  154.297\n",
      "training :  5663  accuracy =   0.8400  loss =  152.814\n",
      "testing  :  5663  accuracy =   0.7890  loss =  154.352\n",
      "training :  5664  accuracy =   0.7700  loss =  152.094\n",
      "testing  :  5664  accuracy =   0.7892  loss =  154.343\n",
      "training :  5665  accuracy =   0.7900  loss =  151.484\n",
      "testing  :  5665  accuracy =   0.7893  loss =  154.349\n",
      "training :  5666  accuracy =   0.8100  loss =  152.552\n",
      "testing  :  5666  accuracy =   0.7896  loss =  154.359\n",
      "training :  5667  accuracy =   0.8000  loss =  153.548\n",
      "testing  :  5667  accuracy =   0.7890  loss =  154.363\n",
      "training :  5668  accuracy =   0.8200  loss =  151.997\n",
      "testing  :  5668  accuracy =   0.7891  loss =  154.352\n",
      "training :  5669  accuracy =   0.7900  loss =  151.814\n",
      "testing  :  5669  accuracy =   0.7889  loss =  154.36\n",
      "training :  5670  accuracy =   0.8300  loss =  151.617\n",
      "testing  :  5670  accuracy =   0.7891  loss =  154.353\n",
      "training :  5671  accuracy =   0.8700  loss =  150.483\n",
      "testing  :  5671  accuracy =   0.7886  loss =  154.336\n",
      "training :  5672  accuracy =   0.8600  loss =  152.22\n",
      "testing  :  5672  accuracy =   0.7882  loss =  154.335\n",
      "training :  5673  accuracy =   0.8100  loss =  153.08\n",
      "testing  :  5673  accuracy =   0.7882  loss =  154.34\n",
      "training :  5674  accuracy =   0.8900  loss =  151.257\n",
      "testing  :  5674  accuracy =   0.7877  loss =  154.347\n",
      "training :  5675  accuracy =   0.7700  loss =  155.194\n",
      "testing  :  5675  accuracy =   0.7875  loss =  154.343\n",
      "training :  5676  accuracy =   0.7600  loss =  152.753\n",
      "testing  :  5676  accuracy =   0.7868  loss =  154.338\n",
      "training :  5677  accuracy =   0.8700  loss =  150.935\n",
      "testing  :  5677  accuracy =   0.7872  loss =  154.342\n",
      "training :  5678  accuracy =   0.8100  loss =  152.034\n",
      "testing  :  5678  accuracy =   0.7871  loss =  154.344\n",
      "training :  5679  accuracy =   0.8000  loss =  154.662\n",
      "testing  :  5679  accuracy =   0.7871  loss =  154.351\n",
      "training :  5680  accuracy =   0.8000  loss =  153.092\n",
      "testing  :  5680  accuracy =   0.7866  loss =  154.331\n",
      "training :  5681  accuracy =   0.8100  loss =  152.427\n",
      "testing  :  5681  accuracy =   0.7868  loss =  154.312\n",
      "training :  5682  accuracy =   0.8400  loss =  151.661\n",
      "testing  :  5682  accuracy =   0.7865  loss =  154.296\n",
      "training :  5683  accuracy =   0.8300  loss =  151.236\n",
      "testing  :  5683  accuracy =   0.7874  loss =  154.294\n",
      "training :  5684  accuracy =   0.7200  loss =  152.377\n",
      "testing  :  5684  accuracy =   0.7868  loss =  154.301\n",
      "training :  5685  accuracy =   0.7900  loss =  152.241\n",
      "testing  :  5685  accuracy =   0.7872  loss =  154.3\n",
      "training :  5686  accuracy =   0.8100  loss =  154.623\n",
      "testing  :  5686  accuracy =   0.7870  loss =  154.349\n",
      "training :  5687  accuracy =   0.7800  loss =  154.15\n",
      "testing  :  5687  accuracy =   0.7864  loss =  154.414\n",
      "training :  5688  accuracy =   0.7700  loss =  153.476\n",
      "testing  :  5688  accuracy =   0.7858  loss =  154.481\n",
      "training :  5689  accuracy =   0.8500  loss =  152.207\n",
      "testing  :  5689  accuracy =   0.7845  loss =  154.537\n",
      "training :  5690  accuracy =   0.7800  loss =  154.482\n",
      "testing  :  5690  accuracy =   0.7841  loss =  154.596\n",
      "training :  5691  accuracy =   0.7700  loss =  154.087\n",
      "testing  :  5691  accuracy =   0.7830  loss =  154.69\n",
      "training :  5692  accuracy =   0.7900  loss =  155.064\n",
      "testing  :  5692  accuracy =   0.7827  loss =  154.76\n",
      "training :  5693  accuracy =   0.7800  loss =  152.755\n",
      "testing  :  5693  accuracy =   0.7825  loss =  154.77\n",
      "training :  5694  accuracy =   0.8400  loss =  151.685\n",
      "testing  :  5694  accuracy =   0.7828  loss =  154.785\n",
      "training :  5695  accuracy =   0.7300  loss =  154.989\n",
      "testing  :  5695  accuracy =   0.7829  loss =  154.802\n",
      "training :  5696  accuracy =   0.8100  loss =  152.351\n",
      "testing  :  5696  accuracy =   0.7844  loss =  154.709\n",
      "training :  5697  accuracy =   0.8000  loss =  153.371\n",
      "testing  :  5697  accuracy =   0.7863  loss =  154.61\n",
      "training :  5698  accuracy =   0.8100  loss =  152.046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5698  accuracy =   0.7876  loss =  154.515\n",
      "training :  5699  accuracy =   0.8800  loss =  149.969\n",
      "testing  :  5699  accuracy =   0.7885  loss =  154.427\n",
      "training :  5700  accuracy =   0.8300  loss =  152.212\n",
      "testing  :  5700  accuracy =   0.7900  loss =  154.363\n",
      "training :  5701  accuracy =   0.7600  loss =  153.596\n",
      "testing  :  5701  accuracy =   0.7916  loss =  154.258\n",
      "training :  5702  accuracy =   0.8300  loss =  151.906\n",
      "testing  :  5702  accuracy =   0.7935  loss =  154.2\n",
      "training :  5703  accuracy =   0.8200  loss =  153.004\n",
      "testing  :  5703  accuracy =   0.7951  loss =  154.173\n",
      "training :  5704  accuracy =   0.6700  loss =  153.696\n",
      "testing  :  5704  accuracy =   0.7959  loss =  154.16\n",
      "training :  5705  accuracy =   0.7900  loss =  151.412\n",
      "testing  :  5705  accuracy =   0.7970  loss =  154.15\n",
      "training :  5706  accuracy =   0.7500  loss =  154.497\n",
      "testing  :  5706  accuracy =   0.7979  loss =  154.145\n",
      "training :  5707  accuracy =   0.8200  loss =  153.251\n",
      "testing  :  5707  accuracy =   0.7994  loss =  154.141\n",
      "training :  5708  accuracy =   0.7700  loss =  153.256\n",
      "testing  :  5708  accuracy =   0.8013  loss =  154.145\n",
      "training :  5709  accuracy =   0.7600  loss =  156.325\n",
      "testing  :  5709  accuracy =   0.8007  loss =  154.136\n",
      "training :  5710  accuracy =   0.7300  loss =  154.139\n",
      "testing  :  5710  accuracy =   0.8007  loss =  154.138\n",
      "training :  5711  accuracy =   0.7700  loss =  153.087\n",
      "testing  :  5711  accuracy =   0.8012  loss =  154.143\n",
      "training :  5712  accuracy =   0.8500  loss =  153.102\n",
      "testing  :  5712  accuracy =   0.8013  loss =  154.163\n",
      "training :  5713  accuracy =   0.8200  loss =  151.568\n",
      "testing  :  5713  accuracy =   0.8012  loss =  154.181\n",
      "training :  5714  accuracy =   0.8500  loss =  153.695\n",
      "testing  :  5714  accuracy =   0.8006  loss =  154.193\n",
      "training :  5715  accuracy =   0.7700  loss =  155.162\n",
      "testing  :  5715  accuracy =   0.8017  loss =  154.293\n",
      "training :  5716  accuracy =   0.8000  loss =  154.983\n",
      "testing  :  5716  accuracy =   0.8030  loss =  154.441\n",
      "training :  5717  accuracy =   0.7800  loss =  157.017\n",
      "testing  :  5717  accuracy =   0.8043  loss =  154.56\n",
      "training :  5718  accuracy =   0.7500  loss =  155.838\n",
      "testing  :  5718  accuracy =   0.8064  loss =  154.587\n",
      "training :  5719  accuracy =   0.7700  loss =  154.181\n",
      "testing  :  5719  accuracy =   0.8078  loss =  154.611\n",
      "training :  5720  accuracy =   0.8300  loss =  151.893\n",
      "testing  :  5720  accuracy =   0.8080  loss =  154.653\n",
      "training :  5721  accuracy =   0.8600  loss =  151.393\n",
      "testing  :  5721  accuracy =   0.8073  loss =  154.67\n",
      "training :  5722  accuracy =   0.8700  loss =  150.401\n",
      "testing  :  5722  accuracy =   0.8053  loss =  154.659\n",
      "training :  5723  accuracy =   0.8000  loss =  153.048\n",
      "testing  :  5723  accuracy =   0.8043  loss =  154.65\n",
      "training :  5724  accuracy =   0.8300  loss =  154.541\n",
      "testing  :  5724  accuracy =   0.8029  loss =  154.648\n",
      "training :  5725  accuracy =   0.8200  loss =  153.155\n",
      "testing  :  5725  accuracy =   0.8011  loss =  154.647\n",
      "training :  5726  accuracy =   0.8200  loss =  155.158\n",
      "testing  :  5726  accuracy =   0.8002  loss =  154.644\n",
      "training :  5727  accuracy =   0.8300  loss =  151.77\n",
      "testing  :  5727  accuracy =   0.8000  loss =  154.594\n",
      "training :  5728  accuracy =   0.7900  loss =  152.053\n",
      "testing  :  5728  accuracy =   0.7992  loss =  154.541\n",
      "training :  5729  accuracy =   0.7800  loss =  153.748\n",
      "testing  :  5729  accuracy =   0.7976  loss =  154.473\n",
      "training :  5730  accuracy =   0.8100  loss =  152.21\n",
      "testing  :  5730  accuracy =   0.7975  loss =  154.436\n",
      "training :  5731  accuracy =   0.7700  loss =  152.934\n",
      "testing  :  5731  accuracy =   0.7959  loss =  154.405\n",
      "training :  5732  accuracy =   0.8200  loss =  152.393\n",
      "testing  :  5732  accuracy =   0.7959  loss =  154.377\n",
      "training :  5733  accuracy =   0.8200  loss =  152.914\n",
      "testing  :  5733  accuracy =   0.7961  loss =  154.357\n",
      "training :  5734  accuracy =   0.8200  loss =  154.298\n",
      "testing  :  5734  accuracy =   0.7964  loss =  154.347\n",
      "training :  5735  accuracy =   0.8200  loss =  153.575\n",
      "testing  :  5735  accuracy =   0.7965  loss =  154.359\n",
      "training :  5736  accuracy =   0.7300  loss =  154.355\n",
      "testing  :  5736  accuracy =   0.7961  loss =  154.374\n",
      "training :  5737  accuracy =   0.8100  loss =  154.811\n",
      "testing  :  5737  accuracy =   0.7965  loss =  154.369\n",
      "training :  5738  accuracy =   0.7900  loss =  153.438\n",
      "testing  :  5738  accuracy =   0.7970  loss =  154.283\n",
      "training :  5739  accuracy =   0.8600  loss =  151.884\n",
      "testing  :  5739  accuracy =   0.7999  loss =  154.227\n",
      "training :  5740  accuracy =   0.7500  loss =  156.153\n",
      "testing  :  5740  accuracy =   0.7996  loss =  154.209\n",
      "training :  5741  accuracy =   0.8100  loss =  152.637\n",
      "testing  :  5741  accuracy =   0.8019  loss =  154.179\n",
      "training :  5742  accuracy =   0.7800  loss =  154.095\n",
      "testing  :  5742  accuracy =   0.8016  loss =  154.148\n",
      "training :  5743  accuracy =   0.7300  loss =  154.479\n",
      "testing  :  5743  accuracy =   0.8016  loss =  154.152\n",
      "training :  5744  accuracy =   0.8100  loss =  152.695\n",
      "testing  :  5744  accuracy =   0.8018  loss =  154.17\n",
      "training :  5745  accuracy =   0.7300  loss =  153.905\n",
      "testing  :  5745  accuracy =   0.8026  loss =  154.213\n",
      "training :  5746  accuracy =   0.8400  loss =  152.668\n",
      "testing  :  5746  accuracy =   0.7992  loss =  154.215\n",
      "training :  5747  accuracy =   0.7900  loss =  151.21\n",
      "testing  :  5747  accuracy =   0.7943  loss =  154.271\n",
      "training :  5748  accuracy =   0.7500  loss =  155.645\n",
      "testing  :  5748  accuracy =   0.7896  loss =  154.368\n",
      "training :  5749  accuracy =   0.7900  loss =  153.783\n",
      "testing  :  5749  accuracy =   0.7863  loss =  154.465\n",
      "training :  5750  accuracy =   0.7800  loss =  153.695\n",
      "testing  :  5750  accuracy =   0.7835  loss =  154.535\n",
      "training :  5751  accuracy =   0.7800  loss =  154.155\n",
      "testing  :  5751  accuracy =   0.7816  loss =  154.569\n",
      "training :  5752  accuracy =   0.7900  loss =  154.292\n",
      "testing  :  5752  accuracy =   0.7817  loss =  154.592\n",
      "training :  5753  accuracy =   0.8000  loss =  153.661\n",
      "testing  :  5753  accuracy =   0.7815  loss =  154.595\n",
      "training :  5754  accuracy =   0.7500  loss =  153.794\n",
      "testing  :  5754  accuracy =   0.7827  loss =  154.564\n",
      "training :  5755  accuracy =   0.7800  loss =  154.995\n",
      "testing  :  5755  accuracy =   0.7859  loss =  154.502\n",
      "training :  5756  accuracy =   0.8000  loss =  153.696\n",
      "testing  :  5756  accuracy =   0.7880  loss =  154.457\n",
      "training :  5757  accuracy =   0.7900  loss =  153.164\n",
      "testing  :  5757  accuracy =   0.7911  loss =  154.381\n",
      "training :  5758  accuracy =   0.8200  loss =  152.033\n",
      "testing  :  5758  accuracy =   0.7940  loss =  154.334\n",
      "training :  5759  accuracy =   0.8100  loss =  152.545\n",
      "testing  :  5759  accuracy =   0.7952  loss =  154.311\n",
      "training :  5760  accuracy =   0.8400  loss =  152.157\n",
      "testing  :  5760  accuracy =   0.7957  loss =  154.296\n",
      "training :  5761  accuracy =   0.7700  loss =  151.861\n",
      "testing  :  5761  accuracy =   0.7960  loss =  154.285\n",
      "training :  5762  accuracy =   0.8100  loss =  152.129\n",
      "testing  :  5762  accuracy =   0.7962  loss =  154.273\n",
      "training :  5763  accuracy =   0.8100  loss =  152.0\n",
      "testing  :  5763  accuracy =   0.7968  loss =  154.261\n",
      "training :  5764  accuracy =   0.8400  loss =  153.288\n",
      "testing  :  5764  accuracy =   0.7965  loss =  154.255\n",
      "training :  5765  accuracy =   0.7800  loss =  153.456\n",
      "testing  :  5765  accuracy =   0.7959  loss =  154.248\n",
      "training :  5766  accuracy =   0.7300  loss =  153.535\n",
      "testing  :  5766  accuracy =   0.7958  loss =  154.177\n",
      "training :  5767  accuracy =   0.8300  loss =  152.167\n",
      "testing  :  5767  accuracy =   0.7981  loss =  154.111\n",
      "training :  5768  accuracy =   0.8500  loss =  152.304\n",
      "testing  :  5768  accuracy =   0.7984  loss =  154.078\n",
      "training :  5769  accuracy =   0.8600  loss =  152.129\n",
      "testing  :  5769  accuracy =   0.7978  loss =  154.068\n",
      "training :  5770  accuracy =   0.8100  loss =  152.509\n",
      "testing  :  5770  accuracy =   0.7979  loss =  154.051\n",
      "training :  5771  accuracy =   0.8500  loss =  152.089\n",
      "testing  :  5771  accuracy =   0.7972  loss =  154.034\n",
      "training :  5772  accuracy =   0.7700  loss =  152.886\n",
      "testing  :  5772  accuracy =   0.7970  loss =  154.029\n",
      "training :  5773  accuracy =   0.8200  loss =  153.46\n",
      "testing  :  5773  accuracy =   0.7974  loss =  154.034\n",
      "training :  5774  accuracy =   0.7400  loss =  156.427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5774  accuracy =   0.7970  loss =  154.072\n",
      "training :  5775  accuracy =   0.8100  loss =  152.156\n",
      "testing  :  5775  accuracy =   0.7969  loss =  154.152\n",
      "training :  5776  accuracy =   0.8200  loss =  153.697\n",
      "testing  :  5776  accuracy =   0.7960  loss =  154.254\n",
      "training :  5777  accuracy =   0.8100  loss =  152.978\n",
      "testing  :  5777  accuracy =   0.7954  loss =  154.351\n",
      "training :  5778  accuracy =   0.8200  loss =  153.489\n",
      "testing  :  5778  accuracy =   0.7953  loss =  154.451\n",
      "training :  5779  accuracy =   0.7800  loss =  153.692\n",
      "testing  :  5779  accuracy =   0.7943  loss =  154.533\n",
      "training :  5780  accuracy =   0.8100  loss =  152.979\n",
      "testing  :  5780  accuracy =   0.7931  loss =  154.626\n",
      "training :  5781  accuracy =   0.8400  loss =  154.082\n",
      "testing  :  5781  accuracy =   0.7917  loss =  154.517\n",
      "training :  5782  accuracy =   0.7800  loss =  155.191\n",
      "testing  :  5782  accuracy =   0.7911  loss =  154.409\n",
      "training :  5783  accuracy =   0.8200  loss =  150.57\n",
      "testing  :  5783  accuracy =   0.7916  loss =  154.312\n",
      "training :  5784  accuracy =   0.7500  loss =  154.441\n",
      "testing  :  5784  accuracy =   0.7910  loss =  154.233\n",
      "training :  5785  accuracy =   0.7900  loss =  151.954\n",
      "testing  :  5785  accuracy =   0.7908  loss =  154.148\n",
      "training :  5786  accuracy =   0.7800  loss =  154.248\n",
      "testing  :  5786  accuracy =   0.7905  loss =  154.089\n",
      "training :  5787  accuracy =   0.7500  loss =  154.745\n",
      "testing  :  5787  accuracy =   0.7900  loss =  154.048\n",
      "training :  5788  accuracy =   0.8900  loss =  151.437\n",
      "testing  :  5788  accuracy =   0.7907  loss =  154.028\n",
      "training :  5789  accuracy =   0.8200  loss =  151.706\n",
      "testing  :  5789  accuracy =   0.7912  loss =  154.022\n",
      "training :  5790  accuracy =   0.8300  loss =  152.638\n",
      "testing  :  5790  accuracy =   0.7915  loss =  154.026\n",
      "training :  5791  accuracy =   0.7800  loss =  153.72\n",
      "testing  :  5791  accuracy =   0.7914  loss =  154.032\n",
      "training :  5792  accuracy =   0.7300  loss =  154.441\n",
      "testing  :  5792  accuracy =   0.7915  loss =  154.035\n",
      "training :  5793  accuracy =   0.7900  loss =  152.39\n",
      "testing  :  5793  accuracy =   0.7939  loss =  154.002\n",
      "training :  5794  accuracy =   0.7700  loss =  151.634\n",
      "testing  :  5794  accuracy =   0.7949  loss =  154.004\n",
      "training :  5795  accuracy =   0.8200  loss =  153.469\n",
      "testing  :  5795  accuracy =   0.7965  loss =  154.029\n",
      "training :  5796  accuracy =   0.7600  loss =  154.103\n",
      "testing  :  5796  accuracy =   0.7975  loss =  154.079\n",
      "training :  5797  accuracy =   0.7400  loss =  154.218\n",
      "testing  :  5797  accuracy =   0.7981  loss =  154.133\n",
      "training :  5798  accuracy =   0.8100  loss =  154.026\n",
      "testing  :  5798  accuracy =   0.7998  loss =  154.166\n",
      "training :  5799  accuracy =   0.9100  loss =  154.186\n",
      "testing  :  5799  accuracy =   0.8015  loss =  154.194\n",
      "training :  5800  accuracy =   0.8300  loss =  152.012\n",
      "testing  :  5800  accuracy =   0.8020  loss =  154.22\n",
      "training :  5801  accuracy =   0.8400  loss =  152.74\n",
      "testing  :  5801  accuracy =   0.8021  loss =  154.236\n",
      "training :  5802  accuracy =   0.8700  loss =  151.457\n",
      "testing  :  5802  accuracy =   0.8028  loss =  154.248\n",
      "training :  5803  accuracy =   0.8000  loss =  151.091\n",
      "testing  :  5803  accuracy =   0.8017  loss =  154.209\n",
      "training :  5804  accuracy =   0.8300  loss =  154.527\n",
      "testing  :  5804  accuracy =   0.8004  loss =  154.183\n",
      "training :  5805  accuracy =   0.8300  loss =  151.728\n",
      "testing  :  5805  accuracy =   0.7987  loss =  154.175\n",
      "training :  5806  accuracy =   0.8200  loss =  152.149\n",
      "testing  :  5806  accuracy =   0.7978  loss =  154.171\n",
      "training :  5807  accuracy =   0.7700  loss =  155.785\n",
      "testing  :  5807  accuracy =   0.7957  loss =  154.164\n",
      "training :  5808  accuracy =   0.8400  loss =  151.546\n",
      "testing  :  5808  accuracy =   0.7949  loss =  154.15\n",
      "training :  5809  accuracy =   0.8300  loss =  153.34\n",
      "testing  :  5809  accuracy =   0.7944  loss =  154.149\n",
      "training :  5810  accuracy =   0.8300  loss =  153.318\n",
      "testing  :  5810  accuracy =   0.7941  loss =  154.157\n",
      "training :  5811  accuracy =   0.8100  loss =  153.774\n",
      "testing  :  5811  accuracy =   0.7931  loss =  154.18\n",
      "training :  5812  accuracy =   0.7800  loss =  153.048\n",
      "testing  :  5812  accuracy =   0.7929  loss =  154.184\n",
      "training :  5813  accuracy =   0.8900  loss =  150.594\n",
      "testing  :  5813  accuracy =   0.7923  loss =  154.191\n",
      "training :  5814  accuracy =   0.8100  loss =  151.771\n",
      "testing  :  5814  accuracy =   0.7917  loss =  154.2\n",
      "training :  5815  accuracy =   0.7100  loss =  152.585\n",
      "testing  :  5815  accuracy =   0.7909  loss =  154.205\n",
      "training :  5816  accuracy =   0.8100  loss =  153.285\n",
      "testing  :  5816  accuracy =   0.7906  loss =  154.209\n",
      "training :  5817  accuracy =   0.7500  loss =  153.611\n",
      "testing  :  5817  accuracy =   0.7904  loss =  154.214\n",
      "training :  5818  accuracy =   0.8100  loss =  153.862\n",
      "testing  :  5818  accuracy =   0.7904  loss =  154.22\n",
      "training :  5819  accuracy =   0.8100  loss =  152.389\n",
      "testing  :  5819  accuracy =   0.7900  loss =  154.233\n",
      "training :  5820  accuracy =   0.8000  loss =  154.718\n",
      "testing  :  5820  accuracy =   0.7900  loss =  154.231\n",
      "training :  5821  accuracy =   0.7500  loss =  154.043\n",
      "testing  :  5821  accuracy =   0.7905  loss =  154.225\n",
      "training :  5822  accuracy =   0.8300  loss =  153.137\n",
      "testing  :  5822  accuracy =   0.7906  loss =  154.217\n",
      "training :  5823  accuracy =   0.8300  loss =  154.343\n",
      "testing  :  5823  accuracy =   0.7907  loss =  154.217\n",
      "training :  5824  accuracy =   0.8200  loss =  151.385\n",
      "testing  :  5824  accuracy =   0.7912  loss =  154.191\n",
      "training :  5825  accuracy =   0.8300  loss =  155.219\n",
      "testing  :  5825  accuracy =   0.7921  loss =  154.169\n",
      "training :  5826  accuracy =   0.8100  loss =  152.503\n",
      "testing  :  5826  accuracy =   0.7921  loss =  154.121\n",
      "training :  5827  accuracy =   0.8300  loss =  153.067\n",
      "testing  :  5827  accuracy =   0.7930  loss =  154.096\n",
      "training :  5828  accuracy =   0.7800  loss =  155.716\n",
      "testing  :  5828  accuracy =   0.7943  loss =  154.099\n",
      "training :  5829  accuracy =   0.7700  loss =  153.088\n",
      "testing  :  5829  accuracy =   0.7950  loss =  154.094\n",
      "training :  5830  accuracy =   0.8500  loss =  151.356\n",
      "testing  :  5830  accuracy =   0.7957  loss =  154.084\n",
      "training :  5831  accuracy =   0.7600  loss =  155.103\n",
      "testing  :  5831  accuracy =   0.7962  loss =  154.081\n",
      "training :  5832  accuracy =   0.7400  loss =  153.513\n",
      "testing  :  5832  accuracy =   0.7950  loss =  154.062\n",
      "training :  5833  accuracy =   0.8200  loss =  152.62\n",
      "testing  :  5833  accuracy =   0.7947  loss =  154.077\n",
      "training :  5834  accuracy =   0.7100  loss =  152.195\n",
      "testing  :  5834  accuracy =   0.7950  loss =  154.117\n",
      "training :  5835  accuracy =   0.8300  loss =  153.202\n",
      "testing  :  5835  accuracy =   0.7949  loss =  154.171\n",
      "training :  5836  accuracy =   0.7800  loss =  151.946\n",
      "testing  :  5836  accuracy =   0.7947  loss =  154.255\n",
      "training :  5837  accuracy =   0.7600  loss =  154.599\n",
      "testing  :  5837  accuracy =   0.7947  loss =  154.344\n",
      "training :  5838  accuracy =   0.8600  loss =  153.949\n",
      "testing  :  5838  accuracy =   0.7950  loss =  154.424\n",
      "training :  5839  accuracy =   0.8000  loss =  154.38\n",
      "testing  :  5839  accuracy =   0.7986  loss =  154.5\n",
      "training :  5840  accuracy =   0.8000  loss =  152.685\n",
      "testing  :  5840  accuracy =   0.8075  loss =  154.585\n",
      "training :  5841  accuracy =   0.8500  loss =  154.441\n",
      "testing  :  5841  accuracy =   0.8343  loss =  154.565\n",
      "training :  5842  accuracy =   0.8500  loss =  153.299\n",
      "testing  :  5842  accuracy =   0.8398  loss =  154.542\n",
      "training :  5843  accuracy =   0.9300  loss =  151.318\n",
      "testing  :  5843  accuracy =   0.8348  loss =  154.509\n",
      "training :  5844  accuracy =   0.8000  loss =  155.34\n",
      "testing  :  5844  accuracy =   0.8240  loss =  154.483\n",
      "training :  5845  accuracy =   0.8300  loss =  151.846\n",
      "testing  :  5845  accuracy =   0.8154  loss =  154.427\n",
      "training :  5846  accuracy =   0.8200  loss =  153.084\n",
      "testing  :  5846  accuracy =   0.8086  loss =  154.36\n",
      "training :  5847  accuracy =   0.8100  loss =  154.731\n",
      "testing  :  5847  accuracy =   0.8034  loss =  154.297\n",
      "training :  5848  accuracy =   0.8600  loss =  153.147\n",
      "testing  :  5848  accuracy =   0.8010  loss =  154.262\n",
      "training :  5849  accuracy =   0.8000  loss =  154.513\n",
      "testing  :  5849  accuracy =   0.7987  loss =  154.239\n",
      "training :  5850  accuracy =   0.8400  loss =  152.366\n",
      "testing  :  5850  accuracy =   0.7950  loss =  154.209\n",
      "training :  5851  accuracy =   0.7900  loss =  154.005\n",
      "testing  :  5851  accuracy =   0.7934  loss =  154.182\n",
      "training :  5852  accuracy =   0.7100  loss =  155.124\n",
      "testing  :  5852  accuracy =   0.7928  loss =  154.162\n",
      "training :  5853  accuracy =   0.7600  loss =  153.904\n",
      "testing  :  5853  accuracy =   0.7930  loss =  154.151\n",
      "training :  5854  accuracy =   0.8700  loss =  152.222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5854  accuracy =   0.7926  loss =  154.137\n",
      "training :  5855  accuracy =   0.8000  loss =  152.971\n",
      "testing  :  5855  accuracy =   0.7925  loss =  154.13\n",
      "training :  5856  accuracy =   0.8400  loss =  151.53\n",
      "testing  :  5856  accuracy =   0.7920  loss =  154.129\n",
      "training :  5857  accuracy =   0.7600  loss =  155.054\n",
      "testing  :  5857  accuracy =   0.7920  loss =  154.127\n",
      "training :  5858  accuracy =   0.8400  loss =  152.563\n",
      "testing  :  5858  accuracy =   0.7933  loss =  154.097\n",
      "training :  5859  accuracy =   0.7800  loss =  154.017\n",
      "testing  :  5859  accuracy =   0.7944  loss =  154.088\n",
      "training :  5860  accuracy =   0.8500  loss =  151.732\n",
      "testing  :  5860  accuracy =   0.7956  loss =  154.096\n",
      "training :  5861  accuracy =   0.7800  loss =  153.953\n",
      "testing  :  5861  accuracy =   0.7964  loss =  154.125\n",
      "training :  5862  accuracy =   0.7600  loss =  153.186\n",
      "testing  :  5862  accuracy =   0.7970  loss =  154.155\n",
      "training :  5863  accuracy =   0.8100  loss =  153.471\n",
      "testing  :  5863  accuracy =   0.7978  loss =  154.188\n",
      "training :  5864  accuracy =   0.6900  loss =  156.268\n",
      "testing  :  5864  accuracy =   0.8004  loss =  154.218\n",
      "training :  5865  accuracy =   0.7700  loss =  154.435\n",
      "testing  :  5865  accuracy =   0.8000  loss =  154.196\n",
      "training :  5866  accuracy =   0.8200  loss =  151.67\n",
      "testing  :  5866  accuracy =   0.8010  loss =  154.179\n",
      "training :  5867  accuracy =   0.7800  loss =  152.847\n",
      "testing  :  5867  accuracy =   0.8022  loss =  154.165\n",
      "training :  5868  accuracy =   0.8200  loss =  152.828\n",
      "testing  :  5868  accuracy =   0.8010  loss =  154.152\n",
      "training :  5869  accuracy =   0.8300  loss =  156.01\n",
      "testing  :  5869  accuracy =   0.7992  loss =  154.141\n",
      "training :  5870  accuracy =   0.7900  loss =  154.662\n",
      "testing  :  5870  accuracy =   0.7990  loss =  154.149\n",
      "training :  5871  accuracy =   0.8400  loss =  154.461\n",
      "testing  :  5871  accuracy =   0.7979  loss =  154.181\n",
      "training :  5872  accuracy =   0.8200  loss =  153.63\n",
      "testing  :  5872  accuracy =   0.7965  loss =  154.211\n",
      "training :  5873  accuracy =   0.7300  loss =  156.511\n",
      "testing  :  5873  accuracy =   0.7954  loss =  154.279\n",
      "training :  5874  accuracy =   0.7500  loss =  152.35\n",
      "testing  :  5874  accuracy =   0.7950  loss =  154.369\n",
      "training :  5875  accuracy =   0.8200  loss =  151.728\n",
      "testing  :  5875  accuracy =   0.7944  loss =  154.447\n",
      "training :  5876  accuracy =   0.8000  loss =  152.782\n",
      "testing  :  5876  accuracy =   0.7938  loss =  154.524\n",
      "training :  5877  accuracy =   0.8000  loss =  152.872\n",
      "testing  :  5877  accuracy =   0.7928  loss =  154.59\n",
      "training :  5878  accuracy =   0.7900  loss =  152.532\n",
      "testing  :  5878  accuracy =   0.7926  loss =  154.64\n",
      "training :  5879  accuracy =   0.8000  loss =  155.6\n",
      "testing  :  5879  accuracy =   0.7923  loss =  154.686\n",
      "training :  5880  accuracy =   0.7800  loss =  155.172\n",
      "testing  :  5880  accuracy =   0.7915  loss =  154.683\n",
      "training :  5881  accuracy =   0.8700  loss =  154.344\n",
      "testing  :  5881  accuracy =   0.7912  loss =  154.659\n",
      "training :  5882  accuracy =   0.8000  loss =  152.399\n",
      "testing  :  5882  accuracy =   0.7904  loss =  154.662\n",
      "training :  5883  accuracy =   0.7300  loss =  154.428\n",
      "testing  :  5883  accuracy =   0.7902  loss =  154.677\n",
      "training :  5884  accuracy =   0.8100  loss =  154.391\n",
      "testing  :  5884  accuracy =   0.7902  loss =  154.602\n",
      "training :  5885  accuracy =   0.8100  loss =  153.368\n",
      "testing  :  5885  accuracy =   0.7907  loss =  154.547\n",
      "training :  5886  accuracy =   0.8500  loss =  152.328\n",
      "testing  :  5886  accuracy =   0.7909  loss =  154.515\n",
      "training :  5887  accuracy =   0.8100  loss =  152.085\n",
      "testing  :  5887  accuracy =   0.7920  loss =  154.494\n",
      "training :  5888  accuracy =   0.8300  loss =  152.828\n",
      "testing  :  5888  accuracy =   0.7937  loss =  154.474\n",
      "training :  5889  accuracy =   0.7700  loss =  152.008\n",
      "testing  :  5889  accuracy =   0.7925  loss =  154.423\n",
      "training :  5890  accuracy =   0.7900  loss =  153.636\n",
      "testing  :  5890  accuracy =   0.7922  loss =  154.373\n",
      "training :  5891  accuracy =   0.7600  loss =  154.518\n",
      "testing  :  5891  accuracy =   0.7924  loss =  154.319\n",
      "training :  5892  accuracy =   0.8200  loss =  154.649\n",
      "testing  :  5892  accuracy =   0.7924  loss =  154.314\n",
      "training :  5893  accuracy =   0.8100  loss =  154.169\n",
      "testing  :  5893  accuracy =   0.7916  loss =  154.348\n",
      "training :  5894  accuracy =   0.8000  loss =  152.891\n",
      "testing  :  5894  accuracy =   0.7915  loss =  154.349\n",
      "training :  5895  accuracy =   0.8000  loss =  153.557\n",
      "testing  :  5895  accuracy =   0.7945  loss =  154.277\n",
      "training :  5896  accuracy =   0.8700  loss =  151.27\n",
      "testing  :  5896  accuracy =   0.7981  loss =  154.223\n",
      "training :  5897  accuracy =   0.7800  loss =  153.745\n",
      "testing  :  5897  accuracy =   0.8014  loss =  154.184\n",
      "training :  5898  accuracy =   0.7200  loss =  155.146\n",
      "testing  :  5898  accuracy =   0.8031  loss =  154.168\n",
      "training :  5899  accuracy =   0.8100  loss =  153.498\n",
      "testing  :  5899  accuracy =   0.8049  loss =  154.169\n",
      "training :  5900  accuracy =   0.7900  loss =  153.662\n",
      "testing  :  5900  accuracy =   0.8095  loss =  154.159\n",
      "training :  5901  accuracy =   0.8600  loss =  153.525\n",
      "testing  :  5901  accuracy =   0.8136  loss =  154.147\n",
      "training :  5902  accuracy =   0.8500  loss =  152.741\n",
      "testing  :  5902  accuracy =   0.8210  loss =  154.129\n",
      "training :  5903  accuracy =   0.8200  loss =  153.357\n",
      "testing  :  5903  accuracy =   0.8292  loss =  154.088\n",
      "training :  5904  accuracy =   0.9300  loss =  151.922\n",
      "testing  :  5904  accuracy =   0.8370  loss =  154.061\n",
      "training :  5905  accuracy =   0.8900  loss =  152.749\n",
      "testing  :  5905  accuracy =   0.8428  loss =  154.044\n",
      "training :  5906  accuracy =   0.8500  loss =  152.952\n",
      "testing  :  5906  accuracy =   0.8441  loss =  154.042\n",
      "training :  5907  accuracy =   0.7800  loss =  153.166\n",
      "testing  :  5907  accuracy =   0.8437  loss =  154.05\n",
      "training :  5908  accuracy =   0.8700  loss =  155.777\n",
      "testing  :  5908  accuracy =   0.8405  loss =  154.059\n",
      "training :  5909  accuracy =   0.8200  loss =  152.443\n",
      "testing  :  5909  accuracy =   0.8308  loss =  154.065\n",
      "training :  5910  accuracy =   0.8800  loss =  152.296\n",
      "testing  :  5910  accuracy =   0.8313  loss =  154.038\n",
      "training :  5911  accuracy =   0.7700  loss =  154.315\n",
      "testing  :  5911  accuracy =   0.8303  loss =  154.014\n",
      "training :  5912  accuracy =   0.8300  loss =  153.699\n",
      "testing  :  5912  accuracy =   0.8289  loss =  153.994\n",
      "training :  5913  accuracy =   0.8600  loss =  154.734\n",
      "testing  :  5913  accuracy =   0.8368  loss =  154.001\n",
      "training :  5914  accuracy =   0.8100  loss =  153.172\n",
      "testing  :  5914  accuracy =   0.8418  loss =  154.015\n",
      "training :  5915  accuracy =   0.9200  loss =  151.022\n",
      "testing  :  5915  accuracy =   0.8451  loss =  154.039\n",
      "training :  5916  accuracy =   0.8800  loss =  153.16\n",
      "testing  :  5916  accuracy =   0.8444  loss =  154.061\n",
      "training :  5917  accuracy =   0.8600  loss =  153.173\n",
      "testing  :  5917  accuracy =   0.8442  loss =  154.077\n",
      "training :  5918  accuracy =   0.9100  loss =  151.848\n",
      "testing  :  5918  accuracy =   0.8429  loss =  154.046\n",
      "training :  5919  accuracy =   0.8900  loss =  151.929\n",
      "testing  :  5919  accuracy =   0.8406  loss =  154.023\n",
      "training :  5920  accuracy =   0.8700  loss =  153.018\n",
      "testing  :  5920  accuracy =   0.8382  loss =  153.98\n",
      "training :  5921  accuracy =   0.8300  loss =  151.415\n",
      "testing  :  5921  accuracy =   0.8365  loss =  153.929\n",
      "training :  5922  accuracy =   0.8800  loss =  153.342\n",
      "testing  :  5922  accuracy =   0.8360  loss =  153.87\n",
      "training :  5923  accuracy =   0.8700  loss =  152.477\n",
      "testing  :  5923  accuracy =   0.8363  loss =  153.798\n",
      "training :  5924  accuracy =   0.9300  loss =  149.999\n",
      "testing  :  5924  accuracy =   0.8384  loss =  153.701\n",
      "training :  5925  accuracy =   0.8200  loss =  155.582\n",
      "testing  :  5925  accuracy =   0.8405  loss =  153.606\n",
      "training :  5926  accuracy =   0.8600  loss =  151.97\n",
      "testing  :  5926  accuracy =   0.8327  loss =  153.55\n",
      "training :  5927  accuracy =   0.7700  loss =  152.463\n",
      "testing  :  5927  accuracy =   0.8255  loss =  153.506\n",
      "training :  5928  accuracy =   0.8300  loss =  150.434\n",
      "testing  :  5928  accuracy =   0.8189  loss =  153.471\n",
      "training :  5929  accuracy =   0.8600  loss =  153.499\n",
      "testing  :  5929  accuracy =   0.8141  loss =  153.472\n",
      "training :  5930  accuracy =   0.7800  loss =  152.333\n",
      "testing  :  5930  accuracy =   0.8108  loss =  153.446\n",
      "training :  5931  accuracy =   0.8000  loss =  152.865\n",
      "testing  :  5931  accuracy =   0.8084  loss =  153.426\n",
      "training :  5932  accuracy =   0.8700  loss =  150.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  5932  accuracy =   0.8071  loss =  153.409\n",
      "training :  5933  accuracy =   0.8200  loss =  152.714\n",
      "testing  :  5933  accuracy =   0.8059  loss =  153.398\n",
      "training :  5934  accuracy =   0.8000  loss =  151.913\n",
      "testing  :  5934  accuracy =   0.8074  loss =  153.369\n",
      "training :  5935  accuracy =   0.8600  loss =  151.604\n",
      "testing  :  5935  accuracy =   0.8100  loss =  153.344\n",
      "training :  5936  accuracy =   0.8400  loss =  151.377\n",
      "testing  :  5936  accuracy =   0.8136  loss =  153.305\n",
      "training :  5937  accuracy =   0.8600  loss =  151.272\n",
      "testing  :  5937  accuracy =   0.8184  loss =  153.269\n",
      "training :  5938  accuracy =   0.8500  loss =  153.094\n",
      "testing  :  5938  accuracy =   0.8232  loss =  153.225\n",
      "training :  5939  accuracy =   0.8200  loss =  151.806\n",
      "testing  :  5939  accuracy =   0.8234  loss =  153.169\n",
      "training :  5940  accuracy =   0.8100  loss =  153.41\n",
      "testing  :  5940  accuracy =   0.8226  loss =  153.139\n",
      "training :  5941  accuracy =   0.8500  loss =  150.661\n",
      "testing  :  5941  accuracy =   0.8205  loss =  153.127\n",
      "training :  5942  accuracy =   0.7900  loss =  152.375\n",
      "testing  :  5942  accuracy =   0.8195  loss =  153.13\n",
      "training :  5943  accuracy =   0.7400  loss =  156.979\n",
      "testing  :  5943  accuracy =   0.8164  loss =  153.151\n",
      "training :  5944  accuracy =   0.9500  loss =  150.144\n",
      "testing  :  5944  accuracy =   0.8114  loss =  153.17\n",
      "training :  5945  accuracy =   0.8500  loss =  150.62\n",
      "testing  :  5945  accuracy =   0.8073  loss =  153.186\n",
      "training :  5946  accuracy =   0.8600  loss =  150.783\n",
      "testing  :  5946  accuracy =   0.8025  loss =  153.178\n",
      "training :  5947  accuracy =   0.8400  loss =  150.884\n",
      "testing  :  5947  accuracy =   0.7992  loss =  153.16\n",
      "training :  5948  accuracy =   0.7900  loss =  152.718\n",
      "testing  :  5948  accuracy =   0.7962  loss =  153.143\n",
      "training :  5949  accuracy =   0.8400  loss =  150.295\n",
      "testing  :  5949  accuracy =   0.7954  loss =  153.131\n",
      "training :  5950  accuracy =   0.8000  loss =  151.359\n",
      "testing  :  5950  accuracy =   0.7951  loss =  153.123\n",
      "training :  5951  accuracy =   0.8100  loss =  151.01\n",
      "testing  :  5951  accuracy =   0.7944  loss =  153.111\n",
      "training :  5952  accuracy =   0.8400  loss =  151.638\n",
      "testing  :  5952  accuracy =   0.7940  loss =  153.097\n",
      "training :  5953  accuracy =   0.7800  loss =  153.704\n",
      "testing  :  5953  accuracy =   0.7967  loss =  153.015\n",
      "training :  5954  accuracy =   0.8000  loss =  150.134\n",
      "testing  :  5954  accuracy =   0.7950  loss =  152.973\n",
      "training :  5955  accuracy =   0.8300  loss =  150.941\n",
      "testing  :  5955  accuracy =   0.7949  loss =  152.954\n",
      "training :  5956  accuracy =   0.8800  loss =  150.331\n",
      "testing  :  5956  accuracy =   0.7943  loss =  152.944\n",
      "training :  5957  accuracy =   0.8300  loss =  150.537\n",
      "testing  :  5957  accuracy =   0.7943  loss =  152.935\n",
      "training :  5958  accuracy =   0.8700  loss =  150.994\n",
      "testing  :  5958  accuracy =   0.7950  loss =  152.944\n",
      "training :  5959  accuracy =   0.8000  loss =  152.84\n",
      "testing  :  5959  accuracy =   0.7955  loss =  152.976\n",
      "training :  5960  accuracy =   0.8200  loss =  153.529\n",
      "testing  :  5960  accuracy =   0.7945  loss =  153.008\n",
      "training :  5961  accuracy =   0.8200  loss =  152.087\n",
      "testing  :  5961  accuracy =   0.7931  loss =  152.986\n",
      "training :  5962  accuracy =   0.8400  loss =  152.079\n",
      "testing  :  5962  accuracy =   0.7923  loss =  152.979\n",
      "training :  5963  accuracy =   0.8100  loss =  151.584\n",
      "testing  :  5963  accuracy =   0.7927  loss =  152.944\n",
      "training :  5964  accuracy =   0.8300  loss =  149.962\n",
      "testing  :  5964  accuracy =   0.7919  loss =  152.925\n",
      "training :  5965  accuracy =   0.8300  loss =  150.892\n",
      "testing  :  5965  accuracy =   0.7908  loss =  152.925\n",
      "training :  5966  accuracy =   0.8100  loss =  151.001\n",
      "testing  :  5966  accuracy =   0.7905  loss =  152.938\n",
      "training :  5967  accuracy =   0.8500  loss =  153.233\n",
      "testing  :  5967  accuracy =   0.7898  loss =  152.955\n",
      "training :  5968  accuracy =   0.8000  loss =  152.028\n",
      "testing  :  5968  accuracy =   0.7893  loss =  152.963\n",
      "training :  5969  accuracy =   0.7800  loss =  154.273\n",
      "testing  :  5969  accuracy =   0.7892  loss =  152.973\n",
      "training :  5970  accuracy =   0.7800  loss =  151.991\n",
      "testing  :  5970  accuracy =   0.7891  loss =  152.984\n",
      "training :  5971  accuracy =   0.7800  loss =  152.463\n",
      "testing  :  5971  accuracy =   0.7893  loss =  152.997\n",
      "training :  5972  accuracy =   0.7500  loss =  152.105\n",
      "testing  :  5972  accuracy =   0.7885  loss =  153.001\n",
      "training :  5973  accuracy =   0.7400  loss =  152.244\n",
      "testing  :  5973  accuracy =   0.7885  loss =  153.0\n",
      "training :  5974  accuracy =   0.8400  loss =  152.679\n",
      "testing  :  5974  accuracy =   0.7886  loss =  152.997\n",
      "training :  5975  accuracy =   0.8100  loss =  153.904\n",
      "testing  :  5975  accuracy =   0.7884  loss =  152.995\n",
      "training :  5976  accuracy =   0.8300  loss =  151.478\n",
      "testing  :  5976  accuracy =   0.7878  loss =  152.995\n",
      "training :  5977  accuracy =   0.8100  loss =  152.183\n",
      "testing  :  5977  accuracy =   0.7879  loss =  153.006\n",
      "training :  5978  accuracy =   0.8400  loss =  150.154\n",
      "testing  :  5978  accuracy =   0.7877  loss =  153.016\n",
      "training :  5979  accuracy =   0.8900  loss =  149.777\n",
      "testing  :  5979  accuracy =   0.7869  loss =  153.028\n",
      "training :  5980  accuracy =   0.7500  loss =  151.58\n",
      "testing  :  5980  accuracy =   0.7863  loss =  153.055\n",
      "training :  5981  accuracy =   0.7600  loss =  151.821\n",
      "testing  :  5981  accuracy =   0.7865  loss =  153.067\n",
      "training :  5982  accuracy =   0.8000  loss =  151.667\n",
      "testing  :  5982  accuracy =   0.7866  loss =  153.085\n",
      "training :  5983  accuracy =   0.7300  loss =  152.062\n",
      "testing  :  5983  accuracy =   0.7866  loss =  153.106\n",
      "training :  5984  accuracy =   0.7800  loss =  153.1\n",
      "testing  :  5984  accuracy =   0.7874  loss =  153.113\n",
      "training :  5985  accuracy =   0.8700  loss =  149.466\n",
      "testing  :  5985  accuracy =   0.7886  loss =  153.126\n",
      "training :  5986  accuracy =   0.7800  loss =  154.956\n",
      "testing  :  5986  accuracy =   0.7891  loss =  153.136\n",
      "training :  5987  accuracy =   0.7800  loss =  152.986\n",
      "testing  :  5987  accuracy =   0.7912  loss =  153.122\n",
      "training :  5988  accuracy =   0.8300  loss =  152.934\n",
      "testing  :  5988  accuracy =   0.7931  loss =  153.08\n",
      "training :  5989  accuracy =   0.8400  loss =  151.362\n",
      "testing  :  5989  accuracy =   0.7942  loss =  153.029\n",
      "training :  5990  accuracy =   0.8400  loss =  150.506\n",
      "testing  :  5990  accuracy =   0.7949  loss =  152.999\n",
      "training :  5991  accuracy =   0.8500  loss =  151.378\n",
      "testing  :  5991  accuracy =   0.7956  loss =  152.99\n",
      "training :  5992  accuracy =   0.8500  loss =  152.627\n",
      "testing  :  5992  accuracy =   0.7967  loss =  152.968\n",
      "training :  5993  accuracy =   0.8000  loss =  153.251\n",
      "testing  :  5993  accuracy =   0.7966  loss =  152.962\n",
      "training :  5994  accuracy =   0.8000  loss =  152.358\n",
      "testing  :  5994  accuracy =   0.7951  loss =  152.977\n",
      "training :  5995  accuracy =   0.8300  loss =  150.26\n",
      "testing  :  5995  accuracy =   0.7939  loss =  153.019\n",
      "training :  5996  accuracy =   0.8100  loss =  151.725\n",
      "testing  :  5996  accuracy =   0.7925  loss =  153.073\n",
      "training :  5997  accuracy =   0.7500  loss =  151.953\n",
      "testing  :  5997  accuracy =   0.7918  loss =  153.134\n",
      "training :  5998  accuracy =   0.7700  loss =  153.263\n",
      "testing  :  5998  accuracy =   0.7900  loss =  153.203\n",
      "training :  5999  accuracy =   0.7800  loss =  151.448\n",
      "testing  :  5999  accuracy =   0.7880  loss =  153.262\n",
      "training :  6000  accuracy =   0.7400  loss =  152.408\n",
      "testing  :  6000  accuracy =   0.7875  loss =  153.27\n",
      "training :  6001  accuracy =   0.8200  loss =  151.302\n",
      "testing  :  6001  accuracy =   0.7870  loss =  153.251\n",
      "training :  6002  accuracy =   0.7400  loss =  153.063\n",
      "testing  :  6002  accuracy =   0.7877  loss =  153.134\n",
      "training :  6003  accuracy =   0.7800  loss =  152.702\n",
      "testing  :  6003  accuracy =   0.7899  loss =  153.047\n",
      "training :  6004  accuracy =   0.8100  loss =  151.331\n",
      "testing  :  6004  accuracy =   0.7916  loss =  152.989\n",
      "training :  6005  accuracy =   0.8300  loss =  153.803\n",
      "testing  :  6005  accuracy =   0.7932  loss =  152.927\n",
      "training :  6006  accuracy =   0.7600  loss =  153.613\n",
      "testing  :  6006  accuracy =   0.7958  loss =  152.849\n",
      "training :  6007  accuracy =   0.7700  loss =  150.712\n",
      "testing  :  6007  accuracy =   0.7972  loss =  152.834\n",
      "training :  6008  accuracy =   0.7100  loss =  151.587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6008  accuracy =   0.7977  loss =  152.844\n",
      "training :  6009  accuracy =   0.7600  loss =  151.872\n",
      "testing  :  6009  accuracy =   0.7975  loss =  152.85\n",
      "training :  6010  accuracy =   0.8400  loss =  151.398\n",
      "testing  :  6010  accuracy =   0.7981  loss =  152.868\n",
      "training :  6011  accuracy =   0.7900  loss =  152.31\n",
      "testing  :  6011  accuracy =   0.7977  loss =  152.894\n",
      "training :  6012  accuracy =   0.8100  loss =  151.516\n",
      "testing  :  6012  accuracy =   0.7965  loss =  152.91\n",
      "training :  6013  accuracy =   0.8000  loss =  152.455\n",
      "testing  :  6013  accuracy =   0.7969  loss =  152.926\n",
      "training :  6014  accuracy =   0.8300  loss =  151.161\n",
      "testing  :  6014  accuracy =   0.7965  loss =  152.896\n",
      "training :  6015  accuracy =   0.7500  loss =  152.042\n",
      "testing  :  6015  accuracy =   0.7960  loss =  152.871\n",
      "training :  6016  accuracy =   0.8400  loss =  151.087\n",
      "testing  :  6016  accuracy =   0.7961  loss =  152.827\n",
      "training :  6017  accuracy =   0.8000  loss =  151.511\n",
      "testing  :  6017  accuracy =   0.7962  loss =  152.784\n",
      "training :  6018  accuracy =   0.7700  loss =  152.71\n",
      "testing  :  6018  accuracy =   0.7976  loss =  152.758\n",
      "training :  6019  accuracy =   0.7600  loss =  152.291\n",
      "testing  :  6019  accuracy =   0.7995  loss =  152.733\n",
      "training :  6020  accuracy =   0.8100  loss =  151.582\n",
      "testing  :  6020  accuracy =   0.8025  loss =  152.709\n",
      "training :  6021  accuracy =   0.8400  loss =  150.891\n",
      "testing  :  6021  accuracy =   0.8052  loss =  152.71\n",
      "training :  6022  accuracy =   0.8200  loss =  150.785\n",
      "testing  :  6022  accuracy =   0.8097  loss =  152.731\n",
      "training :  6023  accuracy =   0.8700  loss =  150.509\n",
      "testing  :  6023  accuracy =   0.8139  loss =  152.777\n",
      "training :  6024  accuracy =   0.8900  loss =  150.078\n",
      "testing  :  6024  accuracy =   0.8160  loss =  152.807\n",
      "training :  6025  accuracy =   0.8800  loss =  150.479\n",
      "testing  :  6025  accuracy =   0.8205  loss =  152.848\n",
      "training :  6026  accuracy =   0.8900  loss =  150.816\n",
      "testing  :  6026  accuracy =   0.8237  loss =  152.893\n",
      "training :  6027  accuracy =   0.8000  loss =  153.46\n",
      "testing  :  6027  accuracy =   0.8292  loss =  152.944\n",
      "training :  6028  accuracy =   0.8500  loss =  151.756\n",
      "testing  :  6028  accuracy =   0.8349  loss =  152.989\n",
      "training :  6029  accuracy =   0.8500  loss =  151.756\n",
      "testing  :  6029  accuracy =   0.8445  loss =  152.892\n",
      "training :  6030  accuracy =   0.8700  loss =  150.288\n",
      "testing  :  6030  accuracy =   0.8518  loss =  152.819\n",
      "training :  6031  accuracy =   0.8800  loss =  149.961\n",
      "testing  :  6031  accuracy =   0.8591  loss =  152.76\n",
      "training :  6032  accuracy =   0.8600  loss =  152.13\n",
      "testing  :  6032  accuracy =   0.8616  loss =  152.723\n",
      "training :  6033  accuracy =   0.8600  loss =  151.684\n",
      "testing  :  6033  accuracy =   0.8553  loss =  152.7\n",
      "training :  6034  accuracy =   0.8200  loss =  153.037\n",
      "testing  :  6034  accuracy =   0.8314  loss =  152.688\n",
      "training :  6035  accuracy =   0.7800  loss =  151.808\n",
      "testing  :  6035  accuracy =   0.8151  loss =  152.681\n",
      "training :  6036  accuracy =   0.7900  loss =  152.917\n",
      "testing  :  6036  accuracy =   0.8025  loss =  152.69\n",
      "training :  6037  accuracy =   0.8100  loss =  152.421\n",
      "testing  :  6037  accuracy =   0.7982  loss =  152.713\n",
      "training :  6038  accuracy =   0.6900  loss =  153.083\n",
      "testing  :  6038  accuracy =   0.7965  loss =  152.732\n",
      "training :  6039  accuracy =   0.7400  loss =  151.476\n",
      "testing  :  6039  accuracy =   0.7951  loss =  152.756\n",
      "training :  6040  accuracy =   0.8300  loss =  150.833\n",
      "testing  :  6040  accuracy =   0.7946  loss =  152.769\n",
      "training :  6041  accuracy =   0.7900  loss =  150.341\n",
      "testing  :  6041  accuracy =   0.7936  loss =  152.821\n",
      "training :  6042  accuracy =   0.8300  loss =  150.381\n",
      "testing  :  6042  accuracy =   0.7927  loss =  152.857\n",
      "training :  6043  accuracy =   0.8000  loss =  150.939\n",
      "testing  :  6043  accuracy =   0.7912  loss =  152.885\n",
      "training :  6044  accuracy =   0.8000  loss =  151.132\n",
      "testing  :  6044  accuracy =   0.7906  loss =  152.9\n",
      "training :  6045  accuracy =   0.8000  loss =  152.048\n",
      "testing  :  6045  accuracy =   0.7909  loss =  152.915\n",
      "training :  6046  accuracy =   0.7200  loss =  154.08\n",
      "testing  :  6046  accuracy =   0.7922  loss =  152.898\n",
      "training :  6047  accuracy =   0.8100  loss =  152.375\n",
      "testing  :  6047  accuracy =   0.7929  loss =  152.87\n",
      "training :  6048  accuracy =   0.7900  loss =  151.637\n",
      "testing  :  6048  accuracy =   0.7943  loss =  152.851\n",
      "training :  6049  accuracy =   0.8200  loss =  151.711\n",
      "testing  :  6049  accuracy =   0.7950  loss =  152.84\n",
      "training :  6050  accuracy =   0.8500  loss =  149.527\n",
      "testing  :  6050  accuracy =   0.7960  loss =  152.818\n",
      "training :  6051  accuracy =   0.8100  loss =  154.052\n",
      "testing  :  6051  accuracy =   0.7971  loss =  152.824\n",
      "training :  6052  accuracy =   0.7900  loss =  151.386\n",
      "testing  :  6052  accuracy =   0.7966  loss =  152.846\n",
      "training :  6053  accuracy =   0.7600  loss =  153.492\n",
      "testing  :  6053  accuracy =   0.7960  loss =  152.882\n",
      "training :  6054  accuracy =   0.8100  loss =  154.07\n",
      "testing  :  6054  accuracy =   0.7961  loss =  152.92\n",
      "training :  6055  accuracy =   0.8200  loss =  151.285\n",
      "testing  :  6055  accuracy =   0.7953  loss =  152.935\n",
      "training :  6056  accuracy =   0.8400  loss =  150.145\n",
      "testing  :  6056  accuracy =   0.7947  loss =  152.936\n",
      "training :  6057  accuracy =   0.8300  loss =  151.26\n",
      "testing  :  6057  accuracy =   0.7948  loss =  152.92\n",
      "training :  6058  accuracy =   0.8500  loss =  150.609\n",
      "testing  :  6058  accuracy =   0.7949  loss =  152.91\n",
      "training :  6059  accuracy =   0.8600  loss =  150.748\n",
      "testing  :  6059  accuracy =   0.7950  loss =  152.898\n",
      "training :  6060  accuracy =   0.7800  loss =  152.787\n",
      "testing  :  6060  accuracy =   0.7944  loss =  152.888\n",
      "training :  6061  accuracy =   0.7500  loss =  153.133\n",
      "testing  :  6061  accuracy =   0.7942  loss =  152.822\n",
      "training :  6062  accuracy =   0.8100  loss =  150.766\n",
      "testing  :  6062  accuracy =   0.7944  loss =  152.775\n",
      "training :  6063  accuracy =   0.8300  loss =  151.028\n",
      "testing  :  6063  accuracy =   0.7948  loss =  152.757\n",
      "training :  6064  accuracy =   0.8100  loss =  151.714\n",
      "testing  :  6064  accuracy =   0.7951  loss =  152.763\n",
      "training :  6065  accuracy =   0.8400  loss =  151.202\n",
      "testing  :  6065  accuracy =   0.7962  loss =  152.77\n",
      "training :  6066  accuracy =   0.8100  loss =  151.416\n",
      "testing  :  6066  accuracy =   0.7962  loss =  152.79\n",
      "training :  6067  accuracy =   0.8000  loss =  151.853\n",
      "testing  :  6067  accuracy =   0.7970  loss =  152.81\n",
      "training :  6068  accuracy =   0.7600  loss =  152.022\n",
      "testing  :  6068  accuracy =   0.7973  loss =  152.827\n",
      "training :  6069  accuracy =   0.8000  loss =  152.472\n",
      "testing  :  6069  accuracy =   0.7966  loss =  152.866\n",
      "training :  6070  accuracy =   0.8000  loss =  153.062\n",
      "testing  :  6070  accuracy =   0.7957  loss =  152.89\n",
      "training :  6071  accuracy =   0.8300  loss =  151.062\n",
      "testing  :  6071  accuracy =   0.7961  loss =  152.908\n",
      "training :  6072  accuracy =   0.7700  loss =  151.244\n",
      "testing  :  6072  accuracy =   0.7983  loss =  152.92\n",
      "training :  6073  accuracy =   0.7500  loss =  153.559\n",
      "testing  :  6073  accuracy =   0.7993  loss =  152.947\n",
      "training :  6074  accuracy =   0.8000  loss =  152.398\n",
      "testing  :  6074  accuracy =   0.8009  loss =  152.979\n",
      "training :  6075  accuracy =   0.7700  loss =  153.701\n",
      "testing  :  6075  accuracy =   0.8040  loss =  152.999\n",
      "training :  6076  accuracy =   0.8200  loss =  152.444\n",
      "testing  :  6076  accuracy =   0.8067  loss =  153.026\n",
      "training :  6077  accuracy =   0.8600  loss =  150.333\n",
      "testing  :  6077  accuracy =   0.8083  loss =  153.054\n",
      "training :  6078  accuracy =   0.8300  loss =  152.417\n",
      "testing  :  6078  accuracy =   0.8099  loss =  153.068\n",
      "training :  6079  accuracy =   0.8900  loss =  152.324\n",
      "testing  :  6079  accuracy =   0.8112  loss =  153.107\n",
      "training :  6080  accuracy =   0.8300  loss =  154.13\n",
      "testing  :  6080  accuracy =   0.8129  loss =  153.125\n",
      "training :  6081  accuracy =   0.8700  loss =  152.422\n",
      "testing  :  6081  accuracy =   0.8139  loss =  153.144\n",
      "training :  6082  accuracy =   0.7800  loss =  151.721\n",
      "testing  :  6082  accuracy =   0.8138  loss =  153.151\n",
      "training :  6083  accuracy =   0.8900  loss =  152.542\n",
      "testing  :  6083  accuracy =   0.8142  loss =  153.163\n",
      "training :  6084  accuracy =   0.8200  loss =  153.588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6084  accuracy =   0.8153  loss =  153.155\n",
      "training :  6085  accuracy =   0.8100  loss =  151.933\n",
      "testing  :  6085  accuracy =   0.8184  loss =  153.11\n",
      "training :  6086  accuracy =   0.8600  loss =  152.928\n",
      "testing  :  6086  accuracy =   0.8224  loss =  153.071\n",
      "training :  6087  accuracy =   0.8700  loss =  149.59\n",
      "testing  :  6087  accuracy =   0.8315  loss =  153.037\n",
      "training :  6088  accuracy =   0.8300  loss =  151.847\n",
      "testing  :  6088  accuracy =   0.8469  loss =  153.012\n",
      "training :  6089  accuracy =   0.9100  loss =  151.54\n",
      "testing  :  6089  accuracy =   0.8594  loss =  152.969\n",
      "training :  6090  accuracy =   0.8900  loss =  151.014\n",
      "testing  :  6090  accuracy =   0.8537  loss =  152.947\n",
      "training :  6091  accuracy =   0.8800  loss =  149.538\n",
      "testing  :  6091  accuracy =   0.8198  loss =  152.932\n",
      "training :  6092  accuracy =   0.8200  loss =  152.02\n",
      "testing  :  6092  accuracy =   0.8048  loss =  152.951\n",
      "training :  6093  accuracy =   0.8300  loss =  151.559\n",
      "testing  :  6093  accuracy =   0.8005  loss =  152.97\n",
      "training :  6094  accuracy =   0.8700  loss =  151.326\n",
      "testing  :  6094  accuracy =   0.7990  loss =  152.975\n",
      "training :  6095  accuracy =   0.8400  loss =  151.261\n",
      "testing  :  6095  accuracy =   0.7977  loss =  152.994\n",
      "training :  6096  accuracy =   0.8000  loss =  153.15\n",
      "testing  :  6096  accuracy =   0.7966  loss =  152.957\n",
      "training :  6097  accuracy =   0.8200  loss =  152.104\n",
      "testing  :  6097  accuracy =   0.7962  loss =  152.929\n",
      "training :  6098  accuracy =   0.7700  loss =  152.071\n",
      "testing  :  6098  accuracy =   0.7953  loss =  152.872\n",
      "training :  6099  accuracy =   0.7500  loss =  157.342\n",
      "testing  :  6099  accuracy =   0.7956  loss =  152.832\n",
      "training :  6100  accuracy =   0.8100  loss =  152.558\n",
      "testing  :  6100  accuracy =   0.7945  loss =  152.816\n",
      "training :  6101  accuracy =   0.8200  loss =  152.45\n",
      "testing  :  6101  accuracy =   0.7940  loss =  152.803\n",
      "training :  6102  accuracy =   0.7600  loss =  155.239\n",
      "testing  :  6102  accuracy =   0.7930  loss =  152.805\n",
      "training :  6103  accuracy =   0.8700  loss =  150.448\n",
      "testing  :  6103  accuracy =   0.7921  loss =  152.815\n",
      "training :  6104  accuracy =   0.7800  loss =  152.946\n",
      "testing  :  6104  accuracy =   0.7911  loss =  152.821\n",
      "training :  6105  accuracy =   0.8300  loss =  152.051\n",
      "testing  :  6105  accuracy =   0.7897  loss =  152.854\n",
      "training :  6106  accuracy =   0.7700  loss =  153.698\n",
      "testing  :  6106  accuracy =   0.7887  loss =  152.924\n",
      "training :  6107  accuracy =   0.8500  loss =  150.041\n",
      "testing  :  6107  accuracy =   0.7883  loss =  152.978\n",
      "training :  6108  accuracy =   0.8400  loss =  150.78\n",
      "testing  :  6108  accuracy =   0.7875  loss =  153.024\n",
      "training :  6109  accuracy =   0.7700  loss =  151.288\n",
      "testing  :  6109  accuracy =   0.7868  loss =  153.071\n",
      "training :  6110  accuracy =   0.7600  loss =  153.003\n",
      "testing  :  6110  accuracy =   0.7879  loss =  153.062\n",
      "training :  6111  accuracy =   0.7900  loss =  151.328\n",
      "testing  :  6111  accuracy =   0.7900  loss =  153.072\n",
      "training :  6112  accuracy =   0.8000  loss =  152.574\n",
      "testing  :  6112  accuracy =   0.7918  loss =  153.055\n",
      "training :  6113  accuracy =   0.8400  loss =  150.889\n",
      "testing  :  6113  accuracy =   0.7971  loss =  153.004\n",
      "training :  6114  accuracy =   0.8100  loss =  151.829\n",
      "testing  :  6114  accuracy =   0.8004  loss =  152.937\n",
      "training :  6115  accuracy =   0.8000  loss =  152.054\n",
      "testing  :  6115  accuracy =   0.8025  loss =  152.844\n",
      "training :  6116  accuracy =   0.7700  loss =  153.449\n",
      "testing  :  6116  accuracy =   0.8039  loss =  152.763\n",
      "training :  6117  accuracy =   0.8400  loss =  150.938\n",
      "testing  :  6117  accuracy =   0.8054  loss =  152.704\n",
      "training :  6118  accuracy =   0.7900  loss =  153.189\n",
      "testing  :  6118  accuracy =   0.8056  loss =  152.673\n",
      "training :  6119  accuracy =   0.7800  loss =  153.264\n",
      "testing  :  6119  accuracy =   0.8061  loss =  152.658\n",
      "training :  6120  accuracy =   0.8200  loss =  150.622\n",
      "testing  :  6120  accuracy =   0.8073  loss =  152.642\n",
      "training :  6121  accuracy =   0.8500  loss =  151.547\n",
      "testing  :  6121  accuracy =   0.8086  loss =  152.633\n",
      "training :  6122  accuracy =   0.8100  loss =  153.009\n",
      "testing  :  6122  accuracy =   0.8085  loss =  152.631\n",
      "training :  6123  accuracy =   0.7900  loss =  153.329\n",
      "testing  :  6123  accuracy =   0.8111  loss =  152.617\n",
      "training :  6124  accuracy =   0.8100  loss =  151.33\n",
      "testing  :  6124  accuracy =   0.8135  loss =  152.647\n",
      "training :  6125  accuracy =   0.8500  loss =  151.995\n",
      "testing  :  6125  accuracy =   0.8197  loss =  152.7\n",
      "training :  6126  accuracy =   0.8600  loss =  150.142\n",
      "testing  :  6126  accuracy =   0.8274  loss =  152.79\n",
      "training :  6127  accuracy =   0.8700  loss =  150.136\n",
      "testing  :  6127  accuracy =   0.8316  loss =  152.856\n",
      "training :  6128  accuracy =   0.8600  loss =  152.908\n",
      "testing  :  6128  accuracy =   0.8388  loss =  152.909\n",
      "training :  6129  accuracy =   0.8700  loss =  153.064\n",
      "testing  :  6129  accuracy =   0.8413  loss =  152.96\n",
      "training :  6130  accuracy =   0.8000  loss =  152.554\n",
      "testing  :  6130  accuracy =   0.8428  loss =  153.009\n",
      "training :  6131  accuracy =   0.8300  loss =  150.351\n",
      "testing  :  6131  accuracy =   0.8518  loss =  153.028\n",
      "training :  6132  accuracy =   0.8100  loss =  152.419\n",
      "testing  :  6132  accuracy =   0.8541  loss =  153.052\n",
      "training :  6133  accuracy =   0.8700  loss =  151.696\n",
      "testing  :  6133  accuracy =   0.8537  loss =  152.96\n",
      "training :  6134  accuracy =   0.8700  loss =  151.913\n",
      "testing  :  6134  accuracy =   0.8508  loss =  152.877\n",
      "training :  6135  accuracy =   0.8000  loss =  151.342\n",
      "testing  :  6135  accuracy =   0.8381  loss =  152.815\n",
      "training :  6136  accuracy =   0.8300  loss =  153.023\n",
      "testing  :  6136  accuracy =   0.8301  loss =  152.738\n",
      "training :  6137  accuracy =   0.7900  loss =  152.326\n",
      "testing  :  6137  accuracy =   0.8272  loss =  152.695\n",
      "training :  6138  accuracy =   0.8300  loss =  152.888\n",
      "testing  :  6138  accuracy =   0.8198  loss =  152.673\n",
      "training :  6139  accuracy =   0.8600  loss =  155.306\n",
      "testing  :  6139  accuracy =   0.8166  loss =  152.664\n",
      "training :  6140  accuracy =   0.8700  loss =  151.399\n",
      "testing  :  6140  accuracy =   0.8146  loss =  152.67\n",
      "training :  6141  accuracy =   0.7800  loss =  153.178\n",
      "testing  :  6141  accuracy =   0.8114  loss =  152.679\n",
      "training :  6142  accuracy =   0.8300  loss =  151.85\n",
      "testing  :  6142  accuracy =   0.8093  loss =  152.672\n",
      "training :  6143  accuracy =   0.8000  loss =  150.756\n",
      "testing  :  6143  accuracy =   0.8061  loss =  152.667\n",
      "training :  6144  accuracy =   0.7800  loss =  151.365\n",
      "testing  :  6144  accuracy =   0.8059  loss =  152.718\n",
      "training :  6145  accuracy =   0.8400  loss =  151.959\n",
      "testing  :  6145  accuracy =   0.8051  loss =  152.747\n",
      "training :  6146  accuracy =   0.8000  loss =  151.038\n",
      "testing  :  6146  accuracy =   0.8049  loss =  152.762\n",
      "training :  6147  accuracy =   0.7500  loss =  153.923\n",
      "testing  :  6147  accuracy =   0.8048  loss =  152.77\n",
      "training :  6148  accuracy =   0.7700  loss =  151.889\n",
      "testing  :  6148  accuracy =   0.8045  loss =  152.782\n",
      "training :  6149  accuracy =   0.8500  loss =  151.365\n",
      "testing  :  6149  accuracy =   0.8041  loss =  152.78\n",
      "training :  6150  accuracy =   0.8900  loss =  149.483\n",
      "testing  :  6150  accuracy =   0.8039  loss =  152.782\n",
      "training :  6151  accuracy =   0.8100  loss =  150.825\n",
      "testing  :  6151  accuracy =   0.8037  loss =  152.796\n",
      "training :  6152  accuracy =   0.8000  loss =  154.027\n",
      "testing  :  6152  accuracy =   0.8032  loss =  152.821\n",
      "training :  6153  accuracy =   0.8000  loss =  152.222\n",
      "testing  :  6153  accuracy =   0.8027  loss =  152.854\n",
      "training :  6154  accuracy =   0.8200  loss =  150.724\n",
      "testing  :  6154  accuracy =   0.8031  loss =  152.889\n",
      "training :  6155  accuracy =   0.8100  loss =  152.841\n",
      "testing  :  6155  accuracy =   0.8034  loss =  152.914\n",
      "training :  6156  accuracy =   0.8000  loss =  153.666\n",
      "testing  :  6156  accuracy =   0.8025  loss =  152.916\n",
      "training :  6157  accuracy =   0.8300  loss =  149.946\n",
      "testing  :  6157  accuracy =   0.8018  loss =  152.898\n",
      "training :  6158  accuracy =   0.7800  loss =  151.892\n",
      "testing  :  6158  accuracy =   0.8014  loss =  152.87\n",
      "training :  6159  accuracy =   0.7700  loss =  153.713\n",
      "testing  :  6159  accuracy =   0.7995  loss =  152.846\n",
      "training :  6160  accuracy =   0.7800  loss =  151.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6160  accuracy =   0.7986  loss =  152.847\n",
      "training :  6161  accuracy =   0.8100  loss =  153.353\n",
      "testing  :  6161  accuracy =   0.7985  loss =  152.858\n",
      "training :  6162  accuracy =   0.8000  loss =  152.437\n",
      "testing  :  6162  accuracy =   0.7980  loss =  152.866\n",
      "training :  6163  accuracy =   0.8000  loss =  152.635\n",
      "testing  :  6163  accuracy =   0.7982  loss =  152.872\n",
      "training :  6164  accuracy =   0.7600  loss =  153.565\n",
      "testing  :  6164  accuracy =   0.7971  loss =  152.88\n",
      "training :  6165  accuracy =   0.8400  loss =  150.522\n",
      "testing  :  6165  accuracy =   0.7955  loss =  152.894\n",
      "training :  6166  accuracy =   0.8000  loss =  153.093\n",
      "testing  :  6166  accuracy =   0.7955  loss =  152.921\n",
      "training :  6167  accuracy =   0.7800  loss =  150.796\n",
      "testing  :  6167  accuracy =   0.7953  loss =  152.94\n",
      "training :  6168  accuracy =   0.7100  loss =  155.023\n",
      "testing  :  6168  accuracy =   0.7949  loss =  152.956\n",
      "training :  6169  accuracy =   0.8000  loss =  152.861\n",
      "testing  :  6169  accuracy =   0.7948  loss =  152.969\n",
      "training :  6170  accuracy =   0.7900  loss =  151.041\n",
      "testing  :  6170  accuracy =   0.7946  loss =  152.975\n",
      "training :  6171  accuracy =   0.7700  loss =  152.638\n",
      "testing  :  6171  accuracy =   0.7946  loss =  153.001\n",
      "training :  6172  accuracy =   0.8100  loss =  151.898\n",
      "testing  :  6172  accuracy =   0.7956  loss =  153.001\n",
      "training :  6173  accuracy =   0.7700  loss =  153.889\n",
      "testing  :  6173  accuracy =   0.7961  loss =  152.996\n",
      "training :  6174  accuracy =   0.8400  loss =  150.582\n",
      "testing  :  6174  accuracy =   0.7996  loss =  152.941\n",
      "training :  6175  accuracy =   0.8300  loss =  152.198\n",
      "testing  :  6175  accuracy =   0.8020  loss =  152.885\n",
      "training :  6176  accuracy =   0.7700  loss =  156.195\n",
      "testing  :  6176  accuracy =   0.8080  loss =  152.845\n",
      "training :  6177  accuracy =   0.8000  loss =  152.031\n",
      "testing  :  6177  accuracy =   0.8107  loss =  152.824\n",
      "training :  6178  accuracy =   0.7700  loss =  152.852\n",
      "testing  :  6178  accuracy =   0.8131  loss =  152.811\n",
      "training :  6179  accuracy =   0.8400  loss =  151.966\n",
      "testing  :  6179  accuracy =   0.8167  loss =  152.798\n",
      "training :  6180  accuracy =   0.7900  loss =  151.812\n",
      "testing  :  6180  accuracy =   0.8194  loss =  152.796\n",
      "training :  6181  accuracy =   0.8500  loss =  153.038\n",
      "testing  :  6181  accuracy =   0.8222  loss =  152.807\n",
      "training :  6182  accuracy =   0.8800  loss =  150.854\n",
      "testing  :  6182  accuracy =   0.8242  loss =  152.826\n",
      "training :  6183  accuracy =   0.8100  loss =  152.658\n",
      "testing  :  6183  accuracy =   0.8253  loss =  152.843\n",
      "training :  6184  accuracy =   0.8000  loss =  151.173\n",
      "testing  :  6184  accuracy =   0.8255  loss =  152.858\n",
      "training :  6185  accuracy =   0.7400  loss =  152.446\n",
      "testing  :  6185  accuracy =   0.8256  loss =  152.872\n",
      "training :  6186  accuracy =   0.7800  loss =  152.462\n",
      "testing  :  6186  accuracy =   0.8254  loss =  152.888\n",
      "training :  6187  accuracy =   0.8700  loss =  150.373\n",
      "testing  :  6187  accuracy =   0.8255  loss =  152.854\n",
      "training :  6188  accuracy =   0.8300  loss =  152.044\n",
      "testing  :  6188  accuracy =   0.8256  loss =  152.847\n",
      "training :  6189  accuracy =   0.8200  loss =  153.928\n",
      "testing  :  6189  accuracy =   0.8259  loss =  152.845\n",
      "training :  6190  accuracy =   0.7900  loss =  151.674\n",
      "testing  :  6190  accuracy =   0.8264  loss =  152.848\n",
      "training :  6191  accuracy =   0.8600  loss =  150.954\n",
      "testing  :  6191  accuracy =   0.8264  loss =  152.843\n",
      "training :  6192  accuracy =   0.8100  loss =  153.385\n",
      "testing  :  6192  accuracy =   0.8260  loss =  152.847\n",
      "training :  6193  accuracy =   0.8400  loss =  150.473\n",
      "testing  :  6193  accuracy =   0.8264  loss =  152.855\n",
      "training :  6194  accuracy =   0.8500  loss =  151.337\n",
      "testing  :  6194  accuracy =   0.8262  loss =  152.87\n",
      "training :  6195  accuracy =   0.8800  loss =  150.819\n",
      "testing  :  6195  accuracy =   0.8264  loss =  152.887\n",
      "training :  6196  accuracy =   0.8800  loss =  150.902\n",
      "testing  :  6196  accuracy =   0.8263  loss =  152.907\n",
      "training :  6197  accuracy =   0.8900  loss =  149.398\n",
      "testing  :  6197  accuracy =   0.8259  loss =  152.904\n",
      "training :  6198  accuracy =   0.7900  loss =  152.255\n",
      "testing  :  6198  accuracy =   0.8247  loss =  152.899\n",
      "training :  6199  accuracy =   0.7600  loss =  151.675\n",
      "testing  :  6199  accuracy =   0.8240  loss =  152.847\n",
      "training :  6200  accuracy =   0.8800  loss =  149.742\n",
      "testing  :  6200  accuracy =   0.8229  loss =  152.803\n",
      "training :  6201  accuracy =   0.8200  loss =  153.442\n",
      "testing  :  6201  accuracy =   0.8214  loss =  152.773\n",
      "training :  6202  accuracy =   0.8400  loss =  152.666\n",
      "testing  :  6202  accuracy =   0.8204  loss =  152.751\n",
      "training :  6203  accuracy =   0.8700  loss =  150.003\n",
      "testing  :  6203  accuracy =   0.8171  loss =  152.725\n",
      "training :  6204  accuracy =   0.8400  loss =  150.125\n",
      "testing  :  6204  accuracy =   0.8165  loss =  152.735\n",
      "training :  6205  accuracy =   0.8500  loss =  151.062\n",
      "testing  :  6205  accuracy =   0.8148  loss =  152.767\n",
      "training :  6206  accuracy =   0.9000  loss =  151.575\n",
      "testing  :  6206  accuracy =   0.8133  loss =  152.82\n",
      "training :  6207  accuracy =   0.8400  loss =  152.594\n",
      "testing  :  6207  accuracy =   0.8108  loss =  152.893\n",
      "training :  6208  accuracy =   0.7900  loss =  150.449\n",
      "testing  :  6208  accuracy =   0.8068  loss =  152.991\n",
      "training :  6209  accuracy =   0.8100  loss =  150.935\n",
      "testing  :  6209  accuracy =   0.8027  loss =  153.084\n",
      "training :  6210  accuracy =   0.8600  loss =  149.935\n",
      "testing  :  6210  accuracy =   0.7999  loss =  153.184\n",
      "training :  6211  accuracy =   0.8100  loss =  151.045\n",
      "testing  :  6211  accuracy =   0.7990  loss =  153.216\n",
      "training :  6212  accuracy =   0.8000  loss =  151.714\n",
      "testing  :  6212  accuracy =   0.7973  loss =  153.219\n",
      "training :  6213  accuracy =   0.8400  loss =  151.442\n",
      "testing  :  6213  accuracy =   0.7990  loss =  153.146\n",
      "training :  6214  accuracy =   0.7600  loss =  151.247\n",
      "testing  :  6214  accuracy =   0.7984  loss =  153.094\n",
      "training :  6215  accuracy =   0.8100  loss =  153.144\n",
      "testing  :  6215  accuracy =   0.7998  loss =  152.985\n",
      "training :  6216  accuracy =   0.8600  loss =  150.544\n",
      "testing  :  6216  accuracy =   0.8052  loss =  152.869\n",
      "training :  6217  accuracy =   0.8000  loss =  151.52\n",
      "testing  :  6217  accuracy =   0.8085  loss =  152.803\n",
      "training :  6218  accuracy =   0.7900  loss =  154.417\n",
      "testing  :  6218  accuracy =   0.8099  loss =  152.809\n",
      "training :  6219  accuracy =   0.8700  loss =  150.516\n",
      "testing  :  6219  accuracy =   0.8090  loss =  152.838\n",
      "training :  6220  accuracy =   0.8400  loss =  150.342\n",
      "testing  :  6220  accuracy =   0.8086  loss =  152.837\n",
      "training :  6221  accuracy =   0.8300  loss =  150.432\n",
      "testing  :  6221  accuracy =   0.8082  loss =  152.842\n",
      "training :  6222  accuracy =   0.8200  loss =  152.777\n",
      "testing  :  6222  accuracy =   0.8088  loss =  152.862\n",
      "training :  6223  accuracy =   0.8000  loss =  150.594\n",
      "testing  :  6223  accuracy =   0.8098  loss =  152.899\n",
      "training :  6224  accuracy =   0.8500  loss =  150.187\n",
      "testing  :  6224  accuracy =   0.8107  loss =  152.919\n",
      "training :  6225  accuracy =   0.8500  loss =  151.329\n",
      "testing  :  6225  accuracy =   0.8114  loss =  152.93\n",
      "training :  6226  accuracy =   0.8500  loss =  150.823\n",
      "testing  :  6226  accuracy =   0.8122  loss =  152.934\n",
      "training :  6227  accuracy =   0.7000  loss =  156.165\n",
      "testing  :  6227  accuracy =   0.8135  loss =  152.921\n",
      "training :  6228  accuracy =   0.8600  loss =  151.636\n",
      "testing  :  6228  accuracy =   0.8126  loss =  152.885\n",
      "training :  6229  accuracy =   0.7400  loss =  157.12\n",
      "testing  :  6229  accuracy =   0.8139  loss =  152.876\n",
      "training :  6230  accuracy =   0.8100  loss =  151.295\n",
      "testing  :  6230  accuracy =   0.8109  loss =  152.876\n",
      "training :  6231  accuracy =   0.8000  loss =  151.793\n",
      "testing  :  6231  accuracy =   0.8096  loss =  152.884\n",
      "training :  6232  accuracy =   0.7200  loss =  153.558\n",
      "testing  :  6232  accuracy =   0.8072  loss =  152.884\n",
      "training :  6233  accuracy =   0.7800  loss =  151.661\n",
      "testing  :  6233  accuracy =   0.8041  loss =  152.883\n",
      "training :  6234  accuracy =   0.8000  loss =  151.291\n",
      "testing  :  6234  accuracy =   0.8031  loss =  152.893\n",
      "training :  6235  accuracy =   0.7900  loss =  152.92\n",
      "testing  :  6235  accuracy =   0.8024  loss =  152.852\n",
      "training :  6236  accuracy =   0.8100  loss =  152.073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6236  accuracy =   0.8009  loss =  152.791\n",
      "training :  6237  accuracy =   0.8100  loss =  152.234\n",
      "testing  :  6237  accuracy =   0.7993  loss =  152.762\n",
      "training :  6238  accuracy =   0.8300  loss =  150.065\n",
      "testing  :  6238  accuracy =   0.7989  loss =  152.738\n",
      "training :  6239  accuracy =   0.8100  loss =  151.143\n",
      "testing  :  6239  accuracy =   0.7975  loss =  152.709\n",
      "training :  6240  accuracy =   0.8200  loss =  151.448\n",
      "testing  :  6240  accuracy =   0.7963  loss =  152.705\n",
      "training :  6241  accuracy =   0.8200  loss =  151.32\n",
      "testing  :  6241  accuracy =   0.7955  loss =  152.71\n",
      "training :  6242  accuracy =   0.8100  loss =  151.594\n",
      "testing  :  6242  accuracy =   0.7949  loss =  152.731\n",
      "training :  6243  accuracy =   0.8900  loss =  150.92\n",
      "testing  :  6243  accuracy =   0.7939  loss =  152.769\n",
      "training :  6244  accuracy =   0.8300  loss =  150.318\n",
      "testing  :  6244  accuracy =   0.7932  loss =  152.817\n",
      "training :  6245  accuracy =   0.8000  loss =  150.981\n",
      "testing  :  6245  accuracy =   0.7927  loss =  152.847\n",
      "training :  6246  accuracy =   0.8100  loss =  150.911\n",
      "testing  :  6246  accuracy =   0.7918  loss =  152.886\n",
      "training :  6247  accuracy =   0.8500  loss =  149.763\n",
      "testing  :  6247  accuracy =   0.7915  loss =  152.916\n",
      "training :  6248  accuracy =   0.8300  loss =  149.032\n",
      "testing  :  6248  accuracy =   0.7924  loss =  152.9\n",
      "training :  6249  accuracy =   0.7300  loss =  151.701\n",
      "testing  :  6249  accuracy =   0.7928  loss =  152.883\n",
      "training :  6250  accuracy =   0.8500  loss =  151.163\n",
      "testing  :  6250  accuracy =   0.7934  loss =  152.866\n",
      "training :  6251  accuracy =   0.8300  loss =  152.16\n",
      "testing  :  6251  accuracy =   0.7940  loss =  152.851\n",
      "training :  6252  accuracy =   0.8200  loss =  151.313\n",
      "testing  :  6252  accuracy =   0.7945  loss =  152.842\n",
      "training :  6253  accuracy =   0.8100  loss =  149.917\n",
      "testing  :  6253  accuracy =   0.7957  loss =  152.846\n",
      "training :  6254  accuracy =   0.8200  loss =  151.093\n",
      "testing  :  6254  accuracy =   0.7963  loss =  152.851\n",
      "training :  6255  accuracy =   0.7600  loss =  150.511\n",
      "testing  :  6255  accuracy =   0.7970  loss =  152.849\n",
      "training :  6256  accuracy =   0.8200  loss =  150.715\n",
      "testing  :  6256  accuracy =   0.7976  loss =  152.849\n",
      "training :  6257  accuracy =   0.8000  loss =  152.543\n",
      "testing  :  6257  accuracy =   0.7979  loss =  152.846\n",
      "training :  6258  accuracy =   0.7800  loss =  151.997\n",
      "testing  :  6258  accuracy =   0.7983  loss =  152.843\n",
      "training :  6259  accuracy =   0.8900  loss =  149.552\n",
      "testing  :  6259  accuracy =   0.7984  loss =  152.829\n",
      "training :  6260  accuracy =   0.7600  loss =  152.85\n",
      "testing  :  6260  accuracy =   0.7989  loss =  152.821\n",
      "training :  6261  accuracy =   0.7200  loss =  155.465\n",
      "testing  :  6261  accuracy =   0.7989  loss =  152.802\n",
      "training :  6262  accuracy =   0.7900  loss =  152.43\n",
      "testing  :  6262  accuracy =   0.7982  loss =  152.771\n",
      "training :  6263  accuracy =   0.8600  loss =  150.768\n",
      "testing  :  6263  accuracy =   0.7981  loss =  152.693\n",
      "training :  6264  accuracy =   0.8200  loss =  151.087\n",
      "testing  :  6264  accuracy =   0.7979  loss =  152.633\n",
      "training :  6265  accuracy =   0.8100  loss =  150.131\n",
      "testing  :  6265  accuracy =   0.7969  loss =  152.616\n",
      "training :  6266  accuracy =   0.8300  loss =  150.023\n",
      "testing  :  6266  accuracy =   0.7971  loss =  152.637\n",
      "training :  6267  accuracy =   0.8200  loss =  151.854\n",
      "testing  :  6267  accuracy =   0.7969  loss =  152.671\n",
      "training :  6268  accuracy =   0.8300  loss =  151.09\n",
      "testing  :  6268  accuracy =   0.7965  loss =  152.704\n",
      "training :  6269  accuracy =   0.8100  loss =  150.131\n",
      "testing  :  6269  accuracy =   0.7962  loss =  152.73\n",
      "training :  6270  accuracy =   0.8600  loss =  150.256\n",
      "testing  :  6270  accuracy =   0.7970  loss =  152.757\n",
      "training :  6271  accuracy =   0.8800  loss =  149.753\n",
      "testing  :  6271  accuracy =   0.7973  loss =  152.784\n",
      "training :  6272  accuracy =   0.8700  loss =  150.453\n",
      "testing  :  6272  accuracy =   0.7970  loss =  152.8\n",
      "training :  6273  accuracy =   0.8000  loss =  151.086\n",
      "testing  :  6273  accuracy =   0.7965  loss =  152.806\n",
      "training :  6274  accuracy =   0.9000  loss =  150.491\n",
      "testing  :  6274  accuracy =   0.7961  loss =  152.807\n",
      "training :  6275  accuracy =   0.7800  loss =  153.318\n",
      "testing  :  6275  accuracy =   0.7959  loss =  152.794\n",
      "training :  6276  accuracy =   0.7600  loss =  150.958\n",
      "testing  :  6276  accuracy =   0.7960  loss =  152.782\n",
      "training :  6277  accuracy =   0.8800  loss =  148.832\n",
      "testing  :  6277  accuracy =   0.7960  loss =  152.782\n",
      "training :  6278  accuracy =   0.8200  loss =  150.475\n",
      "testing  :  6278  accuracy =   0.7958  loss =  152.781\n",
      "training :  6279  accuracy =   0.8100  loss =  153.661\n",
      "testing  :  6279  accuracy =   0.7954  loss =  152.782\n",
      "training :  6280  accuracy =   0.8000  loss =  151.69\n",
      "testing  :  6280  accuracy =   0.7955  loss =  152.762\n",
      "training :  6281  accuracy =   0.8200  loss =  151.197\n",
      "testing  :  6281  accuracy =   0.7958  loss =  152.741\n",
      "training :  6282  accuracy =   0.8600  loss =  150.208\n",
      "testing  :  6282  accuracy =   0.7966  loss =  152.728\n",
      "training :  6283  accuracy =   0.8100  loss =  151.153\n",
      "testing  :  6283  accuracy =   0.7966  loss =  152.721\n",
      "training :  6284  accuracy =   0.7200  loss =  152.495\n",
      "testing  :  6284  accuracy =   0.7977  loss =  152.714\n",
      "training :  6285  accuracy =   0.8000  loss =  149.623\n",
      "testing  :  6285  accuracy =   0.7976  loss =  152.733\n",
      "training :  6286  accuracy =   0.8200  loss =  152.813\n",
      "testing  :  6286  accuracy =   0.7970  loss =  152.756\n",
      "training :  6287  accuracy =   0.8200  loss =  153.775\n",
      "testing  :  6287  accuracy =   0.7971  loss =  152.779\n",
      "training :  6288  accuracy =   0.7800  loss =  151.51\n",
      "testing  :  6288  accuracy =   0.7987  loss =  152.804\n",
      "training :  6289  accuracy =   0.8500  loss =  150.908\n",
      "testing  :  6289  accuracy =   0.7997  loss =  152.835\n",
      "training :  6290  accuracy =   0.8100  loss =  151.814\n",
      "testing  :  6290  accuracy =   0.8003  loss =  152.869\n",
      "training :  6291  accuracy =   0.8000  loss =  150.027\n",
      "testing  :  6291  accuracy =   0.8005  loss =  152.887\n",
      "training :  6292  accuracy =   0.8000  loss =  153.314\n",
      "testing  :  6292  accuracy =   0.8007  loss =  152.91\n",
      "training :  6293  accuracy =   0.7800  loss =  150.791\n",
      "testing  :  6293  accuracy =   0.8012  loss =  152.904\n",
      "training :  6294  accuracy =   0.8300  loss =  150.816\n",
      "testing  :  6294  accuracy =   0.8015  loss =  152.896\n",
      "training :  6295  accuracy =   0.8000  loss =  151.742\n",
      "testing  :  6295  accuracy =   0.8023  loss =  152.877\n",
      "training :  6296  accuracy =   0.8200  loss =  149.997\n",
      "testing  :  6296  accuracy =   0.8025  loss =  152.87\n",
      "training :  6297  accuracy =   0.7700  loss =  152.949\n",
      "testing  :  6297  accuracy =   0.8016  loss =  152.912\n",
      "training :  6298  accuracy =   0.8000  loss =  150.852\n",
      "testing  :  6298  accuracy =   0.7995  loss =  152.946\n",
      "training :  6299  accuracy =   0.8800  loss =  150.267\n",
      "testing  :  6299  accuracy =   0.7971  loss =  152.981\n",
      "training :  6300  accuracy =   0.8500  loss =  150.34\n",
      "testing  :  6300  accuracy =   0.7957  loss =  153.001\n",
      "training :  6301  accuracy =   0.7900  loss =  150.731\n",
      "testing  :  6301  accuracy =   0.7948  loss =  153.02\n",
      "training :  6302  accuracy =   0.8000  loss =  150.683\n",
      "testing  :  6302  accuracy =   0.7937  loss =  153.043\n",
      "training :  6303  accuracy =   0.8000  loss =  150.508\n",
      "testing  :  6303  accuracy =   0.7937  loss =  153.051\n",
      "training :  6304  accuracy =   0.6800  loss =  153.18\n",
      "testing  :  6304  accuracy =   0.7938  loss =  153.029\n",
      "training :  6305  accuracy =   0.8000  loss =  150.489\n",
      "testing  :  6305  accuracy =   0.7938  loss =  152.995\n",
      "training :  6306  accuracy =   0.7300  loss =  153.281\n",
      "testing  :  6306  accuracy =   0.7940  loss =  152.965\n",
      "training :  6307  accuracy =   0.8300  loss =  152.291\n",
      "testing  :  6307  accuracy =   0.7944  loss =  152.896\n",
      "training :  6308  accuracy =   0.8000  loss =  151.449\n",
      "testing  :  6308  accuracy =   0.7954  loss =  152.805\n",
      "training :  6309  accuracy =   0.7500  loss =  154.159\n",
      "testing  :  6309  accuracy =   0.7962  loss =  152.752\n",
      "training :  6310  accuracy =   0.7300  loss =  153.673\n",
      "testing  :  6310  accuracy =   0.7970  loss =  152.711\n",
      "training :  6311  accuracy =   0.7500  loss =  152.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6311  accuracy =   0.7971  loss =  152.68\n",
      "training :  6312  accuracy =   0.8400  loss =  151.59\n",
      "testing  :  6312  accuracy =   0.7976  loss =  152.659\n",
      "training :  6313  accuracy =   0.8200  loss =  150.877\n",
      "testing  :  6313  accuracy =   0.7972  loss =  152.652\n",
      "training :  6314  accuracy =   0.8700  loss =  152.101\n",
      "testing  :  6314  accuracy =   0.7968  loss =  152.649\n",
      "training :  6315  accuracy =   0.7600  loss =  152.865\n",
      "testing  :  6315  accuracy =   0.7968  loss =  152.651\n",
      "training :  6316  accuracy =   0.8200  loss =  151.192\n",
      "testing  :  6316  accuracy =   0.7963  loss =  152.657\n",
      "training :  6317  accuracy =   0.7800  loss =  153.033\n",
      "testing  :  6317  accuracy =   0.7964  loss =  152.668\n",
      "training :  6318  accuracy =   0.7600  loss =  153.019\n",
      "testing  :  6318  accuracy =   0.7966  loss =  152.678\n",
      "training :  6319  accuracy =   0.7500  loss =  152.849\n",
      "testing  :  6319  accuracy =   0.7959  loss =  152.69\n",
      "training :  6320  accuracy =   0.8200  loss =  150.704\n",
      "testing  :  6320  accuracy =   0.7957  loss =  152.703\n",
      "training :  6321  accuracy =   0.8500  loss =  150.403\n",
      "testing  :  6321  accuracy =   0.7954  loss =  152.718\n",
      "training :  6322  accuracy =   0.8600  loss =  149.34\n",
      "testing  :  6322  accuracy =   0.7956  loss =  152.729\n",
      "training :  6323  accuracy =   0.7800  loss =  152.13\n",
      "testing  :  6323  accuracy =   0.7966  loss =  152.732\n",
      "training :  6324  accuracy =   0.8200  loss =  152.861\n",
      "testing  :  6324  accuracy =   0.7964  loss =  152.731\n",
      "training :  6325  accuracy =   0.8400  loss =  152.218\n",
      "testing  :  6325  accuracy =   0.7964  loss =  152.733\n",
      "training :  6326  accuracy =   0.8400  loss =  152.106\n",
      "testing  :  6326  accuracy =   0.7971  loss =  152.716\n",
      "training :  6327  accuracy =   0.8000  loss =  150.586\n",
      "testing  :  6327  accuracy =   0.7976  loss =  152.684\n",
      "training :  6328  accuracy =   0.7900  loss =  150.949\n",
      "testing  :  6328  accuracy =   0.7982  loss =  152.677\n",
      "training :  6329  accuracy =   0.7800  loss =  151.776\n",
      "testing  :  6329  accuracy =   0.7995  loss =  152.684\n",
      "training :  6330  accuracy =   0.8200  loss =  150.822\n",
      "testing  :  6330  accuracy =   0.7989  loss =  152.731\n",
      "training :  6331  accuracy =   0.7800  loss =  150.586\n",
      "testing  :  6331  accuracy =   0.8000  loss =  152.793\n",
      "training :  6332  accuracy =   0.8100  loss =  151.719\n",
      "testing  :  6332  accuracy =   0.8006  loss =  152.86\n",
      "training :  6333  accuracy =   0.8200  loss =  152.127\n",
      "testing  :  6333  accuracy =   0.8005  loss =  152.89\n",
      "training :  6334  accuracy =   0.8300  loss =  152.983\n",
      "testing  :  6334  accuracy =   0.8020  loss =  152.913\n",
      "training :  6335  accuracy =   0.8400  loss =  151.139\n",
      "testing  :  6335  accuracy =   0.8016  loss =  152.934\n",
      "training :  6336  accuracy =   0.7500  loss =  154.968\n",
      "testing  :  6336  accuracy =   0.8014  loss =  152.944\n",
      "training :  6337  accuracy =   0.8300  loss =  153.15\n",
      "testing  :  6337  accuracy =   0.8017  loss =  152.924\n",
      "training :  6338  accuracy =   0.8100  loss =  152.357\n",
      "testing  :  6338  accuracy =   0.8005  loss =  152.86\n",
      "training :  6339  accuracy =   0.8600  loss =  149.694\n",
      "testing  :  6339  accuracy =   0.7998  loss =  152.817\n",
      "training :  6340  accuracy =   0.7500  loss =  153.025\n",
      "testing  :  6340  accuracy =   0.7986  loss =  152.776\n",
      "training :  6341  accuracy =   0.8100  loss =  151.505\n",
      "testing  :  6341  accuracy =   0.7991  loss =  152.747\n",
      "training :  6342  accuracy =   0.7800  loss =  152.087\n",
      "testing  :  6342  accuracy =   0.7979  loss =  152.735\n",
      "training :  6343  accuracy =   0.7300  loss =  151.997\n",
      "testing  :  6343  accuracy =   0.7973  loss =  152.729\n",
      "training :  6344  accuracy =   0.8000  loss =  152.439\n",
      "testing  :  6344  accuracy =   0.7967  loss =  152.729\n",
      "training :  6345  accuracy =   0.7400  loss =  150.869\n",
      "testing  :  6345  accuracy =   0.7952  loss =  152.739\n",
      "training :  6346  accuracy =   0.8200  loss =  151.249\n",
      "testing  :  6346  accuracy =   0.7949  loss =  152.759\n",
      "training :  6347  accuracy =   0.7800  loss =  150.277\n",
      "testing  :  6347  accuracy =   0.7946  loss =  152.79\n",
      "training :  6348  accuracy =   0.7500  loss =  153.474\n",
      "testing  :  6348  accuracy =   0.7938  loss =  152.825\n",
      "training :  6349  accuracy =   0.7800  loss =  150.632\n",
      "testing  :  6349  accuracy =   0.7926  loss =  152.863\n",
      "training :  6350  accuracy =   0.7900  loss =  151.975\n",
      "testing  :  6350  accuracy =   0.7911  loss =  152.893\n",
      "training :  6351  accuracy =   0.7800  loss =  150.848\n",
      "testing  :  6351  accuracy =   0.7911  loss =  152.899\n",
      "training :  6352  accuracy =   0.8000  loss =  151.668\n",
      "testing  :  6352  accuracy =   0.7907  loss =  152.956\n",
      "training :  6353  accuracy =   0.8300  loss =  151.528\n",
      "testing  :  6353  accuracy =   0.7899  loss =  153.003\n",
      "training :  6354  accuracy =   0.7700  loss =  151.849\n",
      "testing  :  6354  accuracy =   0.7894  loss =  153.046\n",
      "training :  6355  accuracy =   0.7900  loss =  152.188\n",
      "testing  :  6355  accuracy =   0.7888  loss =  153.078\n",
      "training :  6356  accuracy =   0.7900  loss =  152.44\n",
      "testing  :  6356  accuracy =   0.7890  loss =  153.098\n",
      "training :  6357  accuracy =   0.7900  loss =  151.094\n",
      "testing  :  6357  accuracy =   0.7895  loss =  153.116\n",
      "training :  6358  accuracy =   0.8000  loss =  152.584\n",
      "testing  :  6358  accuracy =   0.7883  loss =  153.168\n",
      "training :  6359  accuracy =   0.8000  loss =  152.007\n",
      "testing  :  6359  accuracy =   0.7888  loss =  153.142\n",
      "training :  6360  accuracy =   0.8600  loss =  151.378\n",
      "testing  :  6360  accuracy =   0.7906  loss =  153.062\n",
      "training :  6361  accuracy =   0.7700  loss =  150.292\n",
      "testing  :  6361  accuracy =   0.7914  loss =  152.981\n",
      "training :  6362  accuracy =   0.8200  loss =  151.286\n",
      "testing  :  6362  accuracy =   0.7915  loss =  152.92\n",
      "training :  6363  accuracy =   0.8100  loss =  152.106\n",
      "testing  :  6363  accuracy =   0.7923  loss =  152.871\n",
      "training :  6364  accuracy =   0.8100  loss =  151.748\n",
      "testing  :  6364  accuracy =   0.7921  loss =  152.838\n",
      "training :  6365  accuracy =   0.8000  loss =  152.055\n",
      "testing  :  6365  accuracy =   0.7931  loss =  152.824\n",
      "training :  6366  accuracy =   0.7200  loss =  152.628\n",
      "testing  :  6366  accuracy =   0.7941  loss =  152.815\n",
      "training :  6367  accuracy =   0.8100  loss =  150.8\n",
      "testing  :  6367  accuracy =   0.7946  loss =  152.807\n",
      "training :  6368  accuracy =   0.8500  loss =  152.075\n",
      "testing  :  6368  accuracy =   0.7953  loss =  152.805\n",
      "training :  6369  accuracy =   0.8800  loss =  149.998\n",
      "testing  :  6369  accuracy =   0.7959  loss =  152.802\n",
      "training :  6370  accuracy =   0.8100  loss =  151.173\n",
      "testing  :  6370  accuracy =   0.7970  loss =  152.796\n",
      "training :  6371  accuracy =   0.8500  loss =  150.685\n",
      "testing  :  6371  accuracy =   0.7981  loss =  152.787\n",
      "training :  6372  accuracy =   0.7900  loss =  151.715\n",
      "testing  :  6372  accuracy =   0.7983  loss =  152.774\n",
      "training :  6373  accuracy =   0.8200  loss =  151.166\n",
      "testing  :  6373  accuracy =   0.7983  loss =  152.77\n",
      "training :  6374  accuracy =   0.7400  loss =  155.58\n",
      "testing  :  6374  accuracy =   0.7989  loss =  152.772\n",
      "training :  6375  accuracy =   0.8100  loss =  150.166\n",
      "testing  :  6375  accuracy =   0.7988  loss =  152.776\n",
      "training :  6376  accuracy =   0.8200  loss =  151.478\n",
      "testing  :  6376  accuracy =   0.7977  loss =  152.779\n",
      "training :  6377  accuracy =   0.7900  loss =  150.682\n",
      "testing  :  6377  accuracy =   0.7971  loss =  152.78\n",
      "training :  6378  accuracy =   0.8300  loss =  151.234\n",
      "testing  :  6378  accuracy =   0.7961  loss =  152.778\n",
      "training :  6379  accuracy =   0.7900  loss =  151.335\n",
      "testing  :  6379  accuracy =   0.7960  loss =  152.78\n",
      "training :  6380  accuracy =   0.8400  loss =  152.977\n",
      "testing  :  6380  accuracy =   0.7960  loss =  152.787\n",
      "training :  6381  accuracy =   0.8600  loss =  153.116\n",
      "testing  :  6381  accuracy =   0.7960  loss =  152.801\n",
      "training :  6382  accuracy =   0.8000  loss =  152.88\n",
      "testing  :  6382  accuracy =   0.7950  loss =  152.827\n",
      "training :  6383  accuracy =   0.8400  loss =  149.066\n",
      "testing  :  6383  accuracy =   0.7955  loss =  152.816\n",
      "training :  6384  accuracy =   0.7700  loss =  152.823\n",
      "testing  :  6384  accuracy =   0.7962  loss =  152.798\n",
      "training :  6385  accuracy =   0.7700  loss =  150.396\n",
      "testing  :  6385  accuracy =   0.7967  loss =  152.766\n",
      "training :  6386  accuracy =   0.7900  loss =  151.966\n",
      "testing  :  6386  accuracy =   0.7973  loss =  152.746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  6387  accuracy =   0.7700  loss =  152.699\n",
      "testing  :  6387  accuracy =   0.7966  loss =  152.74\n",
      "training :  6388  accuracy =   0.8900  loss =  149.267\n",
      "testing  :  6388  accuracy =   0.7967  loss =  152.74\n",
      "training :  6389  accuracy =   0.8100  loss =  152.183\n",
      "testing  :  6389  accuracy =   0.7965  loss =  152.749\n",
      "training :  6390  accuracy =   0.8300  loss =  151.096\n",
      "testing  :  6390  accuracy =   0.7954  loss =  152.765\n",
      "training :  6391  accuracy =   0.7700  loss =  154.318\n",
      "testing  :  6391  accuracy =   0.7953  loss =  152.781\n",
      "training :  6392  accuracy =   0.7500  loss =  152.639\n",
      "testing  :  6392  accuracy =   0.7942  loss =  152.784\n",
      "training :  6393  accuracy =   0.7700  loss =  151.325\n",
      "testing  :  6393  accuracy =   0.7944  loss =  152.794\n",
      "training :  6394  accuracy =   0.7600  loss =  150.643\n",
      "testing  :  6394  accuracy =   0.7943  loss =  152.806\n",
      "training :  6395  accuracy =   0.8100  loss =  152.319\n",
      "testing  :  6395  accuracy =   0.7942  loss =  152.812\n",
      "training :  6396  accuracy =   0.7900  loss =  151.695\n",
      "testing  :  6396  accuracy =   0.7944  loss =  152.813\n",
      "training :  6397  accuracy =   0.7300  loss =  153.138\n",
      "testing  :  6397  accuracy =   0.7947  loss =  152.82\n",
      "training :  6398  accuracy =   0.7900  loss =  152.49\n",
      "testing  :  6398  accuracy =   0.7946  loss =  152.835\n",
      "training :  6399  accuracy =   0.8600  loss =  153.76\n",
      "testing  :  6399  accuracy =   0.7941  loss =  152.841\n",
      "training :  6400  accuracy =   0.8300  loss =  150.411\n",
      "testing  :  6400  accuracy =   0.7934  loss =  152.835\n",
      "training :  6401  accuracy =   0.8300  loss =  150.89\n",
      "testing  :  6401  accuracy =   0.7920  loss =  152.82\n",
      "training :  6402  accuracy =   0.8700  loss =  149.721\n",
      "testing  :  6402  accuracy =   0.7915  loss =  152.82\n",
      "training :  6403  accuracy =   0.7800  loss =  150.409\n",
      "testing  :  6403  accuracy =   0.7915  loss =  152.842\n",
      "training :  6404  accuracy =   0.8300  loss =  153.376\n",
      "testing  :  6404  accuracy =   0.7921  loss =  152.88\n",
      "training :  6405  accuracy =   0.8200  loss =  150.592\n",
      "testing  :  6405  accuracy =   0.7927  loss =  152.923\n",
      "training :  6406  accuracy =   0.8100  loss =  150.69\n",
      "testing  :  6406  accuracy =   0.7923  loss =  152.938\n",
      "training :  6407  accuracy =   0.7900  loss =  153.427\n",
      "testing  :  6407  accuracy =   0.7925  loss =  152.956\n",
      "training :  6408  accuracy =   0.8300  loss =  150.286\n",
      "testing  :  6408  accuracy =   0.7925  loss =  152.937\n",
      "training :  6409  accuracy =   0.8200  loss =  151.127\n",
      "testing  :  6409  accuracy =   0.7940  loss =  152.934\n",
      "training :  6410  accuracy =   0.8300  loss =  151.205\n",
      "testing  :  6410  accuracy =   0.7935  loss =  152.942\n",
      "training :  6411  accuracy =   0.8200  loss =  150.897\n",
      "testing  :  6411  accuracy =   0.7938  loss =  152.942\n",
      "training :  6412  accuracy =   0.7800  loss =  151.578\n",
      "testing  :  6412  accuracy =   0.7943  loss =  152.927\n",
      "training :  6413  accuracy =   0.8800  loss =  150.204\n",
      "testing  :  6413  accuracy =   0.7943  loss =  152.911\n",
      "training :  6414  accuracy =   0.8300  loss =  150.732\n",
      "testing  :  6414  accuracy =   0.7948  loss =  152.87\n",
      "training :  6415  accuracy =   0.7100  loss =  152.557\n",
      "testing  :  6415  accuracy =   0.7947  loss =  152.85\n",
      "training :  6416  accuracy =   0.8100  loss =  151.651\n",
      "testing  :  6416  accuracy =   0.7942  loss =  152.837\n",
      "training :  6417  accuracy =   0.7800  loss =  151.435\n",
      "testing  :  6417  accuracy =   0.7933  loss =  152.906\n",
      "training :  6418  accuracy =   0.8000  loss =  152.865\n",
      "testing  :  6418  accuracy =   0.7927  loss =  152.936\n",
      "training :  6419  accuracy =   0.8200  loss =  150.284\n",
      "testing  :  6419  accuracy =   0.7922  loss =  152.932\n",
      "training :  6420  accuracy =   0.8000  loss =  154.993\n",
      "testing  :  6420  accuracy =   0.7909  loss =  152.935\n",
      "training :  6421  accuracy =   0.7300  loss =  152.989\n",
      "testing  :  6421  accuracy =   0.7909  loss =  152.871\n",
      "training :  6422  accuracy =   0.8400  loss =  150.921\n",
      "testing  :  6422  accuracy =   0.7919  loss =  152.844\n",
      "training :  6423  accuracy =   0.8500  loss =  150.755\n",
      "testing  :  6423  accuracy =   0.7928  loss =  152.855\n",
      "training :  6424  accuracy =   0.8000  loss =  151.767\n",
      "testing  :  6424  accuracy =   0.7934  loss =  152.873\n",
      "training :  6425  accuracy =   0.8300  loss =  153.058\n",
      "testing  :  6425  accuracy =   0.7946  loss =  152.916\n",
      "training :  6426  accuracy =   0.8000  loss =  151.598\n",
      "testing  :  6426  accuracy =   0.7954  loss =  153.023\n",
      "training :  6427  accuracy =   0.8400  loss =  151.279\n",
      "testing  :  6427  accuracy =   0.7971  loss =  153.213\n",
      "training :  6428  accuracy =   0.7900  loss =  155.249\n",
      "testing  :  6428  accuracy =   0.7986  loss =  153.425\n",
      "training :  6429  accuracy =   0.7800  loss =  151.502\n",
      "testing  :  6429  accuracy =   0.8012  loss =  153.595\n",
      "training :  6430  accuracy =   0.8400  loss =  150.079\n",
      "testing  :  6430  accuracy =   0.8024  loss =  153.659\n",
      "training :  6431  accuracy =   0.7600  loss =  155.232\n",
      "testing  :  6431  accuracy =   0.8028  loss =  153.726\n",
      "training :  6432  accuracy =   0.7400  loss =  153.528\n",
      "testing  :  6432  accuracy =   0.8024  loss =  153.634\n",
      "training :  6433  accuracy =   0.7900  loss =  152.014\n",
      "testing  :  6433  accuracy =   0.8012  loss =  153.533\n",
      "training :  6434  accuracy =   0.7100  loss =  151.382\n",
      "testing  :  6434  accuracy =   0.8019  loss =  153.478\n",
      "training :  6435  accuracy =   0.8200  loss =  153.126\n",
      "testing  :  6435  accuracy =   0.8038  loss =  153.399\n",
      "training :  6436  accuracy =   0.8200  loss =  153.264\n",
      "testing  :  6436  accuracy =   0.8053  loss =  153.342\n",
      "training :  6437  accuracy =   0.8100  loss =  152.657\n",
      "testing  :  6437  accuracy =   0.8050  loss =  153.269\n",
      "training :  6438  accuracy =   0.8700  loss =  151.161\n",
      "testing  :  6438  accuracy =   0.8064  loss =  153.21\n",
      "training :  6439  accuracy =   0.8400  loss =  152.525\n",
      "testing  :  6439  accuracy =   0.8070  loss =  153.077\n",
      "training :  6440  accuracy =   0.8200  loss =  150.622\n",
      "testing  :  6440  accuracy =   0.8090  loss =  152.975\n",
      "training :  6441  accuracy =   0.8000  loss =  150.685\n",
      "testing  :  6441  accuracy =   0.8111  loss =  152.91\n",
      "training :  6442  accuracy =   0.8100  loss =  151.407\n",
      "testing  :  6442  accuracy =   0.8132  loss =  152.878\n",
      "training :  6443  accuracy =   0.9000  loss =  149.535\n",
      "testing  :  6443  accuracy =   0.8146  loss =  152.876\n",
      "training :  6444  accuracy =   0.8400  loss =  152.255\n",
      "testing  :  6444  accuracy =   0.8171  loss =  152.918\n",
      "training :  6445  accuracy =   0.8700  loss =  150.261\n",
      "testing  :  6445  accuracy =   0.8200  loss =  152.988\n",
      "training :  6446  accuracy =   0.8700  loss =  151.125\n",
      "testing  :  6446  accuracy =   0.8244  loss =  153.08\n",
      "training :  6447  accuracy =   0.8100  loss =  153.434\n",
      "testing  :  6447  accuracy =   0.8288  loss =  153.165\n",
      "training :  6448  accuracy =   0.8300  loss =  152.839\n",
      "testing  :  6448  accuracy =   0.8356  loss =  153.24\n",
      "training :  6449  accuracy =   0.8800  loss =  152.637\n",
      "testing  :  6449  accuracy =   0.8409  loss =  153.283\n",
      "training :  6450  accuracy =   0.9100  loss =  151.366\n",
      "testing  :  6450  accuracy =   0.8446  loss =  153.312\n",
      "training :  6451  accuracy =   0.8500  loss =  153.601\n",
      "testing  :  6451  accuracy =   0.8484  loss =  153.312\n",
      "training :  6452  accuracy =   0.8000  loss =  154.888\n",
      "testing  :  6452  accuracy =   0.8503  loss =  153.307\n",
      "training :  6453  accuracy =   0.8500  loss =  152.029\n",
      "testing  :  6453  accuracy =   0.8523  loss =  153.218\n",
      "training :  6454  accuracy =   0.8900  loss =  150.587\n",
      "testing  :  6454  accuracy =   0.8516  loss =  153.159\n",
      "training :  6455  accuracy =   0.8400  loss =  152.433\n",
      "testing  :  6455  accuracy =   0.8526  loss =  153.108\n",
      "training :  6456  accuracy =   0.8900  loss =  150.69\n",
      "testing  :  6456  accuracy =   0.8507  loss =  153.079\n",
      "training :  6457  accuracy =   0.8700  loss =  152.033\n",
      "testing  :  6457  accuracy =   0.8495  loss =  153.049\n",
      "training :  6458  accuracy =   0.8600  loss =  150.58\n",
      "testing  :  6458  accuracy =   0.8466  loss =  153.025\n",
      "training :  6459  accuracy =   0.8500  loss =  152.825\n",
      "testing  :  6459  accuracy =   0.8442  loss =  153.013\n",
      "training :  6460  accuracy =   0.9000  loss =  150.166\n",
      "testing  :  6460  accuracy =   0.8416  loss =  153.006\n",
      "training :  6461  accuracy =   0.8000  loss =  152.654\n",
      "testing  :  6461  accuracy =   0.8391  loss =  152.998\n",
      "training :  6462  accuracy =   0.8500  loss =  151.358\n",
      "testing  :  6462  accuracy =   0.8398  loss =  153.006\n",
      "training :  6463  accuracy =   0.8600  loss =  151.571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6463  accuracy =   0.8394  loss =  152.994\n",
      "training :  6464  accuracy =   0.8300  loss =  153.704\n",
      "testing  :  6464  accuracy =   0.8408  loss =  152.979\n",
      "training :  6465  accuracy =   0.8400  loss =  152.781\n",
      "testing  :  6465  accuracy =   0.8391  loss =  152.96\n",
      "training :  6466  accuracy =   0.8900  loss =  151.275\n",
      "testing  :  6466  accuracy =   0.8381  loss =  152.945\n",
      "training :  6467  accuracy =   0.8400  loss =  151.826\n",
      "testing  :  6467  accuracy =   0.8400  loss =  152.94\n",
      "training :  6468  accuracy =   0.8300  loss =  152.557\n",
      "testing  :  6468  accuracy =   0.8486  loss =  152.927\n",
      "training :  6469  accuracy =   0.8200  loss =  154.785\n",
      "testing  :  6469  accuracy =   0.8538  loss =  152.918\n",
      "training :  6470  accuracy =   0.8900  loss =  153.268\n",
      "testing  :  6470  accuracy =   0.8519  loss =  152.882\n",
      "training :  6471  accuracy =   0.8800  loss =  152.579\n",
      "testing  :  6471  accuracy =   0.8486  loss =  152.845\n",
      "training :  6472  accuracy =   0.8300  loss =  154.246\n",
      "testing  :  6472  accuracy =   0.8434  loss =  152.84\n",
      "training :  6473  accuracy =   0.7800  loss =  154.301\n",
      "testing  :  6473  accuracy =   0.8382  loss =  152.84\n",
      "training :  6474  accuracy =   0.8900  loss =  150.685\n",
      "testing  :  6474  accuracy =   0.8360  loss =  152.843\n",
      "training :  6475  accuracy =   0.8400  loss =  150.323\n",
      "testing  :  6475  accuracy =   0.8340  loss =  152.855\n",
      "training :  6476  accuracy =   0.8700  loss =  151.493\n",
      "testing  :  6476  accuracy =   0.8322  loss =  152.869\n",
      "training :  6477  accuracy =   0.8000  loss =  152.281\n",
      "testing  :  6477  accuracy =   0.8291  loss =  152.871\n",
      "training :  6478  accuracy =   0.9300  loss =  150.758\n",
      "testing  :  6478  accuracy =   0.8265  loss =  152.875\n",
      "training :  6479  accuracy =   0.8400  loss =  154.292\n",
      "testing  :  6479  accuracy =   0.8232  loss =  152.885\n",
      "training :  6480  accuracy =   0.8000  loss =  153.444\n",
      "testing  :  6480  accuracy =   0.8204  loss =  152.835\n",
      "training :  6481  accuracy =   0.8100  loss =  153.108\n",
      "testing  :  6481  accuracy =   0.8176  loss =  152.79\n",
      "training :  6482  accuracy =   0.7800  loss =  151.285\n",
      "testing  :  6482  accuracy =   0.8148  loss =  152.76\n",
      "training :  6483  accuracy =   0.7700  loss =  153.105\n",
      "testing  :  6483  accuracy =   0.8127  loss =  152.746\n",
      "training :  6484  accuracy =   0.8200  loss =  152.182\n",
      "testing  :  6484  accuracy =   0.8113  loss =  152.739\n",
      "training :  6485  accuracy =   0.8400  loss =  151.48\n",
      "testing  :  6485  accuracy =   0.8096  loss =  152.745\n",
      "training :  6486  accuracy =   0.8500  loss =  150.574\n",
      "testing  :  6486  accuracy =   0.8088  loss =  152.761\n",
      "training :  6487  accuracy =   0.8000  loss =  150.877\n",
      "testing  :  6487  accuracy =   0.8077  loss =  152.797\n",
      "training :  6488  accuracy =   0.8600  loss =  150.486\n",
      "testing  :  6488  accuracy =   0.8075  loss =  152.838\n",
      "training :  6489  accuracy =   0.8200  loss =  150.592\n",
      "testing  :  6489  accuracy =   0.8069  loss =  152.883\n",
      "training :  6490  accuracy =   0.8200  loss =  151.442\n",
      "testing  :  6490  accuracy =   0.8063  loss =  152.927\n",
      "training :  6491  accuracy =   0.7600  loss =  156.868\n",
      "testing  :  6491  accuracy =   0.8054  loss =  152.972\n",
      "training :  6492  accuracy =   0.8200  loss =  153.125\n",
      "testing  :  6492  accuracy =   0.8055  loss =  152.956\n",
      "training :  6493  accuracy =   0.8500  loss =  150.639\n",
      "testing  :  6493  accuracy =   0.8058  loss =  152.943\n",
      "training :  6494  accuracy =   0.8200  loss =  150.689\n",
      "testing  :  6494  accuracy =   0.8060  loss =  152.937\n",
      "training :  6495  accuracy =   0.7700  loss =  152.117\n",
      "testing  :  6495  accuracy =   0.8063  loss =  152.908\n",
      "training :  6496  accuracy =   0.8200  loss =  150.469\n",
      "testing  :  6496  accuracy =   0.8063  loss =  152.891\n",
      "training :  6497  accuracy =   0.7600  loss =  152.667\n",
      "testing  :  6497  accuracy =   0.8070  loss =  152.875\n",
      "training :  6498  accuracy =   0.7500  loss =  153.319\n",
      "testing  :  6498  accuracy =   0.8084  loss =  152.863\n",
      "training :  6499  accuracy =   0.7700  loss =  151.443\n",
      "testing  :  6499  accuracy =   0.8093  loss =  152.856\n",
      "training :  6500  accuracy =   0.8100  loss =  152.299\n",
      "testing  :  6500  accuracy =   0.8101  loss =  152.861\n",
      "training :  6501  accuracy =   0.8200  loss =  152.752\n",
      "testing  :  6501  accuracy =   0.8106  loss =  152.874\n",
      "training :  6502  accuracy =   0.8500  loss =  152.841\n",
      "testing  :  6502  accuracy =   0.8109  loss =  152.893\n",
      "training :  6503  accuracy =   0.8300  loss =  152.442\n",
      "testing  :  6503  accuracy =   0.8106  loss =  152.912\n",
      "training :  6504  accuracy =   0.8400  loss =  149.873\n",
      "testing  :  6504  accuracy =   0.8150  loss =  152.911\n",
      "training :  6505  accuracy =   0.8600  loss =  151.957\n",
      "testing  :  6505  accuracy =   0.8194  loss =  152.908\n",
      "training :  6506  accuracy =   0.7900  loss =  151.8\n",
      "testing  :  6506  accuracy =   0.8234  loss =  152.951\n",
      "training :  6507  accuracy =   0.8000  loss =  151.925\n",
      "testing  :  6507  accuracy =   0.8265  loss =  153.009\n",
      "training :  6508  accuracy =   0.8600  loss =  153.818\n",
      "testing  :  6508  accuracy =   0.8303  loss =  153.071\n",
      "training :  6509  accuracy =   0.8700  loss =  150.913\n",
      "testing  :  6509  accuracy =   0.8364  loss =  153.107\n",
      "training :  6510  accuracy =   0.8500  loss =  151.817\n",
      "testing  :  6510  accuracy =   0.8383  loss =  153.112\n",
      "training :  6511  accuracy =   0.8300  loss =  152.425\n",
      "testing  :  6511  accuracy =   0.8354  loss =  153.032\n",
      "training :  6512  accuracy =   0.8500  loss =  152.257\n",
      "testing  :  6512  accuracy =   0.8346  loss =  152.983\n",
      "training :  6513  accuracy =   0.8800  loss =  153.818\n",
      "testing  :  6513  accuracy =   0.8365  loss =  152.959\n",
      "training :  6514  accuracy =   0.8700  loss =  152.214\n",
      "testing  :  6514  accuracy =   0.8352  loss =  152.915\n",
      "training :  6515  accuracy =   0.8800  loss =  149.28\n",
      "testing  :  6515  accuracy =   0.8368  loss =  152.824\n",
      "training :  6516  accuracy =   0.8300  loss =  151.756\n",
      "testing  :  6516  accuracy =   0.8375  loss =  152.782\n",
      "training :  6517  accuracy =   0.8700  loss =  152.52\n",
      "testing  :  6517  accuracy =   0.8407  loss =  152.78\n",
      "training :  6518  accuracy =   0.8200  loss =  152.032\n",
      "testing  :  6518  accuracy =   0.8415  loss =  152.756\n",
      "training :  6519  accuracy =   0.8700  loss =  150.192\n",
      "testing  :  6519  accuracy =   0.8420  loss =  152.75\n",
      "training :  6520  accuracy =   0.8400  loss =  152.064\n",
      "testing  :  6520  accuracy =   0.8429  loss =  152.764\n",
      "training :  6521  accuracy =   0.8100  loss =  151.609\n",
      "testing  :  6521  accuracy =   0.8411  loss =  152.792\n",
      "training :  6522  accuracy =   0.8400  loss =  152.298\n",
      "testing  :  6522  accuracy =   0.8408  loss =  152.815\n",
      "training :  6523  accuracy =   0.9000  loss =  150.002\n",
      "testing  :  6523  accuracy =   0.8387  loss =  152.847\n",
      "training :  6524  accuracy =   0.9200  loss =  150.213\n",
      "testing  :  6524  accuracy =   0.8362  loss =  152.886\n",
      "training :  6525  accuracy =   0.7900  loss =  155.113\n",
      "testing  :  6525  accuracy =   0.8336  loss =  152.906\n",
      "training :  6526  accuracy =   0.8700  loss =  151.379\n",
      "testing  :  6526  accuracy =   0.8293  loss =  152.935\n",
      "training :  6527  accuracy =   0.8600  loss =  151.523\n",
      "testing  :  6527  accuracy =   0.8256  loss =  152.975\n",
      "training :  6528  accuracy =   0.8700  loss =  150.298\n",
      "testing  :  6528  accuracy =   0.8230  loss =  153.027\n",
      "training :  6529  accuracy =   0.8100  loss =  154.229\n",
      "testing  :  6529  accuracy =   0.8209  loss =  153.07\n",
      "training :  6530  accuracy =   0.8400  loss =  152.074\n",
      "testing  :  6530  accuracy =   0.8216  loss =  153.011\n",
      "training :  6531  accuracy =   0.8700  loss =  151.979\n",
      "testing  :  6531  accuracy =   0.8233  loss =  152.965\n",
      "training :  6532  accuracy =   0.9000  loss =  150.688\n",
      "testing  :  6532  accuracy =   0.8252  loss =  152.931\n",
      "training :  6533  accuracy =   0.8700  loss =  152.702\n",
      "testing  :  6533  accuracy =   0.8253  loss =  152.897\n",
      "training :  6534  accuracy =   0.8200  loss =  152.003\n",
      "testing  :  6534  accuracy =   0.8217  loss =  152.839\n",
      "training :  6535  accuracy =   0.8500  loss =  150.498\n",
      "testing  :  6535  accuracy =   0.8204  loss =  152.759\n",
      "training :  6536  accuracy =   0.8400  loss =  150.994\n",
      "testing  :  6536  accuracy =   0.8201  loss =  152.728\n",
      "training :  6537  accuracy =   0.8700  loss =  150.504\n",
      "testing  :  6537  accuracy =   0.8189  loss =  152.722\n",
      "training :  6538  accuracy =   0.8200  loss =  151.725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6538  accuracy =   0.8167  loss =  152.741\n",
      "training :  6539  accuracy =   0.7900  loss =  151.487\n",
      "testing  :  6539  accuracy =   0.8155  loss =  152.778\n",
      "training :  6540  accuracy =   0.8400  loss =  153.011\n",
      "testing  :  6540  accuracy =   0.8142  loss =  152.81\n",
      "training :  6541  accuracy =   0.8600  loss =  150.982\n",
      "testing  :  6541  accuracy =   0.8139  loss =  152.844\n",
      "training :  6542  accuracy =   0.8100  loss =  152.455\n",
      "testing  :  6542  accuracy =   0.8156  loss =  152.877\n",
      "training :  6543  accuracy =   0.7900  loss =  153.838\n",
      "testing  :  6543  accuracy =   0.8153  loss =  152.908\n",
      "training :  6544  accuracy =   0.8800  loss =  149.911\n",
      "testing  :  6544  accuracy =   0.8164  loss =  152.949\n",
      "training :  6545  accuracy =   0.8800  loss =  150.025\n",
      "testing  :  6545  accuracy =   0.8171  loss =  153.013\n",
      "training :  6546  accuracy =   0.8400  loss =  151.232\n",
      "testing  :  6546  accuracy =   0.8179  loss =  153.059\n",
      "training :  6547  accuracy =   0.8000  loss =  150.817\n",
      "testing  :  6547  accuracy =   0.8197  loss =  153.051\n",
      "training :  6548  accuracy =   0.8200  loss =  152.527\n",
      "testing  :  6548  accuracy =   0.8225  loss =  153.034\n",
      "training :  6549  accuracy =   0.8400  loss =  150.583\n",
      "testing  :  6549  accuracy =   0.8253  loss =  152.994\n",
      "training :  6550  accuracy =   0.8100  loss =  151.206\n",
      "testing  :  6550  accuracy =   0.8299  loss =  152.941\n",
      "training :  6551  accuracy =   0.8000  loss =  151.334\n",
      "testing  :  6551  accuracy =   0.8327  loss =  152.907\n",
      "training :  6552  accuracy =   0.8500  loss =  151.326\n",
      "testing  :  6552  accuracy =   0.8341  loss =  152.871\n",
      "training :  6553  accuracy =   0.9000  loss =  152.676\n",
      "testing  :  6553  accuracy =   0.8378  loss =  152.835\n",
      "training :  6554  accuracy =   0.9200  loss =  150.12\n",
      "testing  :  6554  accuracy =   0.8426  loss =  152.814\n",
      "training :  6555  accuracy =   0.8600  loss =  152.051\n",
      "testing  :  6555  accuracy =   0.8458  loss =  152.805\n",
      "training :  6556  accuracy =   0.8200  loss =  151.054\n",
      "testing  :  6556  accuracy =   0.8496  loss =  152.802\n",
      "training :  6557  accuracy =   0.9100  loss =  150.448\n",
      "testing  :  6557  accuracy =   0.8534  loss =  152.822\n",
      "training :  6558  accuracy =   0.8500  loss =  150.733\n",
      "testing  :  6558  accuracy =   0.8555  loss =  152.86\n",
      "training :  6559  accuracy =   0.8800  loss =  153.046\n",
      "testing  :  6559  accuracy =   0.8577  loss =  152.913\n",
      "training :  6560  accuracy =   0.7900  loss =  153.488\n",
      "testing  :  6560  accuracy =   0.8588  loss =  153.006\n",
      "training :  6561  accuracy =   0.8000  loss =  152.819\n",
      "testing  :  6561  accuracy =   0.8578  loss =  153.09\n",
      "training :  6562  accuracy =   0.8700  loss =  152.065\n",
      "testing  :  6562  accuracy =   0.8593  loss =  152.967\n",
      "training :  6563  accuracy =   0.8700  loss =  150.799\n",
      "testing  :  6563  accuracy =   0.8617  loss =  152.873\n",
      "training :  6564  accuracy =   0.9000  loss =  149.874\n",
      "testing  :  6564  accuracy =   0.8617  loss =  152.817\n",
      "training :  6565  accuracy =   0.9100  loss =  150.938\n",
      "testing  :  6565  accuracy =   0.8628  loss =  152.775\n",
      "training :  6566  accuracy =   0.8900  loss =  150.666\n",
      "testing  :  6566  accuracy =   0.8617  loss =  152.744\n",
      "training :  6567  accuracy =   0.8200  loss =  153.341\n",
      "testing  :  6567  accuracy =   0.8634  loss =  152.734\n",
      "training :  6568  accuracy =   0.8700  loss =  151.363\n",
      "testing  :  6568  accuracy =   0.8634  loss =  152.718\n",
      "training :  6569  accuracy =   0.8900  loss =  152.511\n",
      "testing  :  6569  accuracy =   0.8638  loss =  152.707\n",
      "training :  6570  accuracy =   0.9000  loss =  151.789\n",
      "testing  :  6570  accuracy =   0.8625  loss =  152.684\n",
      "training :  6571  accuracy =   0.8800  loss =  151.901\n",
      "testing  :  6571  accuracy =   0.8611  loss =  152.71\n",
      "training :  6572  accuracy =   0.9000  loss =  152.193\n",
      "testing  :  6572  accuracy =   0.8594  loss =  152.76\n",
      "training :  6573  accuracy =   0.8900  loss =  151.391\n",
      "testing  :  6573  accuracy =   0.8575  loss =  152.82\n",
      "training :  6574  accuracy =   0.8400  loss =  151.42\n",
      "testing  :  6574  accuracy =   0.8567  loss =  152.917\n",
      "training :  6575  accuracy =   0.8300  loss =  153.021\n",
      "testing  :  6575  accuracy =   0.8561  loss =  152.98\n",
      "training :  6576  accuracy =   0.8700  loss =  151.179\n",
      "testing  :  6576  accuracy =   0.8551  loss =  152.984\n",
      "training :  6577  accuracy =   0.8400  loss =  152.197\n",
      "testing  :  6577  accuracy =   0.8507  loss =  152.982\n",
      "training :  6578  accuracy =   0.9400  loss =  149.696\n",
      "testing  :  6578  accuracy =   0.8467  loss =  152.949\n",
      "training :  6579  accuracy =   0.8700  loss =  150.491\n",
      "testing  :  6579  accuracy =   0.8421  loss =  152.934\n",
      "training :  6580  accuracy =   0.8400  loss =  152.007\n",
      "testing  :  6580  accuracy =   0.8372  loss =  152.937\n",
      "training :  6581  accuracy =   0.7700  loss =  152.766\n",
      "testing  :  6581  accuracy =   0.8292  loss =  152.926\n",
      "training :  6582  accuracy =   0.7900  loss =  151.553\n",
      "testing  :  6582  accuracy =   0.8238  loss =  152.926\n",
      "training :  6583  accuracy =   0.7900  loss =  151.961\n",
      "testing  :  6583  accuracy =   0.8203  loss =  152.935\n",
      "training :  6584  accuracy =   0.7900  loss =  153.104\n",
      "testing  :  6584  accuracy =   0.8159  loss =  152.944\n",
      "training :  6585  accuracy =   0.8700  loss =  150.609\n",
      "testing  :  6585  accuracy =   0.8206  loss =  152.916\n",
      "training :  6586  accuracy =   0.8500  loss =  153.107\n",
      "testing  :  6586  accuracy =   0.8267  loss =  152.914\n",
      "training :  6587  accuracy =   0.8200  loss =  153.651\n",
      "testing  :  6587  accuracy =   0.8306  loss =  152.938\n",
      "training :  6588  accuracy =   0.8600  loss =  151.841\n",
      "testing  :  6588  accuracy =   0.8346  loss =  152.966\n",
      "training :  6589  accuracy =   0.8300  loss =  151.583\n",
      "testing  :  6589  accuracy =   0.8388  loss =  152.988\n",
      "training :  6590  accuracy =   0.8900  loss =  150.64\n",
      "testing  :  6590  accuracy =   0.8430  loss =  153.007\n",
      "training :  6591  accuracy =   0.8800  loss =  151.046\n",
      "testing  :  6591  accuracy =   0.8469  loss =  153.026\n",
      "training :  6592  accuracy =   0.8400  loss =  152.704\n",
      "testing  :  6592  accuracy =   0.8510  loss =  153.04\n",
      "training :  6593  accuracy =   0.8400  loss =  153.264\n",
      "testing  :  6593  accuracy =   0.8538  loss =  153.038\n",
      "training :  6594  accuracy =   0.9000  loss =  152.141\n",
      "testing  :  6594  accuracy =   0.8564  loss =  153.045\n",
      "training :  6595  accuracy =   0.8600  loss =  150.53\n",
      "testing  :  6595  accuracy =   0.8585  loss =  153.034\n",
      "training :  6596  accuracy =   0.8700  loss =  152.12\n",
      "testing  :  6596  accuracy =   0.8601  loss =  153.025\n",
      "training :  6597  accuracy =   0.8500  loss =  151.273\n",
      "testing  :  6597  accuracy =   0.8617  loss =  153.005\n",
      "training :  6598  accuracy =   0.8600  loss =  152.447\n",
      "testing  :  6598  accuracy =   0.8621  loss =  152.991\n",
      "training :  6599  accuracy =   0.9100  loss =  150.139\n",
      "testing  :  6599  accuracy =   0.8634  loss =  152.966\n",
      "training :  6600  accuracy =   0.8900  loss =  152.121\n",
      "testing  :  6600  accuracy =   0.8634  loss =  152.944\n",
      "training :  6601  accuracy =   0.8700  loss =  151.308\n",
      "testing  :  6601  accuracy =   0.8633  loss =  152.924\n",
      "training :  6602  accuracy =   0.8600  loss =  152.122\n",
      "testing  :  6602  accuracy =   0.8637  loss =  152.897\n",
      "training :  6603  accuracy =   0.8900  loss =  152.484\n",
      "testing  :  6603  accuracy =   0.8674  loss =  152.896\n",
      "training :  6604  accuracy =   0.9300  loss =  150.913\n",
      "testing  :  6604  accuracy =   0.8684  loss =  152.9\n",
      "training :  6605  accuracy =   0.8900  loss =  150.715\n",
      "testing  :  6605  accuracy =   0.8686  loss =  152.899\n",
      "training :  6606  accuracy =   0.8100  loss =  154.522\n",
      "testing  :  6606  accuracy =   0.8668  loss =  152.889\n",
      "training :  6607  accuracy =   0.9000  loss =  151.307\n",
      "testing  :  6607  accuracy =   0.8659  loss =  152.867\n",
      "training :  6608  accuracy =   0.9300  loss =  151.49\n",
      "testing  :  6608  accuracy =   0.8656  loss =  152.876\n",
      "training :  6609  accuracy =   0.9100  loss =  151.678\n",
      "testing  :  6609  accuracy =   0.8652  loss =  152.905\n",
      "training :  6610  accuracy =   0.8900  loss =  151.554\n",
      "testing  :  6610  accuracy =   0.8649  loss =  152.946\n",
      "training :  6611  accuracy =   0.8800  loss =  151.423\n",
      "testing  :  6611  accuracy =   0.8653  loss =  152.982\n",
      "training :  6612  accuracy =   0.8500  loss =  151.37\n",
      "testing  :  6612  accuracy =   0.8648  loss =  153.007\n",
      "training :  6613  accuracy =   0.8500  loss =  152.902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6613  accuracy =   0.8643  loss =  153.031\n",
      "training :  6614  accuracy =   0.8900  loss =  150.154\n",
      "testing  :  6614  accuracy =   0.8652  loss =  153.038\n",
      "training :  6615  accuracy =   0.8500  loss =  151.9\n",
      "testing  :  6615  accuracy =   0.8652  loss =  153.052\n",
      "training :  6616  accuracy =   0.8600  loss =  151.163\n",
      "testing  :  6616  accuracy =   0.8682  loss =  153.031\n",
      "training :  6617  accuracy =   0.8500  loss =  152.732\n",
      "testing  :  6617  accuracy =   0.8738  loss =  153.007\n",
      "training :  6618  accuracy =   0.9100  loss =  152.031\n",
      "testing  :  6618  accuracy =   0.8791  loss =  152.978\n",
      "training :  6619  accuracy =   0.9400  loss =  151.514\n",
      "testing  :  6619  accuracy =   0.8934  loss =  152.951\n",
      "training :  6620  accuracy =   0.8900  loss =  151.496\n",
      "testing  :  6620  accuracy =   0.9101  loss =  152.924\n",
      "training :  6621  accuracy =   0.9100  loss =  151.491\n",
      "testing  :  6621  accuracy =   0.9246  loss =  152.886\n",
      "training :  6622  accuracy =   0.9600  loss =  150.277\n",
      "testing  :  6622  accuracy =   0.9353  loss =  152.832\n",
      "training :  6623  accuracy =   0.9700  loss =  151.812\n",
      "testing  :  6623  accuracy =   0.9386  loss =  152.802\n",
      "training :  6624  accuracy =   0.9600  loss =  150.289\n",
      "testing  :  6624  accuracy =   0.9368  loss =  152.761\n",
      "training :  6625  accuracy =   0.9500  loss =  150.527\n",
      "testing  :  6625  accuracy =   0.9336  loss =  152.711\n",
      "training :  6626  accuracy =   0.9600  loss =  151.613\n",
      "testing  :  6626  accuracy =   0.9299  loss =  152.696\n",
      "training :  6627  accuracy =   0.9600  loss =  152.985\n",
      "testing  :  6627  accuracy =   0.9275  loss =  152.706\n",
      "training :  6628  accuracy =   0.9600  loss =  150.599\n",
      "testing  :  6628  accuracy =   0.9258  loss =  152.726\n",
      "training :  6629  accuracy =   0.9300  loss =  152.474\n",
      "testing  :  6629  accuracy =   0.9249  loss =  152.753\n",
      "training :  6630  accuracy =   0.9300  loss =  151.372\n",
      "testing  :  6630  accuracy =   0.9240  loss =  152.746\n",
      "training :  6631  accuracy =   0.9400  loss =  151.49\n",
      "testing  :  6631  accuracy =   0.9319  loss =  152.735\n",
      "training :  6632  accuracy =   0.9000  loss =  152.645\n",
      "testing  :  6632  accuracy =   0.9385  loss =  152.676\n",
      "training :  6633  accuracy =   0.9300  loss =  151.038\n",
      "testing  :  6633  accuracy =   0.9373  loss =  152.659\n",
      "training :  6634  accuracy =   0.8700  loss =  153.158\n",
      "testing  :  6634  accuracy =   0.9256  loss =  152.665\n",
      "training :  6635  accuracy =   0.9100  loss =  151.45\n",
      "testing  :  6635  accuracy =   0.9082  loss =  152.666\n",
      "training :  6636  accuracy =   0.9100  loss =  153.649\n",
      "testing  :  6636  accuracy =   0.8923  loss =  152.664\n",
      "training :  6637  accuracy =   0.8900  loss =  152.245\n",
      "testing  :  6637  accuracy =   0.8817  loss =  152.667\n",
      "training :  6638  accuracy =   0.8100  loss =  153.307\n",
      "testing  :  6638  accuracy =   0.8731  loss =  152.672\n",
      "training :  6639  accuracy =   0.8800  loss =  151.27\n",
      "testing  :  6639  accuracy =   0.8632  loss =  152.666\n",
      "training :  6640  accuracy =   0.8700  loss =  150.235\n",
      "testing  :  6640  accuracy =   0.8577  loss =  152.657\n",
      "training :  6641  accuracy =   0.9000  loss =  150.045\n",
      "testing  :  6641  accuracy =   0.8523  loss =  152.647\n",
      "training :  6642  accuracy =   0.8600  loss =  150.618\n",
      "testing  :  6642  accuracy =   0.8476  loss =  152.647\n",
      "training :  6643  accuracy =   0.8600  loss =  150.493\n",
      "testing  :  6643  accuracy =   0.8430  loss =  152.644\n",
      "training :  6644  accuracy =   0.8200  loss =  150.337\n",
      "testing  :  6644  accuracy =   0.8364  loss =  152.653\n",
      "training :  6645  accuracy =   0.8800  loss =  151.624\n",
      "testing  :  6645  accuracy =   0.8330  loss =  152.664\n",
      "training :  6646  accuracy =   0.7800  loss =  153.217\n",
      "testing  :  6646  accuracy =   0.8312  loss =  152.666\n",
      "training :  6647  accuracy =   0.8500  loss =  151.435\n",
      "testing  :  6647  accuracy =   0.8301  loss =  152.668\n",
      "training :  6648  accuracy =   0.8200  loss =  152.833\n",
      "testing  :  6648  accuracy =   0.8296  loss =  152.67\n",
      "training :  6649  accuracy =   0.8300  loss =  151.459\n",
      "testing  :  6649  accuracy =   0.8288  loss =  152.67\n",
      "training :  6650  accuracy =   0.8700  loss =  149.673\n",
      "testing  :  6650  accuracy =   0.8319  loss =  152.661\n",
      "training :  6651  accuracy =   0.8600  loss =  151.899\n",
      "testing  :  6651  accuracy =   0.8344  loss =  152.658\n",
      "training :  6652  accuracy =   0.8800  loss =  151.361\n",
      "testing  :  6652  accuracy =   0.8379  loss =  152.657\n",
      "training :  6653  accuracy =   0.8100  loss =  152.361\n",
      "testing  :  6653  accuracy =   0.8407  loss =  152.671\n",
      "training :  6654  accuracy =   0.8400  loss =  153.78\n",
      "testing  :  6654  accuracy =   0.8438  loss =  152.694\n",
      "training :  6655  accuracy =   0.9200  loss =  150.476\n",
      "testing  :  6655  accuracy =   0.8443  loss =  152.727\n",
      "training :  6656  accuracy =   0.8800  loss =  150.656\n",
      "testing  :  6656  accuracy =   0.8464  loss =  152.758\n",
      "training :  6657  accuracy =   0.8500  loss =  150.509\n",
      "testing  :  6657  accuracy =   0.8549  loss =  152.759\n",
      "training :  6658  accuracy =   0.8800  loss =  150.5\n",
      "testing  :  6658  accuracy =   0.8593  loss =  152.758\n",
      "training :  6659  accuracy =   0.8800  loss =  150.726\n",
      "testing  :  6659  accuracy =   0.8616  loss =  152.755\n",
      "training :  6660  accuracy =   0.8700  loss =  152.961\n",
      "testing  :  6660  accuracy =   0.8635  loss =  152.754\n",
      "training :  6661  accuracy =   0.8300  loss =  152.651\n",
      "testing  :  6661  accuracy =   0.8652  loss =  152.751\n",
      "training :  6662  accuracy =   0.8900  loss =  150.19\n",
      "testing  :  6662  accuracy =   0.8659  loss =  152.761\n",
      "training :  6663  accuracy =   0.8800  loss =  150.852\n",
      "testing  :  6663  accuracy =   0.8670  loss =  152.77\n",
      "training :  6664  accuracy =   0.8800  loss =  151.323\n",
      "testing  :  6664  accuracy =   0.8680  loss =  152.742\n",
      "training :  6665  accuracy =   0.9300  loss =  151.475\n",
      "testing  :  6665  accuracy =   0.8692  loss =  152.727\n",
      "training :  6666  accuracy =   0.8800  loss =  152.708\n",
      "testing  :  6666  accuracy =   0.8697  loss =  152.719\n",
      "training :  6667  accuracy =   0.8900  loss =  151.63\n",
      "testing  :  6667  accuracy =   0.8714  loss =  152.704\n",
      "training :  6668  accuracy =   0.8400  loss =  150.603\n",
      "testing  :  6668  accuracy =   0.8727  loss =  152.697\n",
      "training :  6669  accuracy =   0.8900  loss =  150.847\n",
      "testing  :  6669  accuracy =   0.8739  loss =  152.697\n",
      "training :  6670  accuracy =   0.8500  loss =  153.337\n",
      "testing  :  6670  accuracy =   0.8744  loss =  152.707\n",
      "training :  6671  accuracy =   0.8500  loss =  150.77\n",
      "testing  :  6671  accuracy =   0.8749  loss =  152.715\n",
      "training :  6672  accuracy =   0.8300  loss =  152.456\n",
      "testing  :  6672  accuracy =   0.8752  loss =  152.727\n",
      "training :  6673  accuracy =   0.8200  loss =  151.623\n",
      "testing  :  6673  accuracy =   0.8752  loss =  152.737\n",
      "training :  6674  accuracy =   0.8500  loss =  151.875\n",
      "testing  :  6674  accuracy =   0.8751  loss =  152.747\n",
      "training :  6675  accuracy =   0.8900  loss =  153.04\n",
      "testing  :  6675  accuracy =   0.8751  loss =  152.755\n",
      "training :  6676  accuracy =   0.8500  loss =  151.393\n",
      "testing  :  6676  accuracy =   0.8749  loss =  152.751\n",
      "training :  6677  accuracy =   0.9300  loss =  149.777\n",
      "testing  :  6677  accuracy =   0.8743  loss =  152.75\n",
      "training :  6678  accuracy =   0.8800  loss =  152.69\n",
      "testing  :  6678  accuracy =   0.8731  loss =  152.752\n",
      "training :  6679  accuracy =   0.9200  loss =  151.181\n",
      "testing  :  6679  accuracy =   0.8726  loss =  152.751\n",
      "training :  6680  accuracy =   0.8800  loss =  153.481\n",
      "testing  :  6680  accuracy =   0.8723  loss =  152.747\n",
      "training :  6681  accuracy =   0.9000  loss =  151.375\n",
      "testing  :  6681  accuracy =   0.8714  loss =  152.747\n",
      "training :  6682  accuracy =   0.8900  loss =  150.886\n",
      "testing  :  6682  accuracy =   0.8715  loss =  152.753\n",
      "training :  6683  accuracy =   0.9200  loss =  151.476\n",
      "testing  :  6683  accuracy =   0.8714  loss =  152.762\n",
      "training :  6684  accuracy =   0.8500  loss =  152.648\n",
      "testing  :  6684  accuracy =   0.8710  loss =  152.772\n",
      "training :  6685  accuracy =   0.8500  loss =  153.045\n",
      "testing  :  6685  accuracy =   0.8703  loss =  152.787\n",
      "training :  6686  accuracy =   0.9000  loss =  152.185\n",
      "testing  :  6686  accuracy =   0.8695  loss =  152.801\n",
      "training :  6687  accuracy =   0.8900  loss =  149.754\n",
      "testing  :  6687  accuracy =   0.8685  loss =  152.814\n",
      "training :  6688  accuracy =   0.9000  loss =  150.552\n",
      "testing  :  6688  accuracy =   0.8687  loss =  152.829\n",
      "training :  6689  accuracy =   0.8700  loss =  151.332\n",
      "testing  :  6689  accuracy =   0.8685  loss =  152.839\n",
      "training :  6690  accuracy =   0.8900  loss =  150.256\n",
      "testing  :  6690  accuracy =   0.8677  loss =  152.846\n",
      "training :  6691  accuracy =   0.9200  loss =  150.199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6691  accuracy =   0.8672  loss =  152.852\n",
      "training :  6692  accuracy =   0.8900  loss =  151.995\n",
      "testing  :  6692  accuracy =   0.8669  loss =  152.857\n",
      "training :  6693  accuracy =   0.8700  loss =  152.415\n",
      "testing  :  6693  accuracy =   0.8668  loss =  152.861\n",
      "training :  6694  accuracy =   0.8500  loss =  152.883\n",
      "testing  :  6694  accuracy =   0.8668  loss =  152.822\n",
      "training :  6695  accuracy =   0.8800  loss =  152.091\n",
      "testing  :  6695  accuracy =   0.8664  loss =  152.773\n",
      "training :  6696  accuracy =   0.8500  loss =  153.188\n",
      "testing  :  6696  accuracy =   0.8653  loss =  152.763\n",
      "training :  6697  accuracy =   0.8400  loss =  151.341\n",
      "testing  :  6697  accuracy =   0.8636  loss =  152.764\n",
      "training :  6698  accuracy =   0.8400  loss =  152.704\n",
      "testing  :  6698  accuracy =   0.8608  loss =  152.815\n",
      "training :  6699  accuracy =   0.8500  loss =  155.708\n",
      "testing  :  6699  accuracy =   0.8604  loss =  152.884\n",
      "training :  6700  accuracy =   0.8600  loss =  151.698\n",
      "testing  :  6700  accuracy =   0.8601  loss =  152.961\n",
      "training :  6701  accuracy =   0.8400  loss =  152.215\n",
      "testing  :  6701  accuracy =   0.8570  loss =  153.023\n",
      "training :  6702  accuracy =   0.8800  loss =  155.72\n",
      "testing  :  6702  accuracy =   0.8568  loss =  153.079\n",
      "training :  6703  accuracy =   0.9000  loss =  151.182\n",
      "testing  :  6703  accuracy =   0.8561  loss =  153.147\n",
      "training :  6704  accuracy =   0.8300  loss =  154.288\n",
      "testing  :  6704  accuracy =   0.8559  loss =  153.227\n",
      "training :  6705  accuracy =   0.9000  loss =  151.979\n",
      "testing  :  6705  accuracy =   0.8563  loss =  153.278\n",
      "training :  6706  accuracy =   0.8600  loss =  154.035\n",
      "testing  :  6706  accuracy =   0.8571  loss =  153.306\n",
      "training :  6707  accuracy =   0.8200  loss =  152.85\n",
      "testing  :  6707  accuracy =   0.8608  loss =  153.107\n",
      "training :  6708  accuracy =   0.9000  loss =  150.87\n",
      "testing  :  6708  accuracy =   0.8684  loss =  152.849\n",
      "training :  6709  accuracy =   0.9200  loss =  150.457\n",
      "testing  :  6709  accuracy =   0.8716  loss =  152.751\n",
      "training :  6710  accuracy =   0.8700  loss =  153.12\n",
      "testing  :  6710  accuracy =   0.8724  loss =  152.748\n",
      "training :  6711  accuracy =   0.8900  loss =  150.934\n",
      "testing  :  6711  accuracy =   0.8725  loss =  152.814\n",
      "training :  6712  accuracy =   0.8700  loss =  152.171\n",
      "testing  :  6712  accuracy =   0.8718  loss =  152.931\n",
      "training :  6713  accuracy =   0.9300  loss =  150.724\n",
      "testing  :  6713  accuracy =   0.8712  loss =  153.046\n",
      "training :  6714  accuracy =   0.8900  loss =  151.583\n",
      "testing  :  6714  accuracy =   0.8713  loss =  153.14\n",
      "training :  6715  accuracy =   0.9000  loss =  152.036\n",
      "testing  :  6715  accuracy =   0.8708  loss =  153.209\n",
      "training :  6716  accuracy =   0.9000  loss =  153.971\n",
      "testing  :  6716  accuracy =   0.8708  loss =  153.28\n",
      "training :  6717  accuracy =   0.8900  loss =  151.588\n",
      "testing  :  6717  accuracy =   0.8710  loss =  153.325\n",
      "training :  6718  accuracy =   0.8600  loss =  154.073\n",
      "testing  :  6718  accuracy =   0.8712  loss =  153.297\n",
      "training :  6719  accuracy =   0.8200  loss =  153.504\n",
      "testing  :  6719  accuracy =   0.8714  loss =  153.178\n",
      "training :  6720  accuracy =   0.9200  loss =  151.516\n",
      "testing  :  6720  accuracy =   0.8719  loss =  153.074\n",
      "training :  6721  accuracy =   0.8900  loss =  151.632\n",
      "testing  :  6721  accuracy =   0.8726  loss =  152.954\n",
      "training :  6722  accuracy =   0.8800  loss =  153.837\n",
      "testing  :  6722  accuracy =   0.8739  loss =  152.86\n",
      "training :  6723  accuracy =   0.8700  loss =  151.664\n",
      "testing  :  6723  accuracy =   0.8741  loss =  152.797\n",
      "training :  6724  accuracy =   0.8800  loss =  151.544\n",
      "testing  :  6724  accuracy =   0.8745  loss =  152.74\n",
      "training :  6725  accuracy =   0.8800  loss =  151.168\n",
      "testing  :  6725  accuracy =   0.8752  loss =  152.711\n",
      "training :  6726  accuracy =   0.9100  loss =  149.715\n",
      "testing  :  6726  accuracy =   0.8747  loss =  152.707\n",
      "training :  6727  accuracy =   0.9100  loss =  150.128\n",
      "testing  :  6727  accuracy =   0.8745  loss =  152.715\n",
      "training :  6728  accuracy =   0.9200  loss =  151.535\n",
      "testing  :  6728  accuracy =   0.8738  loss =  152.733\n",
      "training :  6729  accuracy =   0.9100  loss =  151.689\n",
      "testing  :  6729  accuracy =   0.8723  loss =  152.769\n",
      "training :  6730  accuracy =   0.8800  loss =  153.158\n",
      "testing  :  6730  accuracy =   0.8710  loss =  152.807\n",
      "training :  6731  accuracy =   0.9000  loss =  151.189\n",
      "testing  :  6731  accuracy =   0.8704  loss =  152.854\n",
      "training :  6732  accuracy =   0.9100  loss =  151.192\n",
      "testing  :  6732  accuracy =   0.8700  loss =  152.917\n",
      "training :  6733  accuracy =   0.9000  loss =  151.849\n",
      "testing  :  6733  accuracy =   0.8694  loss =  152.939\n",
      "training :  6734  accuracy =   0.9100  loss =  151.922\n",
      "testing  :  6734  accuracy =   0.8689  loss =  152.955\n",
      "training :  6735  accuracy =   0.8800  loss =  151.296\n",
      "testing  :  6735  accuracy =   0.8686  loss =  152.962\n",
      "training :  6736  accuracy =   0.8700  loss =  152.918\n",
      "testing  :  6736  accuracy =   0.8682  loss =  152.949\n",
      "training :  6737  accuracy =   0.8700  loss =  150.956\n",
      "testing  :  6737  accuracy =   0.8687  loss =  152.927\n",
      "training :  6738  accuracy =   0.8600  loss =  153.896\n",
      "testing  :  6738  accuracy =   0.8693  loss =  152.907\n",
      "training :  6739  accuracy =   0.9000  loss =  154.621\n",
      "testing  :  6739  accuracy =   0.8719  loss =  152.873\n",
      "training :  6740  accuracy =   0.8500  loss =  152.073\n",
      "testing  :  6740  accuracy =   0.8720  loss =  152.862\n",
      "training :  6741  accuracy =   0.8600  loss =  152.576\n",
      "testing  :  6741  accuracy =   0.8725  loss =  152.844\n",
      "training :  6742  accuracy =   0.9100  loss =  151.624\n",
      "testing  :  6742  accuracy =   0.8729  loss =  152.821\n",
      "training :  6743  accuracy =   0.8600  loss =  150.069\n",
      "testing  :  6743  accuracy =   0.8730  loss =  152.804\n",
      "training :  6744  accuracy =   0.9100  loss =  151.466\n",
      "testing  :  6744  accuracy =   0.8726  loss =  152.813\n",
      "training :  6745  accuracy =   0.8900  loss =  150.713\n",
      "testing  :  6745  accuracy =   0.8713  loss =  152.848\n",
      "training :  6746  accuracy =   0.9100  loss =  150.858\n",
      "testing  :  6746  accuracy =   0.8703  loss =  152.887\n",
      "training :  6747  accuracy =   0.8800  loss =  153.463\n",
      "testing  :  6747  accuracy =   0.8699  loss =  152.92\n",
      "training :  6748  accuracy =   0.8600  loss =  151.561\n",
      "testing  :  6748  accuracy =   0.8688  loss =  152.979\n",
      "training :  6749  accuracy =   0.8900  loss =  150.774\n",
      "testing  :  6749  accuracy =   0.8680  loss =  153.053\n",
      "training :  6750  accuracy =   0.9400  loss =  149.707\n",
      "testing  :  6750  accuracy =   0.8673  loss =  153.115\n",
      "training :  6751  accuracy =   0.8700  loss =  150.875\n",
      "testing  :  6751  accuracy =   0.8665  loss =  153.176\n",
      "training :  6752  accuracy =   0.8100  loss =  154.918\n",
      "testing  :  6752  accuracy =   0.8655  loss =  153.224\n",
      "training :  6753  accuracy =   0.8700  loss =  152.288\n",
      "testing  :  6753  accuracy =   0.8655  loss =  153.212\n",
      "training :  6754  accuracy =   0.9300  loss =  151.931\n",
      "testing  :  6754  accuracy =   0.8659  loss =  153.153\n",
      "training :  6755  accuracy =   0.8800  loss =  152.291\n",
      "testing  :  6755  accuracy =   0.8671  loss =  153.061\n",
      "training :  6756  accuracy =   0.8300  loss =  154.363\n",
      "testing  :  6756  accuracy =   0.8681  loss =  152.994\n",
      "training :  6757  accuracy =   0.9100  loss =  149.785\n",
      "testing  :  6757  accuracy =   0.8690  loss =  152.911\n",
      "training :  6758  accuracy =   0.8400  loss =  151.553\n",
      "testing  :  6758  accuracy =   0.8698  loss =  152.828\n",
      "training :  6759  accuracy =   0.8400  loss =  154.031\n",
      "testing  :  6759  accuracy =   0.8705  loss =  152.761\n",
      "training :  6760  accuracy =   0.8700  loss =  152.324\n",
      "testing  :  6760  accuracy =   0.8719  loss =  152.729\n",
      "training :  6761  accuracy =   0.8800  loss =  153.644\n",
      "testing  :  6761  accuracy =   0.8706  loss =  152.723\n",
      "training :  6762  accuracy =   0.9200  loss =  151.224\n",
      "testing  :  6762  accuracy =   0.8703  loss =  152.736\n",
      "training :  6763  accuracy =   0.8900  loss =  151.628\n",
      "testing  :  6763  accuracy =   0.8694  loss =  152.764\n",
      "training :  6764  accuracy =   0.8800  loss =  153.415\n",
      "testing  :  6764  accuracy =   0.8687  loss =  152.792\n",
      "training :  6765  accuracy =   0.8900  loss =  150.419\n",
      "testing  :  6765  accuracy =   0.8678  loss =  152.811\n",
      "training :  6766  accuracy =   0.8800  loss =  151.648\n",
      "testing  :  6766  accuracy =   0.8671  loss =  152.83\n",
      "training :  6767  accuracy =   0.8700  loss =  151.414\n",
      "testing  :  6767  accuracy =   0.8666  loss =  152.855\n",
      "training :  6768  accuracy =   0.8000  loss =  156.415\n",
      "testing  :  6768  accuracy =   0.8667  loss =  152.871\n",
      "training :  6769  accuracy =   0.8800  loss =  151.737\n",
      "testing  :  6769  accuracy =   0.8658  loss =  152.884\n",
      "training :  6770  accuracy =   0.8800  loss =  150.393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6770  accuracy =   0.8660  loss =  152.889\n",
      "training :  6771  accuracy =   0.9100  loss =  150.316\n",
      "testing  :  6771  accuracy =   0.8650  loss =  152.905\n",
      "training :  6772  accuracy =   0.8500  loss =  151.715\n",
      "testing  :  6772  accuracy =   0.8646  loss =  152.917\n",
      "training :  6773  accuracy =   0.8500  loss =  154.113\n",
      "testing  :  6773  accuracy =   0.8640  loss =  152.929\n",
      "training :  6774  accuracy =   0.9100  loss =  150.908\n",
      "testing  :  6774  accuracy =   0.8665  loss =  152.846\n",
      "training :  6775  accuracy =   0.8900  loss =  151.168\n",
      "testing  :  6775  accuracy =   0.8681  loss =  152.792\n",
      "training :  6776  accuracy =   0.8700  loss =  153.277\n",
      "testing  :  6776  accuracy =   0.8687  loss =  152.763\n",
      "training :  6777  accuracy =   0.8700  loss =  153.74\n",
      "testing  :  6777  accuracy =   0.8690  loss =  152.747\n",
      "training :  6778  accuracy =   0.8700  loss =  152.642\n",
      "testing  :  6778  accuracy =   0.8709  loss =  152.722\n",
      "training :  6779  accuracy =   0.8700  loss =  151.66\n",
      "testing  :  6779  accuracy =   0.8722  loss =  152.724\n",
      "training :  6780  accuracy =   0.8800  loss =  151.675\n",
      "testing  :  6780  accuracy =   0.8743  loss =  152.734\n",
      "training :  6781  accuracy =   0.8800  loss =  152.227\n",
      "testing  :  6781  accuracy =   0.8756  loss =  152.782\n",
      "training :  6782  accuracy =   0.9400  loss =  149.917\n",
      "testing  :  6782  accuracy =   0.8750  loss =  152.861\n",
      "training :  6783  accuracy =   0.8700  loss =  151.612\n",
      "testing  :  6783  accuracy =   0.8760  loss =  152.936\n",
      "training :  6784  accuracy =   0.8600  loss =  152.184\n",
      "testing  :  6784  accuracy =   0.8749  loss =  153.011\n",
      "training :  6785  accuracy =   0.8700  loss =  152.779\n",
      "testing  :  6785  accuracy =   0.8754  loss =  153.082\n",
      "training :  6786  accuracy =   0.8800  loss =  152.225\n",
      "testing  :  6786  accuracy =   0.8763  loss =  153.115\n",
      "training :  6787  accuracy =   0.9200  loss =  150.576\n",
      "testing  :  6787  accuracy =   0.8759  loss =  153.147\n",
      "training :  6788  accuracy =   0.9000  loss =  152.409\n",
      "testing  :  6788  accuracy =   0.8761  loss =  153.185\n",
      "training :  6789  accuracy =   0.8600  loss =  154.733\n",
      "testing  :  6789  accuracy =   0.8749  loss =  153.141\n",
      "training :  6790  accuracy =   0.9200  loss =  152.195\n",
      "testing  :  6790  accuracy =   0.8740  loss =  153.103\n",
      "training :  6791  accuracy =   0.9300  loss =  150.692\n",
      "testing  :  6791  accuracy =   0.8731  loss =  153.071\n",
      "training :  6792  accuracy =   0.9100  loss =  153.434\n",
      "testing  :  6792  accuracy =   0.8729  loss =  153.05\n",
      "training :  6793  accuracy =   0.8700  loss =  150.424\n",
      "testing  :  6793  accuracy =   0.8717  loss =  153.026\n",
      "training :  6794  accuracy =   0.8800  loss =  150.594\n",
      "testing  :  6794  accuracy =   0.8706  loss =  153.021\n",
      "training :  6795  accuracy =   0.9400  loss =  150.541\n",
      "testing  :  6795  accuracy =   0.8706  loss =  153.024\n",
      "training :  6796  accuracy =   0.8600  loss =  150.684\n",
      "testing  :  6796  accuracy =   0.8685  loss =  153.066\n",
      "training :  6797  accuracy =   0.8500  loss =  150.006\n",
      "testing  :  6797  accuracy =   0.8665  loss =  153.141\n",
      "training :  6798  accuracy =   0.9000  loss =  151.093\n",
      "testing  :  6798  accuracy =   0.8647  loss =  153.159\n",
      "training :  6799  accuracy =   0.8800  loss =  151.233\n",
      "testing  :  6799  accuracy =   0.8635  loss =  153.178\n",
      "training :  6800  accuracy =   0.9000  loss =  151.089\n",
      "testing  :  6800  accuracy =   0.8627  loss =  153.176\n",
      "training :  6801  accuracy =   0.9000  loss =  153.376\n",
      "testing  :  6801  accuracy =   0.8649  loss =  153.039\n",
      "training :  6802  accuracy =   0.8500  loss =  152.866\n",
      "testing  :  6802  accuracy =   0.8666  loss =  152.958\n",
      "training :  6803  accuracy =   0.8600  loss =  150.873\n",
      "testing  :  6803  accuracy =   0.8665  loss =  152.922\n",
      "training :  6804  accuracy =   0.8600  loss =  150.253\n",
      "testing  :  6804  accuracy =   0.8673  loss =  152.888\n",
      "training :  6805  accuracy =   0.9100  loss =  151.804\n",
      "testing  :  6805  accuracy =   0.8666  loss =  152.864\n",
      "training :  6806  accuracy =   0.9300  loss =  152.057\n",
      "testing  :  6806  accuracy =   0.8664  loss =  152.857\n",
      "training :  6807  accuracy =   0.9000  loss =  152.422\n",
      "testing  :  6807  accuracy =   0.8657  loss =  152.867\n",
      "training :  6808  accuracy =   0.9200  loss =  150.063\n",
      "testing  :  6808  accuracy =   0.8660  loss =  152.871\n",
      "training :  6809  accuracy =   0.9200  loss =  151.059\n",
      "testing  :  6809  accuracy =   0.8664  loss =  152.875\n",
      "training :  6810  accuracy =   0.9200  loss =  149.354\n",
      "testing  :  6810  accuracy =   0.8662  loss =  152.879\n",
      "training :  6811  accuracy =   0.8500  loss =  151.769\n",
      "testing  :  6811  accuracy =   0.8650  loss =  152.892\n",
      "training :  6812  accuracy =   0.8600  loss =  151.584\n",
      "testing  :  6812  accuracy =   0.8640  loss =  152.908\n",
      "training :  6813  accuracy =   0.9400  loss =  151.532\n",
      "testing  :  6813  accuracy =   0.8636  loss =  152.912\n",
      "training :  6814  accuracy =   0.8300  loss =  150.481\n",
      "testing  :  6814  accuracy =   0.8631  loss =  152.928\n",
      "training :  6815  accuracy =   0.8900  loss =  151.811\n",
      "testing  :  6815  accuracy =   0.8636  loss =  152.94\n",
      "training :  6816  accuracy =   0.8900  loss =  150.917\n",
      "testing  :  6816  accuracy =   0.8635  loss =  152.949\n",
      "training :  6817  accuracy =   0.8500  loss =  151.068\n",
      "testing  :  6817  accuracy =   0.8641  loss =  152.941\n",
      "training :  6818  accuracy =   0.8100  loss =  154.324\n",
      "testing  :  6818  accuracy =   0.8650  loss =  152.926\n",
      "training :  6819  accuracy =   0.9400  loss =  149.028\n",
      "testing  :  6819  accuracy =   0.8648  loss =  152.928\n",
      "training :  6820  accuracy =   0.9000  loss =  150.22\n",
      "testing  :  6820  accuracy =   0.8644  loss =  152.923\n",
      "training :  6821  accuracy =   0.8700  loss =  150.49\n",
      "testing  :  6821  accuracy =   0.8647  loss =  152.913\n",
      "training :  6822  accuracy =   0.9100  loss =  151.635\n",
      "testing  :  6822  accuracy =   0.8654  loss =  152.9\n",
      "training :  6823  accuracy =   0.8700  loss =  151.054\n",
      "testing  :  6823  accuracy =   0.8654  loss =  152.89\n",
      "training :  6824  accuracy =   0.9100  loss =  150.094\n",
      "testing  :  6824  accuracy =   0.8653  loss =  152.888\n",
      "training :  6825  accuracy =   0.9200  loss =  150.526\n",
      "testing  :  6825  accuracy =   0.8646  loss =  152.888\n",
      "training :  6826  accuracy =   0.9000  loss =  150.412\n",
      "testing  :  6826  accuracy =   0.8644  loss =  152.897\n",
      "training :  6827  accuracy =   0.8100  loss =  155.664\n",
      "testing  :  6827  accuracy =   0.8640  loss =  152.902\n",
      "training :  6828  accuracy =   0.9400  loss =  150.549\n",
      "testing  :  6828  accuracy =   0.8639  loss =  152.884\n",
      "training :  6829  accuracy =   0.8300  loss =  156.625\n",
      "testing  :  6829  accuracy =   0.8639  loss =  152.874\n",
      "training :  6830  accuracy =   0.9200  loss =  150.049\n",
      "testing  :  6830  accuracy =   0.8636  loss =  152.874\n",
      "training :  6831  accuracy =   0.9000  loss =  151.775\n",
      "testing  :  6831  accuracy =   0.8636  loss =  152.873\n",
      "training :  6832  accuracy =   0.8700  loss =  152.404\n",
      "testing  :  6832  accuracy =   0.8651  loss =  152.85\n",
      "training :  6833  accuracy =   0.8900  loss =  151.97\n",
      "testing  :  6833  accuracy =   0.8664  loss =  152.839\n",
      "training :  6834  accuracy =   0.8500  loss =  150.603\n",
      "testing  :  6834  accuracy =   0.8666  loss =  152.824\n",
      "training :  6835  accuracy =   0.8300  loss =  151.231\n",
      "testing  :  6835  accuracy =   0.8680  loss =  152.805\n",
      "training :  6836  accuracy =   0.8600  loss =  152.557\n",
      "testing  :  6836  accuracy =   0.8687  loss =  152.781\n",
      "training :  6837  accuracy =   0.8900  loss =  150.848\n",
      "testing  :  6837  accuracy =   0.8691  loss =  152.746\n",
      "training :  6838  accuracy =   0.9000  loss =  149.538\n",
      "testing  :  6838  accuracy =   0.8698  loss =  152.726\n",
      "training :  6839  accuracy =   0.8600  loss =  151.046\n",
      "testing  :  6839  accuracy =   0.8705  loss =  152.702\n",
      "training :  6840  accuracy =   0.8600  loss =  151.549\n",
      "testing  :  6840  accuracy =   0.8712  loss =  152.691\n",
      "training :  6841  accuracy =   0.9100  loss =  152.384\n",
      "testing  :  6841  accuracy =   0.8715  loss =  152.689\n",
      "training :  6842  accuracy =   0.8600  loss =  151.288\n",
      "testing  :  6842  accuracy =   0.8724  loss =  152.693\n",
      "training :  6843  accuracy =   0.9300  loss =  149.92\n",
      "testing  :  6843  accuracy =   0.8726  loss =  152.708\n",
      "training :  6844  accuracy =   0.8900  loss =  150.829\n",
      "testing  :  6844  accuracy =   0.8711  loss =  152.737\n",
      "training :  6845  accuracy =   0.9200  loss =  150.655\n",
      "testing  :  6845  accuracy =   0.8694  loss =  152.795\n",
      "training :  6846  accuracy =   0.8900  loss =  152.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6846  accuracy =   0.8668  loss =  152.842\n",
      "training :  6847  accuracy =   0.9300  loss =  149.293\n",
      "testing  :  6847  accuracy =   0.8651  loss =  152.888\n",
      "training :  6848  accuracy =   0.9100  loss =  149.478\n",
      "testing  :  6848  accuracy =   0.8629  loss =  152.933\n",
      "training :  6849  accuracy =   0.8500  loss =  151.629\n",
      "testing  :  6849  accuracy =   0.8634  loss =  152.941\n",
      "training :  6850  accuracy =   0.8700  loss =  152.14\n",
      "testing  :  6850  accuracy =   0.8637  loss =  152.959\n",
      "training :  6851  accuracy =   0.9200  loss =  151.64\n",
      "testing  :  6851  accuracy =   0.8651  loss =  152.944\n",
      "training :  6852  accuracy =   0.8800  loss =  151.387\n",
      "testing  :  6852  accuracy =   0.8655  loss =  152.922\n",
      "training :  6853  accuracy =   0.8700  loss =  151.893\n",
      "testing  :  6853  accuracy =   0.8655  loss =  152.921\n",
      "training :  6854  accuracy =   0.8800  loss =  150.211\n",
      "testing  :  6854  accuracy =   0.8670  loss =  152.884\n",
      "training :  6855  accuracy =   0.8700  loss =  150.416\n",
      "testing  :  6855  accuracy =   0.8680  loss =  152.843\n",
      "training :  6856  accuracy =   0.9200  loss =  149.724\n",
      "testing  :  6856  accuracy =   0.8686  loss =  152.814\n",
      "training :  6857  accuracy =   0.8900  loss =  152.404\n",
      "testing  :  6857  accuracy =   0.8700  loss =  152.797\n",
      "training :  6858  accuracy =   0.8800  loss =  151.98\n",
      "testing  :  6858  accuracy =   0.8710  loss =  152.776\n",
      "training :  6859  accuracy =   0.9500  loss =  149.702\n",
      "testing  :  6859  accuracy =   0.8712  loss =  152.746\n",
      "training :  6860  accuracy =   0.8600  loss =  151.961\n",
      "testing  :  6860  accuracy =   0.8719  loss =  152.716\n",
      "training :  6861  accuracy =   0.8400  loss =  153.259\n",
      "testing  :  6861  accuracy =   0.8727  loss =  152.692\n",
      "training :  6862  accuracy =   0.8900  loss =  151.54\n",
      "testing  :  6862  accuracy =   0.8729  loss =  152.679\n",
      "training :  6863  accuracy =   0.8900  loss =  150.872\n",
      "testing  :  6863  accuracy =   0.8736  loss =  152.668\n",
      "training :  6864  accuracy =   0.8600  loss =  151.001\n",
      "testing  :  6864  accuracy =   0.8736  loss =  152.661\n",
      "training :  6865  accuracy =   0.9100  loss =  150.227\n",
      "testing  :  6865  accuracy =   0.8739  loss =  152.654\n",
      "training :  6866  accuracy =   0.9000  loss =  149.987\n",
      "testing  :  6866  accuracy =   0.8744  loss =  152.657\n",
      "training :  6867  accuracy =   0.8600  loss =  151.859\n",
      "testing  :  6867  accuracy =   0.8754  loss =  152.668\n",
      "training :  6868  accuracy =   0.9400  loss =  150.439\n",
      "testing  :  6868  accuracy =   0.8758  loss =  152.643\n",
      "training :  6869  accuracy =   0.8400  loss =  151.464\n",
      "testing  :  6869  accuracy =   0.8761  loss =  152.658\n",
      "training :  6870  accuracy =   0.9300  loss =  150.125\n",
      "testing  :  6870  accuracy =   0.8762  loss =  152.747\n",
      "training :  6871  accuracy =   0.9100  loss =  149.492\n",
      "testing  :  6871  accuracy =   0.8760  loss =  152.853\n",
      "training :  6872  accuracy =   0.9400  loss =  149.747\n",
      "testing  :  6872  accuracy =   0.8745  loss =  152.985\n",
      "training :  6873  accuracy =   0.9100  loss =  152.003\n",
      "testing  :  6873  accuracy =   0.8730  loss =  153.097\n",
      "training :  6874  accuracy =   0.9300  loss =  151.259\n",
      "testing  :  6874  accuracy =   0.8716  loss =  153.236\n",
      "training :  6875  accuracy =   0.8600  loss =  153.596\n",
      "testing  :  6875  accuracy =   0.8692  loss =  153.364\n",
      "training :  6876  accuracy =   0.8600  loss =  152.025\n",
      "testing  :  6876  accuracy =   0.8672  loss =  153.472\n",
      "training :  6877  accuracy =   0.9300  loss =  148.948\n",
      "testing  :  6877  accuracy =   0.8665  loss =  153.568\n",
      "training :  6878  accuracy =   0.8600  loss =  151.185\n",
      "testing  :  6878  accuracy =   0.8652  loss =  153.637\n",
      "training :  6879  accuracy =   0.8700  loss =  154.45\n",
      "testing  :  6879  accuracy =   0.8657  loss =  153.616\n",
      "training :  6880  accuracy =   0.8900  loss =  152.351\n",
      "testing  :  6880  accuracy =   0.8675  loss =  153.592\n",
      "training :  6881  accuracy =   0.8600  loss =  150.99\n",
      "testing  :  6881  accuracy =   0.8689  loss =  153.554\n",
      "training :  6882  accuracy =   0.9200  loss =  152.235\n",
      "testing  :  6882  accuracy =   0.8705  loss =  153.487\n",
      "training :  6883  accuracy =   0.9200  loss =  151.122\n",
      "testing  :  6883  accuracy =   0.8730  loss =  153.329\n",
      "training :  6884  accuracy =   0.8500  loss =  152.665\n",
      "testing  :  6884  accuracy =   0.8753  loss =  153.177\n",
      "training :  6885  accuracy =   0.8800  loss =  150.909\n",
      "testing  :  6885  accuracy =   0.8765  loss =  153.037\n",
      "training :  6886  accuracy =   0.8500  loss =  153.534\n",
      "testing  :  6886  accuracy =   0.8779  loss =  152.901\n",
      "training :  6887  accuracy =   0.8700  loss =  152.917\n",
      "testing  :  6887  accuracy =   0.8790  loss =  152.781\n",
      "training :  6888  accuracy =   0.8500  loss =  151.578\n",
      "testing  :  6888  accuracy =   0.8792  loss =  152.685\n",
      "training :  6889  accuracy =   0.9600  loss =  150.838\n",
      "testing  :  6889  accuracy =   0.8795  loss =  152.635\n",
      "training :  6890  accuracy =   0.8400  loss =  152.228\n",
      "testing  :  6890  accuracy =   0.8793  loss =  152.594\n",
      "training :  6891  accuracy =   0.8900  loss =  151.213\n",
      "testing  :  6891  accuracy =   0.8792  loss =  152.579\n",
      "training :  6892  accuracy =   0.9000  loss =  152.681\n",
      "testing  :  6892  accuracy =   0.8788  loss =  152.57\n",
      "training :  6893  accuracy =   0.8800  loss =  150.252\n",
      "testing  :  6893  accuracy =   0.8786  loss =  152.548\n",
      "training :  6894  accuracy =   0.9100  loss =  150.893\n",
      "testing  :  6894  accuracy =   0.8784  loss =  152.537\n",
      "training :  6895  accuracy =   0.8400  loss =  151.778\n",
      "testing  :  6895  accuracy =   0.8774  loss =  152.529\n",
      "training :  6896  accuracy =   0.8800  loss =  150.909\n",
      "testing  :  6896  accuracy =   0.8776  loss =  152.527\n",
      "training :  6897  accuracy =   0.8500  loss =  151.771\n",
      "testing  :  6897  accuracy =   0.8775  loss =  152.528\n",
      "training :  6898  accuracy =   0.8500  loss =  152.498\n",
      "testing  :  6898  accuracy =   0.8770  loss =  152.532\n",
      "training :  6899  accuracy =   0.9100  loss =  149.843\n",
      "testing  :  6899  accuracy =   0.8765  loss =  152.547\n",
      "training :  6900  accuracy =   0.9000  loss =  150.121\n",
      "testing  :  6900  accuracy =   0.8744  loss =  152.56\n",
      "training :  6901  accuracy =   0.8900  loss =  150.647\n",
      "testing  :  6901  accuracy =   0.8736  loss =  152.574\n",
      "training :  6902  accuracy =   0.8900  loss =  149.96\n",
      "testing  :  6902  accuracy =   0.8733  loss =  152.594\n",
      "training :  6903  accuracy =   0.8700  loss =  150.949\n",
      "testing  :  6903  accuracy =   0.8727  loss =  152.616\n",
      "training :  6904  accuracy =   0.8500  loss =  152.084\n",
      "testing  :  6904  accuracy =   0.8728  loss =  152.629\n",
      "training :  6905  accuracy =   0.8500  loss =  150.532\n",
      "testing  :  6905  accuracy =   0.8717  loss =  152.646\n",
      "training :  6906  accuracy =   0.8800  loss =  153.692\n",
      "testing  :  6906  accuracy =   0.8717  loss =  152.678\n",
      "training :  6907  accuracy =   0.9200  loss =  151.15\n",
      "testing  :  6907  accuracy =   0.8717  loss =  152.698\n",
      "training :  6908  accuracy =   0.8900  loss =  151.476\n",
      "testing  :  6908  accuracy =   0.8719  loss =  152.71\n",
      "training :  6909  accuracy =   0.8800  loss =  153.258\n",
      "testing  :  6909  accuracy =   0.8722  loss =  152.725\n",
      "training :  6910  accuracy =   0.8400  loss =  153.772\n",
      "testing  :  6910  accuracy =   0.8723  loss =  152.737\n",
      "training :  6911  accuracy =   0.8200  loss =  153.508\n",
      "testing  :  6911  accuracy =   0.8722  loss =  152.745\n",
      "training :  6912  accuracy =   0.9400  loss =  150.85\n",
      "testing  :  6912  accuracy =   0.8729  loss =  152.729\n",
      "training :  6913  accuracy =   0.9200  loss =  150.087\n",
      "testing  :  6913  accuracy =   0.8728  loss =  152.724\n",
      "training :  6914  accuracy =   0.9200  loss =  150.944\n",
      "testing  :  6914  accuracy =   0.8725  loss =  152.708\n",
      "training :  6915  accuracy =   0.8600  loss =  152.966\n",
      "testing  :  6915  accuracy =   0.8727  loss =  152.692\n",
      "training :  6916  accuracy =   0.8600  loss =  151.316\n",
      "testing  :  6916  accuracy =   0.8727  loss =  152.677\n",
      "training :  6917  accuracy =   0.9100  loss =  151.923\n",
      "testing  :  6917  accuracy =   0.8732  loss =  152.666\n",
      "training :  6918  accuracy =   0.8900  loss =  152.818\n",
      "testing  :  6918  accuracy =   0.8731  loss =  152.667\n",
      "training :  6919  accuracy =   0.8600  loss =  152.721\n",
      "testing  :  6919  accuracy =   0.8732  loss =  152.674\n",
      "training :  6920  accuracy =   0.8800  loss =  150.799\n",
      "testing  :  6920  accuracy =   0.8728  loss =  152.679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  6921  accuracy =   0.8900  loss =  150.236\n",
      "testing  :  6921  accuracy =   0.8724  loss =  152.683\n",
      "training :  6922  accuracy =   0.9200  loss =  149.055\n",
      "testing  :  6922  accuracy =   0.8720  loss =  152.688\n",
      "training :  6923  accuracy =   0.8800  loss =  151.359\n",
      "testing  :  6923  accuracy =   0.8718  loss =  152.693\n",
      "training :  6924  accuracy =   0.8800  loss =  151.986\n",
      "testing  :  6924  accuracy =   0.8715  loss =  152.698\n",
      "training :  6925  accuracy =   0.9200  loss =  151.532\n",
      "testing  :  6925  accuracy =   0.8705  loss =  152.699\n",
      "training :  6926  accuracy =   0.8900  loss =  151.236\n",
      "testing  :  6926  accuracy =   0.8704  loss =  152.699\n",
      "training :  6927  accuracy =   0.9200  loss =  151.203\n",
      "testing  :  6927  accuracy =   0.8702  loss =  152.691\n",
      "training :  6928  accuracy =   0.8600  loss =  150.732\n",
      "testing  :  6928  accuracy =   0.8705  loss =  152.693\n",
      "training :  6929  accuracy =   0.8800  loss =  151.672\n",
      "testing  :  6929  accuracy =   0.8707  loss =  152.689\n",
      "training :  6930  accuracy =   0.8900  loss =  150.681\n",
      "testing  :  6930  accuracy =   0.8710  loss =  152.689\n",
      "training :  6931  accuracy =   0.9000  loss =  150.395\n",
      "testing  :  6931  accuracy =   0.8711  loss =  152.705\n",
      "training :  6932  accuracy =   0.8700  loss =  150.903\n",
      "testing  :  6932  accuracy =   0.8707  loss =  152.74\n",
      "training :  6933  accuracy =   0.9000  loss =  151.898\n",
      "testing  :  6933  accuracy =   0.8705  loss =  152.749\n",
      "training :  6934  accuracy =   0.8900  loss =  152.455\n",
      "testing  :  6934  accuracy =   0.8690  loss =  152.762\n",
      "training :  6935  accuracy =   0.9200  loss =  151.011\n",
      "testing  :  6935  accuracy =   0.8690  loss =  152.783\n",
      "training :  6936  accuracy =   0.8400  loss =  154.443\n",
      "testing  :  6936  accuracy =   0.8690  loss =  152.797\n",
      "training :  6937  accuracy =   0.8200  loss =  152.775\n",
      "testing  :  6937  accuracy =   0.8693  loss =  152.793\n",
      "training :  6938  accuracy =   0.9200  loss =  150.669\n",
      "testing  :  6938  accuracy =   0.8713  loss =  152.709\n",
      "training :  6939  accuracy =   0.9200  loss =  149.503\n",
      "testing  :  6939  accuracy =   0.8720  loss =  152.637\n",
      "training :  6940  accuracy =   0.8800  loss =  152.986\n",
      "testing  :  6940  accuracy =   0.8738  loss =  152.579\n",
      "training :  6941  accuracy =   0.8900  loss =  150.598\n",
      "testing  :  6941  accuracy =   0.8747  loss =  152.542\n",
      "training :  6942  accuracy =   0.9100  loss =  151.997\n",
      "testing  :  6942  accuracy =   0.8749  loss =  152.531\n",
      "training :  6943  accuracy =   0.9100  loss =  151.948\n",
      "testing  :  6943  accuracy =   0.8760  loss =  152.531\n",
      "training :  6944  accuracy =   0.8900  loss =  150.792\n",
      "testing  :  6944  accuracy =   0.8770  loss =  152.542\n",
      "training :  6945  accuracy =   0.8800  loss =  150.794\n",
      "testing  :  6945  accuracy =   0.8775  loss =  152.558\n",
      "training :  6946  accuracy =   0.8900  loss =  151.197\n",
      "testing  :  6946  accuracy =   0.8774  loss =  152.578\n",
      "training :  6947  accuracy =   0.8900  loss =  150.268\n",
      "testing  :  6947  accuracy =   0.8776  loss =  152.602\n",
      "training :  6948  accuracy =   0.8500  loss =  153.255\n",
      "testing  :  6948  accuracy =   0.8780  loss =  152.626\n",
      "training :  6949  accuracy =   0.8600  loss =  151.636\n",
      "testing  :  6949  accuracy =   0.8784  loss =  152.646\n",
      "training :  6950  accuracy =   0.8900  loss =  151.461\n",
      "testing  :  6950  accuracy =   0.8785  loss =  152.657\n",
      "training :  6951  accuracy =   0.8700  loss =  151.4\n",
      "testing  :  6951  accuracy =   0.8787  loss =  152.663\n",
      "training :  6952  accuracy =   0.9200  loss =  150.535\n",
      "testing  :  6952  accuracy =   0.8781  loss =  152.667\n",
      "training :  6953  accuracy =   0.8900  loss =  151.651\n",
      "testing  :  6953  accuracy =   0.8784  loss =  152.678\n",
      "training :  6954  accuracy =   0.8700  loss =  151.91\n",
      "testing  :  6954  accuracy =   0.8781  loss =  152.686\n",
      "training :  6955  accuracy =   0.9000  loss =  151.804\n",
      "testing  :  6955  accuracy =   0.8779  loss =  152.676\n",
      "training :  6956  accuracy =   0.8500  loss =  152.1\n",
      "testing  :  6956  accuracy =   0.8776  loss =  152.668\n",
      "training :  6957  accuracy =   0.8400  loss =  151.076\n",
      "testing  :  6957  accuracy =   0.8768  loss =  152.644\n",
      "training :  6958  accuracy =   0.8800  loss =  150.746\n",
      "testing  :  6958  accuracy =   0.8762  loss =  152.62\n",
      "training :  6959  accuracy =   0.8700  loss =  151.204\n",
      "testing  :  6959  accuracy =   0.8752  loss =  152.608\n",
      "training :  6960  accuracy =   0.9100  loss =  150.435\n",
      "testing  :  6960  accuracy =   0.8726  loss =  152.596\n",
      "training :  6961  accuracy =   0.8400  loss =  150.252\n",
      "testing  :  6961  accuracy =   0.8714  loss =  152.643\n",
      "training :  6962  accuracy =   0.9000  loss =  151.245\n",
      "testing  :  6962  accuracy =   0.8697  loss =  152.73\n",
      "training :  6963  accuracy =   0.9000  loss =  151.413\n",
      "testing  :  6963  accuracy =   0.8682  loss =  152.838\n",
      "training :  6964  accuracy =   0.8500  loss =  151.802\n",
      "testing  :  6964  accuracy =   0.8654  loss =  152.961\n",
      "training :  6965  accuracy =   0.8700  loss =  151.679\n",
      "testing  :  6965  accuracy =   0.8629  loss =  153.09\n",
      "training :  6966  accuracy =   0.8000  loss =  154.71\n",
      "testing  :  6966  accuracy =   0.8618  loss =  153.191\n",
      "training :  6967  accuracy =   0.9000  loss =  150.951\n",
      "testing  :  6967  accuracy =   0.8607  loss =  153.261\n",
      "training :  6968  accuracy =   0.9100  loss =  151.092\n",
      "testing  :  6968  accuracy =   0.8616  loss =  153.21\n",
      "training :  6969  accuracy =   0.9200  loss =  150.12\n",
      "testing  :  6969  accuracy =   0.8625  loss =  153.171\n",
      "training :  6970  accuracy =   0.9200  loss =  151.435\n",
      "testing  :  6970  accuracy =   0.8648  loss =  153.029\n",
      "training :  6971  accuracy =   0.9200  loss =  150.409\n",
      "testing  :  6971  accuracy =   0.8652  loss =  152.914\n",
      "training :  6972  accuracy =   0.8600  loss =  151.931\n",
      "testing  :  6972  accuracy =   0.8675  loss =  152.832\n",
      "training :  6973  accuracy =   0.8900  loss =  151.159\n",
      "testing  :  6973  accuracy =   0.8702  loss =  152.783\n",
      "training :  6974  accuracy =   0.8400  loss =  155.507\n",
      "testing  :  6974  accuracy =   0.8702  loss =  152.766\n",
      "training :  6975  accuracy =   0.8800  loss =  150.144\n",
      "testing  :  6975  accuracy =   0.8715  loss =  152.76\n",
      "training :  6976  accuracy =   0.9100  loss =  151.269\n",
      "testing  :  6976  accuracy =   0.8718  loss =  152.776\n",
      "training :  6977  accuracy =   0.9200  loss =  150.382\n",
      "testing  :  6977  accuracy =   0.8725  loss =  152.808\n",
      "training :  6978  accuracy =   0.8800  loss =  150.94\n",
      "testing  :  6978  accuracy =   0.8731  loss =  152.839\n",
      "training :  6979  accuracy =   0.8900  loss =  152.184\n",
      "testing  :  6979  accuracy =   0.8731  loss =  152.86\n",
      "training :  6980  accuracy =   0.8900  loss =  152.128\n",
      "testing  :  6980  accuracy =   0.8729  loss =  152.886\n",
      "training :  6981  accuracy =   0.8800  loss =  153.383\n",
      "testing  :  6981  accuracy =   0.8730  loss =  152.9\n",
      "training :  6982  accuracy =   0.9000  loss =  151.936\n",
      "testing  :  6982  accuracy =   0.8747  loss =  152.838\n",
      "training :  6983  accuracy =   0.8900  loss =  149.771\n",
      "testing  :  6983  accuracy =   0.8759  loss =  152.822\n",
      "training :  6984  accuracy =   0.9100  loss =  151.321\n",
      "testing  :  6984  accuracy =   0.8762  loss =  152.836\n",
      "training :  6985  accuracy =   0.8900  loss =  151.23\n",
      "testing  :  6985  accuracy =   0.8760  loss =  152.929\n",
      "training :  6986  accuracy =   0.8400  loss =  153.459\n",
      "testing  :  6986  accuracy =   0.8753  loss =  153.028\n",
      "training :  6987  accuracy =   0.8800  loss =  154.694\n",
      "testing  :  6987  accuracy =   0.8747  loss =  153.142\n",
      "training :  6988  accuracy =   0.9400  loss =  150.58\n",
      "testing  :  6988  accuracy =   0.8732  loss =  153.25\n",
      "training :  6989  accuracy =   0.9100  loss =  150.789\n",
      "testing  :  6989  accuracy =   0.8715  loss =  153.283\n",
      "training :  6990  accuracy =   0.9000  loss =  150.153\n",
      "testing  :  6990  accuracy =   0.8694  loss =  153.334\n",
      "training :  6991  accuracy =   0.8500  loss =  152.703\n",
      "testing  :  6991  accuracy =   0.8688  loss =  153.39\n",
      "training :  6992  accuracy =   0.8400  loss =  152.871\n",
      "testing  :  6992  accuracy =   0.8656  loss =  153.476\n",
      "training :  6993  accuracy =   0.8400  loss =  153.021\n",
      "testing  :  6993  accuracy =   0.8668  loss =  153.436\n",
      "training :  6994  accuracy =   0.8600  loss =  151.592\n",
      "testing  :  6994  accuracy =   0.8663  loss =  153.266\n",
      "training :  6995  accuracy =   0.8500  loss =  154.224\n",
      "testing  :  6995  accuracy =   0.8674  loss =  153.089\n",
      "training :  6996  accuracy =   0.8800  loss =  152.533\n",
      "testing  :  6996  accuracy =   0.8675  loss =  152.968\n",
      "training :  6997  accuracy =   0.8400  loss =  152.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  6997  accuracy =   0.8671  loss =  152.888\n",
      "training :  6998  accuracy =   0.8900  loss =  151.02\n",
      "testing  :  6998  accuracy =   0.8676  loss =  152.824\n",
      "training :  6999  accuracy =   0.9000  loss =  153.25\n",
      "testing  :  6999  accuracy =   0.8692  loss =  152.737\n",
      "training :  7000  accuracy =   0.9000  loss =  151.009\n",
      "testing  :  7000  accuracy =   0.8714  loss =  152.682\n",
      "training :  7001  accuracy =   0.9300  loss =  150.7\n",
      "testing  :  7001  accuracy =   0.8719  loss =  152.644\n",
      "training :  7002  accuracy =   0.9200  loss =  149.715\n",
      "testing  :  7002  accuracy =   0.8720  loss =  152.642\n",
      "training :  7003  accuracy =   0.9100  loss =  150.253\n",
      "testing  :  7003  accuracy =   0.8729  loss =  152.658\n",
      "training :  7004  accuracy =   0.8700  loss =  153.537\n",
      "testing  :  7004  accuracy =   0.8728  loss =  152.678\n",
      "training :  7005  accuracy =   0.9700  loss =  149.853\n",
      "testing  :  7005  accuracy =   0.8724  loss =  152.696\n",
      "training :  7006  accuracy =   0.9100  loss =  151.417\n",
      "testing  :  7006  accuracy =   0.8720  loss =  152.718\n",
      "training :  7007  accuracy =   0.8500  loss =  153.794\n",
      "testing  :  7007  accuracy =   0.8709  loss =  152.745\n",
      "training :  7008  accuracy =   0.8900  loss =  150.744\n",
      "testing  :  7008  accuracy =   0.8699  loss =  152.766\n",
      "training :  7009  accuracy =   0.8800  loss =  150.911\n",
      "testing  :  7009  accuracy =   0.8690  loss =  152.786\n",
      "training :  7010  accuracy =   0.9200  loss =  151.789\n",
      "testing  :  7010  accuracy =   0.8681  loss =  152.789\n",
      "training :  7011  accuracy =   0.8800  loss =  150.619\n",
      "testing  :  7011  accuracy =   0.8671  loss =  152.79\n",
      "training :  7012  accuracy =   0.8300  loss =  152.423\n",
      "testing  :  7012  accuracy =   0.8668  loss =  152.807\n",
      "training :  7013  accuracy =   0.9600  loss =  150.393\n",
      "testing  :  7013  accuracy =   0.8667  loss =  152.843\n",
      "training :  7014  accuracy =   0.9100  loss =  150.271\n",
      "testing  :  7014  accuracy =   0.8664  loss =  152.887\n",
      "training :  7015  accuracy =   0.8900  loss =  153.058\n",
      "testing  :  7015  accuracy =   0.8664  loss =  152.921\n",
      "training :  7016  accuracy =   0.9400  loss =  151.476\n",
      "testing  :  7016  accuracy =   0.8660  loss =  152.948\n",
      "training :  7017  accuracy =   0.8600  loss =  150.996\n",
      "testing  :  7017  accuracy =   0.8655  loss =  152.97\n",
      "training :  7018  accuracy =   0.8800  loss =  152.285\n",
      "testing  :  7018  accuracy =   0.8651  loss =  152.949\n",
      "training :  7019  accuracy =   0.8900  loss =  150.501\n",
      "testing  :  7019  accuracy =   0.8653  loss =  152.93\n",
      "training :  7020  accuracy =   0.8700  loss =  153.445\n",
      "testing  :  7020  accuracy =   0.8659  loss =  152.895\n",
      "training :  7021  accuracy =   0.8400  loss =  152.552\n",
      "testing  :  7021  accuracy =   0.8667  loss =  152.82\n",
      "training :  7022  accuracy =   0.9500  loss =  150.318\n",
      "testing  :  7022  accuracy =   0.8690  loss =  152.754\n",
      "training :  7023  accuracy =   0.8900  loss =  150.933\n",
      "testing  :  7023  accuracy =   0.8689  loss =  152.712\n",
      "training :  7024  accuracy =   0.8800  loss =  150.088\n",
      "testing  :  7024  accuracy =   0.8697  loss =  152.681\n",
      "training :  7025  accuracy =   0.9100  loss =  152.183\n",
      "testing  :  7025  accuracy =   0.8700  loss =  152.642\n",
      "training :  7026  accuracy =   0.8900  loss =  151.845\n",
      "testing  :  7026  accuracy =   0.8712  loss =  152.662\n",
      "training :  7027  accuracy =   0.8900  loss =  151.268\n",
      "testing  :  7027  accuracy =   0.8719  loss =  152.716\n",
      "training :  7028  accuracy =   0.8700  loss =  154.885\n",
      "testing  :  7028  accuracy =   0.8717  loss =  152.779\n",
      "training :  7029  accuracy =   0.8800  loss =  151.21\n",
      "testing  :  7029  accuracy =   0.8723  loss =  152.803\n",
      "training :  7030  accuracy =   0.9100  loss =  150.109\n",
      "testing  :  7030  accuracy =   0.8723  loss =  152.844\n",
      "training :  7031  accuracy =   0.8300  loss =  152.917\n",
      "testing  :  7031  accuracy =   0.8736  loss =  152.866\n",
      "training :  7032  accuracy =   0.8500  loss =  152.782\n",
      "testing  :  7032  accuracy =   0.8726  loss =  152.906\n",
      "training :  7033  accuracy =   0.9000  loss =  151.136\n",
      "testing  :  7033  accuracy =   0.8733  loss =  152.931\n",
      "training :  7034  accuracy =   0.9000  loss =  151.196\n",
      "testing  :  7034  accuracy =   0.8745  loss =  152.953\n",
      "training :  7035  accuracy =   0.9000  loss =  151.367\n",
      "testing  :  7035  accuracy =   0.8750  loss =  152.992\n",
      "training :  7036  accuracy =   0.8600  loss =  150.65\n",
      "testing  :  7036  accuracy =   0.8752  loss =  153.035\n",
      "training :  7037  accuracy =   0.8700  loss =  152.175\n",
      "testing  :  7037  accuracy =   0.8752  loss =  153.072\n",
      "training :  7038  accuracy =   0.9300  loss =  151.344\n",
      "testing  :  7038  accuracy =   0.8750  loss =  153.098\n",
      "training :  7039  accuracy =   0.8900  loss =  153.305\n",
      "testing  :  7039  accuracy =   0.8730  loss =  152.974\n",
      "training :  7040  accuracy =   0.9100  loss =  149.999\n",
      "testing  :  7040  accuracy =   0.8727  loss =  152.882\n",
      "training :  7041  accuracy =   0.8600  loss =  151.168\n",
      "testing  :  7041  accuracy =   0.8736  loss =  152.823\n",
      "training :  7042  accuracy =   0.8700  loss =  151.909\n",
      "testing  :  7042  accuracy =   0.8732  loss =  152.777\n",
      "training :  7043  accuracy =   0.9400  loss =  149.568\n",
      "testing  :  7043  accuracy =   0.8724  loss =  152.726\n",
      "training :  7044  accuracy =   0.8800  loss =  152.194\n",
      "testing  :  7044  accuracy =   0.8720  loss =  152.687\n",
      "training :  7045  accuracy =   0.9100  loss =  150.122\n",
      "testing  :  7045  accuracy =   0.8724  loss =  152.64\n",
      "training :  7046  accuracy =   0.9000  loss =  150.668\n",
      "testing  :  7046  accuracy =   0.8720  loss =  152.618\n",
      "training :  7047  accuracy =   0.8400  loss =  153.169\n",
      "testing  :  7047  accuracy =   0.8716  loss =  152.617\n",
      "training :  7048  accuracy =   0.8600  loss =  151.304\n",
      "testing  :  7048  accuracy =   0.8713  loss =  152.625\n",
      "training :  7049  accuracy =   0.8900  loss =  153.247\n",
      "testing  :  7049  accuracy =   0.8708  loss =  152.637\n",
      "training :  7050  accuracy =   0.9700  loss =  148.877\n",
      "testing  :  7050  accuracy =   0.8709  loss =  152.638\n",
      "training :  7051  accuracy =   0.8600  loss =  152.918\n",
      "testing  :  7051  accuracy =   0.8710  loss =  152.64\n",
      "training :  7052  accuracy =   0.8700  loss =  153.336\n",
      "testing  :  7052  accuracy =   0.8705  loss =  152.643\n",
      "training :  7053  accuracy =   0.8700  loss =  151.949\n",
      "testing  :  7053  accuracy =   0.8708  loss =  152.647\n",
      "training :  7054  accuracy =   0.9100  loss =  150.342\n",
      "testing  :  7054  accuracy =   0.8704  loss =  152.651\n",
      "training :  7055  accuracy =   0.8900  loss =  152.154\n",
      "testing  :  7055  accuracy =   0.8702  loss =  152.656\n",
      "training :  7056  accuracy =   0.8800  loss =  150.034\n",
      "testing  :  7056  accuracy =   0.8707  loss =  152.652\n",
      "training :  7057  accuracy =   0.8900  loss =  152.418\n",
      "testing  :  7057  accuracy =   0.8709  loss =  152.65\n",
      "training :  7058  accuracy =   0.8900  loss =  149.789\n",
      "testing  :  7058  accuracy =   0.8709  loss =  152.652\n",
      "training :  7059  accuracy =   0.8600  loss =  153.239\n",
      "testing  :  7059  accuracy =   0.8709  loss =  152.655\n",
      "training :  7060  accuracy =   0.9100  loss =  149.846\n",
      "testing  :  7060  accuracy =   0.8707  loss =  152.639\n",
      "training :  7061  accuracy =   0.8800  loss =  151.701\n",
      "testing  :  7061  accuracy =   0.8709  loss =  152.639\n",
      "training :  7062  accuracy =   0.9100  loss =  150.778\n",
      "testing  :  7062  accuracy =   0.8709  loss =  152.649\n",
      "training :  7063  accuracy =   0.8700  loss =  152.466\n",
      "testing  :  7063  accuracy =   0.8720  loss =  152.661\n",
      "training :  7064  accuracy =   0.9000  loss =  152.135\n",
      "testing  :  7064  accuracy =   0.8731  loss =  152.646\n",
      "training :  7065  accuracy =   0.8800  loss =  152.144\n",
      "testing  :  7065  accuracy =   0.8737  loss =  152.657\n",
      "training :  7066  accuracy =   0.9400  loss =  150.02\n",
      "testing  :  7066  accuracy =   0.8744  loss =  152.698\n",
      "training :  7067  accuracy =   0.8900  loss =  151.202\n",
      "testing  :  7067  accuracy =   0.8764  loss =  152.766\n",
      "training :  7068  accuracy =   0.8800  loss =  153.075\n",
      "testing  :  7068  accuracy =   0.8772  loss =  152.847\n",
      "training :  7069  accuracy =   0.8500  loss =  154.25\n",
      "testing  :  7069  accuracy =   0.8773  loss =  152.923\n",
      "training :  7070  accuracy =   0.8900  loss =  153.479\n",
      "testing  :  7070  accuracy =   0.8782  loss =  152.933\n",
      "training :  7071  accuracy =   0.8800  loss =  152.428\n",
      "testing  :  7071  accuracy =   0.8788  loss =  152.874\n",
      "training :  7072  accuracy =   0.8300  loss =  154.86\n",
      "testing  :  7072  accuracy =   0.8782  loss =  152.834\n",
      "training :  7073  accuracy =   0.8500  loss =  155.141\n",
      "testing  :  7073  accuracy =   0.8757  loss =  152.806\n",
      "training :  7074  accuracy =   0.9000  loss =  150.854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7074  accuracy =   0.8743  loss =  152.783\n",
      "training :  7075  accuracy =   0.9100  loss =  150.258\n",
      "testing  :  7075  accuracy =   0.8732  loss =  152.773\n",
      "training :  7076  accuracy =   0.9100  loss =  151.198\n",
      "testing  :  7076  accuracy =   0.8702  loss =  152.798\n",
      "training :  7077  accuracy =   0.8500  loss =  152.186\n",
      "testing  :  7077  accuracy =   0.8692  loss =  152.825\n",
      "training :  7078  accuracy =   0.9100  loss =  150.91\n",
      "testing  :  7078  accuracy =   0.8682  loss =  152.844\n",
      "training :  7079  accuracy =   0.8300  loss =  153.286\n",
      "testing  :  7079  accuracy =   0.8677  loss =  152.871\n",
      "training :  7080  accuracy =   0.8300  loss =  154.454\n",
      "testing  :  7080  accuracy =   0.8672  loss =  152.888\n",
      "training :  7081  accuracy =   0.8200  loss =  152.74\n",
      "testing  :  7081  accuracy =   0.8676  loss =  152.845\n",
      "training :  7082  accuracy =   0.8700  loss =  151.74\n",
      "testing  :  7082  accuracy =   0.8678  loss =  152.792\n",
      "training :  7083  accuracy =   0.8700  loss =  153.147\n",
      "testing  :  7083  accuracy =   0.8683  loss =  152.742\n",
      "training :  7084  accuracy =   0.8600  loss =  152.321\n",
      "testing  :  7084  accuracy =   0.8692  loss =  152.703\n",
      "training :  7085  accuracy =   0.8300  loss =  151.189\n",
      "testing  :  7085  accuracy =   0.8700  loss =  152.681\n",
      "training :  7086  accuracy =   0.9000  loss =  151.599\n",
      "testing  :  7086  accuracy =   0.8697  loss =  152.667\n",
      "training :  7087  accuracy =   0.8500  loss =  150.657\n",
      "testing  :  7087  accuracy =   0.8699  loss =  152.657\n",
      "training :  7088  accuracy =   0.8600  loss =  151.325\n",
      "testing  :  7088  accuracy =   0.8696  loss =  152.648\n",
      "training :  7089  accuracy =   0.8900  loss =  150.387\n",
      "testing  :  7089  accuracy =   0.8696  loss =  152.633\n",
      "training :  7090  accuracy =   0.8600  loss =  150.961\n",
      "testing  :  7090  accuracy =   0.8692  loss =  152.617\n",
      "training :  7091  accuracy =   0.8700  loss =  153.074\n",
      "testing  :  7091  accuracy =   0.8689  loss =  152.599\n",
      "training :  7092  accuracy =   0.8800  loss =  152.874\n",
      "testing  :  7092  accuracy =   0.8681  loss =  152.583\n",
      "training :  7093  accuracy =   0.9200  loss =  150.359\n",
      "testing  :  7093  accuracy =   0.8672  loss =  152.573\n",
      "training :  7094  accuracy =   0.8900  loss =  149.932\n",
      "testing  :  7094  accuracy =   0.8664  loss =  152.561\n",
      "training :  7095  accuracy =   0.8800  loss =  151.457\n",
      "testing  :  7095  accuracy =   0.8651  loss =  152.551\n",
      "training :  7096  accuracy =   0.8900  loss =  149.638\n",
      "testing  :  7096  accuracy =   0.8646  loss =  152.541\n",
      "training :  7097  accuracy =   0.8400  loss =  153.272\n",
      "testing  :  7097  accuracy =   0.8635  loss =  152.526\n",
      "training :  7098  accuracy =   0.7600  loss =  153.256\n",
      "testing  :  7098  accuracy =   0.8629  loss =  152.506\n",
      "training :  7099  accuracy =   0.8700  loss =  150.364\n",
      "testing  :  7099  accuracy =   0.8621  loss =  152.483\n",
      "training :  7100  accuracy =   0.8600  loss =  151.739\n",
      "testing  :  7100  accuracy =   0.8617  loss =  152.465\n",
      "training :  7101  accuracy =   0.8400  loss =  153.141\n",
      "testing  :  7101  accuracy =   0.8614  loss =  152.461\n",
      "training :  7102  accuracy =   0.8800  loss =  151.776\n",
      "testing  :  7102  accuracy =   0.8604  loss =  152.461\n",
      "training :  7103  accuracy =   0.8300  loss =  153.156\n",
      "testing  :  7103  accuracy =   0.8610  loss =  152.45\n",
      "training :  7104  accuracy =   0.8600  loss =  148.978\n",
      "testing  :  7104  accuracy =   0.8622  loss =  152.432\n",
      "training :  7105  accuracy =   0.8700  loss =  151.96\n",
      "testing  :  7105  accuracy =   0.8624  loss =  152.424\n",
      "training :  7106  accuracy =   0.8100  loss =  152.459\n",
      "testing  :  7106  accuracy =   0.8632  loss =  152.409\n",
      "training :  7107  accuracy =   0.8100  loss =  152.1\n",
      "testing  :  7107  accuracy =   0.8657  loss =  152.366\n",
      "training :  7108  accuracy =   0.8700  loss =  152.256\n",
      "testing  :  7108  accuracy =   0.8673  loss =  152.297\n",
      "training :  7109  accuracy =   0.9000  loss =  150.274\n",
      "testing  :  7109  accuracy =   0.8683  loss =  152.243\n",
      "training :  7110  accuracy =   0.8700  loss =  150.854\n",
      "testing  :  7110  accuracy =   0.8694  loss =  152.188\n",
      "training :  7111  accuracy =   0.8900  loss =  152.05\n",
      "testing  :  7111  accuracy =   0.8702  loss =  152.15\n",
      "training :  7112  accuracy =   0.8600  loss =  151.087\n",
      "testing  :  7112  accuracy =   0.8714  loss =  152.122\n",
      "training :  7113  accuracy =   0.8900  loss =  152.637\n",
      "testing  :  7113  accuracy =   0.8717  loss =  152.117\n",
      "training :  7114  accuracy =   0.9000  loss =  152.514\n",
      "testing  :  7114  accuracy =   0.8722  loss =  152.142\n",
      "training :  7115  accuracy =   0.9100  loss =  149.398\n",
      "testing  :  7115  accuracy =   0.8736  loss =  152.165\n",
      "training :  7116  accuracy =   0.9000  loss =  149.772\n",
      "testing  :  7116  accuracy =   0.8741  loss =  152.198\n",
      "training :  7117  accuracy =   0.9300  loss =  150.539\n",
      "testing  :  7117  accuracy =   0.8741  loss =  152.223\n",
      "training :  7118  accuracy =   0.8600  loss =  150.872\n",
      "testing  :  7118  accuracy =   0.8739  loss =  152.228\n",
      "training :  7119  accuracy =   0.9000  loss =  149.356\n",
      "testing  :  7119  accuracy =   0.8735  loss =  152.261\n",
      "training :  7120  accuracy =   0.8600  loss =  150.888\n",
      "testing  :  7120  accuracy =   0.8731  loss =  152.27\n",
      "training :  7121  accuracy =   0.8700  loss =  150.758\n",
      "testing  :  7121  accuracy =   0.8726  loss =  152.275\n",
      "training :  7122  accuracy =   0.8800  loss =  151.502\n",
      "testing  :  7122  accuracy =   0.8729  loss =  152.26\n",
      "training :  7123  accuracy =   0.9300  loss =  149.562\n",
      "testing  :  7123  accuracy =   0.8728  loss =  152.225\n",
      "training :  7124  accuracy =   0.9200  loss =  148.747\n",
      "testing  :  7124  accuracy =   0.8721  loss =  152.164\n",
      "training :  7125  accuracy =   0.7800  loss =  155.443\n",
      "testing  :  7125  accuracy =   0.8721  loss =  152.111\n",
      "training :  7126  accuracy =   0.9200  loss =  150.44\n",
      "testing  :  7126  accuracy =   0.8722  loss =  152.071\n",
      "training :  7127  accuracy =   0.9000  loss =  150.674\n",
      "testing  :  7127  accuracy =   0.8721  loss =  152.001\n",
      "training :  7128  accuracy =   0.9200  loss =  149.464\n",
      "testing  :  7128  accuracy =   0.8722  loss =  151.947\n",
      "training :  7129  accuracy =   0.8600  loss =  151.543\n",
      "testing  :  7129  accuracy =   0.8728  loss =  151.914\n",
      "training :  7130  accuracy =   0.8800  loss =  151.017\n",
      "testing  :  7130  accuracy =   0.8727  loss =  151.912\n",
      "training :  7131  accuracy =   0.9200  loss =  151.54\n",
      "testing  :  7131  accuracy =   0.8727  loss =  151.904\n",
      "training :  7132  accuracy =   0.8800  loss =  150.062\n",
      "testing  :  7132  accuracy =   0.8726  loss =  151.885\n",
      "training :  7133  accuracy =   0.9300  loss =  151.215\n",
      "testing  :  7133  accuracy =   0.8730  loss =  151.865\n",
      "training :  7134  accuracy =   0.8800  loss =  150.952\n",
      "testing  :  7134  accuracy =   0.8728  loss =  151.856\n",
      "training :  7135  accuracy =   0.8800  loss =  150.162\n",
      "testing  :  7135  accuracy =   0.8727  loss =  151.846\n",
      "training :  7136  accuracy =   0.8800  loss =  150.148\n",
      "testing  :  7136  accuracy =   0.8719  loss =  151.858\n",
      "training :  7137  accuracy =   0.9100  loss =  149.497\n",
      "testing  :  7137  accuracy =   0.8715  loss =  151.901\n",
      "training :  7138  accuracy =   0.9100  loss =  150.987\n",
      "testing  :  7138  accuracy =   0.8704  loss =  151.973\n",
      "training :  7139  accuracy =   0.8500  loss =  149.953\n",
      "testing  :  7139  accuracy =   0.8698  loss =  152.032\n",
      "training :  7140  accuracy =   0.8900  loss =  152.632\n",
      "testing  :  7140  accuracy =   0.8687  loss =  152.031\n",
      "training :  7141  accuracy =   0.9200  loss =  149.565\n",
      "testing  :  7141  accuracy =   0.8689  loss =  152.028\n",
      "training :  7142  accuracy =   0.8800  loss =  152.115\n",
      "testing  :  7142  accuracy =   0.8691  loss =  152.034\n",
      "training :  7143  accuracy =   0.8500  loss =  155.652\n",
      "testing  :  7143  accuracy =   0.8699  loss =  151.929\n",
      "training :  7144  accuracy =   0.8700  loss =  148.61\n",
      "testing  :  7144  accuracy =   0.8719  loss =  151.857\n",
      "training :  7145  accuracy =   0.8700  loss =  149.392\n",
      "testing  :  7145  accuracy =   0.8724  loss =  151.84\n",
      "training :  7146  accuracy =   0.9300  loss =  149.012\n",
      "testing  :  7146  accuracy =   0.8734  loss =  151.843\n",
      "training :  7147  accuracy =   0.8600  loss =  149.944\n",
      "testing  :  7147  accuracy =   0.8733  loss =  151.88\n",
      "training :  7148  accuracy =   0.9000  loss =  151.15\n",
      "testing  :  7148  accuracy =   0.8738  loss =  151.913\n",
      "training :  7149  accuracy =   0.9000  loss =  149.48\n",
      "testing  :  7149  accuracy =   0.8747  loss =  151.952\n",
      "training :  7150  accuracy =   0.8700  loss =  150.593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7150  accuracy =   0.8760  loss =  151.988\n",
      "training :  7151  accuracy =   0.8700  loss =  150.468\n",
      "testing  :  7151  accuracy =   0.8764  loss =  151.996\n",
      "training :  7152  accuracy =   0.8900  loss =  148.845\n",
      "testing  :  7152  accuracy =   0.8767  loss =  151.992\n",
      "training :  7153  accuracy =   0.9200  loss =  152.818\n",
      "testing  :  7153  accuracy =   0.8769  loss =  151.981\n",
      "training :  7154  accuracy =   0.9300  loss =  149.088\n",
      "testing  :  7154  accuracy =   0.8772  loss =  151.944\n",
      "training :  7155  accuracy =   0.8900  loss =  149.607\n",
      "testing  :  7155  accuracy =   0.8766  loss =  151.924\n",
      "training :  7156  accuracy =   0.8600  loss =  149.946\n",
      "testing  :  7156  accuracy =   0.8770  loss =  151.898\n",
      "training :  7157  accuracy =   0.9400  loss =  149.557\n",
      "testing  :  7157  accuracy =   0.8766  loss =  151.871\n",
      "training :  7158  accuracy =   0.8700  loss =  152.16\n",
      "testing  :  7158  accuracy =   0.8763  loss =  151.858\n",
      "training :  7159  accuracy =   0.8900  loss =  150.816\n",
      "testing  :  7159  accuracy =   0.8749  loss =  151.831\n",
      "training :  7160  accuracy =   0.8300  loss =  152.36\n",
      "testing  :  7160  accuracy =   0.8742  loss =  151.786\n",
      "training :  7161  accuracy =   0.8300  loss =  150.737\n",
      "testing  :  7161  accuracy =   0.8731  loss =  151.743\n",
      "training :  7162  accuracy =   0.8900  loss =  150.439\n",
      "testing  :  7162  accuracy =   0.8731  loss =  151.72\n",
      "training :  7163  accuracy =   0.8700  loss =  150.794\n",
      "testing  :  7163  accuracy =   0.8738  loss =  151.737\n",
      "training :  7164  accuracy =   0.9100  loss =  149.246\n",
      "testing  :  7164  accuracy =   0.8733  loss =  151.773\n",
      "training :  7165  accuracy =   0.9100  loss =  149.75\n",
      "testing  :  7165  accuracy =   0.8733  loss =  151.812\n",
      "training :  7166  accuracy =   0.8700  loss =  150.672\n",
      "testing  :  7166  accuracy =   0.8732  loss =  151.862\n",
      "training :  7167  accuracy =   0.8300  loss =  152.164\n",
      "testing  :  7167  accuracy =   0.8731  loss =  151.9\n",
      "training :  7168  accuracy =   0.8600  loss =  150.317\n",
      "testing  :  7168  accuracy =   0.8729  loss =  151.929\n",
      "training :  7169  accuracy =   0.9200  loss =  149.557\n",
      "testing  :  7169  accuracy =   0.8725  loss =  151.945\n",
      "training :  7170  accuracy =   0.9100  loss =  150.787\n",
      "testing  :  7170  accuracy =   0.8724  loss =  151.992\n",
      "training :  7171  accuracy =   0.8800  loss =  150.514\n",
      "testing  :  7171  accuracy =   0.8722  loss =  152.028\n",
      "training :  7172  accuracy =   0.9000  loss =  151.022\n",
      "testing  :  7172  accuracy =   0.8714  loss =  152.073\n",
      "training :  7173  accuracy =   0.9100  loss =  150.751\n",
      "testing  :  7173  accuracy =   0.8710  loss =  152.12\n",
      "training :  7174  accuracy =   0.8600  loss =  150.502\n",
      "testing  :  7174  accuracy =   0.8703  loss =  152.149\n",
      "training :  7175  accuracy =   0.8700  loss =  150.838\n",
      "testing  :  7175  accuracy =   0.8699  loss =  152.143\n",
      "training :  7176  accuracy =   0.8900  loss =  150.551\n",
      "testing  :  7176  accuracy =   0.8689  loss =  152.13\n",
      "training :  7177  accuracy =   0.8700  loss =  151.621\n",
      "testing  :  7177  accuracy =   0.8685  loss =  152.105\n",
      "training :  7178  accuracy =   0.9500  loss =  149.508\n",
      "testing  :  7178  accuracy =   0.8680  loss =  152.092\n",
      "training :  7179  accuracy =   0.8800  loss =  150.17\n",
      "testing  :  7179  accuracy =   0.8676  loss =  152.076\n",
      "training :  7180  accuracy =   0.8900  loss =  150.314\n",
      "testing  :  7180  accuracy =   0.8685  loss =  151.983\n",
      "training :  7181  accuracy =   0.9000  loss =  151.171\n",
      "testing  :  7181  accuracy =   0.8697  loss =  151.901\n",
      "training :  7182  accuracy =   0.8900  loss =  150.8\n",
      "testing  :  7182  accuracy =   0.8695  loss =  151.854\n",
      "training :  7183  accuracy =   0.8600  loss =  150.406\n",
      "testing  :  7183  accuracy =   0.8694  loss =  151.83\n",
      "training :  7184  accuracy =   0.8500  loss =  152.11\n",
      "testing  :  7184  accuracy =   0.8684  loss =  151.851\n",
      "training :  7185  accuracy =   0.8900  loss =  148.715\n",
      "testing  :  7185  accuracy =   0.8680  loss =  151.877\n",
      "training :  7186  accuracy =   0.8400  loss =  153.409\n",
      "testing  :  7186  accuracy =   0.8675  loss =  151.915\n",
      "training :  7187  accuracy =   0.8700  loss =  151.235\n",
      "testing  :  7187  accuracy =   0.8680  loss =  151.909\n",
      "training :  7188  accuracy =   0.8600  loss =  152.18\n",
      "testing  :  7188  accuracy =   0.8671  loss =  151.927\n",
      "training :  7189  accuracy =   0.8500  loss =  150.935\n",
      "testing  :  7189  accuracy =   0.8680  loss =  151.909\n",
      "training :  7190  accuracy =   0.9300  loss =  149.634\n",
      "testing  :  7190  accuracy =   0.8680  loss =  151.886\n",
      "training :  7191  accuracy =   0.8700  loss =  149.706\n",
      "testing  :  7191  accuracy =   0.8683  loss =  151.858\n",
      "training :  7192  accuracy =   0.8500  loss =  151.729\n",
      "testing  :  7192  accuracy =   0.8691  loss =  151.841\n",
      "training :  7193  accuracy =   0.8200  loss =  153.588\n",
      "testing  :  7193  accuracy =   0.8701  loss =  151.813\n",
      "training :  7194  accuracy =   0.9100  loss =  150.095\n",
      "testing  :  7194  accuracy =   0.8717  loss =  151.768\n",
      "training :  7195  accuracy =   0.8900  loss =  148.847\n",
      "testing  :  7195  accuracy =   0.8723  loss =  151.752\n",
      "training :  7196  accuracy =   0.8600  loss =  150.89\n",
      "testing  :  7196  accuracy =   0.8728  loss =  151.753\n",
      "training :  7197  accuracy =   0.8900  loss =  150.519\n",
      "testing  :  7197  accuracy =   0.8735  loss =  151.764\n",
      "training :  7198  accuracy =   0.8800  loss =  151.523\n",
      "testing  :  7198  accuracy =   0.8734  loss =  151.759\n",
      "training :  7199  accuracy =   0.9100  loss =  149.76\n",
      "testing  :  7199  accuracy =   0.8726  loss =  151.74\n",
      "training :  7200  accuracy =   0.9000  loss =  149.536\n",
      "testing  :  7200  accuracy =   0.8718  loss =  151.731\n",
      "training :  7201  accuracy =   0.8900  loss =  149.29\n",
      "testing  :  7201  accuracy =   0.8718  loss =  151.721\n",
      "training :  7202  accuracy =   0.8700  loss =  151.032\n",
      "testing  :  7202  accuracy =   0.8718  loss =  151.73\n",
      "training :  7203  accuracy =   0.8900  loss =  151.02\n",
      "testing  :  7203  accuracy =   0.8709  loss =  151.738\n",
      "training :  7204  accuracy =   0.9600  loss =  149.901\n",
      "testing  :  7204  accuracy =   0.8708  loss =  151.753\n",
      "training :  7205  accuracy =   0.8700  loss =  152.133\n",
      "testing  :  7205  accuracy =   0.8707  loss =  151.759\n",
      "training :  7206  accuracy =   0.8400  loss =  151.94\n",
      "testing  :  7206  accuracy =   0.8714  loss =  151.736\n",
      "training :  7207  accuracy =   0.9200  loss =  149.247\n",
      "testing  :  7207  accuracy =   0.8713  loss =  151.708\n",
      "training :  7208  accuracy =   0.9100  loss =  150.461\n",
      "testing  :  7208  accuracy =   0.8709  loss =  151.684\n",
      "training :  7209  accuracy =   0.9200  loss =  150.075\n",
      "testing  :  7209  accuracy =   0.8705  loss =  151.66\n",
      "training :  7210  accuracy =   0.8900  loss =  150.1\n",
      "testing  :  7210  accuracy =   0.8706  loss =  151.65\n",
      "training :  7211  accuracy =   0.9000  loss =  149.833\n",
      "testing  :  7211  accuracy =   0.8712  loss =  151.65\n",
      "training :  7212  accuracy =   0.8900  loss =  149.95\n",
      "testing  :  7212  accuracy =   0.8713  loss =  151.648\n",
      "training :  7213  accuracy =   0.8700  loss =  150.335\n",
      "testing  :  7213  accuracy =   0.8709  loss =  151.657\n",
      "training :  7214  accuracy =   0.9100  loss =  150.191\n",
      "testing  :  7214  accuracy =   0.8705  loss =  151.674\n",
      "training :  7215  accuracy =   0.8700  loss =  150.562\n",
      "testing  :  7215  accuracy =   0.8706  loss =  151.607\n",
      "training :  7216  accuracy =   0.8600  loss =  149.698\n",
      "testing  :  7216  accuracy =   0.8711  loss =  151.56\n",
      "training :  7217  accuracy =   0.8400  loss =  150.659\n",
      "testing  :  7217  accuracy =   0.8716  loss =  151.551\n",
      "training :  7218  accuracy =   0.9200  loss =  150.888\n",
      "testing  :  7218  accuracy =   0.8726  loss =  151.553\n",
      "training :  7219  accuracy =   0.8800  loss =  149.933\n",
      "testing  :  7219  accuracy =   0.8726  loss =  151.557\n",
      "training :  7220  accuracy =   0.8300  loss =  150.455\n",
      "testing  :  7220  accuracy =   0.8727  loss =  151.569\n",
      "training :  7221  accuracy =   0.9100  loss =  150.179\n",
      "testing  :  7221  accuracy =   0.8732  loss =  151.58\n",
      "training :  7222  accuracy =   0.9300  loss =  149.122\n",
      "testing  :  7222  accuracy =   0.8737  loss =  151.584\n",
      "training :  7223  accuracy =   0.8800  loss =  149.346\n",
      "testing  :  7223  accuracy =   0.8739  loss =  151.571\n",
      "training :  7224  accuracy =   0.8600  loss =  149.715\n",
      "testing  :  7224  accuracy =   0.8744  loss =  151.554\n",
      "training :  7225  accuracy =   0.9100  loss =  149.206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7225  accuracy =   0.8746  loss =  151.515\n",
      "training :  7226  accuracy =   0.8600  loss =  149.769\n",
      "testing  :  7226  accuracy =   0.8740  loss =  151.493\n",
      "training :  7227  accuracy =   0.8500  loss =  151.134\n",
      "testing  :  7227  accuracy =   0.8736  loss =  151.473\n",
      "training :  7228  accuracy =   0.8500  loss =  149.7\n",
      "testing  :  7228  accuracy =   0.8739  loss =  151.462\n",
      "training :  7229  accuracy =   0.9200  loss =  151.021\n",
      "testing  :  7229  accuracy =   0.8741  loss =  151.452\n",
      "training :  7230  accuracy =   0.9100  loss =  148.771\n",
      "testing  :  7230  accuracy =   0.8735  loss =  151.442\n",
      "training :  7231  accuracy =   0.9500  loss =  148.737\n",
      "testing  :  7231  accuracy =   0.8735  loss =  151.451\n",
      "training :  7232  accuracy =   0.8800  loss =  150.96\n",
      "testing  :  7232  accuracy =   0.8733  loss =  151.46\n",
      "training :  7233  accuracy =   0.8700  loss =  151.04\n",
      "testing  :  7233  accuracy =   0.8727  loss =  151.468\n",
      "training :  7234  accuracy =   0.8900  loss =  152.138\n",
      "testing  :  7234  accuracy =   0.8722  loss =  151.477\n",
      "training :  7235  accuracy =   0.8600  loss =  151.126\n",
      "testing  :  7235  accuracy =   0.8727  loss =  151.486\n",
      "training :  7236  accuracy =   0.8600  loss =  151.929\n",
      "testing  :  7236  accuracy =   0.8724  loss =  151.481\n",
      "training :  7237  accuracy =   0.8800  loss =  150.801\n",
      "testing  :  7237  accuracy =   0.8726  loss =  151.469\n",
      "training :  7238  accuracy =   0.8200  loss =  151.983\n",
      "testing  :  7238  accuracy =   0.8727  loss =  151.47\n",
      "training :  7239  accuracy =   0.8900  loss =  150.041\n",
      "testing  :  7239  accuracy =   0.8730  loss =  151.475\n",
      "training :  7240  accuracy =   0.8900  loss =  148.598\n",
      "testing  :  7240  accuracy =   0.8727  loss =  151.495\n",
      "training :  7241  accuracy =   0.8900  loss =  149.277\n",
      "testing  :  7241  accuracy =   0.8725  loss =  151.523\n",
      "training :  7242  accuracy =   0.8700  loss =  149.598\n",
      "testing  :  7242  accuracy =   0.8726  loss =  151.543\n",
      "training :  7243  accuracy =   0.8800  loss =  149.245\n",
      "testing  :  7243  accuracy =   0.8722  loss =  151.548\n",
      "training :  7244  accuracy =   0.8500  loss =  150.462\n",
      "testing  :  7244  accuracy =   0.8719  loss =  151.554\n",
      "training :  7245  accuracy =   0.9400  loss =  150.508\n",
      "testing  :  7245  accuracy =   0.8725  loss =  151.548\n",
      "training :  7246  accuracy =   0.8500  loss =  153.071\n",
      "testing  :  7246  accuracy =   0.8729  loss =  151.55\n",
      "training :  7247  accuracy =   0.9500  loss =  149.313\n",
      "testing  :  7247  accuracy =   0.8732  loss =  151.558\n",
      "training :  7248  accuracy =   0.8500  loss =  150.931\n",
      "testing  :  7248  accuracy =   0.8734  loss =  151.568\n",
      "training :  7249  accuracy =   0.9200  loss =  149.736\n",
      "testing  :  7249  accuracy =   0.8733  loss =  151.569\n",
      "training :  7250  accuracy =   0.8800  loss =  149.031\n",
      "testing  :  7250  accuracy =   0.8735  loss =  151.568\n",
      "training :  7251  accuracy =   0.8800  loss =  151.057\n",
      "testing  :  7251  accuracy =   0.8735  loss =  151.569\n",
      "training :  7252  accuracy =   0.9000  loss =  150.53\n",
      "testing  :  7252  accuracy =   0.8738  loss =  151.567\n",
      "training :  7253  accuracy =   0.8300  loss =  152.106\n",
      "testing  :  7253  accuracy =   0.8736  loss =  151.562\n",
      "training :  7254  accuracy =   0.8700  loss =  151.804\n",
      "testing  :  7254  accuracy =   0.8735  loss =  151.548\n",
      "training :  7255  accuracy =   0.9100  loss =  149.667\n",
      "testing  :  7255  accuracy =   0.8731  loss =  151.538\n",
      "training :  7256  accuracy =   0.9100  loss =  148.804\n",
      "testing  :  7256  accuracy =   0.8734  loss =  151.533\n",
      "training :  7257  accuracy =   0.8700  loss =  148.84\n",
      "testing  :  7257  accuracy =   0.8727  loss =  151.53\n",
      "training :  7258  accuracy =   0.8700  loss =  151.144\n",
      "testing  :  7258  accuracy =   0.8727  loss =  151.527\n",
      "training :  7259  accuracy =   0.9000  loss =  148.989\n",
      "testing  :  7259  accuracy =   0.8726  loss =  151.523\n",
      "training :  7260  accuracy =   0.8800  loss =  150.764\n",
      "testing  :  7260  accuracy =   0.8721  loss =  151.522\n",
      "training :  7261  accuracy =   0.8400  loss =  152.858\n",
      "testing  :  7261  accuracy =   0.8715  loss =  151.518\n",
      "training :  7262  accuracy =   0.8900  loss =  148.745\n",
      "testing  :  7262  accuracy =   0.8717  loss =  151.491\n",
      "training :  7263  accuracy =   0.9000  loss =  148.481\n",
      "testing  :  7263  accuracy =   0.8721  loss =  151.482\n",
      "training :  7264  accuracy =   0.8900  loss =  149.799\n",
      "testing  :  7264  accuracy =   0.8723  loss =  151.478\n",
      "training :  7265  accuracy =   0.9200  loss =  149.637\n",
      "testing  :  7265  accuracy =   0.8726  loss =  151.486\n",
      "training :  7266  accuracy =   0.9000  loss =  149.586\n",
      "testing  :  7266  accuracy =   0.8724  loss =  151.499\n",
      "training :  7267  accuracy =   0.8700  loss =  150.923\n",
      "testing  :  7267  accuracy =   0.8717  loss =  151.52\n",
      "training :  7268  accuracy =   0.8600  loss =  149.947\n",
      "testing  :  7268  accuracy =   0.8714  loss =  151.534\n",
      "training :  7269  accuracy =   0.9000  loss =  150.148\n",
      "testing  :  7269  accuracy =   0.8715  loss =  151.536\n",
      "training :  7270  accuracy =   0.8500  loss =  151.766\n",
      "testing  :  7270  accuracy =   0.8729  loss =  151.507\n",
      "training :  7271  accuracy =   0.8600  loss =  148.925\n",
      "testing  :  7271  accuracy =   0.8742  loss =  151.456\n",
      "training :  7272  accuracy =   0.8300  loss =  151.122\n",
      "testing  :  7272  accuracy =   0.8751  loss =  151.43\n",
      "training :  7273  accuracy =   0.8300  loss =  150.166\n",
      "testing  :  7273  accuracy =   0.8760  loss =  151.429\n",
      "training :  7274  accuracy =   0.8500  loss =  150.657\n",
      "testing  :  7274  accuracy =   0.8753  loss =  151.45\n",
      "training :  7275  accuracy =   0.8800  loss =  152.452\n",
      "testing  :  7275  accuracy =   0.8757  loss =  151.493\n",
      "training :  7276  accuracy =   0.8500  loss =  151.344\n",
      "testing  :  7276  accuracy =   0.8759  loss =  151.545\n",
      "training :  7277  accuracy =   0.9300  loss =  148.297\n",
      "testing  :  7277  accuracy =   0.8764  loss =  151.595\n",
      "training :  7278  accuracy =   0.8800  loss =  151.413\n",
      "testing  :  7278  accuracy =   0.8762  loss =  151.649\n",
      "training :  7279  accuracy =   0.9200  loss =  149.498\n",
      "testing  :  7279  accuracy =   0.8761  loss =  151.676\n",
      "training :  7280  accuracy =   0.8900  loss =  151.076\n",
      "testing  :  7280  accuracy =   0.8760  loss =  151.698\n",
      "training :  7281  accuracy =   0.9200  loss =  150.328\n",
      "testing  :  7281  accuracy =   0.8763  loss =  151.664\n",
      "training :  7282  accuracy =   0.9000  loss =  149.948\n",
      "testing  :  7282  accuracy =   0.8762  loss =  151.629\n",
      "training :  7283  accuracy =   0.9200  loss =  149.666\n",
      "testing  :  7283  accuracy =   0.8761  loss =  151.615\n",
      "training :  7284  accuracy =   0.8700  loss =  150.942\n",
      "testing  :  7284  accuracy =   0.8758  loss =  151.611\n",
      "training :  7285  accuracy =   0.8600  loss =  151.733\n",
      "testing  :  7285  accuracy =   0.8749  loss =  151.595\n",
      "training :  7286  accuracy =   0.8900  loss =  150.863\n",
      "testing  :  7286  accuracy =   0.8752  loss =  151.592\n",
      "training :  7287  accuracy =   0.8900  loss =  148.764\n",
      "testing  :  7287  accuracy =   0.8753  loss =  151.583\n",
      "training :  7288  accuracy =   0.9000  loss =  149.668\n",
      "testing  :  7288  accuracy =   0.8746  loss =  151.576\n",
      "training :  7289  accuracy =   0.8800  loss =  150.354\n",
      "testing  :  7289  accuracy =   0.8748  loss =  151.558\n",
      "training :  7290  accuracy =   0.8900  loss =  149.818\n",
      "testing  :  7290  accuracy =   0.8743  loss =  151.519\n",
      "training :  7291  accuracy =   0.9200  loss =  149.375\n",
      "testing  :  7291  accuracy =   0.8738  loss =  151.515\n",
      "training :  7292  accuracy =   0.9000  loss =  149.938\n",
      "testing  :  7292  accuracy =   0.8730  loss =  151.547\n",
      "training :  7293  accuracy =   0.8800  loss =  150.355\n",
      "testing  :  7293  accuracy =   0.8731  loss =  151.589\n",
      "training :  7294  accuracy =   0.8800  loss =  151.775\n",
      "testing  :  7294  accuracy =   0.8737  loss =  151.615\n",
      "training :  7295  accuracy =   0.9000  loss =  149.634\n",
      "testing  :  7295  accuracy =   0.8732  loss =  151.633\n",
      "training :  7296  accuracy =   0.8600  loss =  151.72\n",
      "testing  :  7296  accuracy =   0.8730  loss =  151.652\n",
      "training :  7297  accuracy =   0.8500  loss =  151.841\n",
      "testing  :  7297  accuracy =   0.8730  loss =  151.674\n",
      "training :  7298  accuracy =   0.8400  loss =  151.434\n",
      "testing  :  7298  accuracy =   0.8718  loss =  151.696\n",
      "training :  7299  accuracy =   0.8300  loss =  153.39\n",
      "testing  :  7299  accuracy =   0.8710  loss =  151.674\n",
      "training :  7300  accuracy =   0.8900  loss =  149.886\n",
      "testing  :  7300  accuracy =   0.8705  loss =  151.627\n",
      "training :  7301  accuracy =   0.8600  loss =  149.549\n",
      "testing  :  7301  accuracy =   0.8706  loss =  151.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  7302  accuracy =   0.8900  loss =  154.036\n",
      "testing  :  7302  accuracy =   0.8706  loss =  151.545\n",
      "training :  7303  accuracy =   0.9100  loss =  149.171\n",
      "testing  :  7303  accuracy =   0.8704  loss =  151.495\n",
      "training :  7304  accuracy =   0.8600  loss =  152.664\n",
      "testing  :  7304  accuracy =   0.8707  loss =  151.48\n",
      "training :  7305  accuracy =   0.8900  loss =  151.788\n",
      "testing  :  7305  accuracy =   0.8708  loss =  151.493\n",
      "training :  7306  accuracy =   0.8900  loss =  151.164\n",
      "testing  :  7306  accuracy =   0.8711  loss =  151.487\n",
      "training :  7307  accuracy =   0.8600  loss =  149.124\n",
      "testing  :  7307  accuracy =   0.8722  loss =  151.487\n",
      "training :  7308  accuracy =   0.9100  loss =  149.242\n",
      "testing  :  7308  accuracy =   0.8725  loss =  151.484\n",
      "training :  7309  accuracy =   0.9200  loss =  149.053\n",
      "testing  :  7309  accuracy =   0.8722  loss =  151.494\n",
      "training :  7310  accuracy =   0.8700  loss =  152.776\n",
      "testing  :  7310  accuracy =   0.8732  loss =  151.509\n",
      "training :  7311  accuracy =   0.8800  loss =  149.437\n",
      "testing  :  7311  accuracy =   0.8730  loss =  151.501\n",
      "training :  7312  accuracy =   0.8700  loss =  151.321\n",
      "testing  :  7312  accuracy =   0.8735  loss =  151.496\n",
      "training :  7313  accuracy =   0.9000  loss =  149.1\n",
      "testing  :  7313  accuracy =   0.8743  loss =  151.474\n",
      "training :  7314  accuracy =   0.8900  loss =  150.488\n",
      "testing  :  7314  accuracy =   0.8750  loss =  151.424\n",
      "training :  7315  accuracy =   0.8900  loss =  151.267\n",
      "testing  :  7315  accuracy =   0.8756  loss =  151.396\n",
      "training :  7316  accuracy =   0.8800  loss =  152.208\n",
      "testing  :  7316  accuracy =   0.8766  loss =  151.399\n",
      "training :  7317  accuracy =   0.9100  loss =  149.866\n",
      "testing  :  7317  accuracy =   0.8772  loss =  151.411\n",
      "training :  7318  accuracy =   0.8700  loss =  152.617\n",
      "testing  :  7318  accuracy =   0.8776  loss =  151.435\n",
      "training :  7319  accuracy =   0.8500  loss =  150.839\n",
      "testing  :  7319  accuracy =   0.8778  loss =  151.467\n",
      "training :  7320  accuracy =   0.9400  loss =  149.02\n",
      "testing  :  7320  accuracy =   0.8789  loss =  151.496\n",
      "training :  7321  accuracy =   0.9000  loss =  150.589\n",
      "testing  :  7321  accuracy =   0.8792  loss =  151.521\n",
      "training :  7322  accuracy =   0.8900  loss =  153.18\n",
      "testing  :  7322  accuracy =   0.8792  loss =  151.545\n",
      "training :  7323  accuracy =   0.9000  loss =  149.819\n",
      "testing  :  7323  accuracy =   0.8783  loss =  151.53\n",
      "training :  7324  accuracy =   0.9100  loss =  149.708\n",
      "testing  :  7324  accuracy =   0.8779  loss =  151.514\n",
      "training :  7325  accuracy =   0.8800  loss =  150.656\n",
      "testing  :  7325  accuracy =   0.8771  loss =  151.488\n",
      "training :  7326  accuracy =   0.9000  loss =  149.016\n",
      "testing  :  7326  accuracy =   0.8762  loss =  151.499\n",
      "training :  7327  accuracy =   0.9100  loss =  150.113\n",
      "testing  :  7327  accuracy =   0.8760  loss =  151.521\n",
      "training :  7328  accuracy =   0.9200  loss =  151.742\n",
      "testing  :  7328  accuracy =   0.8753  loss =  151.524\n",
      "training :  7329  accuracy =   0.9100  loss =  150.838\n",
      "testing  :  7329  accuracy =   0.8749  loss =  151.53\n",
      "training :  7330  accuracy =   0.8900  loss =  149.786\n",
      "testing  :  7330  accuracy =   0.8747  loss =  151.535\n",
      "training :  7331  accuracy =   0.8900  loss =  150.312\n",
      "testing  :  7331  accuracy =   0.8739  loss =  151.54\n",
      "training :  7332  accuracy =   0.9100  loss =  150.159\n",
      "testing  :  7332  accuracy =   0.8738  loss =  151.572\n",
      "training :  7333  accuracy =   0.9000  loss =  151.752\n",
      "testing  :  7333  accuracy =   0.8740  loss =  151.601\n",
      "training :  7334  accuracy =   0.9200  loss =  150.758\n",
      "testing  :  7334  accuracy =   0.8739  loss =  151.622\n",
      "training :  7335  accuracy =   0.8800  loss =  150.007\n",
      "testing  :  7335  accuracy =   0.8738  loss =  151.636\n",
      "training :  7336  accuracy =   0.8700  loss =  151.528\n",
      "testing  :  7336  accuracy =   0.8740  loss =  151.649\n",
      "training :  7337  accuracy =   0.8800  loss =  150.953\n",
      "testing  :  7337  accuracy =   0.8754  loss =  151.667\n",
      "training :  7338  accuracy =   0.9000  loss =  151.441\n",
      "testing  :  7338  accuracy =   0.8760  loss =  151.729\n",
      "training :  7339  accuracy =   0.9100  loss =  152.625\n",
      "testing  :  7339  accuracy =   0.8767  loss =  151.764\n",
      "training :  7340  accuracy =   0.8600  loss =  149.593\n",
      "testing  :  7340  accuracy =   0.8771  loss =  151.752\n",
      "training :  7341  accuracy =   0.8200  loss =  151.873\n",
      "testing  :  7341  accuracy =   0.8775  loss =  151.729\n",
      "training :  7342  accuracy =   0.9200  loss =  150.469\n",
      "testing  :  7342  accuracy =   0.8781  loss =  151.668\n",
      "training :  7343  accuracy =   0.8700  loss =  149.184\n",
      "testing  :  7343  accuracy =   0.8784  loss =  151.611\n",
      "training :  7344  accuracy =   0.9000  loss =  150.41\n",
      "testing  :  7344  accuracy =   0.8790  loss =  151.561\n",
      "training :  7345  accuracy =   0.9000  loss =  149.78\n",
      "testing  :  7345  accuracy =   0.8778  loss =  151.518\n",
      "training :  7346  accuracy =   0.9100  loss =  149.532\n",
      "testing  :  7346  accuracy =   0.8775  loss =  151.491\n",
      "training :  7347  accuracy =   0.8900  loss =  151.239\n",
      "testing  :  7347  accuracy =   0.8766  loss =  151.485\n",
      "training :  7348  accuracy =   0.8500  loss =  151.449\n",
      "testing  :  7348  accuracy =   0.8748  loss =  151.497\n",
      "training :  7349  accuracy =   0.8900  loss =  149.254\n",
      "testing  :  7349  accuracy =   0.8739  loss =  151.511\n",
      "training :  7350  accuracy =   0.9200  loss =  148.871\n",
      "testing  :  7350  accuracy =   0.8731  loss =  151.512\n",
      "training :  7351  accuracy =   0.8700  loss =  150.065\n",
      "testing  :  7351  accuracy =   0.8733  loss =  151.512\n",
      "training :  7352  accuracy =   0.8100  loss =  152.348\n",
      "testing  :  7352  accuracy =   0.8732  loss =  151.506\n",
      "training :  7353  accuracy =   0.8900  loss =  151.0\n",
      "testing  :  7353  accuracy =   0.8734  loss =  151.487\n",
      "training :  7354  accuracy =   0.9500  loss =  148.548\n",
      "testing  :  7354  accuracy =   0.8740  loss =  151.47\n",
      "training :  7355  accuracy =   0.8600  loss =  150.399\n",
      "testing  :  7355  accuracy =   0.8744  loss =  151.458\n",
      "training :  7356  accuracy =   0.8200  loss =  151.68\n",
      "testing  :  7356  accuracy =   0.8741  loss =  151.45\n",
      "training :  7357  accuracy =   0.9200  loss =  148.445\n",
      "testing  :  7357  accuracy =   0.8734  loss =  151.464\n",
      "training :  7358  accuracy =   0.8400  loss =  149.963\n",
      "testing  :  7358  accuracy =   0.8728  loss =  151.484\n",
      "training :  7359  accuracy =   0.8500  loss =  152.801\n",
      "testing  :  7359  accuracy =   0.8724  loss =  151.52\n",
      "training :  7360  accuracy =   0.8900  loss =  149.595\n",
      "testing  :  7360  accuracy =   0.8726  loss =  151.534\n",
      "training :  7361  accuracy =   0.8800  loss =  152.92\n",
      "testing  :  7361  accuracy =   0.8724  loss =  151.539\n",
      "training :  7362  accuracy =   0.9100  loss =  150.939\n",
      "testing  :  7362  accuracy =   0.8724  loss =  151.528\n",
      "training :  7363  accuracy =   0.8900  loss =  150.398\n",
      "testing  :  7363  accuracy =   0.8727  loss =  151.513\n",
      "training :  7364  accuracy =   0.8700  loss =  151.478\n",
      "testing  :  7364  accuracy =   0.8726  loss =  151.481\n",
      "training :  7365  accuracy =   0.8900  loss =  149.345\n",
      "testing  :  7365  accuracy =   0.8729  loss =  151.453\n",
      "training :  7366  accuracy =   0.8800  loss =  150.678\n",
      "testing  :  7366  accuracy =   0.8733  loss =  151.419\n",
      "training :  7367  accuracy =   0.8900  loss =  149.337\n",
      "testing  :  7367  accuracy =   0.8740  loss =  151.394\n",
      "training :  7368  accuracy =   0.7900  loss =  155.357\n",
      "testing  :  7368  accuracy =   0.8750  loss =  151.369\n",
      "training :  7369  accuracy =   0.8700  loss =  151.825\n",
      "testing  :  7369  accuracy =   0.8750  loss =  151.332\n",
      "training :  7370  accuracy =   0.8900  loss =  149.508\n",
      "testing  :  7370  accuracy =   0.8745  loss =  151.303\n",
      "training :  7371  accuracy =   0.9100  loss =  149.395\n",
      "testing  :  7371  accuracy =   0.8756  loss =  151.281\n",
      "training :  7372  accuracy =   0.8700  loss =  150.153\n",
      "testing  :  7372  accuracy =   0.8754  loss =  151.261\n",
      "training :  7373  accuracy =   0.9100  loss =  150.064\n",
      "testing  :  7373  accuracy =   0.8764  loss =  151.246\n",
      "training :  7374  accuracy =   0.9100  loss =  150.098\n",
      "testing  :  7374  accuracy =   0.8764  loss =  151.237\n",
      "training :  7375  accuracy =   0.9000  loss =  149.755\n",
      "testing  :  7375  accuracy =   0.8769  loss =  151.235\n",
      "training :  7376  accuracy =   0.8400  loss =  154.242\n",
      "testing  :  7376  accuracy =   0.8771  loss =  151.222\n",
      "training :  7377  accuracy =   0.9100  loss =  150.715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7377  accuracy =   0.8767  loss =  151.203\n",
      "training :  7378  accuracy =   0.8800  loss =  151.031\n",
      "testing  :  7378  accuracy =   0.8770  loss =  151.194\n",
      "training :  7379  accuracy =   0.9100  loss =  149.874\n",
      "testing  :  7379  accuracy =   0.8769  loss =  151.188\n",
      "training :  7380  accuracy =   0.8900  loss =  150.299\n",
      "testing  :  7380  accuracy =   0.8775  loss =  151.186\n",
      "training :  7381  accuracy =   0.9000  loss =  150.822\n",
      "testing  :  7381  accuracy =   0.8778  loss =  151.184\n",
      "training :  7382  accuracy =   0.9600  loss =  148.312\n",
      "testing  :  7382  accuracy =   0.8780  loss =  151.183\n",
      "training :  7383  accuracy =   0.8800  loss =  151.358\n",
      "testing  :  7383  accuracy =   0.8784  loss =  151.187\n",
      "training :  7384  accuracy =   0.8700  loss =  151.387\n",
      "testing  :  7384  accuracy =   0.8789  loss =  151.2\n",
      "training :  7385  accuracy =   0.8800  loss =  151.354\n",
      "testing  :  7385  accuracy =   0.8785  loss =  151.221\n",
      "training :  7386  accuracy =   0.8900  loss =  149.834\n",
      "testing  :  7386  accuracy =   0.8771  loss =  151.231\n",
      "training :  7387  accuracy =   0.9300  loss =  149.569\n",
      "testing  :  7387  accuracy =   0.8772  loss =  151.246\n",
      "training :  7388  accuracy =   0.8500  loss =  150.214\n",
      "testing  :  7388  accuracy =   0.8771  loss =  151.274\n",
      "training :  7389  accuracy =   0.8500  loss =  152.51\n",
      "testing  :  7389  accuracy =   0.8763  loss =  151.326\n",
      "training :  7390  accuracy =   0.9300  loss =  149.57\n",
      "testing  :  7390  accuracy =   0.8762  loss =  151.389\n",
      "training :  7391  accuracy =   0.9200  loss =  150.12\n",
      "testing  :  7391  accuracy =   0.8759  loss =  151.473\n",
      "training :  7392  accuracy =   0.9200  loss =  150.66\n",
      "testing  :  7392  accuracy =   0.8755  loss =  151.561\n",
      "training :  7393  accuracy =   0.8700  loss =  150.124\n",
      "testing  :  7393  accuracy =   0.8743  loss =  151.644\n",
      "training :  7394  accuracy =   0.8800  loss =  150.405\n",
      "testing  :  7394  accuracy =   0.8734  loss =  151.646\n",
      "training :  7395  accuracy =   0.9500  loss =  148.509\n",
      "testing  :  7395  accuracy =   0.8713  loss =  151.68\n",
      "training :  7396  accuracy =   0.8400  loss =  150.342\n",
      "testing  :  7396  accuracy =   0.8702  loss =  151.73\n",
      "training :  7397  accuracy =   0.8500  loss =  148.741\n",
      "testing  :  7397  accuracy =   0.8692  loss =  151.781\n",
      "training :  7398  accuracy =   0.8700  loss =  150.229\n",
      "testing  :  7398  accuracy =   0.8693  loss =  151.828\n",
      "training :  7399  accuracy =   0.8800  loss =  151.582\n",
      "testing  :  7399  accuracy =   0.8697  loss =  151.781\n",
      "training :  7400  accuracy =   0.9100  loss =  148.828\n",
      "testing  :  7400  accuracy =   0.8702  loss =  151.727\n",
      "training :  7401  accuracy =   0.9100  loss =  151.938\n",
      "testing  :  7401  accuracy =   0.8716  loss =  151.618\n",
      "training :  7402  accuracy =   0.8400  loss =  152.184\n",
      "testing  :  7402  accuracy =   0.8717  loss =  151.549\n",
      "training :  7403  accuracy =   0.8900  loss =  150.124\n",
      "testing  :  7403  accuracy =   0.8725  loss =  151.488\n",
      "training :  7404  accuracy =   0.8800  loss =  149.215\n",
      "testing  :  7404  accuracy =   0.8735  loss =  151.362\n",
      "training :  7405  accuracy =   0.9100  loss =  149.207\n",
      "testing  :  7405  accuracy =   0.8743  loss =  151.264\n",
      "training :  7406  accuracy =   0.9300  loss =  150.109\n",
      "testing  :  7406  accuracy =   0.8743  loss =  151.209\n",
      "training :  7407  accuracy =   0.9100  loss =  150.302\n",
      "testing  :  7407  accuracy =   0.8739  loss =  151.214\n",
      "training :  7408  accuracy =   0.9300  loss =  149.577\n",
      "testing  :  7408  accuracy =   0.8728  loss =  151.241\n",
      "training :  7409  accuracy =   0.9200  loss =  150.48\n",
      "testing  :  7409  accuracy =   0.8724  loss =  151.271\n",
      "training :  7410  accuracy =   0.9100  loss =  148.048\n",
      "testing  :  7410  accuracy =   0.8710  loss =  151.316\n",
      "training :  7411  accuracy =   0.8900  loss =  149.539\n",
      "testing  :  7411  accuracy =   0.8702  loss =  151.394\n",
      "training :  7412  accuracy =   0.8700  loss =  149.894\n",
      "testing  :  7412  accuracy =   0.8694  loss =  151.457\n",
      "training :  7413  accuracy =   0.9400  loss =  149.339\n",
      "testing  :  7413  accuracy =   0.8705  loss =  151.457\n",
      "training :  7414  accuracy =   0.8400  loss =  149.858\n",
      "testing  :  7414  accuracy =   0.8696  loss =  151.477\n",
      "training :  7415  accuracy =   0.8900  loss =  150.601\n",
      "testing  :  7415  accuracy =   0.8694  loss =  151.505\n",
      "training :  7416  accuracy =   0.8900  loss =  148.64\n",
      "testing  :  7416  accuracy =   0.8712  loss =  151.429\n",
      "training :  7417  accuracy =   0.8800  loss =  150.457\n",
      "testing  :  7417  accuracy =   0.8726  loss =  151.343\n",
      "training :  7418  accuracy =   0.8100  loss =  152.67\n",
      "testing  :  7418  accuracy =   0.8742  loss =  151.3\n",
      "training :  7419  accuracy =   0.9500  loss =  147.507\n",
      "testing  :  7419  accuracy =   0.8754  loss =  151.263\n",
      "training :  7420  accuracy =   0.9200  loss =  148.718\n",
      "testing  :  7420  accuracy =   0.8767  loss =  151.24\n",
      "training :  7421  accuracy =   0.8800  loss =  149.039\n",
      "testing  :  7421  accuracy =   0.8770  loss =  151.229\n",
      "training :  7422  accuracy =   0.9200  loss =  150.857\n",
      "testing  :  7422  accuracy =   0.8778  loss =  151.214\n",
      "training :  7423  accuracy =   0.8700  loss =  149.362\n",
      "testing  :  7423  accuracy =   0.8783  loss =  151.216\n",
      "training :  7424  accuracy =   0.9100  loss =  149.101\n",
      "testing  :  7424  accuracy =   0.8783  loss =  151.215\n",
      "training :  7425  accuracy =   0.9300  loss =  149.004\n",
      "testing  :  7425  accuracy =   0.8782  loss =  151.217\n",
      "training :  7426  accuracy =   0.8900  loss =  150.443\n",
      "testing  :  7426  accuracy =   0.8781  loss =  151.221\n",
      "training :  7427  accuracy =   0.8300  loss =  154.983\n",
      "testing  :  7427  accuracy =   0.8783  loss =  151.237\n",
      "training :  7428  accuracy =   0.9500  loss =  149.308\n",
      "testing  :  7428  accuracy =   0.8788  loss =  151.262\n",
      "training :  7429  accuracy =   0.8400  loss =  154.745\n",
      "testing  :  7429  accuracy =   0.8787  loss =  151.28\n",
      "training :  7430  accuracy =   0.9200  loss =  149.893\n",
      "testing  :  7430  accuracy =   0.8779  loss =  151.276\n",
      "training :  7431  accuracy =   0.9000  loss =  149.268\n",
      "testing  :  7431  accuracy =   0.8774  loss =  151.227\n",
      "training :  7432  accuracy =   0.8700  loss =  151.202\n",
      "testing  :  7432  accuracy =   0.8768  loss =  151.163\n",
      "training :  7433  accuracy =   0.8700  loss =  152.357\n",
      "testing  :  7433  accuracy =   0.8766  loss =  151.09\n",
      "training :  7434  accuracy =   0.8600  loss =  149.058\n",
      "testing  :  7434  accuracy =   0.8765  loss =  151.05\n",
      "training :  7435  accuracy =   0.8400  loss =  149.4\n",
      "testing  :  7435  accuracy =   0.8766  loss =  150.994\n",
      "training :  7436  accuracy =   0.8900  loss =  149.536\n",
      "testing  :  7436  accuracy =   0.8768  loss =  150.928\n",
      "training :  7437  accuracy =   0.8900  loss =  150.774\n",
      "testing  :  7437  accuracy =   0.8775  loss =  150.86\n",
      "training :  7438  accuracy =   0.9000  loss =  148.282\n",
      "testing  :  7438  accuracy =   0.8773  loss =  150.787\n",
      "training :  7439  accuracy =   0.8600  loss =  149.44\n",
      "testing  :  7439  accuracy =   0.8772  loss =  150.71\n",
      "training :  7440  accuracy =   0.9000  loss =  148.26\n",
      "testing  :  7440  accuracy =   0.8771  loss =  150.637\n",
      "training :  7441  accuracy =   0.9000  loss =  150.577\n",
      "testing  :  7441  accuracy =   0.8767  loss =  150.579\n",
      "training :  7442  accuracy =   0.8800  loss =  149.498\n",
      "testing  :  7442  accuracy =   0.8764  loss =  150.541\n",
      "training :  7443  accuracy =   0.9500  loss =  147.9\n",
      "testing  :  7443  accuracy =   0.8760  loss =  150.514\n",
      "training :  7444  accuracy =   0.9100  loss =  147.857\n",
      "testing  :  7444  accuracy =   0.8758  loss =  150.497\n",
      "training :  7445  accuracy =   0.9100  loss =  148.894\n",
      "testing  :  7445  accuracy =   0.8762  loss =  150.485\n",
      "training :  7446  accuracy =   0.9000  loss =  149.784\n",
      "testing  :  7446  accuracy =   0.8763  loss =  150.488\n",
      "training :  7447  accuracy =   0.9200  loss =  148.338\n",
      "testing  :  7447  accuracy =   0.8749  loss =  150.509\n",
      "training :  7448  accuracy =   0.9100  loss =  148.259\n",
      "testing  :  7448  accuracy =   0.8755  loss =  150.496\n",
      "training :  7449  accuracy =   0.8700  loss =  148.98\n",
      "testing  :  7449  accuracy =   0.8762  loss =  150.469\n",
      "training :  7450  accuracy =   0.9000  loss =  148.81\n",
      "testing  :  7450  accuracy =   0.8764  loss =  150.442\n",
      "training :  7451  accuracy =   0.9300  loss =  148.618\n",
      "testing  :  7451  accuracy =   0.8765  loss =  150.422\n",
      "training :  7452  accuracy =   0.8800  loss =  148.938\n",
      "testing  :  7452  accuracy =   0.8766  loss =  150.403\n",
      "training :  7453  accuracy =   0.8900  loss =  148.31\n",
      "testing  :  7453  accuracy =   0.8771  loss =  150.388\n",
      "training :  7454  accuracy =   0.8700  loss =  148.514\n",
      "testing  :  7454  accuracy =   0.8776  loss =  150.375\n",
      "training :  7455  accuracy =   0.8700  loss =  148.831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7455  accuracy =   0.8771  loss =  150.362\n",
      "training :  7456  accuracy =   0.9500  loss =  147.146\n",
      "testing  :  7456  accuracy =   0.8770  loss =  150.355\n",
      "training :  7457  accuracy =   0.8900  loss =  150.248\n",
      "testing  :  7457  accuracy =   0.8771  loss =  150.354\n",
      "training :  7458  accuracy =   0.8700  loss =  149.72\n",
      "testing  :  7458  accuracy =   0.8773  loss =  150.352\n",
      "training :  7459  accuracy =   0.9300  loss =  148.862\n",
      "testing  :  7459  accuracy =   0.8778  loss =  150.322\n",
      "training :  7460  accuracy =   0.8700  loss =  149.448\n",
      "testing  :  7460  accuracy =   0.8780  loss =  150.292\n",
      "training :  7461  accuracy =   0.8300  loss =  152.154\n",
      "testing  :  7461  accuracy =   0.8787  loss =  150.27\n",
      "training :  7462  accuracy =   0.8900  loss =  148.976\n",
      "testing  :  7462  accuracy =   0.8783  loss =  150.253\n",
      "training :  7463  accuracy =   0.9100  loss =  148.502\n",
      "testing  :  7463  accuracy =   0.8790  loss =  150.247\n",
      "training :  7464  accuracy =   0.8800  loss =  148.424\n",
      "testing  :  7464  accuracy =   0.8793  loss =  150.249\n",
      "training :  7465  accuracy =   0.9100  loss =  147.605\n",
      "testing  :  7465  accuracy =   0.8792  loss =  150.257\n",
      "training :  7466  accuracy =   0.9000  loss =  147.732\n",
      "testing  :  7466  accuracy =   0.8792  loss =  150.265\n",
      "training :  7467  accuracy =   0.8800  loss =  148.999\n",
      "testing  :  7467  accuracy =   0.8792  loss =  150.276\n",
      "training :  7468  accuracy =   0.9500  loss =  147.083\n",
      "testing  :  7468  accuracy =   0.8791  loss =  150.284\n",
      "training :  7469  accuracy =   0.8600  loss =  149.068\n",
      "testing  :  7469  accuracy =   0.8790  loss =  150.293\n",
      "training :  7470  accuracy =   0.9300  loss =  148.495\n",
      "testing  :  7470  accuracy =   0.8788  loss =  150.303\n",
      "training :  7471  accuracy =   0.9200  loss =  147.683\n",
      "testing  :  7471  accuracy =   0.8786  loss =  150.314\n",
      "training :  7472  accuracy =   0.9500  loss =  146.986\n",
      "testing  :  7472  accuracy =   0.8783  loss =  150.33\n",
      "training :  7473  accuracy =   0.9100  loss =  149.471\n",
      "testing  :  7473  accuracy =   0.8782  loss =  150.349\n",
      "training :  7474  accuracy =   0.9600  loss =  147.927\n",
      "testing  :  7474  accuracy =   0.8780  loss =  150.347\n",
      "training :  7475  accuracy =   0.8600  loss =  150.825\n",
      "testing  :  7475  accuracy =   0.8783  loss =  150.346\n",
      "training :  7476  accuracy =   0.8600  loss =  150.289\n",
      "testing  :  7476  accuracy =   0.8787  loss =  150.349\n",
      "training :  7477  accuracy =   0.9500  loss =  147.07\n",
      "testing  :  7477  accuracy =   0.8787  loss =  150.364\n",
      "training :  7478  accuracy =   0.8800  loss =  148.29\n",
      "testing  :  7478  accuracy =   0.8788  loss =  150.381\n",
      "training :  7479  accuracy =   0.9000  loss =  151.281\n",
      "testing  :  7479  accuracy =   0.8784  loss =  150.404\n",
      "training :  7480  accuracy =   0.8800  loss =  149.454\n",
      "testing  :  7480  accuracy =   0.8780  loss =  150.428\n",
      "training :  7481  accuracy =   0.8600  loss =  150.048\n",
      "testing  :  7481  accuracy =   0.8776  loss =  150.431\n",
      "training :  7482  accuracy =   0.9200  loss =  148.356\n",
      "testing  :  7482  accuracy =   0.8771  loss =  150.443\n",
      "training :  7483  accuracy =   0.9400  loss =  147.502\n",
      "testing  :  7483  accuracy =   0.8762  loss =  150.454\n",
      "training :  7484  accuracy =   0.8700  loss =  148.596\n",
      "testing  :  7484  accuracy =   0.8758  loss =  150.47\n",
      "training :  7485  accuracy =   0.8900  loss =  147.769\n",
      "testing  :  7485  accuracy =   0.8752  loss =  150.49\n",
      "training :  7486  accuracy =   0.8600  loss =  151.083\n",
      "testing  :  7486  accuracy =   0.8745  loss =  150.506\n",
      "training :  7487  accuracy =   0.8800  loss =  151.037\n",
      "testing  :  7487  accuracy =   0.8739  loss =  150.521\n",
      "training :  7488  accuracy =   0.8500  loss =  150.349\n",
      "testing  :  7488  accuracy =   0.8732  loss =  150.508\n",
      "training :  7489  accuracy =   0.9500  loss =  148.706\n",
      "testing  :  7489  accuracy =   0.8733  loss =  150.51\n",
      "training :  7490  accuracy =   0.8600  loss =  150.669\n",
      "testing  :  7490  accuracy =   0.8732  loss =  150.509\n",
      "training :  7491  accuracy =   0.8800  loss =  149.103\n",
      "testing  :  7491  accuracy =   0.8731  loss =  150.511\n",
      "training :  7492  accuracy =   0.9100  loss =  150.087\n",
      "testing  :  7492  accuracy =   0.8744  loss =  150.515\n",
      "training :  7493  accuracy =   0.8900  loss =  148.534\n",
      "testing  :  7493  accuracy =   0.8748  loss =  150.526\n",
      "training :  7494  accuracy =   0.9200  loss =  148.58\n",
      "testing  :  7494  accuracy =   0.8752  loss =  150.565\n",
      "training :  7495  accuracy =   0.8300  loss =  151.435\n",
      "testing  :  7495  accuracy =   0.8754  loss =  150.614\n",
      "training :  7496  accuracy =   0.9000  loss =  148.864\n",
      "testing  :  7496  accuracy =   0.8759  loss =  150.661\n",
      "training :  7497  accuracy =   0.8400  loss =  151.504\n",
      "testing  :  7497  accuracy =   0.8765  loss =  150.709\n",
      "training :  7498  accuracy =   0.9100  loss =  148.924\n",
      "testing  :  7498  accuracy =   0.8767  loss =  150.688\n",
      "training :  7499  accuracy =   0.9100  loss =  149.452\n",
      "testing  :  7499  accuracy =   0.8773  loss =  150.683\n",
      "training :  7500  accuracy =   0.9000  loss =  150.068\n",
      "testing  :  7500  accuracy =   0.8779  loss =  150.692\n",
      "training :  7501  accuracy =   0.8700  loss =  149.743\n",
      "testing  :  7501  accuracy =   0.8778  loss =  150.69\n",
      "training :  7502  accuracy =   0.9000  loss =  148.352\n",
      "testing  :  7502  accuracy =   0.8779  loss =  150.644\n",
      "training :  7503  accuracy =   0.8800  loss =  148.442\n",
      "testing  :  7503  accuracy =   0.8791  loss =  150.615\n",
      "training :  7504  accuracy =   0.8700  loss =  149.237\n",
      "testing  :  7504  accuracy =   0.8788  loss =  150.592\n",
      "training :  7505  accuracy =   0.8700  loss =  149.2\n",
      "testing  :  7505  accuracy =   0.8796  loss =  150.561\n",
      "training :  7506  accuracy =   0.8700  loss =  151.109\n",
      "testing  :  7506  accuracy =   0.8800  loss =  150.54\n",
      "training :  7507  accuracy =   0.9300  loss =  148.962\n",
      "testing  :  7507  accuracy =   0.8800  loss =  150.511\n",
      "training :  7508  accuracy =   0.8800  loss =  151.113\n",
      "testing  :  7508  accuracy =   0.8807  loss =  150.491\n",
      "training :  7509  accuracy =   0.8700  loss =  150.974\n",
      "testing  :  7509  accuracy =   0.8811  loss =  150.471\n",
      "training :  7510  accuracy =   0.8700  loss =  150.783\n",
      "testing  :  7510  accuracy =   0.8820  loss =  150.462\n",
      "training :  7511  accuracy =   0.8400  loss =  149.584\n",
      "testing  :  7511  accuracy =   0.8826  loss =  150.424\n",
      "training :  7512  accuracy =   0.9300  loss =  148.797\n",
      "testing  :  7512  accuracy =   0.8827  loss =  150.381\n",
      "training :  7513  accuracy =   0.9000  loss =  147.922\n",
      "testing  :  7513  accuracy =   0.8827  loss =  150.343\n",
      "training :  7514  accuracy =   0.9300  loss =  149.39\n",
      "testing  :  7514  accuracy =   0.8825  loss =  150.314\n",
      "training :  7515  accuracy =   0.8800  loss =  150.038\n",
      "testing  :  7515  accuracy =   0.8817  loss =  150.3\n",
      "training :  7516  accuracy =   0.8800  loss =  149.69\n",
      "testing  :  7516  accuracy =   0.8816  loss =  150.297\n",
      "training :  7517  accuracy =   0.9200  loss =  149.106\n",
      "testing  :  7517  accuracy =   0.8813  loss =  150.307\n",
      "training :  7518  accuracy =   0.9000  loss =  150.496\n",
      "testing  :  7518  accuracy =   0.8813  loss =  150.317\n",
      "training :  7519  accuracy =   0.8500  loss =  150.704\n",
      "testing  :  7519  accuracy =   0.8814  loss =  150.324\n",
      "training :  7520  accuracy =   0.8900  loss =  149.092\n",
      "testing  :  7520  accuracy =   0.8803  loss =  150.331\n",
      "training :  7521  accuracy =   0.8900  loss =  148.095\n",
      "testing  :  7521  accuracy =   0.8783  loss =  150.348\n",
      "training :  7522  accuracy =   0.9200  loss =  147.585\n",
      "testing  :  7522  accuracy =   0.8774  loss =  150.369\n",
      "training :  7523  accuracy =   0.8800  loss =  149.455\n",
      "testing  :  7523  accuracy =   0.8761  loss =  150.394\n",
      "training :  7524  accuracy =   0.9000  loss =  148.771\n",
      "testing  :  7524  accuracy =   0.8755  loss =  150.392\n",
      "training :  7525  accuracy =   0.9100  loss =  149.753\n",
      "testing  :  7525  accuracy =   0.8751  loss =  150.381\n",
      "training :  7526  accuracy =   0.9000  loss =  149.655\n",
      "testing  :  7526  accuracy =   0.8754  loss =  150.372\n",
      "training :  7527  accuracy =   0.9400  loss =  149.103\n",
      "testing  :  7527  accuracy =   0.8755  loss =  150.331\n",
      "training :  7528  accuracy =   0.8700  loss =  149.192\n",
      "testing  :  7528  accuracy =   0.8759  loss =  150.299\n",
      "training :  7529  accuracy =   0.8900  loss =  149.34\n",
      "testing  :  7529  accuracy =   0.8775  loss =  150.237\n",
      "training :  7530  accuracy =   0.8800  loss =  149.851\n",
      "testing  :  7530  accuracy =   0.8790  loss =  150.2\n",
      "training :  7531  accuracy =   0.9000  loss =  148.66\n",
      "testing  :  7531  accuracy =   0.8804  loss =  150.182\n",
      "training :  7532  accuracy =   0.8700  loss =  148.72\n",
      "testing  :  7532  accuracy =   0.8821  loss =  150.197\n",
      "training :  7533  accuracy =   0.9000  loss =  148.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7533  accuracy =   0.8830  loss =  150.241\n",
      "training :  7534  accuracy =   0.9100  loss =  149.891\n",
      "testing  :  7534  accuracy =   0.8834  loss =  150.281\n",
      "training :  7535  accuracy =   0.9300  loss =  149.1\n",
      "testing  :  7535  accuracy =   0.8839  loss =  150.307\n",
      "training :  7536  accuracy =   0.8900  loss =  150.768\n",
      "testing  :  7536  accuracy =   0.8840  loss =  150.323\n",
      "training :  7537  accuracy =   0.8600  loss =  150.609\n",
      "testing  :  7537  accuracy =   0.8838  loss =  150.354\n",
      "training :  7538  accuracy =   0.9200  loss =  148.377\n",
      "testing  :  7538  accuracy =   0.8836  loss =  150.375\n",
      "training :  7539  accuracy =   0.9100  loss =  147.979\n",
      "testing  :  7539  accuracy =   0.8834  loss =  150.409\n",
      "training :  7540  accuracy =   0.9100  loss =  149.867\n",
      "testing  :  7540  accuracy =   0.8836  loss =  150.426\n",
      "training :  7541  accuracy =   0.8700  loss =  150.474\n",
      "testing  :  7541  accuracy =   0.8832  loss =  150.449\n",
      "training :  7542  accuracy =   0.9100  loss =  148.671\n",
      "testing  :  7542  accuracy =   0.8830  loss =  150.46\n",
      "training :  7543  accuracy =   0.9000  loss =  149.533\n",
      "testing  :  7543  accuracy =   0.8818  loss =  150.482\n",
      "training :  7544  accuracy =   0.9000  loss =  148.355\n",
      "testing  :  7544  accuracy =   0.8811  loss =  150.496\n",
      "training :  7545  accuracy =   0.8900  loss =  148.987\n",
      "testing  :  7545  accuracy =   0.8811  loss =  150.511\n",
      "training :  7546  accuracy =   0.9000  loss =  149.102\n",
      "testing  :  7546  accuracy =   0.8808  loss =  150.534\n",
      "training :  7547  accuracy =   0.8900  loss =  148.078\n",
      "testing  :  7547  accuracy =   0.8820  loss =  150.544\n",
      "training :  7548  accuracy =   0.8600  loss =  150.702\n",
      "testing  :  7548  accuracy =   0.8837  loss =  150.524\n",
      "training :  7549  accuracy =   0.8500  loss =  148.68\n",
      "testing  :  7549  accuracy =   0.8849  loss =  150.511\n",
      "training :  7550  accuracy =   0.9100  loss =  148.684\n",
      "testing  :  7550  accuracy =   0.8862  loss =  150.504\n",
      "training :  7551  accuracy =   0.8700  loss =  148.083\n",
      "testing  :  7551  accuracy =   0.8866  loss =  150.544\n",
      "training :  7552  accuracy =   0.9200  loss =  149.169\n",
      "testing  :  7552  accuracy =   0.8885  loss =  150.581\n",
      "training :  7553  accuracy =   0.9100  loss =  151.472\n",
      "testing  :  7553  accuracy =   0.8907  loss =  150.628\n",
      "training :  7554  accuracy =   0.9000  loss =  149.65\n",
      "testing  :  7554  accuracy =   0.8939  loss =  150.577\n",
      "training :  7555  accuracy =   0.9300  loss =  150.32\n",
      "testing  :  7555  accuracy =   0.8969  loss =  150.524\n",
      "training :  7556  accuracy =   0.9100  loss =  150.78\n",
      "testing  :  7556  accuracy =   0.8991  loss =  150.509\n",
      "training :  7557  accuracy =   0.9000  loss =  149.557\n",
      "testing  :  7557  accuracy =   0.9014  loss =  150.516\n",
      "training :  7558  accuracy =   0.9100  loss =  148.929\n",
      "testing  :  7558  accuracy =   0.9031  loss =  150.554\n",
      "training :  7559  accuracy =   0.9300  loss =  148.202\n",
      "testing  :  7559  accuracy =   0.9034  loss =  150.587\n",
      "training :  7560  accuracy =   0.9300  loss =  149.538\n",
      "testing  :  7560  accuracy =   0.9040  loss =  150.598\n",
      "training :  7561  accuracy =   0.9100  loss =  148.228\n",
      "testing  :  7561  accuracy =   0.9045  loss =  150.596\n",
      "training :  7562  accuracy =   0.9100  loss =  149.069\n",
      "testing  :  7562  accuracy =   0.9055  loss =  150.596\n",
      "training :  7563  accuracy =   0.9200  loss =  148.822\n",
      "testing  :  7563  accuracy =   0.9054  loss =  150.59\n",
      "training :  7564  accuracy =   0.9200  loss =  150.868\n",
      "testing  :  7564  accuracy =   0.9038  loss =  150.574\n",
      "training :  7565  accuracy =   0.9100  loss =  149.256\n",
      "testing  :  7565  accuracy =   0.9043  loss =  150.566\n",
      "training :  7566  accuracy =   0.8900  loss =  150.394\n",
      "testing  :  7566  accuracy =   0.9067  loss =  150.468\n",
      "training :  7567  accuracy =   0.9400  loss =  147.613\n",
      "testing  :  7567  accuracy =   0.9103  loss =  150.366\n",
      "training :  7568  accuracy =   0.9500  loss =  148.348\n",
      "testing  :  7568  accuracy =   0.9129  loss =  150.274\n",
      "training :  7569  accuracy =   0.9800  loss =  147.275\n",
      "testing  :  7569  accuracy =   0.9151  loss =  150.214\n",
      "training :  7570  accuracy =   0.9500  loss =  149.373\n",
      "testing  :  7570  accuracy =   0.9171  loss =  150.181\n",
      "training :  7571  accuracy =   0.9500  loss =  147.599\n",
      "testing  :  7571  accuracy =   0.9183  loss =  150.161\n",
      "training :  7572  accuracy =   0.9100  loss =  148.889\n",
      "testing  :  7572  accuracy =   0.9197  loss =  150.13\n",
      "training :  7573  accuracy =   0.9200  loss =  148.443\n",
      "testing  :  7573  accuracy =   0.9222  loss =  150.109\n",
      "training :  7574  accuracy =   0.8900  loss =  151.239\n",
      "testing  :  7574  accuracy =   0.9241  loss =  150.096\n",
      "training :  7575  accuracy =   0.9500  loss =  147.465\n",
      "testing  :  7575  accuracy =   0.9276  loss =  150.097\n",
      "training :  7576  accuracy =   0.9900  loss =  148.017\n",
      "testing  :  7576  accuracy =   0.9317  loss =  150.107\n",
      "training :  7577  accuracy =   0.9500  loss =  147.842\n",
      "testing  :  7577  accuracy =   0.9365  loss =  150.12\n",
      "training :  7578  accuracy =   0.9400  loss =  148.861\n",
      "testing  :  7578  accuracy =   0.9384  loss =  150.13\n",
      "training :  7579  accuracy =   0.9700  loss =  148.333\n",
      "testing  :  7579  accuracy =   0.9401  loss =  150.133\n",
      "training :  7580  accuracy =   0.9500  loss =  151.209\n",
      "testing  :  7580  accuracy =   0.9422  loss =  150.151\n",
      "training :  7581  accuracy =   0.9500  loss =  149.867\n",
      "testing  :  7581  accuracy =   0.9454  loss =  150.175\n",
      "training :  7582  accuracy =   0.9500  loss =  151.047\n",
      "testing  :  7582  accuracy =   0.9492  loss =  150.182\n",
      "training :  7583  accuracy =   0.9800  loss =  147.375\n",
      "testing  :  7583  accuracy =   0.9504  loss =  150.195\n",
      "training :  7584  accuracy =   0.9400  loss =  149.872\n",
      "testing  :  7584  accuracy =   0.9520  loss =  150.211\n",
      "training :  7585  accuracy =   0.9800  loss =  148.131\n",
      "testing  :  7585  accuracy =   0.9537  loss =  150.201\n",
      "training :  7586  accuracy =   0.9600  loss =  150.008\n",
      "testing  :  7586  accuracy =   0.9538  loss =  150.209\n",
      "training :  7587  accuracy =   0.9500  loss =  150.342\n",
      "testing  :  7587  accuracy =   0.9572  loss =  149.994\n",
      "training :  7588  accuracy =   0.9900  loss =  147.525\n",
      "testing  :  7588  accuracy =   0.9595  loss =  149.831\n",
      "training :  7589  accuracy =   1.0000  loss =  147.096\n",
      "testing  :  7589  accuracy =   0.9606  loss =  149.725\n",
      "training :  7590  accuracy =   0.9800  loss =  148.82\n",
      "testing  :  7590  accuracy =   0.9619  loss =  149.657\n",
      "training :  7591  accuracy =   0.9800  loss =  148.601\n",
      "testing  :  7591  accuracy =   0.9622  loss =  149.625\n",
      "training :  7592  accuracy =   0.9700  loss =  149.882\n",
      "testing  :  7592  accuracy =   0.9622  loss =  149.603\n",
      "training :  7593  accuracy =   0.9600  loss =  149.681\n",
      "testing  :  7593  accuracy =   0.9621  loss =  149.596\n",
      "training :  7594  accuracy =   1.0000  loss =  146.576\n",
      "testing  :  7594  accuracy =   0.9613  loss =  149.59\n",
      "training :  7595  accuracy =   0.9400  loss =  151.043\n",
      "testing  :  7595  accuracy =   0.9614  loss =  149.611\n",
      "training :  7596  accuracy =   0.9500  loss =  151.051\n",
      "testing  :  7596  accuracy =   0.9613  loss =  149.647\n",
      "training :  7597  accuracy =   0.9700  loss =  147.994\n",
      "testing  :  7597  accuracy =   0.9606  loss =  149.685\n",
      "training :  7598  accuracy =   1.0000  loss =  146.519\n",
      "testing  :  7598  accuracy =   0.9599  loss =  149.709\n",
      "training :  7599  accuracy =   0.9600  loss =  149.839\n",
      "testing  :  7599  accuracy =   0.9602  loss =  149.737\n",
      "training :  7600  accuracy =   0.9700  loss =  149.976\n",
      "testing  :  7600  accuracy =   0.9600  loss =  149.748\n",
      "training :  7601  accuracy =   0.9800  loss =  147.901\n",
      "testing  :  7601  accuracy =   0.9598  loss =  149.74\n",
      "training :  7602  accuracy =   0.9900  loss =  147.14\n",
      "testing  :  7602  accuracy =   0.9596  loss =  149.7\n",
      "training :  7603  accuracy =   1.0000  loss =  146.476\n",
      "testing  :  7603  accuracy =   0.9602  loss =  149.613\n",
      "training :  7604  accuracy =   0.9600  loss =  150.535\n",
      "testing  :  7604  accuracy =   0.9620  loss =  149.542\n",
      "training :  7605  accuracy =   1.0000  loss =  146.312\n",
      "testing  :  7605  accuracy =   0.9627  loss =  149.48\n",
      "training :  7606  accuracy =   1.0000  loss =  146.723\n",
      "testing  :  7606  accuracy =   0.9636  loss =  149.421\n",
      "training :  7607  accuracy =   0.9800  loss =  148.836\n",
      "testing  :  7607  accuracy =   0.9637  loss =  149.385\n",
      "training :  7608  accuracy =   0.9900  loss =  147.364\n",
      "testing  :  7608  accuracy =   0.9637  loss =  149.36\n",
      "training :  7609  accuracy =   0.9900  loss =  147.662\n",
      "testing  :  7609  accuracy =   0.9642  loss =  149.343\n",
      "training :  7610  accuracy =   0.9800  loss =  147.768\n",
      "testing  :  7610  accuracy =   0.9645  loss =  149.341\n",
      "training :  7611  accuracy =   0.9900  loss =  147.944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7611  accuracy =   0.9643  loss =  149.345\n",
      "training :  7612  accuracy =   0.9600  loss =  149.798\n",
      "testing  :  7612  accuracy =   0.9648  loss =  149.335\n",
      "training :  7613  accuracy =   0.9800  loss =  148.308\n",
      "testing  :  7613  accuracy =   0.9642  loss =  149.343\n",
      "training :  7614  accuracy =   0.9700  loss =  148.673\n",
      "testing  :  7614  accuracy =   0.9641  loss =  149.368\n",
      "training :  7615  accuracy =   0.9700  loss =  149.587\n",
      "testing  :  7615  accuracy =   0.9641  loss =  149.382\n",
      "training :  7616  accuracy =   0.9700  loss =  148.528\n",
      "testing  :  7616  accuracy =   0.9638  loss =  149.394\n",
      "training :  7617  accuracy =   0.9900  loss =  146.471\n",
      "testing  :  7617  accuracy =   0.9641  loss =  149.407\n",
      "training :  7618  accuracy =   0.9600  loss =  149.468\n",
      "testing  :  7618  accuracy =   0.9645  loss =  149.41\n",
      "training :  7619  accuracy =   0.9600  loss =  148.169\n",
      "testing  :  7619  accuracy =   0.9647  loss =  149.423\n",
      "training :  7620  accuracy =   0.9500  loss =  150.182\n",
      "testing  :  7620  accuracy =   0.9642  loss =  149.46\n",
      "training :  7621  accuracy =   0.9700  loss =  147.994\n",
      "testing  :  7621  accuracy =   0.9638  loss =  149.484\n",
      "training :  7622  accuracy =   0.9900  loss =  147.532\n",
      "testing  :  7622  accuracy =   0.9634  loss =  149.485\n",
      "training :  7623  accuracy =   0.9900  loss =  147.78\n",
      "testing  :  7623  accuracy =   0.9631  loss =  149.486\n",
      "training :  7624  accuracy =   1.0000  loss =  146.693\n",
      "testing  :  7624  accuracy =   0.9634  loss =  149.472\n",
      "training :  7625  accuracy =   0.9800  loss =  148.134\n",
      "testing  :  7625  accuracy =   0.9638  loss =  149.464\n",
      "training :  7626  accuracy =   0.9800  loss =  148.589\n",
      "testing  :  7626  accuracy =   0.9630  loss =  149.47\n",
      "training :  7627  accuracy =   1.0000  loss =  146.479\n",
      "testing  :  7627  accuracy =   0.9630  loss =  149.477\n",
      "training :  7628  accuracy =   0.9500  loss =  150.669\n",
      "testing  :  7628  accuracy =   0.9627  loss =  149.488\n",
      "training :  7629  accuracy =   1.0000  loss =  146.742\n",
      "testing  :  7629  accuracy =   0.9619  loss =  149.499\n",
      "training :  7630  accuracy =   0.9900  loss =  147.442\n",
      "testing  :  7630  accuracy =   0.9624  loss =  149.5\n",
      "training :  7631  accuracy =   0.9600  loss =  149.654\n",
      "testing  :  7631  accuracy =   0.9620  loss =  149.494\n",
      "training :  7632  accuracy =   0.9600  loss =  149.699\n",
      "testing  :  7632  accuracy =   0.9625  loss =  149.494\n",
      "training :  7633  accuracy =   0.9900  loss =  146.938\n",
      "testing  :  7633  accuracy =   0.9617  loss =  149.479\n",
      "training :  7634  accuracy =   1.0000  loss =  146.555\n",
      "testing  :  7634  accuracy =   0.9616  loss =  149.489\n",
      "training :  7635  accuracy =   0.9800  loss =  148.557\n",
      "testing  :  7635  accuracy =   0.9612  loss =  149.489\n",
      "training :  7636  accuracy =   0.9600  loss =  148.84\n",
      "testing  :  7636  accuracy =   0.9624  loss =  149.457\n",
      "training :  7637  accuracy =   0.9700  loss =  149.068\n",
      "testing  :  7637  accuracy =   0.9631  loss =  149.436\n",
      "training :  7638  accuracy =   0.9900  loss =  147.408\n",
      "testing  :  7638  accuracy =   0.9634  loss =  149.415\n",
      "training :  7639  accuracy =   0.9700  loss =  148.764\n",
      "testing  :  7639  accuracy =   0.9640  loss =  149.416\n",
      "training :  7640  accuracy =   0.9900  loss =  146.85\n",
      "testing  :  7640  accuracy =   0.9641  loss =  149.411\n",
      "training :  7641  accuracy =   1.0000  loss =  146.728\n",
      "testing  :  7641  accuracy =   0.9640  loss =  149.434\n",
      "training :  7642  accuracy =   0.9800  loss =  148.278\n",
      "testing  :  7642  accuracy =   0.9638  loss =  149.436\n",
      "training :  7643  accuracy =   0.9800  loss =  147.162\n",
      "testing  :  7643  accuracy =   0.9633  loss =  149.45\n",
      "training :  7644  accuracy =   0.9700  loss =  148.905\n",
      "testing  :  7644  accuracy =   0.9628  loss =  149.427\n",
      "training :  7645  accuracy =   0.9900  loss =  147.438\n",
      "testing  :  7645  accuracy =   0.9627  loss =  149.421\n",
      "training :  7646  accuracy =   0.9800  loss =  148.168\n",
      "testing  :  7646  accuracy =   0.9625  loss =  149.428\n",
      "training :  7647  accuracy =   0.9800  loss =  148.378\n",
      "testing  :  7647  accuracy =   0.9627  loss =  149.435\n",
      "training :  7648  accuracy =   0.9900  loss =  147.409\n",
      "testing  :  7648  accuracy =   0.9625  loss =  149.438\n",
      "training :  7649  accuracy =   0.9700  loss =  148.667\n",
      "testing  :  7649  accuracy =   0.9617  loss =  149.458\n",
      "training :  7650  accuracy =   1.0000  loss =  146.665\n",
      "testing  :  7650  accuracy =   0.9609  loss =  149.479\n",
      "training :  7651  accuracy =   0.9700  loss =  148.7\n",
      "testing  :  7651  accuracy =   0.9603  loss =  149.486\n",
      "training :  7652  accuracy =   0.9600  loss =  149.652\n",
      "testing  :  7652  accuracy =   0.9606  loss =  149.492\n",
      "training :  7653  accuracy =   0.9900  loss =  146.931\n",
      "testing  :  7653  accuracy =   0.9612  loss =  149.463\n",
      "training :  7654  accuracy =   0.9800  loss =  148.849\n",
      "testing  :  7654  accuracy =   0.9618  loss =  149.43\n",
      "training :  7655  accuracy =   0.9500  loss =  150.606\n",
      "testing  :  7655  accuracy =   0.9623  loss =  149.394\n",
      "training :  7656  accuracy =   1.0000  loss =  146.278\n",
      "testing  :  7656  accuracy =   0.9621  loss =  149.409\n",
      "training :  7657  accuracy =   0.9800  loss =  148.343\n",
      "testing  :  7657  accuracy =   0.9617  loss =  149.426\n",
      "training :  7658  accuracy =   1.0000  loss =  146.501\n",
      "testing  :  7658  accuracy =   0.9621  loss =  149.367\n",
      "training :  7659  accuracy =   0.9800  loss =  148.699\n",
      "testing  :  7659  accuracy =   0.9624  loss =  149.323\n",
      "training :  7660  accuracy =   0.9800  loss =  147.499\n",
      "testing  :  7660  accuracy =   0.9631  loss =  149.28\n",
      "training :  7661  accuracy =   0.9500  loss =  150.15\n",
      "testing  :  7661  accuracy =   0.9636  loss =  149.252\n",
      "training :  7662  accuracy =   0.9800  loss =  147.692\n",
      "testing  :  7662  accuracy =   0.9652  loss =  149.201\n",
      "training :  7663  accuracy =   0.9900  loss =  147.376\n",
      "testing  :  7663  accuracy =   0.9654  loss =  149.182\n",
      "training :  7664  accuracy =   0.9500  loss =  149.272\n",
      "testing  :  7664  accuracy =   0.9659  loss =  149.184\n",
      "training :  7665  accuracy =   0.9900  loss =  147.522\n",
      "testing  :  7665  accuracy =   0.9655  loss =  149.199\n",
      "training :  7666  accuracy =   0.9800  loss =  147.108\n",
      "testing  :  7666  accuracy =   0.9650  loss =  149.217\n",
      "training :  7667  accuracy =   0.9800  loss =  146.975\n",
      "testing  :  7667  accuracy =   0.9648  loss =  149.252\n",
      "training :  7668  accuracy =   0.9700  loss =  149.399\n",
      "testing  :  7668  accuracy =   0.9642  loss =  149.275\n",
      "training :  7669  accuracy =   0.9500  loss =  150.191\n",
      "testing  :  7669  accuracy =   0.9640  loss =  149.296\n",
      "training :  7670  accuracy =   0.9500  loss =  149.972\n",
      "testing  :  7670  accuracy =   0.9635  loss =  149.307\n",
      "training :  7671  accuracy =   0.9600  loss =  149.616\n",
      "testing  :  7671  accuracy =   0.9635  loss =  149.316\n",
      "training :  7672  accuracy =   0.9700  loss =  149.535\n",
      "testing  :  7672  accuracy =   0.9636  loss =  149.333\n",
      "training :  7673  accuracy =   0.9400  loss =  150.876\n",
      "testing  :  7673  accuracy =   0.9636  loss =  149.353\n",
      "training :  7674  accuracy =   1.0000  loss =  146.752\n",
      "testing  :  7674  accuracy =   0.9626  loss =  149.374\n",
      "training :  7675  accuracy =   1.0000  loss =  146.309\n",
      "testing  :  7675  accuracy =   0.9620  loss =  149.39\n",
      "training :  7676  accuracy =   0.9500  loss =  149.644\n",
      "testing  :  7676  accuracy =   0.9622  loss =  149.405\n",
      "training :  7677  accuracy =   0.9700  loss =  147.831\n",
      "testing  :  7677  accuracy =   0.9626  loss =  149.328\n",
      "training :  7678  accuracy =   0.9700  loss =  148.182\n",
      "testing  :  7678  accuracy =   0.9641  loss =  149.22\n",
      "training :  7679  accuracy =   0.9800  loss =  148.631\n",
      "testing  :  7679  accuracy =   0.9656  loss =  149.122\n",
      "training :  7680  accuracy =   0.9400  loss =  150.217\n",
      "testing  :  7680  accuracy =   0.9661  loss =  149.083\n",
      "training :  7681  accuracy =   0.9600  loss =  149.91\n",
      "testing  :  7681  accuracy =   0.9660  loss =  149.086\n",
      "training :  7682  accuracy =   0.9800  loss =  148.465\n",
      "testing  :  7682  accuracy =   0.9650  loss =  149.113\n",
      "training :  7683  accuracy =   0.9500  loss =  149.384\n",
      "testing  :  7683  accuracy =   0.9645  loss =  149.159\n",
      "training :  7684  accuracy =   0.9600  loss =  148.587\n",
      "testing  :  7684  accuracy =   0.9629  loss =  149.203\n",
      "training :  7685  accuracy =   0.9800  loss =  147.388\n",
      "testing  :  7685  accuracy =   0.9613  loss =  149.244\n",
      "training :  7686  accuracy =   0.9600  loss =  148.089\n",
      "testing  :  7686  accuracy =   0.9606  loss =  149.289\n",
      "training :  7687  accuracy =   0.9900  loss =  146.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7687  accuracy =   0.9617  loss =  149.252\n",
      "training :  7688  accuracy =   0.9900  loss =  147.554\n",
      "testing  :  7688  accuracy =   0.9617  loss =  149.27\n",
      "training :  7689  accuracy =   0.9900  loss =  146.782\n",
      "testing  :  7689  accuracy =   0.9628  loss =  149.297\n",
      "training :  7690  accuracy =   0.9600  loss =  149.011\n",
      "testing  :  7690  accuracy =   0.9636  loss =  149.317\n",
      "training :  7691  accuracy =   0.9400  loss =  151.111\n",
      "testing  :  7691  accuracy =   0.9633  loss =  149.283\n",
      "training :  7692  accuracy =   0.9600  loss =  149.817\n",
      "testing  :  7692  accuracy =   0.9641  loss =  149.233\n",
      "training :  7693  accuracy =   0.9800  loss =  148.65\n",
      "testing  :  7693  accuracy =   0.9638  loss =  149.208\n",
      "training :  7694  accuracy =   0.9900  loss =  146.534\n",
      "testing  :  7694  accuracy =   0.9642  loss =  149.132\n",
      "training :  7695  accuracy =   0.9800  loss =  147.681\n",
      "testing  :  7695  accuracy =   0.9652  loss =  149.113\n",
      "training :  7696  accuracy =   0.9800  loss =  147.895\n",
      "testing  :  7696  accuracy =   0.9639  loss =  149.121\n",
      "training :  7697  accuracy =   0.9700  loss =  149.494\n",
      "testing  :  7697  accuracy =   0.9646  loss =  149.155\n",
      "training :  7698  accuracy =   0.9800  loss =  148.005\n",
      "testing  :  7698  accuracy =   0.9643  loss =  149.219\n",
      "training :  7699  accuracy =   0.9900  loss =  147.338\n",
      "testing  :  7699  accuracy =   0.9635  loss =  149.285\n",
      "training :  7700  accuracy =   0.9900  loss =  147.559\n",
      "testing  :  7700  accuracy =   0.9614  loss =  149.39\n",
      "training :  7701  accuracy =   0.9600  loss =  149.048\n",
      "testing  :  7701  accuracy =   0.9606  loss =  149.5\n",
      "training :  7702  accuracy =   0.9700  loss =  148.643\n",
      "testing  :  7702  accuracy =   0.9586  loss =  149.706\n",
      "training :  7703  accuracy =   0.9400  loss =  149.983\n",
      "testing  :  7703  accuracy =   0.9570  loss =  149.93\n",
      "training :  7704  accuracy =   0.9800  loss =  147.71\n",
      "testing  :  7704  accuracy =   0.9557  loss =  150.07\n",
      "training :  7705  accuracy =   0.9500  loss =  150.408\n",
      "testing  :  7705  accuracy =   0.9538  loss =  150.181\n",
      "training :  7706  accuracy =   0.9900  loss =  147.849\n",
      "testing  :  7706  accuracy =   0.9564  loss =  149.955\n",
      "training :  7707  accuracy =   0.9700  loss =  148.588\n",
      "testing  :  7707  accuracy =   0.9581  loss =  149.776\n",
      "training :  7708  accuracy =   0.9400  loss =  151.405\n",
      "testing  :  7708  accuracy =   0.9597  loss =  149.548\n",
      "training :  7709  accuracy =   0.9700  loss =  147.871\n",
      "testing  :  7709  accuracy =   0.9636  loss =  149.281\n",
      "training :  7710  accuracy =   0.9700  loss =  148.297\n",
      "testing  :  7710  accuracy =   0.9648  loss =  149.126\n",
      "training :  7711  accuracy =   0.9600  loss =  147.784\n",
      "testing  :  7711  accuracy =   0.9648  loss =  149.073\n",
      "training :  7712  accuracy =   0.9800  loss =  148.44\n",
      "testing  :  7712  accuracy =   0.9634  loss =  149.172\n",
      "training :  7713  accuracy =   0.9400  loss =  150.39\n",
      "testing  :  7713  accuracy =   0.9623  loss =  149.36\n",
      "training :  7714  accuracy =   0.9800  loss =  147.624\n",
      "testing  :  7714  accuracy =   0.9612  loss =  149.488\n",
      "training :  7715  accuracy =   1.0000  loss =  146.652\n",
      "testing  :  7715  accuracy =   0.9596  loss =  149.648\n",
      "training :  7716  accuracy =   0.9800  loss =  147.732\n",
      "testing  :  7716  accuracy =   0.9576  loss =  149.819\n",
      "training :  7717  accuracy =   0.9600  loss =  150.067\n",
      "testing  :  7717  accuracy =   0.9560  loss =  149.92\n",
      "training :  7718  accuracy =   0.9500  loss =  150.127\n",
      "testing  :  7718  accuracy =   0.9585  loss =  149.793\n",
      "training :  7719  accuracy =   0.9700  loss =  148.693\n",
      "testing  :  7719  accuracy =   0.9602  loss =  149.566\n",
      "training :  7720  accuracy =   0.9600  loss =  148.824\n",
      "testing  :  7720  accuracy =   0.9620  loss =  149.442\n",
      "training :  7721  accuracy =   0.9800  loss =  148.248\n",
      "testing  :  7721  accuracy =   0.9624  loss =  149.41\n",
      "training :  7722  accuracy =   0.9700  loss =  147.88\n",
      "testing  :  7722  accuracy =   0.9623  loss =  149.418\n",
      "training :  7723  accuracy =   0.9700  loss =  147.373\n",
      "testing  :  7723  accuracy =   0.9615  loss =  149.437\n",
      "training :  7724  accuracy =   0.9500  loss =  149.543\n",
      "testing  :  7724  accuracy =   0.9610  loss =  149.505\n",
      "training :  7725  accuracy =   0.9600  loss =  150.514\n",
      "testing  :  7725  accuracy =   0.9595  loss =  149.609\n",
      "training :  7726  accuracy =   0.9800  loss =  147.576\n",
      "testing  :  7726  accuracy =   0.9573  loss =  149.746\n",
      "training :  7727  accuracy =   0.9700  loss =  148.956\n",
      "testing  :  7727  accuracy =   0.9550  loss =  149.91\n",
      "training :  7728  accuracy =   0.9900  loss =  147.116\n",
      "testing  :  7728  accuracy =   0.9542  loss =  150.006\n",
      "training :  7729  accuracy =   0.9200  loss =  153.231\n",
      "testing  :  7729  accuracy =   0.9525  loss =  150.086\n",
      "training :  7730  accuracy =   0.9600  loss =  148.09\n",
      "testing  :  7730  accuracy =   0.9515  loss =  150.099\n",
      "training :  7731  accuracy =   0.9800  loss =  147.728\n",
      "testing  :  7731  accuracy =   0.9526  loss =  150.089\n",
      "training :  7732  accuracy =   0.9500  loss =  148.924\n",
      "testing  :  7732  accuracy =   0.9536  loss =  150.066\n",
      "training :  7733  accuracy =   0.9600  loss =  148.454\n",
      "testing  :  7733  accuracy =   0.9584  loss =  149.797\n",
      "training :  7734  accuracy =   0.9800  loss =  147.987\n",
      "testing  :  7734  accuracy =   0.9613  loss =  149.451\n",
      "training :  7735  accuracy =   0.9900  loss =  147.269\n",
      "testing  :  7735  accuracy =   0.9638  loss =  149.222\n",
      "training :  7736  accuracy =   0.9700  loss =  148.749\n",
      "testing  :  7736  accuracy =   0.9650  loss =  149.09\n",
      "training :  7737  accuracy =   1.0000  loss =  146.612\n",
      "testing  :  7737  accuracy =   0.9659  loss =  149.01\n",
      "training :  7738  accuracy =   0.9700  loss =  149.38\n",
      "testing  :  7738  accuracy =   0.9657  loss =  148.988\n",
      "training :  7739  accuracy =   0.9700  loss =  147.552\n",
      "testing  :  7739  accuracy =   0.9657  loss =  149.021\n",
      "training :  7740  accuracy =   0.9700  loss =  149.411\n",
      "testing  :  7740  accuracy =   0.9654  loss =  149.055\n",
      "training :  7741  accuracy =   0.9900  loss =  147.16\n",
      "testing  :  7741  accuracy =   0.9644  loss =  149.099\n",
      "training :  7742  accuracy =   0.9600  loss =  149.971\n",
      "testing  :  7742  accuracy =   0.9637  loss =  149.163\n",
      "training :  7743  accuracy =   0.9500  loss =  150.766\n",
      "testing  :  7743  accuracy =   0.9630  loss =  149.217\n",
      "training :  7744  accuracy =   0.9800  loss =  147.562\n",
      "testing  :  7744  accuracy =   0.9627  loss =  149.285\n",
      "training :  7745  accuracy =   0.9800  loss =  147.295\n",
      "testing  :  7745  accuracy =   0.9621  loss =  149.314\n",
      "training :  7746  accuracy =   0.9900  loss =  147.506\n",
      "testing  :  7746  accuracy =   0.9622  loss =  149.314\n",
      "training :  7747  accuracy =   1.0000  loss =  146.54\n",
      "testing  :  7747  accuracy =   0.9619  loss =  149.311\n",
      "training :  7748  accuracy =   0.9700  loss =  149.587\n",
      "testing  :  7748  accuracy =   0.9625  loss =  149.306\n",
      "training :  7749  accuracy =   1.0000  loss =  146.761\n",
      "testing  :  7749  accuracy =   0.9623  loss =  149.308\n",
      "training :  7750  accuracy =   0.9900  loss =  147.434\n",
      "testing  :  7750  accuracy =   0.9620  loss =  149.301\n",
      "training :  7751  accuracy =   1.0000  loss =  146.911\n",
      "testing  :  7751  accuracy =   0.9631  loss =  149.286\n",
      "training :  7752  accuracy =   0.9900  loss =  146.546\n",
      "testing  :  7752  accuracy =   0.9630  loss =  149.264\n",
      "training :  7753  accuracy =   0.9400  loss =  150.521\n",
      "testing  :  7753  accuracy =   0.9631  loss =  149.241\n",
      "training :  7754  accuracy =   1.0000  loss =  146.37\n",
      "testing  :  7754  accuracy =   0.9626  loss =  149.217\n",
      "training :  7755  accuracy =   0.9800  loss =  147.834\n",
      "testing  :  7755  accuracy =   0.9631  loss =  149.211\n",
      "training :  7756  accuracy =   0.9900  loss =  146.948\n",
      "testing  :  7756  accuracy =   0.9635  loss =  149.206\n",
      "training :  7757  accuracy =   0.9800  loss =  147.475\n",
      "testing  :  7757  accuracy =   0.9634  loss =  149.194\n",
      "training :  7758  accuracy =   0.9700  loss =  148.1\n",
      "testing  :  7758  accuracy =   0.9635  loss =  149.198\n",
      "training :  7759  accuracy =   0.9900  loss =  148.259\n",
      "testing  :  7759  accuracy =   0.9630  loss =  149.22\n",
      "training :  7760  accuracy =   0.9600  loss =  149.113\n",
      "testing  :  7760  accuracy =   0.9625  loss =  149.284\n",
      "training :  7761  accuracy =   0.9700  loss =  147.205\n",
      "testing  :  7761  accuracy =   0.9615  loss =  149.354\n",
      "training :  7762  accuracy =   0.9800  loss =  148.646\n",
      "testing  :  7762  accuracy =   0.9612  loss =  149.355\n",
      "training :  7763  accuracy =   0.9900  loss =  147.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7763  accuracy =   0.9615  loss =  149.333\n",
      "training :  7764  accuracy =   1.0000  loss =  146.776\n",
      "testing  :  7764  accuracy =   0.9616  loss =  149.32\n",
      "training :  7765  accuracy =   0.9900  loss =  147.209\n",
      "testing  :  7765  accuracy =   0.9619  loss =  149.296\n",
      "training :  7766  accuracy =   0.9700  loss =  147.286\n",
      "testing  :  7766  accuracy =   0.9626  loss =  149.277\n",
      "training :  7767  accuracy =   0.9600  loss =  148.9\n",
      "testing  :  7767  accuracy =   0.9629  loss =  149.242\n",
      "training :  7768  accuracy =   0.9700  loss =  147.328\n",
      "testing  :  7768  accuracy =   0.9630  loss =  149.192\n",
      "training :  7769  accuracy =   0.9800  loss =  147.027\n",
      "testing  :  7769  accuracy =   0.9638  loss =  149.143\n",
      "training :  7770  accuracy =   0.9600  loss =  149.502\n",
      "testing  :  7770  accuracy =   0.9639  loss =  149.114\n",
      "training :  7771  accuracy =   0.9800  loss =  148.651\n",
      "testing  :  7771  accuracy =   0.9640  loss =  149.093\n",
      "training :  7772  accuracy =   0.9900  loss =  147.519\n",
      "testing  :  7772  accuracy =   0.9643  loss =  149.066\n",
      "training :  7773  accuracy =   0.9800  loss =  147.368\n",
      "testing  :  7773  accuracy =   0.9645  loss =  149.053\n",
      "training :  7774  accuracy =   0.9900  loss =  147.426\n",
      "testing  :  7774  accuracy =   0.9648  loss =  149.056\n",
      "training :  7775  accuracy =   0.9600  loss =  149.913\n",
      "testing  :  7775  accuracy =   0.9649  loss =  149.063\n",
      "training :  7776  accuracy =   0.9800  loss =  148.66\n",
      "testing  :  7776  accuracy =   0.9651  loss =  149.062\n",
      "training :  7777  accuracy =   0.9800  loss =  148.66\n",
      "testing  :  7777  accuracy =   0.9656  loss =  149.057\n",
      "training :  7778  accuracy =   0.9800  loss =  147.779\n",
      "testing  :  7778  accuracy =   0.9658  loss =  149.046\n",
      "training :  7779  accuracy =   0.9800  loss =  147.56\n",
      "testing  :  7779  accuracy =   0.9660  loss =  149.033\n",
      "training :  7780  accuracy =   0.9900  loss =  146.652\n",
      "testing  :  7780  accuracy =   0.9663  loss =  149.022\n",
      "training :  7781  accuracy =   0.9900  loss =  147.487\n",
      "testing  :  7781  accuracy =   0.9667  loss =  149.013\n",
      "training :  7782  accuracy =   0.9700  loss =  149.189\n",
      "testing  :  7782  accuracy =   0.9662  loss =  149.007\n",
      "training :  7783  accuracy =   0.9800  loss =  147.6\n",
      "testing  :  7783  accuracy =   0.9662  loss =  149.007\n",
      "training :  7784  accuracy =   0.9800  loss =  147.921\n",
      "testing  :  7784  accuracy =   0.9660  loss =  149.015\n",
      "training :  7785  accuracy =   0.9900  loss =  147.576\n",
      "testing  :  7785  accuracy =   0.9665  loss =  149.014\n",
      "training :  7786  accuracy =   0.9600  loss =  150.533\n",
      "testing  :  7786  accuracy =   0.9666  loss =  149.027\n",
      "training :  7787  accuracy =   0.9700  loss =  147.923\n",
      "testing  :  7787  accuracy =   0.9658  loss =  149.053\n",
      "training :  7788  accuracy =   0.9800  loss =  148.644\n",
      "testing  :  7788  accuracy =   0.9653  loss =  149.063\n",
      "training :  7789  accuracy =   0.9700  loss =  148.254\n",
      "testing  :  7789  accuracy =   0.9650  loss =  149.077\n",
      "training :  7790  accuracy =   0.9900  loss =  147.437\n",
      "testing  :  7790  accuracy =   0.9646  loss =  149.093\n",
      "training :  7791  accuracy =   0.9800  loss =  147.536\n",
      "testing  :  7791  accuracy =   0.9647  loss =  149.11\n",
      "training :  7792  accuracy =   0.9600  loss =  150.087\n",
      "testing  :  7792  accuracy =   0.9646  loss =  149.138\n",
      "training :  7793  accuracy =   0.9800  loss =  148.447\n",
      "testing  :  7793  accuracy =   0.9646  loss =  149.158\n",
      "training :  7794  accuracy =   0.9900  loss =  147.391\n",
      "testing  :  7794  accuracy =   0.9647  loss =  149.19\n",
      "training :  7795  accuracy =   0.9800  loss =  147.509\n",
      "testing  :  7795  accuracy =   0.9633  loss =  149.238\n",
      "training :  7796  accuracy =   0.9700  loss =  148.719\n",
      "testing  :  7796  accuracy =   0.9628  loss =  149.301\n",
      "training :  7797  accuracy =   0.9600  loss =  147.769\n",
      "testing  :  7797  accuracy =   0.9621  loss =  149.362\n",
      "training :  7798  accuracy =   0.9800  loss =  148.121\n",
      "testing  :  7798  accuracy =   0.9615  loss =  149.414\n",
      "training :  7799  accuracy =   0.9800  loss =  147.888\n",
      "testing  :  7799  accuracy =   0.9611  loss =  149.462\n",
      "training :  7800  accuracy =   0.9700  loss =  148.224\n",
      "testing  :  7800  accuracy =   0.9611  loss =  149.519\n",
      "training :  7801  accuracy =   1.0000  loss =  146.559\n",
      "testing  :  7801  accuracy =   0.9600  loss =  149.599\n",
      "training :  7802  accuracy =   0.9500  loss =  149.971\n",
      "testing  :  7802  accuracy =   0.9588  loss =  149.709\n",
      "training :  7803  accuracy =   0.9800  loss =  148.739\n",
      "testing  :  7803  accuracy =   0.9575  loss =  149.784\n",
      "training :  7804  accuracy =   0.9900  loss =  147.543\n",
      "testing  :  7804  accuracy =   0.9571  loss =  149.832\n",
      "training :  7805  accuracy =   0.9400  loss =  153.121\n",
      "testing  :  7805  accuracy =   0.9565  loss =  149.906\n",
      "training :  7806  accuracy =   0.9600  loss =  149.029\n",
      "testing  :  7806  accuracy =   0.9550  loss =  149.962\n",
      "training :  7807  accuracy =   0.9900  loss =  147.551\n",
      "testing  :  7807  accuracy =   0.9555  loss =  149.942\n",
      "training :  7808  accuracy =   0.9900  loss =  147.087\n",
      "testing  :  7808  accuracy =   0.9556  loss =  149.896\n",
      "training :  7809  accuracy =   0.9600  loss =  148.636\n",
      "testing  :  7809  accuracy =   0.9564  loss =  149.8\n",
      "training :  7810  accuracy =   0.9800  loss =  147.629\n",
      "testing  :  7810  accuracy =   0.9611  loss =  149.489\n",
      "training :  7811  accuracy =   0.9700  loss =  149.177\n",
      "testing  :  7811  accuracy =   0.9642  loss =  149.291\n",
      "training :  7812  accuracy =   0.9800  loss =  147.947\n",
      "testing  :  7812  accuracy =   0.9657  loss =  149.149\n",
      "training :  7813  accuracy =   0.9700  loss =  147.879\n",
      "testing  :  7813  accuracy =   0.9672  loss =  149.044\n",
      "training :  7814  accuracy =   0.9900  loss =  146.94\n",
      "testing  :  7814  accuracy =   0.9677  loss =  148.986\n",
      "training :  7815  accuracy =   1.0000  loss =  146.995\n",
      "testing  :  7815  accuracy =   0.9675  loss =  148.978\n",
      "training :  7816  accuracy =   1.0000  loss =  146.427\n",
      "testing  :  7816  accuracy =   0.9677  loss =  149.005\n",
      "training :  7817  accuracy =   1.0000  loss =  146.571\n",
      "testing  :  7817  accuracy =   0.9667  loss =  149.028\n",
      "training :  7818  accuracy =   0.9700  loss =  148.137\n",
      "testing  :  7818  accuracy =   0.9665  loss =  149.06\n",
      "training :  7819  accuracy =   0.9900  loss =  147.439\n",
      "testing  :  7819  accuracy =   0.9663  loss =  149.09\n",
      "training :  7820  accuracy =   0.9900  loss =  147.211\n",
      "testing  :  7820  accuracy =   0.9661  loss =  149.111\n",
      "training :  7821  accuracy =   0.9900  loss =  147.33\n",
      "testing  :  7821  accuracy =   0.9658  loss =  149.104\n",
      "training :  7822  accuracy =   0.9800  loss =  146.888\n",
      "testing  :  7822  accuracy =   0.9659  loss =  149.101\n",
      "training :  7823  accuracy =   0.9900  loss =  146.854\n",
      "testing  :  7823  accuracy =   0.9664  loss =  149.102\n",
      "training :  7824  accuracy =   0.9800  loss =  147.442\n",
      "testing  :  7824  accuracy =   0.9666  loss =  149.082\n",
      "training :  7825  accuracy =   0.9900  loss =  147.478\n",
      "testing  :  7825  accuracy =   0.9673  loss =  149.043\n",
      "training :  7826  accuracy =   0.9800  loss =  147.576\n",
      "testing  :  7826  accuracy =   0.9674  loss =  149.027\n",
      "training :  7827  accuracy =   0.9800  loss =  147.4\n",
      "testing  :  7827  accuracy =   0.9677  loss =  149.024\n",
      "training :  7828  accuracy =   0.9900  loss =  146.592\n",
      "testing  :  7828  accuracy =   0.9672  loss =  149.015\n",
      "training :  7829  accuracy =   0.9800  loss =  148.398\n",
      "testing  :  7829  accuracy =   0.9667  loss =  149.009\n",
      "training :  7830  accuracy =   0.9800  loss =  147.46\n",
      "testing  :  7830  accuracy =   0.9661  loss =  149.003\n",
      "training :  7831  accuracy =   0.9900  loss =  146.761\n",
      "testing  :  7831  accuracy =   0.9665  loss =  149.003\n",
      "training :  7832  accuracy =   0.9600  loss =  149.714\n",
      "testing  :  7832  accuracy =   0.9661  loss =  149.008\n",
      "training :  7833  accuracy =   0.9700  loss =  149.136\n",
      "testing  :  7833  accuracy =   0.9659  loss =  149.022\n",
      "training :  7834  accuracy =   0.9500  loss =  150.443\n",
      "testing  :  7834  accuracy =   0.9662  loss =  149.025\n",
      "training :  7835  accuracy =   0.9800  loss =  147.886\n",
      "testing  :  7835  accuracy =   0.9665  loss =  149.027\n",
      "training :  7836  accuracy =   0.9800  loss =  147.806\n",
      "testing  :  7836  accuracy =   0.9661  loss =  149.03\n",
      "training :  7837  accuracy =   0.9800  loss =  148.294\n",
      "testing  :  7837  accuracy =   0.9656  loss =  149.036\n",
      "training :  7838  accuracy =   0.9800  loss =  147.508\n",
      "testing  :  7838  accuracy =   0.9659  loss =  149.041\n",
      "training :  7839  accuracy =   0.9800  loss =  147.05\n",
      "testing  :  7839  accuracy =   0.9660  loss =  149.05\n",
      "training :  7840  accuracy =   1.0000  loss =  146.439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7840  accuracy =   0.9665  loss =  149.028\n",
      "training :  7841  accuracy =   0.9900  loss =  146.438\n",
      "testing  :  7841  accuracy =   0.9669  loss =  149.005\n",
      "training :  7842  accuracy =   1.0000  loss =  146.458\n",
      "testing  :  7842  accuracy =   0.9674  loss =  148.984\n",
      "training :  7843  accuracy =   0.9700  loss =  148.713\n",
      "testing  :  7843  accuracy =   0.9676  loss =  148.969\n",
      "training :  7844  accuracy =   0.9900  loss =  146.805\n",
      "testing  :  7844  accuracy =   0.9679  loss =  148.953\n",
      "training :  7845  accuracy =   0.9900  loss =  147.721\n",
      "testing  :  7845  accuracy =   0.9681  loss =  148.941\n",
      "training :  7846  accuracy =   0.9600  loss =  149.715\n",
      "testing  :  7846  accuracy =   0.9682  loss =  148.927\n",
      "training :  7847  accuracy =   0.9800  loss =  146.795\n",
      "testing  :  7847  accuracy =   0.9684  loss =  148.933\n",
      "training :  7848  accuracy =   0.9900  loss =  147.287\n",
      "testing  :  7848  accuracy =   0.9683  loss =  148.938\n",
      "training :  7849  accuracy =   0.9700  loss =  148.231\n",
      "testing  :  7849  accuracy =   0.9681  loss =  148.944\n",
      "training :  7850  accuracy =   0.9900  loss =  146.827\n",
      "testing  :  7850  accuracy =   0.9676  loss =  148.945\n",
      "training :  7851  accuracy =   0.9700  loss =  148.916\n",
      "testing  :  7851  accuracy =   0.9679  loss =  148.942\n",
      "training :  7852  accuracy =   0.9900  loss =  147.376\n",
      "testing  :  7852  accuracy =   0.9677  loss =  148.947\n",
      "training :  7853  accuracy =   0.9700  loss =  148.187\n",
      "testing  :  7853  accuracy =   0.9669  loss =  148.968\n",
      "training :  7854  accuracy =   0.9600  loss =  149.123\n",
      "testing  :  7854  accuracy =   0.9667  loss =  148.985\n",
      "training :  7855  accuracy =   0.9900  loss =  146.69\n",
      "testing  :  7855  accuracy =   0.9670  loss =  148.999\n",
      "training :  7856  accuracy =   1.0000  loss =  146.525\n",
      "testing  :  7856  accuracy =   0.9677  loss =  149.022\n",
      "training :  7857  accuracy =   0.9900  loss =  146.552\n",
      "testing  :  7857  accuracy =   0.9677  loss =  149.036\n",
      "training :  7858  accuracy =   0.9900  loss =  147.744\n",
      "testing  :  7858  accuracy =   0.9675  loss =  149.05\n",
      "training :  7859  accuracy =   0.9900  loss =  146.744\n",
      "testing  :  7859  accuracy =   0.9677  loss =  149.054\n",
      "training :  7860  accuracy =   0.9600  loss =  149.51\n",
      "testing  :  7860  accuracy =   0.9684  loss =  149.051\n",
      "training :  7861  accuracy =   0.9600  loss =  149.772\n",
      "testing  :  7861  accuracy =   0.9682  loss =  149.042\n",
      "training :  7862  accuracy =   1.0000  loss =  146.652\n",
      "testing  :  7862  accuracy =   0.9674  loss =  149.027\n",
      "training :  7863  accuracy =   0.9800  loss =  147.527\n",
      "testing  :  7863  accuracy =   0.9670  loss =  149.02\n",
      "training :  7864  accuracy =   0.9800  loss =  147.621\n",
      "testing  :  7864  accuracy =   0.9665  loss =  148.991\n",
      "training :  7865  accuracy =   0.9900  loss =  147.282\n",
      "testing  :  7865  accuracy =   0.9669  loss =  148.977\n",
      "training :  7866  accuracy =   0.9800  loss =  146.881\n",
      "testing  :  7866  accuracy =   0.9668  loss =  148.973\n",
      "training :  7867  accuracy =   0.9600  loss =  148.936\n",
      "testing  :  7867  accuracy =   0.9671  loss =  148.975\n",
      "training :  7868  accuracy =   0.9900  loss =  146.652\n",
      "testing  :  7868  accuracy =   0.9672  loss =  148.957\n",
      "training :  7869  accuracy =   0.9900  loss =  146.541\n",
      "testing  :  7869  accuracy =   0.9678  loss =  148.947\n",
      "training :  7870  accuracy =   0.9600  loss =  149.345\n",
      "testing  :  7870  accuracy =   0.9671  loss =  148.942\n",
      "training :  7871  accuracy =   0.9800  loss =  146.856\n",
      "testing  :  7871  accuracy =   0.9664  loss =  148.963\n",
      "training :  7872  accuracy =   0.9600  loss =  148.496\n",
      "testing  :  7872  accuracy =   0.9657  loss =  149.029\n",
      "training :  7873  accuracy =   0.9900  loss =  146.531\n",
      "testing  :  7873  accuracy =   0.9647  loss =  149.127\n",
      "training :  7874  accuracy =   0.9800  loss =  147.739\n",
      "testing  :  7874  accuracy =   0.9635  loss =  149.233\n",
      "training :  7875  accuracy =   0.9700  loss =  149.153\n",
      "testing  :  7875  accuracy =   0.9626  loss =  149.315\n",
      "training :  7876  accuracy =   0.9500  loss =  149.042\n",
      "testing  :  7876  accuracy =   0.9620  loss =  149.401\n",
      "training :  7877  accuracy =   0.9800  loss =  147.567\n",
      "testing  :  7877  accuracy =   0.9617  loss =  149.398\n",
      "training :  7878  accuracy =   0.9800  loss =  148.506\n",
      "testing  :  7878  accuracy =   0.9622  loss =  149.392\n",
      "training :  7879  accuracy =   0.9600  loss =  147.715\n",
      "testing  :  7879  accuracy =   0.9619  loss =  149.393\n",
      "training :  7880  accuracy =   0.9700  loss =  148.649\n",
      "testing  :  7880  accuracy =   0.9622  loss =  149.369\n",
      "training :  7881  accuracy =   0.9800  loss =  148.449\n",
      "testing  :  7881  accuracy =   0.9626  loss =  149.327\n",
      "training :  7882  accuracy =   1.0000  loss =  146.42\n",
      "testing  :  7882  accuracy =   0.9630  loss =  149.302\n",
      "training :  7883  accuracy =   0.9700  loss =  148.701\n",
      "testing  :  7883  accuracy =   0.9634  loss =  149.28\n",
      "training :  7884  accuracy =   0.9900  loss =  147.15\n",
      "testing  :  7884  accuracy =   0.9637  loss =  149.251\n",
      "training :  7885  accuracy =   0.9800  loss =  147.7\n",
      "testing  :  7885  accuracy =   0.9640  loss =  149.244\n",
      "training :  7886  accuracy =   0.9700  loss =  148.173\n",
      "testing  :  7886  accuracy =   0.9642  loss =  149.226\n",
      "training :  7887  accuracy =   1.0000  loss =  146.469\n",
      "testing  :  7887  accuracy =   0.9642  loss =  149.216\n",
      "training :  7888  accuracy =   0.9800  loss =  147.905\n",
      "testing  :  7888  accuracy =   0.9639  loss =  149.214\n",
      "training :  7889  accuracy =   0.9900  loss =  147.431\n",
      "testing  :  7889  accuracy =   0.9648  loss =  149.186\n",
      "training :  7890  accuracy =   0.9900  loss =  146.782\n",
      "testing  :  7890  accuracy =   0.9654  loss =  149.152\n",
      "training :  7891  accuracy =   0.9800  loss =  147.35\n",
      "testing  :  7891  accuracy =   0.9652  loss =  149.13\n",
      "training :  7892  accuracy =   0.9600  loss =  149.24\n",
      "testing  :  7892  accuracy =   0.9670  loss =  149.064\n",
      "training :  7893  accuracy =   0.9800  loss =  147.047\n",
      "testing  :  7893  accuracy =   0.9667  loss =  149.009\n",
      "training :  7894  accuracy =   0.9800  loss =  148.699\n",
      "testing  :  7894  accuracy =   0.9673  loss =  148.985\n",
      "training :  7895  accuracy =   0.9900  loss =  147.211\n",
      "testing  :  7895  accuracy =   0.9674  loss =  148.99\n",
      "training :  7896  accuracy =   0.9700  loss =  148.507\n",
      "testing  :  7896  accuracy =   0.9676  loss =  149.007\n",
      "training :  7897  accuracy =   0.9700  loss =  147.805\n",
      "testing  :  7897  accuracy =   0.9672  loss =  149.031\n",
      "training :  7898  accuracy =   0.9700  loss =  148.212\n",
      "testing  :  7898  accuracy =   0.9668  loss =  149.065\n",
      "training :  7899  accuracy =   0.9400  loss =  151.863\n",
      "testing  :  7899  accuracy =   0.9666  loss =  149.096\n",
      "training :  7900  accuracy =   0.9600  loss =  148.734\n",
      "testing  :  7900  accuracy =   0.9658  loss =  149.101\n",
      "training :  7901  accuracy =   0.9900  loss =  146.674\n",
      "testing  :  7901  accuracy =   0.9655  loss =  149.117\n",
      "training :  7902  accuracy =   0.9500  loss =  151.211\n",
      "testing  :  7902  accuracy =   0.9645  loss =  149.133\n",
      "training :  7903  accuracy =   0.9900  loss =  147.706\n",
      "testing  :  7903  accuracy =   0.9647  loss =  149.147\n",
      "training :  7904  accuracy =   0.9900  loss =  147.278\n",
      "testing  :  7904  accuracy =   0.9647  loss =  149.185\n",
      "training :  7905  accuracy =   0.9700  loss =  148.653\n",
      "testing  :  7905  accuracy =   0.9635  loss =  149.228\n",
      "training :  7906  accuracy =   0.9800  loss =  147.923\n",
      "testing  :  7906  accuracy =   0.9633  loss =  149.271\n",
      "training :  7907  accuracy =   0.9800  loss =  146.64\n",
      "testing  :  7907  accuracy =   0.9630  loss =  149.251\n",
      "training :  7908  accuracy =   0.9700  loss =  149.017\n",
      "testing  :  7908  accuracy =   0.9637  loss =  149.228\n",
      "training :  7909  accuracy =   0.9900  loss =  147.445\n",
      "testing  :  7909  accuracy =   0.9645  loss =  149.211\n",
      "training :  7910  accuracy =   0.9600  loss =  150.278\n",
      "testing  :  7910  accuracy =   0.9645  loss =  149.189\n",
      "training :  7911  accuracy =   0.9900  loss =  146.422\n",
      "testing  :  7911  accuracy =   0.9643  loss =  149.172\n",
      "training :  7912  accuracy =   0.9800  loss =  147.863\n",
      "testing  :  7912  accuracy =   0.9643  loss =  149.17\n",
      "training :  7913  accuracy =   0.9700  loss =  147.626\n",
      "testing  :  7913  accuracy =   0.9640  loss =  149.162\n",
      "training :  7914  accuracy =   0.9900  loss =  147.492\n",
      "testing  :  7914  accuracy =   0.9646  loss =  149.169\n",
      "training :  7915  accuracy =   0.9700  loss =  148.6\n",
      "testing  :  7915  accuracy =   0.9645  loss =  149.183\n",
      "training :  7916  accuracy =   0.9600  loss =  150.506\n",
      "testing  :  7916  accuracy =   0.9645  loss =  149.197\n",
      "training :  7917  accuracy =   0.9900  loss =  147.543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7917  accuracy =   0.9636  loss =  149.208\n",
      "training :  7918  accuracy =   0.9800  loss =  148.465\n",
      "testing  :  7918  accuracy =   0.9639  loss =  149.22\n",
      "training :  7919  accuracy =   0.9700  loss =  148.586\n",
      "testing  :  7919  accuracy =   0.9639  loss =  149.241\n",
      "training :  7920  accuracy =   0.9900  loss =  147.341\n",
      "testing  :  7920  accuracy =   0.9639  loss =  149.238\n",
      "training :  7921  accuracy =   0.9800  loss =  148.954\n",
      "testing  :  7921  accuracy =   0.9642  loss =  149.236\n",
      "training :  7922  accuracy =   0.9600  loss =  148.994\n",
      "testing  :  7922  accuracy =   0.9641  loss =  149.228\n",
      "training :  7923  accuracy =   1.0000  loss =  146.308\n",
      "testing  :  7923  accuracy =   0.9644  loss =  149.208\n",
      "training :  7924  accuracy =   0.9900  loss =  146.998\n",
      "testing  :  7924  accuracy =   0.9643  loss =  149.187\n",
      "training :  7925  accuracy =   0.9700  loss =  148.657\n",
      "testing  :  7925  accuracy =   0.9649  loss =  149.165\n",
      "training :  7926  accuracy =   1.0000  loss =  146.397\n",
      "testing  :  7926  accuracy =   0.9652  loss =  149.15\n",
      "training :  7927  accuracy =   1.0000  loss =  146.773\n",
      "testing  :  7927  accuracy =   0.9653  loss =  149.138\n",
      "training :  7928  accuracy =   0.9600  loss =  149.96\n",
      "testing  :  7928  accuracy =   0.9656  loss =  149.132\n",
      "training :  7929  accuracy =   0.9900  loss =  147.359\n",
      "testing  :  7929  accuracy =   0.9658  loss =  149.127\n",
      "training :  7930  accuracy =   0.9600  loss =  148.473\n",
      "testing  :  7930  accuracy =   0.9659  loss =  149.123\n",
      "training :  7931  accuracy =   0.9700  loss =  148.383\n",
      "testing  :  7931  accuracy =   0.9650  loss =  149.12\n",
      "training :  7932  accuracy =   1.0000  loss =  146.353\n",
      "testing  :  7932  accuracy =   0.9654  loss =  149.125\n",
      "training :  7933  accuracy =   0.9700  loss =  148.668\n",
      "testing  :  7933  accuracy =   0.9654  loss =  149.146\n",
      "training :  7934  accuracy =   0.9800  loss =  148.824\n",
      "testing  :  7934  accuracy =   0.9655  loss =  149.169\n",
      "training :  7935  accuracy =   0.9800  loss =  147.486\n",
      "testing  :  7935  accuracy =   0.9655  loss =  149.197\n",
      "training :  7936  accuracy =   0.9700  loss =  148.849\n",
      "testing  :  7936  accuracy =   0.9651  loss =  149.224\n",
      "training :  7937  accuracy =   0.9600  loss =  149.538\n",
      "testing  :  7937  accuracy =   0.9646  loss =  149.26\n",
      "training :  7938  accuracy =   0.9800  loss =  148.668\n",
      "testing  :  7938  accuracy =   0.9640  loss =  149.293\n",
      "training :  7939  accuracy =   0.9400  loss =  151.018\n",
      "testing  :  7939  accuracy =   0.9637  loss =  149.316\n",
      "training :  7940  accuracy =   0.9700  loss =  147.997\n",
      "testing  :  7940  accuracy =   0.9633  loss =  149.331\n",
      "training :  7941  accuracy =   0.9700  loss =  148.818\n",
      "testing  :  7941  accuracy =   0.9634  loss =  149.337\n",
      "training :  7942  accuracy =   0.9700  loss =  148.606\n",
      "testing  :  7942  accuracy =   0.9627  loss =  149.335\n",
      "training :  7943  accuracy =   1.0000  loss =  146.346\n",
      "testing  :  7943  accuracy =   0.9630  loss =  149.339\n",
      "training :  7944  accuracy =   0.9800  loss =  147.596\n",
      "testing  :  7944  accuracy =   0.9628  loss =  149.342\n",
      "training :  7945  accuracy =   0.9800  loss =  148.249\n",
      "testing  :  7945  accuracy =   0.9624  loss =  149.36\n",
      "training :  7946  accuracy =   0.9900  loss =  146.706\n",
      "testing  :  7946  accuracy =   0.9620  loss =  149.37\n",
      "training :  7947  accuracy =   0.9600  loss =  149.237\n",
      "testing  :  7947  accuracy =   0.9619  loss =  149.357\n",
      "training :  7948  accuracy =   0.9800  loss =  147.381\n",
      "testing  :  7948  accuracy =   0.9637  loss =  149.26\n",
      "training :  7949  accuracy =   1.0000  loss =  146.247\n",
      "testing  :  7949  accuracy =   0.9648  loss =  149.186\n",
      "training :  7950  accuracy =   1.0000  loss =  146.303\n",
      "testing  :  7950  accuracy =   0.9649  loss =  149.157\n",
      "training :  7951  accuracy =   1.0000  loss =  146.334\n",
      "testing  :  7951  accuracy =   0.9651  loss =  149.152\n",
      "training :  7952  accuracy =   0.9500  loss =  150.033\n",
      "testing  :  7952  accuracy =   0.9658  loss =  149.158\n",
      "training :  7953  accuracy =   0.9700  loss =  149.271\n",
      "testing  :  7953  accuracy =   0.9654  loss =  149.163\n",
      "training :  7954  accuracy =   0.9800  loss =  146.551\n",
      "testing  :  7954  accuracy =   0.9658  loss =  149.15\n",
      "training :  7955  accuracy =   0.9800  loss =  147.535\n",
      "testing  :  7955  accuracy =   0.9655  loss =  149.138\n",
      "training :  7956  accuracy =   0.9600  loss =  149.634\n",
      "testing  :  7956  accuracy =   0.9650  loss =  149.139\n",
      "training :  7957  accuracy =   0.9900  loss =  146.652\n",
      "testing  :  7957  accuracy =   0.9644  loss =  149.136\n",
      "training :  7958  accuracy =   1.0000  loss =  146.277\n",
      "testing  :  7958  accuracy =   0.9643  loss =  149.131\n",
      "training :  7959  accuracy =   0.9600  loss =  149.229\n",
      "testing  :  7959  accuracy =   0.9647  loss =  149.135\n",
      "training :  7960  accuracy =   0.9800  loss =  147.274\n",
      "testing  :  7960  accuracy =   0.9650  loss =  149.121\n",
      "training :  7961  accuracy =   0.9500  loss =  150.704\n",
      "testing  :  7961  accuracy =   0.9647  loss =  149.114\n",
      "training :  7962  accuracy =   0.9800  loss =  147.554\n",
      "testing  :  7962  accuracy =   0.9654  loss =  149.124\n",
      "training :  7963  accuracy =   0.9900  loss =  147.222\n",
      "testing  :  7963  accuracy =   0.9649  loss =  149.144\n",
      "training :  7964  accuracy =   0.9700  loss =  148.567\n",
      "testing  :  7964  accuracy =   0.9646  loss =  149.159\n",
      "training :  7965  accuracy =   0.9900  loss =  147.554\n",
      "testing  :  7965  accuracy =   0.9653  loss =  149.144\n",
      "training :  7966  accuracy =   0.9700  loss =  148.714\n",
      "testing  :  7966  accuracy =   0.9655  loss =  149.139\n",
      "training :  7967  accuracy =   0.9900  loss =  146.581\n",
      "testing  :  7967  accuracy =   0.9659  loss =  149.133\n",
      "training :  7968  accuracy =   0.9400  loss =  151.197\n",
      "testing  :  7968  accuracy =   0.9653  loss =  149.132\n",
      "training :  7969  accuracy =   0.9800  loss =  148.308\n",
      "testing  :  7969  accuracy =   0.9650  loss =  149.126\n",
      "training :  7970  accuracy =   0.9700  loss =  148.409\n",
      "testing  :  7970  accuracy =   0.9647  loss =  149.123\n",
      "training :  7971  accuracy =   0.9900  loss =  146.454\n",
      "testing  :  7971  accuracy =   0.9647  loss =  149.123\n",
      "training :  7972  accuracy =   0.9700  loss =  148.417\n",
      "testing  :  7972  accuracy =   0.9648  loss =  149.128\n",
      "training :  7973  accuracy =   0.9700  loss =  148.272\n",
      "testing  :  7973  accuracy =   0.9645  loss =  149.135\n",
      "training :  7974  accuracy =   0.9700  loss =  148.546\n",
      "testing  :  7974  accuracy =   0.9648  loss =  149.134\n",
      "training :  7975  accuracy =   0.9800  loss =  147.86\n",
      "testing  :  7975  accuracy =   0.9645  loss =  149.129\n",
      "training :  7976  accuracy =   0.9200  loss =  149.37\n",
      "testing  :  7976  accuracy =   0.9640  loss =  149.126\n",
      "training :  7977  accuracy =   0.9700  loss =  148.953\n",
      "testing  :  7977  accuracy =   0.9629  loss =  149.134\n",
      "training :  7978  accuracy =   0.9800  loss =  147.031\n",
      "testing  :  7978  accuracy =   0.9624  loss =  149.148\n",
      "training :  7979  accuracy =   0.9500  loss =  148.593\n",
      "testing  :  7979  accuracy =   0.9624  loss =  149.156\n",
      "training :  7980  accuracy =   0.9800  loss =  147.162\n",
      "testing  :  7980  accuracy =   0.9632  loss =  149.118\n",
      "training :  7981  accuracy =   0.9500  loss =  150.026\n",
      "testing  :  7981  accuracy =   0.9639  loss =  149.053\n",
      "training :  7982  accuracy =   1.0000  loss =  146.757\n",
      "testing  :  7982  accuracy =   0.9654  loss =  148.993\n",
      "training :  7983  accuracy =   0.9700  loss =  147.809\n",
      "testing  :  7983  accuracy =   0.9652  loss =  148.955\n",
      "training :  7984  accuracy =   0.9800  loss =  147.782\n",
      "testing  :  7984  accuracy =   0.9659  loss =  148.98\n",
      "training :  7985  accuracy =   0.9900  loss =  147.395\n",
      "testing  :  7985  accuracy =   0.9661  loss =  149.031\n",
      "training :  7986  accuracy =   0.9900  loss =  147.201\n",
      "testing  :  7986  accuracy =   0.9653  loss =  149.092\n",
      "training :  7987  accuracy =   0.9800  loss =  148.406\n",
      "testing  :  7987  accuracy =   0.9647  loss =  149.126\n",
      "training :  7988  accuracy =   0.9800  loss =  147.851\n",
      "testing  :  7988  accuracy =   0.9641  loss =  149.168\n",
      "training :  7989  accuracy =   0.9500  loss =  149.745\n",
      "testing  :  7989  accuracy =   0.9637  loss =  149.202\n",
      "training :  7990  accuracy =   0.9800  loss =  147.52\n",
      "testing  :  7990  accuracy =   0.9633  loss =  149.224\n",
      "training :  7991  accuracy =   0.9800  loss =  147.641\n",
      "testing  :  7991  accuracy =   0.9638  loss =  149.152\n",
      "training :  7992  accuracy =   0.9500  loss =  149.763\n",
      "testing  :  7992  accuracy =   0.9647  loss =  149.1\n",
      "training :  7993  accuracy =   0.9900  loss =  147.405\n",
      "testing  :  7993  accuracy =   0.9651  loss =  149.034\n",
      "training :  7994  accuracy =   0.9600  loss =  148.537\n",
      "testing  :  7994  accuracy =   0.9658  loss =  148.987\n",
      "training :  7995  accuracy =   0.9800  loss =  147.628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  7995  accuracy =   0.9668  loss =  148.939\n",
      "training :  7996  accuracy =   0.9800  loss =  148.15\n",
      "testing  :  7996  accuracy =   0.9675  loss =  148.907\n",
      "training :  7997  accuracy =   0.9800  loss =  146.825\n",
      "testing  :  7997  accuracy =   0.9680  loss =  148.885\n",
      "training :  7998  accuracy =   0.9800  loss =  148.347\n",
      "testing  :  7998  accuracy =   0.9686  loss =  148.894\n",
      "training :  7999  accuracy =   1.0000  loss =  146.566\n",
      "testing  :  7999  accuracy =   0.9686  loss =  148.845\n",
      "training :  8000  accuracy =   1.0000  loss =  146.434\n",
      "testing  :  8000  accuracy =   0.9695  loss =  148.813\n",
      "training :  8001  accuracy =   0.9400  loss =  150.068\n",
      "testing  :  8001  accuracy =   0.9698  loss =  148.807\n",
      "training :  8002  accuracy =   0.9700  loss =  149.954\n",
      "testing  :  8002  accuracy =   0.9703  loss =  148.791\n",
      "training :  8003  accuracy =   0.9900  loss =  147.197\n",
      "testing  :  8003  accuracy =   0.9700  loss =  148.778\n",
      "training :  8004  accuracy =   0.9900  loss =  147.375\n",
      "testing  :  8004  accuracy =   0.9696  loss =  148.783\n",
      "training :  8005  accuracy =   1.0000  loss =  146.47\n",
      "testing  :  8005  accuracy =   0.9694  loss =  148.809\n",
      "training :  8006  accuracy =   0.9700  loss =  148.456\n",
      "testing  :  8006  accuracy =   0.9688  loss =  148.845\n",
      "training :  8007  accuracy =   0.9900  loss =  147.446\n",
      "testing  :  8007  accuracy =   0.9678  loss =  148.891\n",
      "training :  8008  accuracy =   0.9900  loss =  146.462\n",
      "testing  :  8008  accuracy =   0.9673  loss =  148.939\n",
      "training :  8009  accuracy =   0.9800  loss =  147.703\n",
      "testing  :  8009  accuracy =   0.9657  loss =  148.986\n",
      "training :  8010  accuracy =   1.0000  loss =  146.391\n",
      "testing  :  8010  accuracy =   0.9647  loss =  149.04\n",
      "training :  8011  accuracy =   1.0000  loss =  146.68\n",
      "testing  :  8011  accuracy =   0.9639  loss =  149.097\n",
      "training :  8012  accuracy =   0.9600  loss =  148.87\n",
      "testing  :  8012  accuracy =   0.9633  loss =  149.149\n",
      "training :  8013  accuracy =   0.9800  loss =  147.741\n",
      "testing  :  8013  accuracy =   0.9628  loss =  149.189\n",
      "training :  8014  accuracy =   0.9900  loss =  146.976\n",
      "testing  :  8014  accuracy =   0.9633  loss =  149.145\n",
      "training :  8015  accuracy =   0.9700  loss =  149.286\n",
      "testing  :  8015  accuracy =   0.9637  loss =  149.114\n",
      "training :  8016  accuracy =   0.9900  loss =  147.278\n",
      "testing  :  8016  accuracy =   0.9661  loss =  149.01\n",
      "training :  8017  accuracy =   0.9900  loss =  146.689\n",
      "testing  :  8017  accuracy =   0.9667  loss =  148.942\n",
      "training :  8018  accuracy =   0.9700  loss =  149.167\n",
      "testing  :  8018  accuracy =   0.9667  loss =  148.932\n",
      "training :  8019  accuracy =   1.0000  loss =  146.393\n",
      "testing  :  8019  accuracy =   0.9663  loss =  148.955\n",
      "training :  8020  accuracy =   0.9900  loss =  146.414\n",
      "testing  :  8020  accuracy =   0.9653  loss =  148.992\n",
      "training :  8021  accuracy =   0.9800  loss =  148.245\n",
      "testing  :  8021  accuracy =   0.9650  loss =  149.088\n",
      "training :  8022  accuracy =   0.9800  loss =  147.941\n",
      "testing  :  8022  accuracy =   0.9646  loss =  149.158\n",
      "training :  8023  accuracy =   0.9900  loss =  147.493\n",
      "testing  :  8023  accuracy =   0.9642  loss =  149.237\n",
      "training :  8024  accuracy =   0.9800  loss =  147.671\n",
      "testing  :  8024  accuracy =   0.9641  loss =  149.304\n",
      "training :  8025  accuracy =   0.9600  loss =  147.153\n",
      "testing  :  8025  accuracy =   0.9639  loss =  149.352\n",
      "training :  8026  accuracy =   0.9800  loss =  147.272\n",
      "testing  :  8026  accuracy =   0.9634  loss =  149.387\n",
      "training :  8027  accuracy =   0.9200  loss =  154.269\n",
      "testing  :  8027  accuracy =   0.9636  loss =  149.393\n",
      "training :  8028  accuracy =   0.9800  loss =  148.364\n",
      "testing  :  8028  accuracy =   0.9632  loss =  149.386\n",
      "training :  8029  accuracy =   0.9600  loss =  150.982\n",
      "testing  :  8029  accuracy =   0.9635  loss =  149.381\n",
      "training :  8030  accuracy =   0.9800  loss =  148.198\n",
      "testing  :  8030  accuracy =   0.9639  loss =  149.351\n",
      "training :  8031  accuracy =   0.9700  loss =  147.798\n",
      "testing  :  8031  accuracy =   0.9644  loss =  149.263\n",
      "training :  8032  accuracy =   0.9900  loss =  146.857\n",
      "testing  :  8032  accuracy =   0.9646  loss =  149.177\n",
      "training :  8033  accuracy =   0.9600  loss =  149.449\n",
      "testing  :  8033  accuracy =   0.9652  loss =  149.07\n",
      "training :  8034  accuracy =   0.9900  loss =  146.624\n",
      "testing  :  8034  accuracy =   0.9664  loss =  148.991\n",
      "training :  8035  accuracy =   0.9900  loss =  146.748\n",
      "testing  :  8035  accuracy =   0.9667  loss =  148.939\n",
      "training :  8036  accuracy =   0.9800  loss =  148.794\n",
      "testing  :  8036  accuracy =   0.9671  loss =  148.905\n",
      "training :  8037  accuracy =   0.9900  loss =  147.379\n",
      "testing  :  8037  accuracy =   0.9679  loss =  148.879\n",
      "training :  8038  accuracy =   0.9900  loss =  147.527\n",
      "testing  :  8038  accuracy =   0.9679  loss =  148.872\n",
      "training :  8039  accuracy =   0.9800  loss =  147.555\n",
      "testing  :  8039  accuracy =   0.9680  loss =  148.875\n",
      "training :  8040  accuracy =   0.9900  loss =  146.699\n",
      "testing  :  8040  accuracy =   0.9675  loss =  148.878\n",
      "training :  8041  accuracy =   0.9700  loss =  148.768\n",
      "testing  :  8041  accuracy =   0.9675  loss =  148.871\n",
      "training :  8042  accuracy =   0.9900  loss =  147.327\n",
      "testing  :  8042  accuracy =   0.9672  loss =  148.869\n",
      "training :  8043  accuracy =   1.0000  loss =  146.399\n",
      "testing  :  8043  accuracy =   0.9675  loss =  148.869\n",
      "training :  8044  accuracy =   0.9900  loss =  146.548\n",
      "testing  :  8044  accuracy =   0.9673  loss =  148.87\n",
      "training :  8045  accuracy =   0.9700  loss =  147.1\n",
      "testing  :  8045  accuracy =   0.9670  loss =  148.872\n",
      "training :  8046  accuracy =   0.9900  loss =  146.721\n",
      "testing  :  8046  accuracy =   0.9670  loss =  148.873\n",
      "training :  8047  accuracy =   0.9900  loss =  147.035\n",
      "testing  :  8047  accuracy =   0.9670  loss =  148.877\n",
      "training :  8048  accuracy =   1.0000  loss =  146.284\n",
      "testing  :  8048  accuracy =   0.9679  loss =  148.898\n",
      "training :  8049  accuracy =   0.9900  loss =  146.472\n",
      "testing  :  8049  accuracy =   0.9676  loss =  148.927\n",
      "training :  8050  accuracy =   0.9900  loss =  147.215\n",
      "testing  :  8050  accuracy =   0.9670  loss =  148.952\n",
      "training :  8051  accuracy =   0.9800  loss =  148.043\n",
      "testing  :  8051  accuracy =   0.9663  loss =  148.977\n",
      "training :  8052  accuracy =   0.9900  loss =  147.198\n",
      "testing  :  8052  accuracy =   0.9660  loss =  148.941\n",
      "training :  8053  accuracy =   1.0000  loss =  146.372\n",
      "testing  :  8053  accuracy =   0.9654  loss =  148.939\n",
      "training :  8054  accuracy =   1.0000  loss =  146.192\n",
      "testing  :  8054  accuracy =   0.9660  loss =  148.964\n",
      "training :  8055  accuracy =   0.9900  loss =  146.426\n",
      "testing  :  8055  accuracy =   0.9659  loss =  149.009\n",
      "training :  8056  accuracy =   0.9900  loss =  147.311\n",
      "testing  :  8056  accuracy =   0.9656  loss =  149.037\n",
      "training :  8057  accuracy =   0.9800  loss =  148.204\n",
      "testing  :  8057  accuracy =   0.9654  loss =  149.053\n",
      "training :  8058  accuracy =   0.9700  loss =  148.176\n",
      "testing  :  8058  accuracy =   0.9649  loss =  149.07\n",
      "training :  8059  accuracy =   0.9900  loss =  146.569\n",
      "testing  :  8059  accuracy =   0.9662  loss =  149.0\n",
      "training :  8060  accuracy =   0.9800  loss =  147.835\n",
      "testing  :  8060  accuracy =   0.9667  loss =  148.937\n",
      "training :  8061  accuracy =   0.9600  loss =  148.821\n",
      "testing  :  8061  accuracy =   0.9671  loss =  148.906\n",
      "training :  8062  accuracy =   0.9900  loss =  146.918\n",
      "testing  :  8062  accuracy =   0.9678  loss =  148.901\n",
      "training :  8063  accuracy =   0.9800  loss =  147.934\n",
      "testing  :  8063  accuracy =   0.9679  loss =  148.879\n",
      "training :  8064  accuracy =   0.9800  loss =  147.548\n",
      "testing  :  8064  accuracy =   0.9683  loss =  148.869\n",
      "training :  8065  accuracy =   0.9900  loss =  147.258\n",
      "testing  :  8065  accuracy =   0.9686  loss =  148.857\n",
      "training :  8066  accuracy =   1.0000  loss =  146.204\n",
      "testing  :  8066  accuracy =   0.9687  loss =  148.846\n",
      "training :  8067  accuracy =   0.9800  loss =  148.044\n",
      "testing  :  8067  accuracy =   0.9681  loss =  148.84\n",
      "training :  8068  accuracy =   0.9900  loss =  146.444\n",
      "testing  :  8068  accuracy =   0.9680  loss =  148.842\n",
      "training :  8069  accuracy =   0.9900  loss =  147.18\n",
      "testing  :  8069  accuracy =   0.9682  loss =  148.84\n",
      "training :  8070  accuracy =   0.9800  loss =  147.58\n",
      "testing  :  8070  accuracy =   0.9681  loss =  148.84\n",
      "training :  8071  accuracy =   0.9900  loss =  147.463\n",
      "testing  :  8071  accuracy =   0.9683  loss =  148.839\n",
      "training :  8072  accuracy =   1.0000  loss =  146.315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8072  accuracy =   0.9685  loss =  148.844\n",
      "training :  8073  accuracy =   0.9800  loss =  148.109\n",
      "testing  :  8073  accuracy =   0.9685  loss =  148.85\n",
      "training :  8074  accuracy =   0.9800  loss =  147.587\n",
      "testing  :  8074  accuracy =   0.9682  loss =  148.853\n",
      "training :  8075  accuracy =   0.9700  loss =  149.373\n",
      "testing  :  8075  accuracy =   0.9681  loss =  148.881\n",
      "training :  8076  accuracy =   0.9900  loss =  146.667\n",
      "testing  :  8076  accuracy =   0.9672  loss =  148.929\n",
      "training :  8077  accuracy =   0.9800  loss =  148.264\n",
      "testing  :  8077  accuracy =   0.9665  loss =  148.971\n",
      "training :  8078  accuracy =   1.0000  loss =  146.39\n",
      "testing  :  8078  accuracy =   0.9662  loss =  149.014\n",
      "training :  8079  accuracy =   0.9500  loss =  150.73\n",
      "testing  :  8079  accuracy =   0.9651  loss =  149.065\n",
      "training :  8080  accuracy =   0.9700  loss =  148.877\n",
      "testing  :  8080  accuracy =   0.9648  loss =  149.106\n",
      "training :  8081  accuracy =   0.9800  loss =  148.359\n",
      "testing  :  8081  accuracy =   0.9652  loss =  149.137\n",
      "training :  8082  accuracy =   1.0000  loss =  146.461\n",
      "testing  :  8082  accuracy =   0.9649  loss =  149.167\n",
      "training :  8083  accuracy =   1.0000  loss =  146.189\n",
      "testing  :  8083  accuracy =   0.9652  loss =  149.189\n",
      "training :  8084  accuracy =   1.0000  loss =  146.253\n",
      "testing  :  8084  accuracy =   0.9650  loss =  149.208\n",
      "training :  8085  accuracy =   1.0000  loss =  146.461\n",
      "testing  :  8085  accuracy =   0.9645  loss =  149.227\n",
      "training :  8086  accuracy =   0.9700  loss =  148.759\n",
      "testing  :  8086  accuracy =   0.9638  loss =  149.227\n",
      "training :  8087  accuracy =   0.9700  loss =  148.79\n",
      "testing  :  8087  accuracy =   0.9637  loss =  149.216\n",
      "training :  8088  accuracy =   0.9900  loss =  146.96\n",
      "testing  :  8088  accuracy =   0.9632  loss =  149.205\n",
      "training :  8089  accuracy =   0.9700  loss =  148.344\n",
      "testing  :  8089  accuracy =   0.9635  loss =  149.19\n",
      "training :  8090  accuracy =   0.9800  loss =  147.424\n",
      "testing  :  8090  accuracy =   0.9643  loss =  149.143\n",
      "training :  8091  accuracy =   0.9700  loss =  147.539\n",
      "testing  :  8091  accuracy =   0.9653  loss =  149.052\n",
      "training :  8092  accuracy =   0.9400  loss =  150.269\n",
      "testing  :  8092  accuracy =   0.9667  loss =  148.991\n",
      "training :  8093  accuracy =   0.9800  loss =  147.424\n",
      "testing  :  8093  accuracy =   0.9670  loss =  148.938\n",
      "training :  8094  accuracy =   0.9600  loss =  147.818\n",
      "testing  :  8094  accuracy =   0.9673  loss =  148.875\n",
      "training :  8095  accuracy =   0.9500  loss =  148.76\n",
      "testing  :  8095  accuracy =   0.9677  loss =  148.831\n",
      "training :  8096  accuracy =   0.9900  loss =  147.571\n",
      "testing  :  8096  accuracy =   0.9674  loss =  148.815\n",
      "training :  8097  accuracy =   0.9600  loss =  147.869\n",
      "testing  :  8097  accuracy =   0.9668  loss =  148.862\n",
      "training :  8098  accuracy =   0.9900  loss =  147.198\n",
      "testing  :  8098  accuracy =   0.9657  loss =  148.93\n",
      "training :  8099  accuracy =   0.9900  loss =  147.353\n",
      "testing  :  8099  accuracy =   0.9651  loss =  149.021\n",
      "training :  8100  accuracy =   0.9900  loss =  146.822\n",
      "testing  :  8100  accuracy =   0.9640  loss =  149.078\n",
      "training :  8101  accuracy =   0.9800  loss =  147.4\n",
      "testing  :  8101  accuracy =   0.9631  loss =  149.12\n",
      "training :  8102  accuracy =   0.9900  loss =  147.376\n",
      "testing  :  8102  accuracy =   0.9627  loss =  149.153\n",
      "training :  8103  accuracy =   1.0000  loss =  146.497\n",
      "testing  :  8103  accuracy =   0.9624  loss =  149.186\n",
      "training :  8104  accuracy =   0.9800  loss =  148.312\n",
      "testing  :  8104  accuracy =   0.9624  loss =  149.202\n",
      "training :  8105  accuracy =   0.9900  loss =  147.08\n",
      "testing  :  8105  accuracy =   0.9624  loss =  149.178\n",
      "training :  8106  accuracy =   0.9700  loss =  149.416\n",
      "testing  :  8106  accuracy =   0.9633  loss =  149.118\n",
      "training :  8107  accuracy =   0.9800  loss =  147.546\n",
      "testing  :  8107  accuracy =   0.9636  loss =  149.076\n",
      "training :  8108  accuracy =   0.9700  loss =  149.398\n",
      "testing  :  8108  accuracy =   0.9632  loss =  149.055\n",
      "training :  8109  accuracy =   0.9800  loss =  148.516\n",
      "testing  :  8109  accuracy =   0.9633  loss =  149.058\n",
      "training :  8110  accuracy =   0.9400  loss =  150.475\n",
      "testing  :  8110  accuracy =   0.9639  loss =  149.077\n",
      "training :  8111  accuracy =   0.9800  loss =  147.993\n",
      "testing  :  8111  accuracy =   0.9639  loss =  149.099\n",
      "training :  8112  accuracy =   0.9800  loss =  147.48\n",
      "testing  :  8112  accuracy =   0.9642  loss =  149.072\n",
      "training :  8113  accuracy =   0.9800  loss =  148.004\n",
      "testing  :  8113  accuracy =   0.9650  loss =  149.044\n",
      "training :  8114  accuracy =   0.9600  loss =  148.083\n",
      "testing  :  8114  accuracy =   0.9652  loss =  149.03\n",
      "training :  8115  accuracy =   0.9700  loss =  148.757\n",
      "testing  :  8115  accuracy =   0.9648  loss =  148.985\n",
      "training :  8116  accuracy =   0.9900  loss =  147.611\n",
      "testing  :  8116  accuracy =   0.9653  loss =  148.956\n",
      "training :  8117  accuracy =   0.9800  loss =  147.008\n",
      "testing  :  8117  accuracy =   0.9659  loss =  148.935\n",
      "training :  8118  accuracy =   0.9500  loss =  150.3\n",
      "testing  :  8118  accuracy =   0.9649  loss =  148.943\n",
      "training :  8119  accuracy =   0.9600  loss =  148.629\n",
      "testing  :  8119  accuracy =   0.9655  loss =  148.946\n",
      "training :  8120  accuracy =   0.9800  loss =  147.604\n",
      "testing  :  8120  accuracy =   0.9653  loss =  148.972\n",
      "training :  8121  accuracy =   0.9900  loss =  146.798\n",
      "testing  :  8121  accuracy =   0.9652  loss =  149.003\n",
      "training :  8122  accuracy =   1.0000  loss =  146.773\n",
      "testing  :  8122  accuracy =   0.9655  loss =  148.99\n",
      "training :  8123  accuracy =   0.9800  loss =  148.146\n",
      "testing  :  8123  accuracy =   0.9657  loss =  148.979\n",
      "training :  8124  accuracy =   0.9800  loss =  147.714\n",
      "testing  :  8124  accuracy =   0.9657  loss =  148.972\n",
      "training :  8125  accuracy =   0.9800  loss =  146.611\n",
      "testing  :  8125  accuracy =   0.9659  loss =  148.957\n",
      "training :  8126  accuracy =   0.9800  loss =  147.641\n",
      "testing  :  8126  accuracy =   0.9658  loss =  148.942\n",
      "training :  8127  accuracy =   0.9800  loss =  148.005\n",
      "testing  :  8127  accuracy =   0.9654  loss =  148.927\n",
      "training :  8128  accuracy =   0.9800  loss =  147.559\n",
      "testing  :  8128  accuracy =   0.9658  loss =  148.898\n",
      "training :  8129  accuracy =   0.9900  loss =  146.702\n",
      "testing  :  8129  accuracy =   0.9659  loss =  148.877\n",
      "training :  8130  accuracy =   0.9800  loss =  146.921\n",
      "testing  :  8130  accuracy =   0.9662  loss =  148.86\n",
      "training :  8131  accuracy =   0.9700  loss =  147.606\n",
      "testing  :  8131  accuracy =   0.9664  loss =  148.849\n",
      "training :  8132  accuracy =   0.9900  loss =  146.817\n",
      "testing  :  8132  accuracy =   0.9666  loss =  148.846\n",
      "training :  8133  accuracy =   0.9600  loss =  148.143\n",
      "testing  :  8133  accuracy =   0.9673  loss =  148.847\n",
      "training :  8134  accuracy =   0.9800  loss =  147.496\n",
      "testing  :  8134  accuracy =   0.9678  loss =  148.848\n",
      "training :  8135  accuracy =   0.9900  loss =  147.535\n",
      "testing  :  8135  accuracy =   0.9673  loss =  148.858\n",
      "training :  8136  accuracy =   0.9700  loss =  149.394\n",
      "testing  :  8136  accuracy =   0.9673  loss =  148.867\n",
      "training :  8137  accuracy =   0.9800  loss =  148.484\n",
      "testing  :  8137  accuracy =   0.9679  loss =  148.884\n",
      "training :  8138  accuracy =   0.9900  loss =  147.669\n",
      "testing  :  8138  accuracy =   0.9677  loss =  148.906\n",
      "training :  8139  accuracy =   0.9900  loss =  146.832\n",
      "testing  :  8139  accuracy =   0.9676  loss =  148.93\n",
      "training :  8140  accuracy =   0.9700  loss =  149.598\n",
      "testing  :  8140  accuracy =   0.9670  loss =  148.956\n",
      "training :  8141  accuracy =   0.9800  loss =  146.842\n",
      "testing  :  8141  accuracy =   0.9665  loss =  148.986\n",
      "training :  8142  accuracy =   1.0000  loss =  146.758\n",
      "testing  :  8142  accuracy =   0.9657  loss =  149.028\n",
      "training :  8143  accuracy =   0.9800  loss =  148.144\n",
      "testing  :  8143  accuracy =   0.9651  loss =  149.071\n",
      "training :  8144  accuracy =   0.9800  loss =  147.55\n",
      "testing  :  8144  accuracy =   0.9653  loss =  149.088\n",
      "training :  8145  accuracy =   0.9700  loss =  149.012\n",
      "testing  :  8145  accuracy =   0.9645  loss =  149.108\n",
      "training :  8146  accuracy =   0.9800  loss =  147.658\n",
      "testing  :  8146  accuracy =   0.9647  loss =  149.091\n",
      "training :  8147  accuracy =   1.0000  loss =  146.21\n",
      "testing  :  8147  accuracy =   0.9650  loss =  149.079\n",
      "training :  8148  accuracy =   0.9700  loss =  148.934\n",
      "testing  :  8148  accuracy =   0.9644  loss =  149.079\n",
      "training :  8149  accuracy =   1.0000  loss =  146.39\n",
      "testing  :  8149  accuracy =   0.9643  loss =  149.07\n",
      "training :  8150  accuracy =   0.9800  loss =  147.579\n",
      "testing  :  8150  accuracy =   0.9645  loss =  149.065\n",
      "training :  8151  accuracy =   1.0000  loss =  146.716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8151  accuracy =   0.9650  loss =  149.04\n",
      "training :  8152  accuracy =   0.9600  loss =  147.64\n",
      "testing  :  8152  accuracy =   0.9652  loss =  149.019\n",
      "training :  8153  accuracy =   0.9900  loss =  147.444\n",
      "testing  :  8153  accuracy =   0.9654  loss =  148.989\n",
      "training :  8154  accuracy =   0.9800  loss =  147.531\n",
      "testing  :  8154  accuracy =   0.9658  loss =  148.96\n",
      "training :  8155  accuracy =   0.9700  loss =  148.415\n",
      "testing  :  8155  accuracy =   0.9663  loss =  148.93\n",
      "training :  8156  accuracy =   0.9800  loss =  148.59\n",
      "testing  :  8156  accuracy =   0.9666  loss =  148.912\n",
      "training :  8157  accuracy =   1.0000  loss =  146.621\n",
      "testing  :  8157  accuracy =   0.9669  loss =  148.904\n",
      "training :  8158  accuracy =   0.9900  loss =  146.761\n",
      "testing  :  8158  accuracy =   0.9670  loss =  148.906\n",
      "training :  8159  accuracy =   0.9700  loss =  147.694\n",
      "testing  :  8159  accuracy =   0.9671  loss =  148.91\n",
      "training :  8160  accuracy =   0.9900  loss =  147.251\n",
      "testing  :  8160  accuracy =   0.9669  loss =  148.901\n",
      "training :  8161  accuracy =   0.9900  loss =  146.364\n",
      "testing  :  8161  accuracy =   0.9665  loss =  148.892\n",
      "training :  8162  accuracy =   0.9900  loss =  147.214\n",
      "testing  :  8162  accuracy =   0.9666  loss =  148.888\n",
      "training :  8163  accuracy =   0.9800  loss =  147.959\n",
      "testing  :  8163  accuracy =   0.9669  loss =  148.891\n",
      "training :  8164  accuracy =   0.9700  loss =  148.648\n",
      "testing  :  8164  accuracy =   0.9671  loss =  148.882\n",
      "training :  8165  accuracy =   0.9800  loss =  147.846\n",
      "testing  :  8165  accuracy =   0.9674  loss =  148.875\n",
      "training :  8166  accuracy =   0.9800  loss =  148.139\n",
      "testing  :  8166  accuracy =   0.9674  loss =  148.843\n",
      "training :  8167  accuracy =   1.0000  loss =  146.409\n",
      "testing  :  8167  accuracy =   0.9678  loss =  148.829\n",
      "training :  8168  accuracy =   0.9900  loss =  147.36\n",
      "testing  :  8168  accuracy =   0.9669  loss =  148.834\n",
      "training :  8169  accuracy =   1.0000  loss =  146.366\n",
      "testing  :  8169  accuracy =   0.9669  loss =  148.849\n",
      "training :  8170  accuracy =   0.9800  loss =  148.511\n",
      "testing  :  8170  accuracy =   0.9669  loss =  148.876\n",
      "training :  8171  accuracy =   0.9900  loss =  147.394\n",
      "testing  :  8171  accuracy =   0.9658  loss =  148.92\n",
      "training :  8172  accuracy =   1.0000  loss =  146.336\n",
      "testing  :  8172  accuracy =   0.9659  loss =  148.973\n",
      "training :  8173  accuracy =   0.9800  loss =  147.525\n",
      "testing  :  8173  accuracy =   0.9656  loss =  149.023\n",
      "training :  8174  accuracy =   0.9500  loss =  150.813\n",
      "testing  :  8174  accuracy =   0.9653  loss =  149.073\n",
      "training :  8175  accuracy =   0.9900  loss =  147.0\n",
      "testing  :  8175  accuracy =   0.9648  loss =  149.133\n",
      "training :  8176  accuracy =   0.9700  loss =  148.53\n",
      "testing  :  8176  accuracy =   0.9638  loss =  149.158\n",
      "training :  8177  accuracy =   0.9700  loss =  148.973\n",
      "testing  :  8177  accuracy =   0.9635  loss =  149.176\n",
      "training :  8178  accuracy =   0.9800  loss =  147.76\n",
      "testing  :  8178  accuracy =   0.9639  loss =  149.151\n",
      "training :  8179  accuracy =   0.9900  loss =  146.69\n",
      "testing  :  8179  accuracy =   0.9643  loss =  149.155\n",
      "training :  8180  accuracy =   0.9700  loss =  149.343\n",
      "testing  :  8180  accuracy =   0.9647  loss =  149.164\n",
      "training :  8181  accuracy =   0.9400  loss =  149.814\n",
      "testing  :  8181  accuracy =   0.9644  loss =  149.162\n",
      "training :  8182  accuracy =   0.9700  loss =  149.541\n",
      "testing  :  8182  accuracy =   0.9645  loss =  149.093\n",
      "training :  8183  accuracy =   0.9800  loss =  146.596\n",
      "testing  :  8183  accuracy =   0.9654  loss =  149.047\n",
      "training :  8184  accuracy =   0.9800  loss =  147.913\n",
      "testing  :  8184  accuracy =   0.9654  loss =  149.018\n",
      "training :  8185  accuracy =   0.9800  loss =  147.857\n",
      "testing  :  8185  accuracy =   0.9658  loss =  148.98\n",
      "training :  8186  accuracy =   0.9700  loss =  147.07\n",
      "testing  :  8186  accuracy =   0.9655  loss =  148.966\n",
      "training :  8187  accuracy =   0.9500  loss =  149.894\n",
      "testing  :  8187  accuracy =   0.9656  loss =  148.929\n",
      "training :  8188  accuracy =   0.9900  loss =  147.29\n",
      "testing  :  8188  accuracy =   0.9670  loss =  148.889\n",
      "training :  8189  accuracy =   0.9900  loss =  146.536\n",
      "testing  :  8189  accuracy =   0.9677  loss =  148.869\n",
      "training :  8190  accuracy =   0.9700  loss =  147.705\n",
      "testing  :  8190  accuracy =   0.9670  loss =  148.864\n",
      "training :  8191  accuracy =   0.9800  loss =  148.289\n",
      "testing  :  8191  accuracy =   0.9668  loss =  148.865\n",
      "training :  8192  accuracy =   0.9800  loss =  148.469\n",
      "testing  :  8192  accuracy =   0.9669  loss =  148.87\n",
      "training :  8193  accuracy =   0.9700  loss =  147.474\n",
      "testing  :  8193  accuracy =   0.9664  loss =  148.876\n",
      "training :  8194  accuracy =   1.0000  loss =  146.305\n",
      "testing  :  8194  accuracy =   0.9663  loss =  148.882\n",
      "training :  8195  accuracy =   0.9800  loss =  148.569\n",
      "testing  :  8195  accuracy =   0.9660  loss =  148.891\n",
      "training :  8196  accuracy =   0.9600  loss =  149.087\n",
      "testing  :  8196  accuracy =   0.9664  loss =  148.893\n",
      "training :  8197  accuracy =   0.9700  loss =  148.41\n",
      "testing  :  8197  accuracy =   0.9660  loss =  148.876\n",
      "training :  8198  accuracy =   0.9900  loss =  147.323\n",
      "testing  :  8198  accuracy =   0.9664  loss =  148.869\n",
      "training :  8199  accuracy =   0.9700  loss =  149.457\n",
      "testing  :  8199  accuracy =   0.9663  loss =  148.858\n",
      "training :  8200  accuracy =   0.9700  loss =  148.493\n",
      "testing  :  8200  accuracy =   0.9663  loss =  148.851\n",
      "training :  8201  accuracy =   0.9700  loss =  147.741\n",
      "testing  :  8201  accuracy =   0.9664  loss =  148.851\n",
      "training :  8202  accuracy =   0.9900  loss =  147.168\n",
      "testing  :  8202  accuracy =   0.9666  loss =  148.851\n",
      "training :  8203  accuracy =   1.0000  loss =  146.271\n",
      "testing  :  8203  accuracy =   0.9668  loss =  148.858\n",
      "training :  8204  accuracy =   0.9700  loss =  149.289\n",
      "testing  :  8204  accuracy =   0.9667  loss =  148.873\n",
      "training :  8205  accuracy =   1.0000  loss =  146.257\n",
      "testing  :  8205  accuracy =   0.9666  loss =  148.887\n",
      "training :  8206  accuracy =   0.9800  loss =  146.869\n",
      "testing  :  8206  accuracy =   0.9670  loss =  148.909\n",
      "training :  8207  accuracy =   0.9500  loss =  149.34\n",
      "testing  :  8207  accuracy =   0.9669  loss =  148.904\n",
      "training :  8208  accuracy =   1.0000  loss =  146.23\n",
      "testing  :  8208  accuracy =   0.9675  loss =  148.886\n",
      "training :  8209  accuracy =   0.9800  loss =  146.776\n",
      "testing  :  8209  accuracy =   0.9675  loss =  148.886\n",
      "training :  8210  accuracy =   0.9900  loss =  147.541\n",
      "testing  :  8210  accuracy =   0.9676  loss =  148.885\n",
      "training :  8211  accuracy =   1.0000  loss =  146.565\n",
      "testing  :  8211  accuracy =   0.9675  loss =  148.888\n",
      "training :  8212  accuracy =   0.9600  loss =  149.305\n",
      "testing  :  8212  accuracy =   0.9676  loss =  148.891\n",
      "training :  8213  accuracy =   1.0000  loss =  146.432\n",
      "testing  :  8213  accuracy =   0.9675  loss =  148.904\n",
      "training :  8214  accuracy =   1.0000  loss =  146.805\n",
      "testing  :  8214  accuracy =   0.9673  loss =  148.928\n",
      "training :  8215  accuracy =   0.9800  loss =  146.934\n",
      "testing  :  8215  accuracy =   0.9669  loss =  148.963\n",
      "training :  8216  accuracy =   0.9800  loss =  147.943\n",
      "testing  :  8216  accuracy =   0.9669  loss =  148.997\n",
      "training :  8217  accuracy =   1.0000  loss =  146.451\n",
      "testing  :  8217  accuracy =   0.9661  loss =  149.028\n",
      "training :  8218  accuracy =   0.9600  loss =  149.309\n",
      "testing  :  8218  accuracy =   0.9656  loss =  149.063\n",
      "training :  8219  accuracy =   0.9900  loss =  146.628\n",
      "testing  :  8219  accuracy =   0.9651  loss =  149.094\n",
      "training :  8220  accuracy =   0.9500  loss =  150.259\n",
      "testing  :  8220  accuracy =   0.9647  loss =  149.114\n",
      "training :  8221  accuracy =   0.9800  loss =  147.745\n",
      "testing  :  8221  accuracy =   0.9657  loss =  149.069\n",
      "training :  8222  accuracy =   0.9900  loss =  147.262\n",
      "testing  :  8222  accuracy =   0.9656  loss =  149.016\n",
      "training :  8223  accuracy =   0.9800  loss =  147.689\n",
      "testing  :  8223  accuracy =   0.9660  loss =  148.973\n",
      "training :  8224  accuracy =   0.9800  loss =  147.984\n",
      "testing  :  8224  accuracy =   0.9658  loss =  148.936\n",
      "training :  8225  accuracy =   0.9800  loss =  148.309\n",
      "testing  :  8225  accuracy =   0.9659  loss =  148.914\n",
      "training :  8226  accuracy =   0.9900  loss =  147.467\n",
      "testing  :  8226  accuracy =   0.9665  loss =  148.908\n",
      "training :  8227  accuracy =   0.9900  loss =  147.173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8227  accuracy =   0.9668  loss =  148.907\n",
      "training :  8228  accuracy =   0.9500  loss =  150.2\n",
      "testing  :  8228  accuracy =   0.9677  loss =  148.909\n",
      "training :  8229  accuracy =   1.0000  loss =  146.324\n",
      "testing  :  8229  accuracy =   0.9667  loss =  148.926\n",
      "training :  8230  accuracy =   0.9900  loss =  147.341\n",
      "testing  :  8230  accuracy =   0.9663  loss =  148.947\n",
      "training :  8231  accuracy =   0.9600  loss =  148.829\n",
      "testing  :  8231  accuracy =   0.9652  loss =  148.967\n",
      "training :  8232  accuracy =   0.9800  loss =  148.192\n",
      "testing  :  8232  accuracy =   0.9661  loss =  148.968\n",
      "training :  8233  accuracy =   0.9800  loss =  147.612\n",
      "testing  :  8233  accuracy =   0.9662  loss =  148.974\n",
      "training :  8234  accuracy =   1.0000  loss =  146.18\n",
      "testing  :  8234  accuracy =   0.9661  loss =  148.989\n",
      "training :  8235  accuracy =   1.0000  loss =  146.649\n",
      "testing  :  8235  accuracy =   0.9659  loss =  149.01\n",
      "training :  8236  accuracy =   0.9900  loss =  147.652\n",
      "testing  :  8236  accuracy =   0.9657  loss =  149.024\n",
      "training :  8237  accuracy =   0.9800  loss =  148.298\n",
      "testing  :  8237  accuracy =   0.9653  loss =  149.035\n",
      "training :  8238  accuracy =   0.9900  loss =  147.024\n",
      "testing  :  8238  accuracy =   0.9650  loss =  149.05\n",
      "training :  8239  accuracy =   0.9700  loss =  148.056\n",
      "testing  :  8239  accuracy =   0.9653  loss =  149.049\n",
      "training :  8240  accuracy =   0.9900  loss =  146.351\n",
      "testing  :  8240  accuracy =   0.9657  loss =  149.046\n",
      "training :  8241  accuracy =   0.9900  loss =  146.362\n",
      "testing  :  8241  accuracy =   0.9656  loss =  149.042\n",
      "training :  8242  accuracy =   0.9800  loss =  147.972\n",
      "testing  :  8242  accuracy =   0.9653  loss =  149.038\n",
      "training :  8243  accuracy =   1.0000  loss =  146.371\n",
      "testing  :  8243  accuracy =   0.9647  loss =  149.038\n",
      "training :  8244  accuracy =   0.9700  loss =  148.451\n",
      "testing  :  8244  accuracy =   0.9648  loss =  149.038\n",
      "training :  8245  accuracy =   1.0000  loss =  146.409\n",
      "testing  :  8245  accuracy =   0.9658  loss =  149.002\n",
      "training :  8246  accuracy =   0.9900  loss =  147.372\n",
      "testing  :  8246  accuracy =   0.9666  loss =  149.011\n",
      "training :  8247  accuracy =   0.9900  loss =  147.442\n",
      "testing  :  8247  accuracy =   0.9664  loss =  149.029\n",
      "training :  8248  accuracy =   0.9800  loss =  148.495\n",
      "testing  :  8248  accuracy =   0.9663  loss =  149.032\n",
      "training :  8249  accuracy =   0.9400  loss =  149.813\n",
      "testing  :  8249  accuracy =   0.9658  loss =  149.036\n",
      "training :  8250  accuracy =   0.9800  loss =  147.619\n",
      "testing  :  8250  accuracy =   0.9656  loss =  149.014\n",
      "training :  8251  accuracy =   0.9700  loss =  148.834\n",
      "testing  :  8251  accuracy =   0.9665  loss =  148.982\n",
      "training :  8252  accuracy =   0.9500  loss =  150.121\n",
      "testing  :  8252  accuracy =   0.9668  loss =  148.94\n",
      "training :  8253  accuracy =   0.9900  loss =  146.517\n",
      "testing  :  8253  accuracy =   0.9670  loss =  148.873\n",
      "training :  8254  accuracy =   0.9900  loss =  147.457\n",
      "testing  :  8254  accuracy =   0.9671  loss =  148.833\n",
      "training :  8255  accuracy =   0.9900  loss =  147.752\n",
      "testing  :  8255  accuracy =   0.9671  loss =  148.838\n",
      "training :  8256  accuracy =   0.9800  loss =  146.459\n",
      "testing  :  8256  accuracy =   0.9666  loss =  148.873\n",
      "training :  8257  accuracy =   0.9900  loss =  147.301\n",
      "testing  :  8257  accuracy =   0.9660  loss =  148.924\n",
      "training :  8258  accuracy =   1.0000  loss =  146.245\n",
      "testing  :  8258  accuracy =   0.9654  loss =  148.986\n",
      "training :  8259  accuracy =   0.9500  loss =  149.776\n",
      "testing  :  8259  accuracy =   0.9645  loss =  149.053\n",
      "training :  8260  accuracy =   0.9800  loss =  148.365\n",
      "testing  :  8260  accuracy =   0.9642  loss =  149.095\n",
      "training :  8261  accuracy =   0.9700  loss =  149.28\n",
      "testing  :  8261  accuracy =   0.9638  loss =  149.14\n",
      "training :  8262  accuracy =   0.9800  loss =  146.841\n",
      "testing  :  8262  accuracy =   0.9642  loss =  149.171\n",
      "training :  8263  accuracy =   0.9700  loss =  148.722\n",
      "testing  :  8263  accuracy =   0.9634  loss =  149.19\n",
      "training :  8264  accuracy =   0.9800  loss =  148.899\n",
      "testing  :  8264  accuracy =   0.9636  loss =  149.115\n",
      "training :  8265  accuracy =   0.9800  loss =  147.529\n",
      "testing  :  8265  accuracy =   0.9627  loss =  149.072\n",
      "training :  8266  accuracy =   0.9900  loss =  146.994\n",
      "testing  :  8266  accuracy =   0.9625  loss =  149.058\n",
      "training :  8267  accuracy =   1.0000  loss =  146.683\n",
      "testing  :  8267  accuracy =   0.9628  loss =  149.052\n",
      "training :  8268  accuracy =   0.9800  loss =  148.49\n",
      "testing  :  8268  accuracy =   0.9634  loss =  149.054\n",
      "training :  8269  accuracy =   0.9600  loss =  149.625\n",
      "testing  :  8269  accuracy =   0.9633  loss =  149.059\n",
      "training :  8270  accuracy =   0.9500  loss =  149.986\n",
      "testing  :  8270  accuracy =   0.9642  loss =  149.055\n",
      "training :  8271  accuracy =   0.9600  loss =  150.198\n",
      "testing  :  8271  accuracy =   0.9641  loss =  149.059\n",
      "training :  8272  accuracy =   0.9700  loss =  149.392\n",
      "testing  :  8272  accuracy =   0.9643  loss =  149.052\n",
      "training :  8273  accuracy =   0.9600  loss =  149.831\n",
      "testing  :  8273  accuracy =   0.9647  loss =  149.056\n",
      "training :  8274  accuracy =   1.0000  loss =  146.425\n",
      "testing  :  8274  accuracy =   0.9641  loss =  149.043\n",
      "training :  8275  accuracy =   0.9900  loss =  146.486\n",
      "testing  :  8275  accuracy =   0.9638  loss =  149.035\n",
      "training :  8276  accuracy =   0.9800  loss =  147.552\n",
      "testing  :  8276  accuracy =   0.9636  loss =  149.028\n",
      "training :  8277  accuracy =   1.0000  loss =  146.309\n",
      "testing  :  8277  accuracy =   0.9647  loss =  149.01\n",
      "training :  8278  accuracy =   0.9800  loss =  148.262\n",
      "testing  :  8278  accuracy =   0.9648  loss =  148.996\n",
      "training :  8279  accuracy =   0.9700  loss =  149.502\n",
      "testing  :  8279  accuracy =   0.9649  loss =  148.984\n",
      "training :  8280  accuracy =   0.9600  loss =  149.747\n",
      "testing  :  8280  accuracy =   0.9650  loss =  148.972\n",
      "training :  8281  accuracy =   0.9600  loss =  150.248\n",
      "testing  :  8281  accuracy =   0.9649  loss =  148.961\n",
      "training :  8282  accuracy =   0.9800  loss =  148.188\n",
      "testing  :  8282  accuracy =   0.9648  loss =  148.952\n",
      "training :  8283  accuracy =   0.9800  loss =  148.359\n",
      "testing  :  8283  accuracy =   0.9648  loss =  148.951\n",
      "training :  8284  accuracy =   0.9800  loss =  148.403\n",
      "testing  :  8284  accuracy =   0.9656  loss =  148.954\n",
      "training :  8285  accuracy =   0.9900  loss =  146.387\n",
      "testing  :  8285  accuracy =   0.9658  loss =  148.957\n",
      "training :  8286  accuracy =   0.9900  loss =  146.562\n",
      "testing  :  8286  accuracy =   0.9653  loss =  148.97\n",
      "training :  8287  accuracy =   1.0000  loss =  146.465\n",
      "testing  :  8287  accuracy =   0.9650  loss =  148.986\n",
      "training :  8288  accuracy =   1.0000  loss =  146.46\n",
      "testing  :  8288  accuracy =   0.9653  loss =  148.998\n",
      "training :  8289  accuracy =   0.9900  loss =  146.416\n",
      "testing  :  8289  accuracy =   0.9652  loss =  149.009\n",
      "training :  8290  accuracy =   0.9700  loss =  148.388\n",
      "testing  :  8290  accuracy =   0.9651  loss =  149.018\n",
      "training :  8291  accuracy =   0.9800  loss =  147.764\n",
      "testing  :  8291  accuracy =   0.9646  loss =  149.024\n",
      "training :  8292  accuracy =   0.9700  loss =  149.411\n",
      "testing  :  8292  accuracy =   0.9644  loss =  149.028\n",
      "training :  8293  accuracy =   0.9800  loss =  148.382\n",
      "testing  :  8293  accuracy =   0.9649  loss =  149.024\n",
      "training :  8294  accuracy =   1.0000  loss =  146.332\n",
      "testing  :  8294  accuracy =   0.9649  loss =  149.024\n",
      "training :  8295  accuracy =   0.9900  loss =  147.399\n",
      "testing  :  8295  accuracy =   0.9653  loss =  149.019\n",
      "training :  8296  accuracy =   1.0000  loss =  146.375\n",
      "testing  :  8296  accuracy =   0.9652  loss =  149.016\n",
      "training :  8297  accuracy =   0.9800  loss =  148.28\n",
      "testing  :  8297  accuracy =   0.9655  loss =  149.012\n",
      "training :  8298  accuracy =   0.9700  loss =  148.341\n",
      "testing  :  8298  accuracy =   0.9656  loss =  148.978\n",
      "training :  8299  accuracy =   1.0000  loss =  146.308\n",
      "testing  :  8299  accuracy =   0.9656  loss =  148.938\n",
      "training :  8300  accuracy =   0.9900  loss =  147.212\n",
      "testing  :  8300  accuracy =   0.9666  loss =  148.906\n",
      "training :  8301  accuracy =   0.9700  loss =  149.391\n",
      "testing  :  8301  accuracy =   0.9666  loss =  148.898\n",
      "training :  8302  accuracy =   0.9700  loss =  148.629\n",
      "testing  :  8302  accuracy =   0.9666  loss =  148.905\n",
      "training :  8303  accuracy =   0.9600  loss =  148.75\n",
      "testing  :  8303  accuracy =   0.9666  loss =  148.92\n",
      "training :  8304  accuracy =   0.9900  loss =  147.267\n",
      "testing  :  8304  accuracy =   0.9662  loss =  148.934\n",
      "training :  8305  accuracy =   0.9800  loss =  147.359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8305  accuracy =   0.9660  loss =  148.958\n",
      "training :  8306  accuracy =   0.9800  loss =  148.192\n",
      "testing  :  8306  accuracy =   0.9655  loss =  148.982\n",
      "training :  8307  accuracy =   0.9800  loss =  147.704\n",
      "testing  :  8307  accuracy =   0.9650  loss =  149.02\n",
      "training :  8308  accuracy =   0.9700  loss =  149.741\n",
      "testing  :  8308  accuracy =   0.9646  loss =  149.058\n",
      "training :  8309  accuracy =   1.0000  loss =  146.859\n",
      "testing  :  8309  accuracy =   0.9648  loss =  149.1\n",
      "training :  8310  accuracy =   1.0000  loss =  146.445\n",
      "testing  :  8310  accuracy =   0.9641  loss =  149.14\n",
      "training :  8311  accuracy =   0.9900  loss =  147.191\n",
      "testing  :  8311  accuracy =   0.9637  loss =  149.17\n",
      "training :  8312  accuracy =   0.9900  loss =  147.354\n",
      "testing  :  8312  accuracy =   0.9630  loss =  149.195\n",
      "training :  8313  accuracy =   0.9700  loss =  148.704\n",
      "testing  :  8313  accuracy =   0.9626  loss =  149.212\n",
      "training :  8314  accuracy =   0.9800  loss =  147.828\n",
      "testing  :  8314  accuracy =   0.9627  loss =  149.217\n",
      "training :  8315  accuracy =   0.9700  loss =  147.325\n",
      "testing  :  8315  accuracy =   0.9623  loss =  149.185\n",
      "training :  8316  accuracy =   1.0000  loss =  146.384\n",
      "testing  :  8316  accuracy =   0.9629  loss =  149.164\n",
      "training :  8317  accuracy =   0.9500  loss =  149.596\n",
      "testing  :  8317  accuracy =   0.9630  loss =  149.157\n",
      "training :  8318  accuracy =   0.9900  loss =  147.499\n",
      "testing  :  8318  accuracy =   0.9633  loss =  149.153\n",
      "training :  8319  accuracy =   0.9900  loss =  146.55\n",
      "testing  :  8319  accuracy =   0.9639  loss =  149.133\n",
      "training :  8320  accuracy =   0.9700  loss =  147.891\n",
      "testing  :  8320  accuracy =   0.9645  loss =  149.11\n",
      "training :  8321  accuracy =   0.9900  loss =  146.711\n",
      "testing  :  8321  accuracy =   0.9656  loss =  149.057\n",
      "training :  8322  accuracy =   0.9800  loss =  148.171\n",
      "testing  :  8322  accuracy =   0.9662  loss =  149.015\n",
      "training :  8323  accuracy =   1.0000  loss =  146.375\n",
      "testing  :  8323  accuracy =   0.9669  loss =  148.98\n",
      "training :  8324  accuracy =   0.9900  loss =  146.328\n",
      "testing  :  8324  accuracy =   0.9674  loss =  148.943\n",
      "training :  8325  accuracy =   0.9500  loss =  151.136\n",
      "testing  :  8325  accuracy =   0.9676  loss =  148.914\n",
      "training :  8326  accuracy =   0.9900  loss =  146.541\n",
      "testing  :  8326  accuracy =   0.9675  loss =  148.874\n",
      "training :  8327  accuracy =   1.0000  loss =  146.764\n",
      "testing  :  8327  accuracy =   0.9679  loss =  148.851\n",
      "training :  8328  accuracy =   0.9800  loss =  147.165\n",
      "testing  :  8328  accuracy =   0.9676  loss =  148.839\n",
      "training :  8329  accuracy =   0.9600  loss =  149.651\n",
      "testing  :  8329  accuracy =   0.9675  loss =  148.837\n",
      "training :  8330  accuracy =   0.9900  loss =  147.257\n",
      "testing  :  8330  accuracy =   0.9672  loss =  148.848\n",
      "training :  8331  accuracy =   0.9800  loss =  147.441\n",
      "testing  :  8331  accuracy =   0.9668  loss =  148.875\n",
      "training :  8332  accuracy =   1.0000  loss =  146.477\n",
      "testing  :  8332  accuracy =   0.9668  loss =  148.915\n",
      "training :  8333  accuracy =   1.0000  loss =  146.367\n",
      "testing  :  8333  accuracy =   0.9667  loss =  148.96\n",
      "training :  8334  accuracy =   0.9800  loss =  148.507\n",
      "testing  :  8334  accuracy =   0.9663  loss =  148.996\n",
      "training :  8335  accuracy =   0.9800  loss =  147.852\n",
      "testing  :  8335  accuracy =   0.9660  loss =  149.024\n",
      "training :  8336  accuracy =   0.9800  loss =  147.581\n",
      "testing  :  8336  accuracy =   0.9658  loss =  149.051\n",
      "training :  8337  accuracy =   1.0000  loss =  146.463\n",
      "testing  :  8337  accuracy =   0.9660  loss =  149.065\n",
      "training :  8338  accuracy =   0.9700  loss =  149.206\n",
      "testing  :  8338  accuracy =   0.9660  loss =  149.087\n",
      "training :  8339  accuracy =   0.9800  loss =  147.258\n",
      "testing  :  8339  accuracy =   0.9659  loss =  149.097\n",
      "training :  8340  accuracy =   0.9700  loss =  149.416\n",
      "testing  :  8340  accuracy =   0.9657  loss =  149.091\n",
      "training :  8341  accuracy =   1.0000  loss =  146.222\n",
      "testing  :  8341  accuracy =   0.9656  loss =  149.078\n",
      "training :  8342  accuracy =   0.9800  loss =  147.738\n",
      "testing  :  8342  accuracy =   0.9660  loss =  149.064\n",
      "training :  8343  accuracy =   0.9500  loss =  151.166\n",
      "testing  :  8343  accuracy =   0.9667  loss =  149.033\n",
      "training :  8344  accuracy =   0.9900  loss =  146.488\n",
      "testing  :  8344  accuracy =   0.9668  loss =  148.998\n",
      "training :  8345  accuracy =   1.0000  loss =  146.591\n",
      "testing  :  8345  accuracy =   0.9665  loss =  148.965\n",
      "training :  8346  accuracy =   0.9800  loss =  147.669\n",
      "testing  :  8346  accuracy =   0.9664  loss =  148.938\n",
      "training :  8347  accuracy =   0.9900  loss =  147.036\n",
      "testing  :  8347  accuracy =   0.9664  loss =  148.911\n",
      "training :  8348  accuracy =   0.9700  loss =  149.196\n",
      "testing  :  8348  accuracy =   0.9666  loss =  148.881\n",
      "training :  8349  accuracy =   1.0000  loss =  146.532\n",
      "testing  :  8349  accuracy =   0.9666  loss =  148.868\n",
      "training :  8350  accuracy =   1.0000  loss =  146.446\n",
      "testing  :  8350  accuracy =   0.9670  loss =  148.866\n",
      "training :  8351  accuracy =   0.9900  loss =  147.138\n",
      "testing  :  8351  accuracy =   0.9673  loss =  148.867\n",
      "training :  8352  accuracy =   1.0000  loss =  146.194\n",
      "testing  :  8352  accuracy =   0.9672  loss =  148.864\n",
      "training :  8353  accuracy =   0.9600  loss =  149.922\n",
      "testing  :  8353  accuracy =   0.9672  loss =  148.868\n",
      "training :  8354  accuracy =   1.0000  loss =  146.188\n",
      "testing  :  8354  accuracy =   0.9675  loss =  148.87\n",
      "training :  8355  accuracy =   0.9900  loss =  147.009\n",
      "testing  :  8355  accuracy =   0.9673  loss =  148.879\n",
      "training :  8356  accuracy =   1.0000  loss =  146.431\n",
      "testing  :  8356  accuracy =   0.9672  loss =  148.892\n",
      "training :  8357  accuracy =   0.9800  loss =  147.338\n",
      "testing  :  8357  accuracy =   0.9670  loss =  148.908\n",
      "training :  8358  accuracy =   0.9900  loss =  146.85\n",
      "testing  :  8358  accuracy =   0.9668  loss =  148.928\n",
      "training :  8359  accuracy =   0.9900  loss =  147.484\n",
      "testing  :  8359  accuracy =   0.9668  loss =  148.948\n",
      "training :  8360  accuracy =   0.9800  loss =  148.319\n",
      "testing  :  8360  accuracy =   0.9661  loss =  148.959\n",
      "training :  8361  accuracy =   0.9800  loss =  147.73\n",
      "testing  :  8361  accuracy =   0.9658  loss =  148.969\n",
      "training :  8362  accuracy =   0.9800  loss =  148.276\n",
      "testing  :  8362  accuracy =   0.9654  loss =  149.004\n",
      "training :  8363  accuracy =   1.0000  loss =  146.641\n",
      "testing  :  8363  accuracy =   0.9650  loss =  149.05\n",
      "training :  8364  accuracy =   0.9800  loss =  147.551\n",
      "testing  :  8364  accuracy =   0.9642  loss =  149.094\n",
      "training :  8365  accuracy =   0.9900  loss =  146.806\n",
      "testing  :  8365  accuracy =   0.9641  loss =  149.081\n",
      "training :  8366  accuracy =   0.9900  loss =  146.764\n",
      "testing  :  8366  accuracy =   0.9637  loss =  149.103\n",
      "training :  8367  accuracy =   0.9700  loss =  148.648\n",
      "testing  :  8367  accuracy =   0.9632  loss =  149.122\n",
      "training :  8368  accuracy =   1.0000  loss =  146.731\n",
      "testing  :  8368  accuracy =   0.9632  loss =  149.134\n",
      "training :  8369  accuracy =   0.9900  loss =  146.849\n",
      "testing  :  8369  accuracy =   0.9628  loss =  149.142\n",
      "training :  8370  accuracy =   0.9700  loss =  148.529\n",
      "testing  :  8370  accuracy =   0.9628  loss =  149.14\n",
      "training :  8371  accuracy =   0.9800  loss =  147.162\n",
      "testing  :  8371  accuracy =   0.9628  loss =  149.127\n",
      "training :  8372  accuracy =   0.9900  loss =  147.396\n",
      "testing  :  8372  accuracy =   0.9625  loss =  149.125\n",
      "training :  8373  accuracy =   0.9900  loss =  146.797\n",
      "testing  :  8373  accuracy =   0.9626  loss =  149.131\n",
      "training :  8374  accuracy =   0.9900  loss =  147.414\n",
      "testing  :  8374  accuracy =   0.9628  loss =  149.115\n",
      "training :  8375  accuracy =   0.9600  loss =  149.692\n",
      "testing  :  8375  accuracy =   0.9634  loss =  149.091\n",
      "training :  8376  accuracy =   0.9800  loss =  148.348\n",
      "testing  :  8376  accuracy =   0.9640  loss =  149.072\n",
      "training :  8377  accuracy =   0.9700  loss =  148.776\n",
      "testing  :  8377  accuracy =   0.9648  loss =  149.062\n",
      "training :  8378  accuracy =   0.9900  loss =  147.237\n",
      "testing  :  8378  accuracy =   0.9655  loss =  149.021\n",
      "training :  8379  accuracy =   0.9900  loss =  147.385\n",
      "testing  :  8379  accuracy =   0.9651  loss =  148.984\n",
      "training :  8380  accuracy =   1.0000  loss =  146.216\n",
      "testing  :  8380  accuracy =   0.9653  loss =  148.956\n",
      "training :  8381  accuracy =   0.9700  loss =  147.234\n",
      "testing  :  8381  accuracy =   0.9657  loss =  148.944\n",
      "training :  8382  accuracy =   0.9800  loss =  147.416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8382  accuracy =   0.9663  loss =  148.89\n",
      "training :  8383  accuracy =   0.9900  loss =  147.25\n",
      "testing  :  8383  accuracy =   0.9675  loss =  148.849\n",
      "training :  8384  accuracy =   0.9900  loss =  147.49\n",
      "testing  :  8384  accuracy =   0.9683  loss =  148.831\n",
      "training :  8385  accuracy =   0.9800  loss =  147.624\n",
      "testing  :  8385  accuracy =   0.9673  loss =  148.828\n",
      "training :  8386  accuracy =   0.9600  loss =  150.297\n",
      "testing  :  8386  accuracy =   0.9665  loss =  148.839\n",
      "training :  8387  accuracy =   0.9800  loss =  148.326\n",
      "testing  :  8387  accuracy =   0.9662  loss =  148.878\n",
      "training :  8388  accuracy =   0.9800  loss =  148.469\n",
      "testing  :  8388  accuracy =   0.9660  loss =  148.925\n",
      "training :  8389  accuracy =   0.9900  loss =  147.436\n",
      "testing  :  8389  accuracy =   0.9657  loss =  148.964\n",
      "training :  8390  accuracy =   0.9900  loss =  147.174\n",
      "testing  :  8390  accuracy =   0.9654  loss =  148.995\n",
      "training :  8391  accuracy =   0.9800  loss =  147.075\n",
      "testing  :  8391  accuracy =   0.9649  loss =  149.021\n",
      "training :  8392  accuracy =   0.9800  loss =  148.536\n",
      "testing  :  8392  accuracy =   0.9646  loss =  149.059\n",
      "training :  8393  accuracy =   0.9700  loss =  148.315\n",
      "testing  :  8393  accuracy =   0.9648  loss =  149.095\n",
      "training :  8394  accuracy =   0.9900  loss =  147.268\n",
      "testing  :  8394  accuracy =   0.9641  loss =  149.126\n",
      "training :  8395  accuracy =   0.9900  loss =  146.702\n",
      "testing  :  8395  accuracy =   0.9644  loss =  149.156\n",
      "training :  8396  accuracy =   0.9800  loss =  148.154\n",
      "testing  :  8396  accuracy =   0.9638  loss =  149.16\n",
      "training :  8397  accuracy =   0.9800  loss =  148.056\n",
      "testing  :  8397  accuracy =   0.9631  loss =  149.219\n",
      "training :  8398  accuracy =   1.0000  loss =  146.687\n",
      "testing  :  8398  accuracy =   0.9622  loss =  149.279\n",
      "training :  8399  accuracy =   0.9800  loss =  148.311\n",
      "testing  :  8399  accuracy =   0.9612  loss =  149.311\n",
      "training :  8400  accuracy =   0.9800  loss =  147.542\n",
      "testing  :  8400  accuracy =   0.9603  loss =  149.343\n",
      "training :  8401  accuracy =   0.9900  loss =  146.883\n",
      "testing  :  8401  accuracy =   0.9590  loss =  149.405\n",
      "training :  8402  accuracy =   0.9800  loss =  148.555\n",
      "testing  :  8402  accuracy =   0.9589  loss =  149.403\n",
      "training :  8403  accuracy =   0.9700  loss =  149.333\n",
      "testing  :  8403  accuracy =   0.9588  loss =  149.392\n",
      "training :  8404  accuracy =   0.9700  loss =  147.708\n",
      "testing  :  8404  accuracy =   0.9586  loss =  149.403\n",
      "training :  8405  accuracy =   0.9600  loss =  149.0\n",
      "testing  :  8405  accuracy =   0.9590  loss =  149.426\n",
      "training :  8406  accuracy =   0.9400  loss =  150.284\n",
      "testing  :  8406  accuracy =   0.9591  loss =  149.472\n",
      "training :  8407  accuracy =   1.0000  loss =  146.489\n",
      "testing  :  8407  accuracy =   0.9596  loss =  149.463\n",
      "training :  8408  accuracy =   1.0000  loss =  146.497\n",
      "testing  :  8408  accuracy =   0.9596  loss =  149.454\n",
      "training :  8409  accuracy =   0.9900  loss =  147.551\n",
      "testing  :  8409  accuracy =   0.9598  loss =  149.44\n",
      "training :  8410  accuracy =   0.9700  loss =  147.576\n",
      "testing  :  8410  accuracy =   0.9601  loss =  149.421\n",
      "training :  8411  accuracy =   0.9600  loss =  149.995\n",
      "testing  :  8411  accuracy =   0.9611  loss =  149.404\n",
      "training :  8412  accuracy =   0.9900  loss =  147.546\n",
      "testing  :  8412  accuracy =   0.9627  loss =  149.247\n",
      "training :  8413  accuracy =   0.9800  loss =  148.327\n",
      "testing  :  8413  accuracy =   0.9647  loss =  149.137\n",
      "training :  8414  accuracy =   0.9900  loss =  147.438\n",
      "testing  :  8414  accuracy =   0.9662  loss =  149.062\n",
      "training :  8415  accuracy =   0.9900  loss =  146.751\n",
      "testing  :  8415  accuracy =   0.9667  loss =  148.983\n",
      "training :  8416  accuracy =   0.9900  loss =  146.627\n",
      "testing  :  8416  accuracy =   0.9675  loss =  148.91\n",
      "training :  8417  accuracy =   0.9900  loss =  146.329\n",
      "testing  :  8417  accuracy =   0.9680  loss =  148.875\n",
      "training :  8418  accuracy =   0.9900  loss =  147.323\n",
      "testing  :  8418  accuracy =   0.9681  loss =  148.861\n",
      "training :  8419  accuracy =   1.0000  loss =  146.297\n",
      "testing  :  8419  accuracy =   0.9687  loss =  148.847\n",
      "training :  8420  accuracy =   1.0000  loss =  146.298\n",
      "testing  :  8420  accuracy =   0.9685  loss =  148.834\n",
      "training :  8421  accuracy =   0.9700  loss =  147.717\n",
      "testing  :  8421  accuracy =   0.9690  loss =  148.829\n",
      "training :  8422  accuracy =   1.0000  loss =  146.494\n",
      "testing  :  8422  accuracy =   0.9691  loss =  148.827\n",
      "training :  8423  accuracy =   0.9900  loss =  147.322\n",
      "testing  :  8423  accuracy =   0.9688  loss =  148.835\n",
      "training :  8424  accuracy =   1.0000  loss =  146.393\n",
      "testing  :  8424  accuracy =   0.9685  loss =  148.857\n",
      "training :  8425  accuracy =   1.0000  loss =  146.315\n",
      "testing  :  8425  accuracy =   0.9682  loss =  148.884\n",
      "training :  8426  accuracy =   0.9900  loss =  146.933\n",
      "testing  :  8426  accuracy =   0.9677  loss =  148.91\n",
      "training :  8427  accuracy =   0.9800  loss =  147.644\n",
      "testing  :  8427  accuracy =   0.9672  loss =  148.92\n",
      "training :  8428  accuracy =   0.9800  loss =  147.043\n",
      "testing  :  8428  accuracy =   0.9672  loss =  148.902\n",
      "training :  8429  accuracy =   0.9800  loss =  148.516\n",
      "testing  :  8429  accuracy =   0.9677  loss =  148.872\n",
      "training :  8430  accuracy =   0.9700  loss =  147.787\n",
      "testing  :  8430  accuracy =   0.9678  loss =  148.843\n",
      "training :  8431  accuracy =   0.9800  loss =  147.097\n",
      "testing  :  8431  accuracy =   0.9676  loss =  148.886\n",
      "training :  8432  accuracy =   0.9700  loss =  148.351\n",
      "testing  :  8432  accuracy =   0.9674  loss =  148.895\n",
      "training :  8433  accuracy =   0.9500  loss =  148.871\n",
      "testing  :  8433  accuracy =   0.9661  loss =  148.917\n",
      "training :  8434  accuracy =   0.9400  loss =  151.321\n",
      "testing  :  8434  accuracy =   0.9651  loss =  149.015\n",
      "training :  8435  accuracy =   0.9900  loss =  147.228\n",
      "testing  :  8435  accuracy =   0.9635  loss =  149.063\n",
      "training :  8436  accuracy =   0.9700  loss =  147.751\n",
      "testing  :  8436  accuracy =   0.9633  loss =  149.056\n",
      "training :  8437  accuracy =   0.9800  loss =  147.704\n",
      "testing  :  8437  accuracy =   0.9635  loss =  149.066\n",
      "training :  8438  accuracy =   0.9700  loss =  148.242\n",
      "testing  :  8438  accuracy =   0.9631  loss =  149.113\n",
      "training :  8439  accuracy =   0.9700  loss =  147.021\n",
      "testing  :  8439  accuracy =   0.9633  loss =  149.166\n",
      "training :  8440  accuracy =   1.0000  loss =  146.249\n",
      "testing  :  8440  accuracy =   0.9625  loss =  149.216\n",
      "training :  8441  accuracy =   0.9700  loss =  148.066\n",
      "testing  :  8441  accuracy =   0.9612  loss =  149.3\n",
      "training :  8442  accuracy =   1.0000  loss =  146.549\n",
      "testing  :  8442  accuracy =   0.9606  loss =  149.304\n",
      "training :  8443  accuracy =   0.9600  loss =  149.443\n",
      "testing  :  8443  accuracy =   0.9606  loss =  149.295\n",
      "training :  8444  accuracy =   0.9700  loss =  149.414\n",
      "testing  :  8444  accuracy =   0.9619  loss =  149.214\n",
      "training :  8445  accuracy =   0.9700  loss =  148.321\n",
      "testing  :  8445  accuracy =   0.9625  loss =  149.151\n",
      "training :  8446  accuracy =   0.9400  loss =  150.664\n",
      "testing  :  8446  accuracy =   0.9645  loss =  149.061\n",
      "training :  8447  accuracy =   1.0000  loss =  146.552\n",
      "testing  :  8447  accuracy =   0.9644  loss =  149.027\n",
      "training :  8448  accuracy =   0.9900  loss =  147.551\n",
      "testing  :  8448  accuracy =   0.9648  loss =  149.039\n",
      "training :  8449  accuracy =   0.9900  loss =  147.557\n",
      "testing  :  8449  accuracy =   0.9646  loss =  149.054\n",
      "training :  8450  accuracy =   0.9900  loss =  146.83\n",
      "testing  :  8450  accuracy =   0.9655  loss =  149.068\n",
      "training :  8451  accuracy =   0.9800  loss =  148.299\n",
      "testing  :  8451  accuracy =   0.9660  loss =  149.072\n",
      "training :  8452  accuracy =   0.9900  loss =  147.385\n",
      "testing  :  8452  accuracy =   0.9655  loss =  149.09\n",
      "training :  8453  accuracy =   0.9900  loss =  147.549\n",
      "testing  :  8453  accuracy =   0.9646  loss =  149.111\n",
      "training :  8454  accuracy =   0.9900  loss =  147.623\n",
      "testing  :  8454  accuracy =   0.9641  loss =  149.125\n",
      "training :  8455  accuracy =   1.0000  loss =  146.419\n",
      "testing  :  8455  accuracy =   0.9648  loss =  149.134\n",
      "training :  8456  accuracy =   1.0000  loss =  146.378\n",
      "testing  :  8456  accuracy =   0.9650  loss =  149.146\n",
      "training :  8457  accuracy =   1.0000  loss =  146.196\n",
      "testing  :  8457  accuracy =   0.9649  loss =  149.158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  8458  accuracy =   0.9700  loss =  147.79\n",
      "testing  :  8458  accuracy =   0.9649  loss =  149.166\n",
      "training :  8459  accuracy =   1.0000  loss =  146.646\n",
      "testing  :  8459  accuracy =   0.9649  loss =  149.145\n",
      "training :  8460  accuracy =   0.9600  loss =  149.364\n",
      "testing  :  8460  accuracy =   0.9650  loss =  149.127\n",
      "training :  8461  accuracy =   0.9700  loss =  149.703\n",
      "testing  :  8461  accuracy =   0.9647  loss =  149.1\n",
      "training :  8462  accuracy =   1.0000  loss =  146.386\n",
      "testing  :  8462  accuracy =   0.9653  loss =  149.057\n",
      "training :  8463  accuracy =   0.9900  loss =  146.718\n",
      "testing  :  8463  accuracy =   0.9658  loss =  149.025\n",
      "training :  8464  accuracy =   0.9900  loss =  147.326\n",
      "testing  :  8464  accuracy =   0.9656  loss =  149.021\n",
      "training :  8465  accuracy =   0.9900  loss =  147.231\n",
      "testing  :  8465  accuracy =   0.9654  loss =  149.019\n",
      "training :  8466  accuracy =   0.9700  loss =  148.963\n",
      "testing  :  8466  accuracy =   0.9648  loss =  149.017\n",
      "training :  8467  accuracy =   0.9700  loss =  149.176\n",
      "testing  :  8467  accuracy =   0.9654  loss =  149.006\n",
      "training :  8468  accuracy =   0.9900  loss =  147.093\n",
      "testing  :  8468  accuracy =   0.9656  loss =  148.992\n",
      "training :  8469  accuracy =   0.9700  loss =  147.286\n",
      "testing  :  8469  accuracy =   0.9660  loss =  148.985\n",
      "training :  8470  accuracy =   0.9800  loss =  147.122\n",
      "testing  :  8470  accuracy =   0.9668  loss =  148.93\n",
      "training :  8471  accuracy =   0.9800  loss =  147.495\n",
      "testing  :  8471  accuracy =   0.9664  loss =  148.933\n",
      "training :  8472  accuracy =   0.9600  loss =  149.032\n",
      "testing  :  8472  accuracy =   0.9670  loss =  148.962\n",
      "training :  8473  accuracy =   0.9900  loss =  146.575\n",
      "testing  :  8473  accuracy =   0.9660  loss =  149.017\n",
      "training :  8474  accuracy =   0.9900  loss =  147.472\n",
      "testing  :  8474  accuracy =   0.9647  loss =  149.095\n",
      "training :  8475  accuracy =   0.9500  loss =  149.712\n",
      "testing  :  8475  accuracy =   0.9640  loss =  149.157\n",
      "training :  8476  accuracy =   0.9800  loss =  148.79\n",
      "testing  :  8476  accuracy =   0.9627  loss =  149.225\n",
      "training :  8477  accuracy =   0.9900  loss =  146.689\n",
      "testing  :  8477  accuracy =   0.9619  loss =  149.296\n",
      "training :  8478  accuracy =   0.9800  loss =  148.569\n",
      "testing  :  8478  accuracy =   0.9614  loss =  149.372\n",
      "training :  8479  accuracy =   0.9900  loss =  147.792\n",
      "testing  :  8479  accuracy =   0.9604  loss =  149.436\n",
      "training :  8480  accuracy =   0.9500  loss =  150.443\n",
      "testing  :  8480  accuracy =   0.9600  loss =  149.476\n",
      "training :  8481  accuracy =   0.9700  loss =  148.52\n",
      "testing  :  8481  accuracy =   0.9595  loss =  149.497\n",
      "training :  8482  accuracy =   0.9900  loss =  146.759\n",
      "testing  :  8482  accuracy =   0.9593  loss =  149.536\n",
      "training :  8483  accuracy =   0.9700  loss =  148.426\n",
      "testing  :  8483  accuracy =   0.9599  loss =  149.513\n",
      "training :  8484  accuracy =   0.9500  loss =  148.886\n",
      "testing  :  8484  accuracy =   0.9603  loss =  149.482\n",
      "training :  8485  accuracy =   0.9700  loss =  147.553\n",
      "testing  :  8485  accuracy =   0.9603  loss =  149.413\n",
      "training :  8486  accuracy =   0.9700  loss =  147.962\n",
      "testing  :  8486  accuracy =   0.9611  loss =  149.37\n",
      "training :  8487  accuracy =   0.9900  loss =  146.426\n",
      "testing  :  8487  accuracy =   0.9620  loss =  149.313\n",
      "training :  8488  accuracy =   0.9800  loss =  148.3\n",
      "testing  :  8488  accuracy =   0.9623  loss =  149.268\n",
      "training :  8489  accuracy =   0.9600  loss =  148.451\n",
      "testing  :  8489  accuracy =   0.9640  loss =  149.244\n",
      "training :  8490  accuracy =   0.9900  loss =  146.945\n",
      "testing  :  8490  accuracy =   0.9644  loss =  149.219\n",
      "training :  8491  accuracy =   0.9900  loss =  147.66\n",
      "testing  :  8491  accuracy =   0.9640  loss =  149.173\n",
      "training :  8492  accuracy =   0.9600  loss =  148.791\n",
      "testing  :  8492  accuracy =   0.9644  loss =  149.127\n",
      "training :  8493  accuracy =   0.9800  loss =  146.608\n",
      "testing  :  8493  accuracy =   0.9648  loss =  149.09\n",
      "training :  8494  accuracy =   0.9800  loss =  147.548\n",
      "testing  :  8494  accuracy =   0.9651  loss =  149.063\n",
      "training :  8495  accuracy =   1.0000  loss =  146.388\n",
      "testing  :  8495  accuracy =   0.9657  loss =  149.047\n",
      "training :  8496  accuracy =   0.9900  loss =  147.615\n",
      "testing  :  8496  accuracy =   0.9661  loss =  149.037\n",
      "training :  8497  accuracy =   0.9800  loss =  147.68\n",
      "testing  :  8497  accuracy =   0.9659  loss =  149.029\n",
      "training :  8498  accuracy =   0.9900  loss =  146.843\n",
      "testing  :  8498  accuracy =   0.9656  loss =  149.021\n",
      "training :  8499  accuracy =   0.9600  loss =  150.766\n",
      "testing  :  8499  accuracy =   0.9660  loss =  149.01\n",
      "training :  8500  accuracy =   0.9600  loss =  148.966\n",
      "testing  :  8500  accuracy =   0.9665  loss =  148.999\n",
      "training :  8501  accuracy =   0.9800  loss =  146.654\n",
      "testing  :  8501  accuracy =   0.9667  loss =  148.987\n",
      "training :  8502  accuracy =   0.9500  loss =  150.972\n",
      "testing  :  8502  accuracy =   0.9667  loss =  148.978\n",
      "training :  8503  accuracy =   0.9900  loss =  147.063\n",
      "testing  :  8503  accuracy =   0.9669  loss =  148.969\n",
      "training :  8504  accuracy =   0.9900  loss =  147.497\n",
      "testing  :  8504  accuracy =   0.9664  loss =  149.001\n",
      "training :  8505  accuracy =   0.9700  loss =  148.338\n",
      "testing  :  8505  accuracy =   0.9664  loss =  149.019\n",
      "training :  8506  accuracy =   0.9800  loss =  147.745\n",
      "testing  :  8506  accuracy =   0.9656  loss =  149.029\n",
      "training :  8507  accuracy =   1.0000  loss =  146.325\n",
      "testing  :  8507  accuracy =   0.9654  loss =  149.007\n",
      "training :  8508  accuracy =   0.9800  loss =  147.963\n",
      "testing  :  8508  accuracy =   0.9654  loss =  148.997\n",
      "training :  8509  accuracy =   0.9900  loss =  146.868\n",
      "testing  :  8509  accuracy =   0.9659  loss =  148.988\n",
      "training :  8510  accuracy =   0.9500  loss =  150.489\n",
      "testing  :  8510  accuracy =   0.9662  loss =  148.978\n",
      "training :  8511  accuracy =   1.0000  loss =  146.435\n",
      "testing  :  8511  accuracy =   0.9665  loss =  148.968\n",
      "training :  8512  accuracy =   0.9900  loss =  147.304\n",
      "testing  :  8512  accuracy =   0.9665  loss =  148.957\n",
      "training :  8513  accuracy =   1.0000  loss =  146.571\n",
      "testing  :  8513  accuracy =   0.9660  loss =  148.949\n",
      "training :  8514  accuracy =   0.9900  loss =  147.636\n",
      "testing  :  8514  accuracy =   0.9658  loss =  148.933\n",
      "training :  8515  accuracy =   0.9800  loss =  148.446\n",
      "testing  :  8515  accuracy =   0.9662  loss =  148.926\n",
      "training :  8516  accuracy =   0.9600  loss =  149.955\n",
      "testing  :  8516  accuracy =   0.9664  loss =  148.92\n",
      "training :  8517  accuracy =   0.9900  loss =  147.186\n",
      "testing  :  8517  accuracy =   0.9661  loss =  148.926\n",
      "training :  8518  accuracy =   0.9700  loss =  149.273\n",
      "testing  :  8518  accuracy =   0.9662  loss =  148.942\n",
      "training :  8519  accuracy =   0.9800  loss =  147.897\n",
      "testing  :  8519  accuracy =   0.9657  loss =  148.963\n",
      "training :  8520  accuracy =   0.9900  loss =  146.759\n",
      "testing  :  8520  accuracy =   0.9656  loss =  148.967\n",
      "training :  8521  accuracy =   0.9400  loss =  151.776\n",
      "testing  :  8521  accuracy =   0.9651  loss =  149.027\n",
      "training :  8522  accuracy =   0.9800  loss =  147.84\n",
      "testing  :  8522  accuracy =   0.9645  loss =  149.077\n",
      "training :  8523  accuracy =   1.0000  loss =  146.44\n",
      "testing  :  8523  accuracy =   0.9629  loss =  149.178\n",
      "training :  8524  accuracy =   0.9900  loss =  147.233\n",
      "testing  :  8524  accuracy =   0.9615  loss =  149.311\n",
      "training :  8525  accuracy =   0.9800  loss =  147.816\n",
      "testing  :  8525  accuracy =   0.9595  loss =  149.443\n",
      "training :  8526  accuracy =   1.0000  loss =  146.292\n",
      "testing  :  8526  accuracy =   0.9585  loss =  149.545\n",
      "training :  8527  accuracy =   0.9900  loss =  146.901\n",
      "testing  :  8527  accuracy =   0.9571  loss =  149.639\n",
      "training :  8528  accuracy =   0.9300  loss =  151.081\n",
      "testing  :  8528  accuracy =   0.9563  loss =  149.706\n",
      "training :  8529  accuracy =   0.9600  loss =  148.656\n",
      "testing  :  8529  accuracy =   0.9573  loss =  149.662\n",
      "training :  8530  accuracy =   0.9800  loss =  147.665\n",
      "testing  :  8530  accuracy =   0.9581  loss =  149.615\n",
      "training :  8531  accuracy =   0.9700  loss =  147.634\n",
      "testing  :  8531  accuracy =   0.9588  loss =  149.524\n",
      "training :  8532  accuracy =   1.0000  loss =  146.426\n",
      "testing  :  8532  accuracy =   0.9595  loss =  149.407\n",
      "training :  8533  accuracy =   0.9700  loss =  148.584\n",
      "testing  :  8533  accuracy =   0.9605  loss =  149.346\n",
      "training :  8534  accuracy =   0.9700  loss =  148.573\n",
      "testing  :  8534  accuracy =   0.9611  loss =  149.304\n",
      "training :  8535  accuracy =   0.9900  loss =  147.205\n",
      "testing  :  8535  accuracy =   0.9620  loss =  149.266\n",
      "training :  8536  accuracy =   0.9800  loss =  147.68\n",
      "testing  :  8536  accuracy =   0.9627  loss =  149.23\n",
      "training :  8537  accuracy =   0.9600  loss =  150.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8537  accuracy =   0.9628  loss =  149.215\n",
      "training :  8538  accuracy =   0.9700  loss =  148.535\n",
      "testing  :  8538  accuracy =   0.9635  loss =  149.21\n",
      "training :  8539  accuracy =   0.9600  loss =  150.488\n",
      "testing  :  8539  accuracy =   0.9636  loss =  149.204\n",
      "training :  8540  accuracy =   0.9800  loss =  146.775\n",
      "testing  :  8540  accuracy =   0.9638  loss =  149.206\n",
      "training :  8541  accuracy =   0.9500  loss =  149.588\n",
      "testing  :  8541  accuracy =   0.9639  loss =  149.204\n",
      "training :  8542  accuracy =   0.9700  loss =  148.533\n",
      "testing  :  8542  accuracy =   0.9642  loss =  149.167\n",
      "training :  8543  accuracy =   1.0000  loss =  146.156\n",
      "testing  :  8543  accuracy =   0.9639  loss =  149.145\n",
      "training :  8544  accuracy =   0.9900  loss =  147.372\n",
      "testing  :  8544  accuracy =   0.9645  loss =  149.138\n",
      "training :  8545  accuracy =   0.9900  loss =  147.434\n",
      "testing  :  8545  accuracy =   0.9649  loss =  149.132\n",
      "training :  8546  accuracy =   1.0000  loss =  146.239\n",
      "testing  :  8546  accuracy =   0.9648  loss =  149.124\n",
      "training :  8547  accuracy =   0.9800  loss =  147.592\n",
      "testing  :  8547  accuracy =   0.9650  loss =  149.12\n",
      "training :  8548  accuracy =   0.9900  loss =  147.235\n",
      "testing  :  8548  accuracy =   0.9650  loss =  149.115\n",
      "training :  8549  accuracy =   0.9900  loss =  146.796\n",
      "testing  :  8549  accuracy =   0.9647  loss =  149.105\n",
      "training :  8550  accuracy =   1.0000  loss =  146.543\n",
      "testing  :  8550  accuracy =   0.9648  loss =  149.079\n",
      "training :  8551  accuracy =   1.0000  loss =  146.169\n",
      "testing  :  8551  accuracy =   0.9647  loss =  149.051\n",
      "training :  8552  accuracy =   0.9800  loss =  148.453\n",
      "testing  :  8552  accuracy =   0.9650  loss =  149.029\n",
      "training :  8553  accuracy =   0.9800  loss =  148.323\n",
      "testing  :  8553  accuracy =   0.9649  loss =  149.018\n",
      "training :  8554  accuracy =   1.0000  loss =  146.267\n",
      "testing  :  8554  accuracy =   0.9651  loss =  149.008\n",
      "training :  8555  accuracy =   0.9900  loss =  147.243\n",
      "testing  :  8555  accuracy =   0.9650  loss =  148.998\n",
      "training :  8556  accuracy =   0.9700  loss =  149.301\n",
      "testing  :  8556  accuracy =   0.9650  loss =  148.995\n",
      "training :  8557  accuracy =   1.0000  loss =  146.298\n",
      "testing  :  8557  accuracy =   0.9646  loss =  148.987\n",
      "training :  8558  accuracy =   1.0000  loss =  146.478\n",
      "testing  :  8558  accuracy =   0.9648  loss =  148.981\n",
      "training :  8559  accuracy =   0.9700  loss =  147.635\n",
      "testing  :  8559  accuracy =   0.9647  loss =  148.984\n",
      "training :  8560  accuracy =   0.9800  loss =  146.908\n",
      "testing  :  8560  accuracy =   0.9647  loss =  148.982\n",
      "training :  8561  accuracy =   0.9600  loss =  149.644\n",
      "testing  :  8561  accuracy =   0.9650  loss =  148.976\n",
      "training :  8562  accuracy =   0.9900  loss =  147.522\n",
      "testing  :  8562  accuracy =   0.9648  loss =  148.988\n",
      "training :  8563  accuracy =   0.9900  loss =  147.177\n",
      "testing  :  8563  accuracy =   0.9654  loss =  148.994\n",
      "training :  8564  accuracy =   0.9900  loss =  147.549\n",
      "testing  :  8564  accuracy =   0.9653  loss =  149.013\n",
      "training :  8565  accuracy =   0.9900  loss =  147.275\n",
      "testing  :  8565  accuracy =   0.9653  loss =  149.039\n",
      "training :  8566  accuracy =   0.9800  loss =  148.388\n",
      "testing  :  8566  accuracy =   0.9657  loss =  149.076\n",
      "training :  8567  accuracy =   1.0000  loss =  146.403\n",
      "testing  :  8567  accuracy =   0.9656  loss =  149.102\n",
      "training :  8568  accuracy =   0.9600  loss =  150.788\n",
      "testing  :  8568  accuracy =   0.9655  loss =  149.105\n",
      "training :  8569  accuracy =   0.9800  loss =  148.571\n",
      "testing  :  8569  accuracy =   0.9661  loss =  149.092\n",
      "training :  8570  accuracy =   0.9800  loss =  146.971\n",
      "testing  :  8570  accuracy =   0.9659  loss =  149.082\n",
      "training :  8571  accuracy =   0.9800  loss =  147.372\n",
      "testing  :  8571  accuracy =   0.9664  loss =  149.067\n",
      "training :  8572  accuracy =   0.9900  loss =  147.202\n",
      "testing  :  8572  accuracy =   0.9658  loss =  149.048\n",
      "training :  8573  accuracy =   0.9800  loss =  147.433\n",
      "testing  :  8573  accuracy =   0.9673  loss =  149.054\n",
      "training :  8574  accuracy =   0.9700  loss =  148.569\n",
      "testing  :  8574  accuracy =   0.9667  loss =  149.071\n",
      "training :  8575  accuracy =   0.9800  loss =  147.565\n",
      "testing  :  8575  accuracy =   0.9669  loss =  149.05\n",
      "training :  8576  accuracy =   0.9500  loss =  149.473\n",
      "testing  :  8576  accuracy =   0.9672  loss =  149.015\n",
      "training :  8577  accuracy =   0.9800  loss =  148.486\n",
      "testing  :  8577  accuracy =   0.9670  loss =  148.98\n",
      "training :  8578  accuracy =   1.0000  loss =  146.225\n",
      "testing  :  8578  accuracy =   0.9682  loss =  148.948\n",
      "training :  8579  accuracy =   0.9900  loss =  147.279\n",
      "testing  :  8579  accuracy =   0.9684  loss =  148.93\n",
      "training :  8580  accuracy =   0.9900  loss =  147.433\n",
      "testing  :  8580  accuracy =   0.9681  loss =  148.915\n",
      "training :  8581  accuracy =   0.9500  loss =  150.74\n",
      "testing  :  8581  accuracy =   0.9683  loss =  148.903\n",
      "training :  8582  accuracy =   0.9800  loss =  148.002\n",
      "testing  :  8582  accuracy =   0.9689  loss =  148.88\n",
      "training :  8583  accuracy =   0.9700  loss =  148.437\n",
      "testing  :  8583  accuracy =   0.9684  loss =  148.868\n",
      "training :  8584  accuracy =   0.9800  loss =  146.753\n",
      "testing  :  8584  accuracy =   0.9681  loss =  148.889\n",
      "training :  8585  accuracy =   0.9900  loss =  146.608\n",
      "testing  :  8585  accuracy =   0.9673  loss =  148.936\n",
      "training :  8586  accuracy =   0.9900  loss =  146.439\n",
      "testing  :  8586  accuracy =   0.9670  loss =  148.995\n",
      "training :  8587  accuracy =   0.9700  loss =  148.228\n",
      "testing  :  8587  accuracy =   0.9655  loss =  149.07\n",
      "training :  8588  accuracy =   0.9800  loss =  148.264\n",
      "testing  :  8588  accuracy =   0.9636  loss =  149.153\n",
      "training :  8589  accuracy =   0.9700  loss =  148.471\n",
      "testing  :  8589  accuracy =   0.9631  loss =  149.196\n",
      "training :  8590  accuracy =   0.9900  loss =  146.54\n",
      "testing  :  8590  accuracy =   0.9618  loss =  149.254\n",
      "training :  8591  accuracy =   0.9800  loss =  148.744\n",
      "testing  :  8591  accuracy =   0.9610  loss =  149.306\n",
      "training :  8592  accuracy =   0.9500  loss =  150.79\n",
      "testing  :  8592  accuracy =   0.9611  loss =  149.301\n",
      "training :  8593  accuracy =   0.9900  loss =  147.389\n",
      "testing  :  8593  accuracy =   0.9618  loss =  149.274\n",
      "training :  8594  accuracy =   0.9900  loss =  147.655\n",
      "testing  :  8594  accuracy =   0.9628  loss =  149.245\n",
      "training :  8595  accuracy =   0.9800  loss =  147.675\n",
      "testing  :  8595  accuracy =   0.9630  loss =  149.22\n",
      "training :  8596  accuracy =   0.9700  loss =  147.84\n",
      "testing  :  8596  accuracy =   0.9638  loss =  149.17\n",
      "training :  8597  accuracy =   0.9900  loss =  146.63\n",
      "testing  :  8597  accuracy =   0.9646  loss =  149.113\n",
      "training :  8598  accuracy =   0.9800  loss =  147.427\n",
      "testing  :  8598  accuracy =   0.9647  loss =  149.077\n",
      "training :  8599  accuracy =   0.9900  loss =  146.82\n",
      "testing  :  8599  accuracy =   0.9651  loss =  149.029\n",
      "training :  8600  accuracy =   1.0000  loss =  146.37\n",
      "testing  :  8600  accuracy =   0.9656  loss =  149.0\n",
      "training :  8601  accuracy =   0.9500  loss =  150.137\n",
      "testing  :  8601  accuracy =   0.9659  loss =  148.985\n",
      "training :  8602  accuracy =   0.9700  loss =  149.006\n",
      "testing  :  8602  accuracy =   0.9659  loss =  148.983\n",
      "training :  8603  accuracy =   0.9900  loss =  147.504\n",
      "testing  :  8603  accuracy =   0.9663  loss =  148.983\n",
      "training :  8604  accuracy =   0.9900  loss =  146.941\n",
      "testing  :  8604  accuracy =   0.9663  loss =  148.997\n",
      "training :  8605  accuracy =   0.9900  loss =  147.263\n",
      "testing  :  8605  accuracy =   0.9665  loss =  149.011\n",
      "training :  8606  accuracy =   0.9700  loss =  148.858\n",
      "testing  :  8606  accuracy =   0.9662  loss =  149.047\n",
      "training :  8607  accuracy =   0.9800  loss =  146.799\n",
      "testing  :  8607  accuracy =   0.9665  loss =  149.058\n",
      "training :  8608  accuracy =   1.0000  loss =  146.353\n",
      "testing  :  8608  accuracy =   0.9668  loss =  149.031\n",
      "training :  8609  accuracy =   0.9700  loss =  148.693\n",
      "testing  :  8609  accuracy =   0.9667  loss =  149.007\n",
      "training :  8610  accuracy =   0.9900  loss =  146.319\n",
      "testing  :  8610  accuracy =   0.9669  loss =  148.984\n",
      "training :  8611  accuracy =   1.0000  loss =  146.437\n",
      "testing  :  8611  accuracy =   0.9673  loss =  148.967\n",
      "training :  8612  accuracy =   0.9600  loss =  149.656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8612  accuracy =   0.9675  loss =  148.956\n",
      "training :  8613  accuracy =   0.9900  loss =  147.167\n",
      "testing  :  8613  accuracy =   0.9677  loss =  148.934\n",
      "training :  8614  accuracy =   1.0000  loss =  146.274\n",
      "testing  :  8614  accuracy =   0.9677  loss =  148.915\n",
      "training :  8615  accuracy =   0.9900  loss =  147.541\n",
      "testing  :  8615  accuracy =   0.9681  loss =  148.898\n",
      "training :  8616  accuracy =   0.9900  loss =  147.342\n",
      "testing  :  8616  accuracy =   0.9683  loss =  148.881\n",
      "training :  8617  accuracy =   0.9800  loss =  146.472\n",
      "testing  :  8617  accuracy =   0.9685  loss =  148.868\n",
      "training :  8618  accuracy =   0.9600  loss =  148.874\n",
      "testing  :  8618  accuracy =   0.9687  loss =  148.855\n",
      "training :  8619  accuracy =   1.0000  loss =  146.278\n",
      "testing  :  8619  accuracy =   0.9688  loss =  148.838\n",
      "training :  8620  accuracy =   1.0000  loss =  146.443\n",
      "testing  :  8620  accuracy =   0.9686  loss =  148.828\n",
      "training :  8621  accuracy =   0.9800  loss =  146.696\n",
      "testing  :  8621  accuracy =   0.9690  loss =  148.82\n",
      "training :  8622  accuracy =   0.9700  loss =  148.426\n",
      "testing  :  8622  accuracy =   0.9689  loss =  148.812\n",
      "training :  8623  accuracy =   0.9900  loss =  146.426\n",
      "testing  :  8623  accuracy =   0.9688  loss =  148.81\n",
      "training :  8624  accuracy =   0.9800  loss =  147.361\n",
      "testing  :  8624  accuracy =   0.9688  loss =  148.814\n",
      "training :  8625  accuracy =   0.9800  loss =  147.163\n",
      "testing  :  8625  accuracy =   0.9690  loss =  148.823\n",
      "training :  8626  accuracy =   0.9800  loss =  147.405\n",
      "testing  :  8626  accuracy =   0.9691  loss =  148.834\n",
      "training :  8627  accuracy =   0.9400  loss =  152.007\n",
      "testing  :  8627  accuracy =   0.9688  loss =  148.837\n",
      "training :  8628  accuracy =   0.9800  loss =  147.353\n",
      "testing  :  8628  accuracy =   0.9681  loss =  148.848\n",
      "training :  8629  accuracy =   0.9400  loss =  151.396\n",
      "testing  :  8629  accuracy =   0.9673  loss =  148.876\n",
      "training :  8630  accuracy =   0.9700  loss =  148.61\n",
      "testing  :  8630  accuracy =   0.9669  loss =  148.892\n",
      "training :  8631  accuracy =   0.9600  loss =  149.093\n",
      "testing  :  8631  accuracy =   0.9672  loss =  148.901\n",
      "training :  8632  accuracy =   1.0000  loss =  146.441\n",
      "testing  :  8632  accuracy =   0.9675  loss =  148.906\n",
      "training :  8633  accuracy =   0.9700  loss =  147.772\n",
      "testing  :  8633  accuracy =   0.9675  loss =  148.925\n",
      "training :  8634  accuracy =   0.9900  loss =  146.627\n",
      "testing  :  8634  accuracy =   0.9673  loss =  148.915\n",
      "training :  8635  accuracy =   1.0000  loss =  147.023\n",
      "testing  :  8635  accuracy =   0.9674  loss =  148.895\n",
      "training :  8636  accuracy =   0.9600  loss =  149.124\n",
      "testing  :  8636  accuracy =   0.9676  loss =  148.881\n",
      "training :  8637  accuracy =   0.9900  loss =  146.506\n",
      "testing  :  8637  accuracy =   0.9675  loss =  148.846\n",
      "training :  8638  accuracy =   0.9900  loss =  147.578\n",
      "testing  :  8638  accuracy =   0.9683  loss =  148.84\n",
      "training :  8639  accuracy =   0.9800  loss =  148.259\n",
      "testing  :  8639  accuracy =   0.9680  loss =  148.845\n",
      "training :  8640  accuracy =   1.0000  loss =  146.386\n",
      "testing  :  8640  accuracy =   0.9677  loss =  148.859\n",
      "training :  8641  accuracy =   0.9700  loss =  149.507\n",
      "testing  :  8641  accuracy =   0.9675  loss =  148.883\n",
      "training :  8642  accuracy =   0.9700  loss =  147.432\n",
      "testing  :  8642  accuracy =   0.9673  loss =  148.911\n",
      "training :  8643  accuracy =   0.9900  loss =  147.576\n",
      "testing  :  8643  accuracy =   0.9662  loss =  148.945\n",
      "training :  8644  accuracy =   0.9900  loss =  146.951\n",
      "testing  :  8644  accuracy =   0.9660  loss =  148.978\n",
      "training :  8645  accuracy =   0.9800  loss =  147.341\n",
      "testing  :  8645  accuracy =   0.9667  loss =  148.966\n",
      "training :  8646  accuracy =   0.9900  loss =  146.718\n",
      "testing  :  8646  accuracy =   0.9666  loss =  148.96\n",
      "training :  8647  accuracy =   0.9900  loss =  146.564\n",
      "testing  :  8647  accuracy =   0.9671  loss =  148.996\n",
      "training :  8648  accuracy =   1.0000  loss =  146.328\n",
      "testing  :  8648  accuracy =   0.9670  loss =  148.995\n",
      "training :  8649  accuracy =   0.9900  loss =  146.572\n",
      "testing  :  8649  accuracy =   0.9666  loss =  149.0\n",
      "training :  8650  accuracy =   0.9800  loss =  148.086\n",
      "testing  :  8650  accuracy =   0.9661  loss =  149.006\n",
      "training :  8651  accuracy =   0.9900  loss =  147.357\n",
      "testing  :  8651  accuracy =   0.9658  loss =  149.006\n",
      "training :  8652  accuracy =   0.9900  loss =  147.148\n",
      "testing  :  8652  accuracy =   0.9660  loss =  149.003\n",
      "training :  8653  accuracy =   0.9900  loss =  146.95\n",
      "testing  :  8653  accuracy =   0.9661  loss =  149.006\n",
      "training :  8654  accuracy =   1.0000  loss =  146.32\n",
      "testing  :  8654  accuracy =   0.9662  loss =  148.985\n",
      "training :  8655  accuracy =   1.0000  loss =  146.252\n",
      "testing  :  8655  accuracy =   0.9663  loss =  148.97\n",
      "training :  8656  accuracy =   0.9900  loss =  147.239\n",
      "testing  :  8656  accuracy =   0.9663  loss =  148.966\n",
      "training :  8657  accuracy =   0.9800  loss =  148.525\n",
      "testing  :  8657  accuracy =   0.9665  loss =  148.969\n",
      "training :  8658  accuracy =   0.9900  loss =  147.351\n",
      "testing  :  8658  accuracy =   0.9661  loss =  148.97\n",
      "training :  8659  accuracy =   0.9900  loss =  147.292\n",
      "testing  :  8659  accuracy =   0.9662  loss =  148.968\n",
      "training :  8660  accuracy =   0.9500  loss =  150.629\n",
      "testing  :  8660  accuracy =   0.9680  loss =  148.894\n",
      "training :  8661  accuracy =   0.9500  loss =  150.424\n",
      "testing  :  8661  accuracy =   0.9690  loss =  148.82\n",
      "training :  8662  accuracy =   1.0000  loss =  146.351\n",
      "testing  :  8662  accuracy =   0.9688  loss =  148.797\n",
      "training :  8663  accuracy =   0.9800  loss =  147.618\n",
      "testing  :  8663  accuracy =   0.9695  loss =  148.793\n",
      "training :  8664  accuracy =   0.9800  loss =  147.307\n",
      "testing  :  8664  accuracy =   0.9687  loss =  148.777\n",
      "training :  8665  accuracy =   0.9800  loss =  146.581\n",
      "testing  :  8665  accuracy =   0.9690  loss =  148.786\n",
      "training :  8666  accuracy =   0.9900  loss =  146.423\n",
      "testing  :  8666  accuracy =   0.9687  loss =  148.808\n",
      "training :  8667  accuracy =   0.9900  loss =  147.178\n",
      "testing  :  8667  accuracy =   0.9684  loss =  148.872\n",
      "training :  8668  accuracy =   0.9800  loss =  146.639\n",
      "testing  :  8668  accuracy =   0.9672  loss =  148.946\n",
      "training :  8669  accuracy =   0.9900  loss =  146.987\n",
      "testing  :  8669  accuracy =   0.9663  loss =  149.01\n",
      "training :  8670  accuracy =   0.9900  loss =  147.393\n",
      "testing  :  8670  accuracy =   0.9649  loss =  149.078\n",
      "training :  8671  accuracy =   1.0000  loss =  146.353\n",
      "testing  :  8671  accuracy =   0.9643  loss =  149.138\n",
      "training :  8672  accuracy =   0.9900  loss =  146.529\n",
      "testing  :  8672  accuracy =   0.9632  loss =  149.201\n",
      "training :  8673  accuracy =   0.9900  loss =  146.786\n",
      "testing  :  8673  accuracy =   0.9630  loss =  149.247\n",
      "training :  8674  accuracy =   0.9700  loss =  148.572\n",
      "testing  :  8674  accuracy =   0.9629  loss =  149.268\n",
      "training :  8675  accuracy =   0.9700  loss =  149.24\n",
      "testing  :  8675  accuracy =   0.9632  loss =  149.258\n",
      "training :  8676  accuracy =   0.9900  loss =  147.299\n",
      "testing  :  8676  accuracy =   0.9629  loss =  149.244\n",
      "training :  8677  accuracy =   0.9900  loss =  147.205\n",
      "testing  :  8677  accuracy =   0.9629  loss =  149.237\n",
      "training :  8678  accuracy =   0.9700  loss =  147.515\n",
      "testing  :  8678  accuracy =   0.9627  loss =  149.246\n",
      "training :  8679  accuracy =   0.9800  loss =  148.464\n",
      "testing  :  8679  accuracy =   0.9654  loss =  149.065\n",
      "training :  8680  accuracy =   0.9600  loss =  148.851\n",
      "testing  :  8680  accuracy =   0.9676  loss =  148.955\n",
      "training :  8681  accuracy =   0.9700  loss =  148.438\n",
      "testing  :  8681  accuracy =   0.9674  loss =  148.925\n",
      "training :  8682  accuracy =   0.9900  loss =  146.469\n",
      "testing  :  8682  accuracy =   0.9675  loss =  148.915\n",
      "training :  8683  accuracy =   1.0000  loss =  146.194\n",
      "testing  :  8683  accuracy =   0.9668  loss =  148.923\n",
      "training :  8684  accuracy =   1.0000  loss =  146.308\n",
      "testing  :  8684  accuracy =   0.9667  loss =  148.964\n",
      "training :  8685  accuracy =   1.0000  loss =  146.432\n",
      "testing  :  8685  accuracy =   0.9663  loss =  149.013\n",
      "training :  8686  accuracy =   0.9600  loss =  150.043\n",
      "testing  :  8686  accuracy =   0.9656  loss =  149.069\n",
      "training :  8687  accuracy =   0.9700  loss =  148.667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8687  accuracy =   0.9664  loss =  149.018\n",
      "training :  8688  accuracy =   0.9900  loss =  146.509\n",
      "testing  :  8688  accuracy =   0.9661  loss =  148.982\n",
      "training :  8689  accuracy =   0.9900  loss =  147.435\n",
      "testing  :  8689  accuracy =   0.9659  loss =  148.988\n",
      "training :  8690  accuracy =   0.9900  loss =  147.45\n",
      "testing  :  8690  accuracy =   0.9661  loss =  149.019\n",
      "training :  8691  accuracy =   0.9900  loss =  147.161\n",
      "testing  :  8691  accuracy =   0.9662  loss =  149.024\n",
      "training :  8692  accuracy =   0.9600  loss =  149.584\n",
      "testing  :  8692  accuracy =   0.9665  loss =  149.026\n",
      "training :  8693  accuracy =   0.9800  loss =  147.244\n",
      "testing  :  8693  accuracy =   0.9671  loss =  149.016\n",
      "training :  8694  accuracy =   0.9700  loss =  148.991\n",
      "testing  :  8694  accuracy =   0.9678  loss =  148.986\n",
      "training :  8695  accuracy =   0.9900  loss =  147.393\n",
      "testing  :  8695  accuracy =   0.9680  loss =  148.929\n",
      "training :  8696  accuracy =   0.9800  loss =  147.52\n",
      "testing  :  8696  accuracy =   0.9678  loss =  148.878\n",
      "training :  8697  accuracy =   0.9800  loss =  148.46\n",
      "testing  :  8697  accuracy =   0.9683  loss =  148.849\n",
      "training :  8698  accuracy =   0.9700  loss =  148.222\n",
      "testing  :  8698  accuracy =   0.9680  loss =  148.828\n",
      "training :  8699  accuracy =   0.9800  loss =  148.013\n",
      "testing  :  8699  accuracy =   0.9686  loss =  148.823\n",
      "training :  8700  accuracy =   1.0000  loss =  146.472\n",
      "testing  :  8700  accuracy =   0.9684  loss =  148.817\n",
      "training :  8701  accuracy =   1.0000  loss =  146.452\n",
      "testing  :  8701  accuracy =   0.9681  loss =  148.82\n",
      "training :  8702  accuracy =   0.9800  loss =  146.998\n",
      "testing  :  8702  accuracy =   0.9682  loss =  148.827\n",
      "training :  8703  accuracy =   1.0000  loss =  146.206\n",
      "testing  :  8703  accuracy =   0.9681  loss =  148.876\n",
      "training :  8704  accuracy =   0.9900  loss =  146.741\n",
      "testing  :  8704  accuracy =   0.9670  loss =  148.929\n",
      "training :  8705  accuracy =   1.0000  loss =  146.404\n",
      "testing  :  8705  accuracy =   0.9664  loss =  148.953\n",
      "training :  8706  accuracy =   0.9800  loss =  148.335\n",
      "testing  :  8706  accuracy =   0.9663  loss =  148.987\n",
      "training :  8707  accuracy =   0.9900  loss =  147.571\n",
      "testing  :  8707  accuracy =   0.9664  loss =  149.009\n",
      "training :  8708  accuracy =   0.9500  loss =  150.65\n",
      "testing  :  8708  accuracy =   0.9671  loss =  148.997\n",
      "training :  8709  accuracy =   0.9800  loss =  147.954\n",
      "testing  :  8709  accuracy =   0.9680  loss =  148.95\n",
      "training :  8710  accuracy =   0.9500  loss =  149.185\n",
      "testing  :  8710  accuracy =   0.9682  loss =  148.908\n",
      "training :  8711  accuracy =   0.9900  loss =  146.727\n",
      "testing  :  8711  accuracy =   0.9686  loss =  148.864\n",
      "training :  8712  accuracy =   0.9800  loss =  147.578\n",
      "testing  :  8712  accuracy =   0.9690  loss =  148.851\n",
      "training :  8713  accuracy =   0.9800  loss =  148.455\n",
      "testing  :  8713  accuracy =   0.9687  loss =  148.837\n",
      "training :  8714  accuracy =   0.9900  loss =  147.623\n",
      "testing  :  8714  accuracy =   0.9696  loss =  148.802\n",
      "training :  8715  accuracy =   0.9800  loss =  148.554\n",
      "testing  :  8715  accuracy =   0.9690  loss =  148.787\n",
      "training :  8716  accuracy =   0.9900  loss =  147.116\n",
      "testing  :  8716  accuracy =   0.9686  loss =  148.799\n",
      "training :  8717  accuracy =   1.0000  loss =  146.503\n",
      "testing  :  8717  accuracy =   0.9685  loss =  148.821\n",
      "training :  8718  accuracy =   0.9600  loss =  149.084\n",
      "testing  :  8718  accuracy =   0.9680  loss =  148.837\n",
      "training :  8719  accuracy =   0.9500  loss =  150.424\n",
      "testing  :  8719  accuracy =   0.9675  loss =  148.849\n",
      "training :  8720  accuracy =   0.9900  loss =  147.574\n",
      "testing  :  8720  accuracy =   0.9673  loss =  148.821\n",
      "training :  8721  accuracy =   0.9900  loss =  146.479\n",
      "testing  :  8721  accuracy =   0.9675  loss =  148.827\n",
      "training :  8722  accuracy =   0.9800  loss =  147.746\n",
      "testing  :  8722  accuracy =   0.9674  loss =  148.847\n",
      "training :  8723  accuracy =   0.9900  loss =  147.276\n",
      "testing  :  8723  accuracy =   0.9676  loss =  148.875\n",
      "training :  8724  accuracy =   0.9900  loss =  147.74\n",
      "testing  :  8724  accuracy =   0.9672  loss =  148.912\n",
      "training :  8725  accuracy =   0.9900  loss =  146.524\n",
      "testing  :  8725  accuracy =   0.9669  loss =  148.933\n",
      "training :  8726  accuracy =   0.9800  loss =  147.445\n",
      "testing  :  8726  accuracy =   0.9671  loss =  148.951\n",
      "training :  8727  accuracy =   0.9700  loss =  149.521\n",
      "testing  :  8727  accuracy =   0.9669  loss =  148.962\n",
      "training :  8728  accuracy =   0.9600  loss =  147.968\n",
      "testing  :  8728  accuracy =   0.9669  loss =  148.955\n",
      "training :  8729  accuracy =   1.0000  loss =  146.175\n",
      "testing  :  8729  accuracy =   0.9667  loss =  148.948\n",
      "training :  8730  accuracy =   0.9900  loss =  146.595\n",
      "testing  :  8730  accuracy =   0.9667  loss =  148.942\n",
      "training :  8731  accuracy =   0.9900  loss =  147.349\n",
      "testing  :  8731  accuracy =   0.9664  loss =  148.924\n",
      "training :  8732  accuracy =   1.0000  loss =  146.676\n",
      "testing  :  8732  accuracy =   0.9662  loss =  148.916\n",
      "training :  8733  accuracy =   0.9900  loss =  147.681\n",
      "testing  :  8733  accuracy =   0.9665  loss =  148.899\n",
      "training :  8734  accuracy =   0.9800  loss =  147.948\n",
      "testing  :  8734  accuracy =   0.9672  loss =  148.88\n",
      "training :  8735  accuracy =   0.9900  loss =  147.544\n",
      "testing  :  8735  accuracy =   0.9670  loss =  148.864\n",
      "training :  8736  accuracy =   0.9500  loss =  148.931\n",
      "testing  :  8736  accuracy =   0.9671  loss =  148.852\n",
      "training :  8737  accuracy =   0.9800  loss =  147.657\n",
      "testing  :  8737  accuracy =   0.9671  loss =  148.849\n",
      "training :  8738  accuracy =   0.9900  loss =  147.45\n",
      "testing  :  8738  accuracy =   0.9665  loss =  148.847\n",
      "training :  8739  accuracy =   1.0000  loss =  146.36\n",
      "testing  :  8739  accuracy =   0.9661  loss =  148.855\n",
      "training :  8740  accuracy =   0.9600  loss =  150.028\n",
      "testing  :  8740  accuracy =   0.9662  loss =  148.864\n",
      "training :  8741  accuracy =   0.9700  loss =  148.307\n",
      "testing  :  8741  accuracy =   0.9667  loss =  148.863\n",
      "training :  8742  accuracy =   0.9900  loss =  147.727\n",
      "testing  :  8742  accuracy =   0.9668  loss =  148.889\n",
      "training :  8743  accuracy =   0.9800  loss =  148.045\n",
      "testing  :  8743  accuracy =   0.9660  loss =  148.912\n",
      "training :  8744  accuracy =   0.9900  loss =  147.913\n",
      "testing  :  8744  accuracy =   0.9660  loss =  148.933\n",
      "training :  8745  accuracy =   0.9700  loss =  148.748\n",
      "testing  :  8745  accuracy =   0.9661  loss =  148.951\n",
      "training :  8746  accuracy =   0.9800  loss =  147.57\n",
      "testing  :  8746  accuracy =   0.9669  loss =  148.9\n",
      "training :  8747  accuracy =   1.0000  loss =  146.187\n",
      "testing  :  8747  accuracy =   0.9672  loss =  148.862\n",
      "training :  8748  accuracy =   0.9800  loss =  146.731\n",
      "testing  :  8748  accuracy =   0.9673  loss =  148.843\n",
      "training :  8749  accuracy =   1.0000  loss =  146.166\n",
      "testing  :  8749  accuracy =   0.9675  loss =  148.853\n",
      "training :  8750  accuracy =   0.9900  loss =  147.149\n",
      "testing  :  8750  accuracy =   0.9672  loss =  148.876\n",
      "training :  8751  accuracy =   0.9800  loss =  148.211\n",
      "testing  :  8751  accuracy =   0.9666  loss =  148.909\n",
      "training :  8752  accuracy =   1.0000  loss =  146.586\n",
      "testing  :  8752  accuracy =   0.9673  loss =  148.89\n",
      "training :  8753  accuracy =   0.9700  loss =  148.727\n",
      "testing  :  8753  accuracy =   0.9674  loss =  148.882\n",
      "training :  8754  accuracy =   0.9800  loss =  147.436\n",
      "testing  :  8754  accuracy =   0.9670  loss =  148.842\n",
      "training :  8755  accuracy =   0.9700  loss =  149.481\n",
      "testing  :  8755  accuracy =   0.9670  loss =  148.831\n",
      "training :  8756  accuracy =   0.9700  loss =  148.409\n",
      "testing  :  8756  accuracy =   0.9673  loss =  148.832\n",
      "training :  8757  accuracy =   0.9700  loss =  147.663\n",
      "testing  :  8757  accuracy =   0.9678  loss =  148.837\n",
      "training :  8758  accuracy =   0.9700  loss =  148.181\n",
      "testing  :  8758  accuracy =   0.9671  loss =  148.856\n",
      "training :  8759  accuracy =   0.9900  loss =  146.809\n",
      "testing  :  8759  accuracy =   0.9673  loss =  148.862\n",
      "training :  8760  accuracy =   0.9900  loss =  147.465\n",
      "testing  :  8760  accuracy =   0.9678  loss =  148.866\n",
      "training :  8761  accuracy =   1.0000  loss =  146.158\n",
      "testing  :  8761  accuracy =   0.9672  loss =  148.881\n",
      "training :  8762  accuracy =   0.9900  loss =  147.421\n",
      "testing  :  8762  accuracy =   0.9665  loss =  148.909\n",
      "training :  8763  accuracy =   0.9900  loss =  147.328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8763  accuracy =   0.9663  loss =  148.94\n",
      "training :  8764  accuracy =   0.9700  loss =  148.758\n",
      "testing  :  8764  accuracy =   0.9657  loss =  148.967\n",
      "training :  8765  accuracy =   0.9900  loss =  147.322\n",
      "testing  :  8765  accuracy =   0.9657  loss =  148.991\n",
      "training :  8766  accuracy =   0.9700  loss =  148.544\n",
      "testing  :  8766  accuracy =   0.9652  loss =  149.015\n",
      "training :  8767  accuracy =   1.0000  loss =  146.288\n",
      "testing  :  8767  accuracy =   0.9676  loss =  148.874\n",
      "training :  8768  accuracy =   0.9900  loss =  147.205\n",
      "testing  :  8768  accuracy =   0.9686  loss =  148.781\n",
      "training :  8769  accuracy =   1.0000  loss =  146.315\n",
      "testing  :  8769  accuracy =   0.9689  loss =  148.747\n",
      "training :  8770  accuracy =   0.9600  loss =  148.577\n",
      "testing  :  8770  accuracy =   0.9689  loss =  148.748\n",
      "training :  8771  accuracy =   0.9900  loss =  147.399\n",
      "testing  :  8771  accuracy =   0.9689  loss =  148.763\n",
      "training :  8772  accuracy =   1.0000  loss =  146.382\n",
      "testing  :  8772  accuracy =   0.9686  loss =  148.784\n",
      "training :  8773  accuracy =   0.9800  loss =  147.304\n",
      "testing  :  8773  accuracy =   0.9693  loss =  148.8\n",
      "training :  8774  accuracy =   0.9700  loss =  149.434\n",
      "testing  :  8774  accuracy =   0.9693  loss =  148.82\n",
      "training :  8775  accuracy =   1.0000  loss =  146.379\n",
      "testing  :  8775  accuracy =   0.9685  loss =  148.847\n",
      "training :  8776  accuracy =   0.9800  loss =  147.083\n",
      "testing  :  8776  accuracy =   0.9683  loss =  148.866\n",
      "training :  8777  accuracy =   0.9700  loss =  147.605\n",
      "testing  :  8777  accuracy =   0.9671  loss =  148.903\n",
      "training :  8778  accuracy =   0.9900  loss =  147.644\n",
      "testing  :  8778  accuracy =   0.9671  loss =  148.915\n",
      "training :  8779  accuracy =   0.9900  loss =  146.864\n",
      "testing  :  8779  accuracy =   0.9667  loss =  148.931\n",
      "training :  8780  accuracy =   0.9600  loss =  150.162\n",
      "testing  :  8780  accuracy =   0.9663  loss =  148.941\n",
      "training :  8781  accuracy =   0.9700  loss =  149.091\n",
      "testing  :  8781  accuracy =   0.9668  loss =  148.957\n",
      "training :  8782  accuracy =   0.9600  loss =  149.072\n",
      "testing  :  8782  accuracy =   0.9663  loss =  148.962\n",
      "training :  8783  accuracy =   1.0000  loss =  146.283\n",
      "testing  :  8783  accuracy =   0.9661  loss =  148.981\n",
      "training :  8784  accuracy =   0.9800  loss =  147.617\n",
      "testing  :  8784  accuracy =   0.9660  loss =  149.003\n",
      "training :  8785  accuracy =   0.9800  loss =  147.868\n",
      "testing  :  8785  accuracy =   0.9662  loss =  148.999\n",
      "training :  8786  accuracy =   0.9900  loss =  147.543\n",
      "testing  :  8786  accuracy =   0.9664  loss =  148.971\n",
      "training :  8787  accuracy =   0.9700  loss =  149.419\n",
      "testing  :  8787  accuracy =   0.9661  loss =  148.954\n",
      "training :  8788  accuracy =   0.9900  loss =  146.862\n",
      "testing  :  8788  accuracy =   0.9665  loss =  148.945\n",
      "training :  8789  accuracy =   0.9900  loss =  146.88\n",
      "testing  :  8789  accuracy =   0.9666  loss =  148.958\n",
      "training :  8790  accuracy =   0.9800  loss =  148.335\n",
      "testing  :  8790  accuracy =   0.9676  loss =  148.931\n",
      "training :  8791  accuracy =   0.9800  loss =  148.428\n",
      "testing  :  8791  accuracy =   0.9678  loss =  148.905\n",
      "training :  8792  accuracy =   0.9700  loss =  148.457\n",
      "testing  :  8792  accuracy =   0.9676  loss =  148.89\n",
      "training :  8793  accuracy =   0.9800  loss =  147.216\n",
      "testing  :  8793  accuracy =   0.9670  loss =  148.895\n",
      "training :  8794  accuracy =   1.0000  loss =  146.273\n",
      "testing  :  8794  accuracy =   0.9677  loss =  148.895\n",
      "training :  8795  accuracy =   0.9800  loss =  147.96\n",
      "testing  :  8795  accuracy =   0.9666  loss =  148.92\n",
      "training :  8796  accuracy =   0.9700  loss =  148.522\n",
      "testing  :  8796  accuracy =   0.9661  loss =  148.934\n",
      "training :  8797  accuracy =   0.9700  loss =  148.914\n",
      "testing  :  8797  accuracy =   0.9656  loss =  148.962\n",
      "training :  8798  accuracy =   1.0000  loss =  146.656\n",
      "testing  :  8798  accuracy =   0.9659  loss =  148.975\n",
      "training :  8799  accuracy =   0.9700  loss =  149.216\n",
      "testing  :  8799  accuracy =   0.9659  loss =  148.972\n",
      "training :  8800  accuracy =   0.9500  loss =  148.957\n",
      "testing  :  8800  accuracy =   0.9655  loss =  148.971\n",
      "training :  8801  accuracy =   0.9700  loss =  148.339\n",
      "testing  :  8801  accuracy =   0.9657  loss =  148.947\n",
      "training :  8802  accuracy =   1.0000  loss =  146.335\n",
      "testing  :  8802  accuracy =   0.9655  loss =  148.934\n",
      "training :  8803  accuracy =   1.0000  loss =  146.18\n",
      "testing  :  8803  accuracy =   0.9663  loss =  148.92\n",
      "training :  8804  accuracy =   0.9600  loss =  149.072\n",
      "testing  :  8804  accuracy =   0.9665  loss =  148.924\n",
      "training :  8805  accuracy =   0.9900  loss =  146.455\n",
      "testing  :  8805  accuracy =   0.9657  loss =  148.892\n",
      "training :  8806  accuracy =   1.0000  loss =  146.206\n",
      "testing  :  8806  accuracy =   0.9657  loss =  148.881\n",
      "training :  8807  accuracy =   0.9700  loss =  147.903\n",
      "testing  :  8807  accuracy =   0.9652  loss =  148.887\n",
      "training :  8808  accuracy =   1.0000  loss =  146.206\n",
      "testing  :  8808  accuracy =   0.9656  loss =  148.902\n",
      "training :  8809  accuracy =   0.9900  loss =  146.54\n",
      "testing  :  8809  accuracy =   0.9651  loss =  148.925\n",
      "training :  8810  accuracy =   0.9800  loss =  147.701\n",
      "testing  :  8810  accuracy =   0.9654  loss =  148.951\n",
      "training :  8811  accuracy =   1.0000  loss =  146.429\n",
      "testing  :  8811  accuracy =   0.9652  loss =  148.982\n",
      "training :  8812  accuracy =   0.9600  loss =  148.088\n",
      "testing  :  8812  accuracy =   0.9651  loss =  149.017\n",
      "training :  8813  accuracy =   0.9600  loss =  147.735\n",
      "testing  :  8813  accuracy =   0.9644  loss =  149.061\n",
      "training :  8814  accuracy =   0.9800  loss =  147.741\n",
      "testing  :  8814  accuracy =   0.9637  loss =  149.113\n",
      "training :  8815  accuracy =   0.9700  loss =  147.274\n",
      "testing  :  8815  accuracy =   0.9638  loss =  149.135\n",
      "training :  8816  accuracy =   0.9600  loss =  148.367\n",
      "testing  :  8816  accuracy =   0.9636  loss =  149.114\n",
      "training :  8817  accuracy =   0.9900  loss =  146.815\n",
      "testing  :  8817  accuracy =   0.9637  loss =  149.135\n",
      "training :  8818  accuracy =   0.9800  loss =  148.229\n",
      "testing  :  8818  accuracy =   0.9638  loss =  149.14\n",
      "training :  8819  accuracy =   0.9700  loss =  147.769\n",
      "testing  :  8819  accuracy =   0.9639  loss =  149.145\n",
      "training :  8820  accuracy =   0.9700  loss =  149.626\n",
      "testing  :  8820  accuracy =   0.9641  loss =  149.077\n",
      "training :  8821  accuracy =   0.9800  loss =  147.643\n",
      "testing  :  8821  accuracy =   0.9652  loss =  149.023\n",
      "training :  8822  accuracy =   1.0000  loss =  146.231\n",
      "testing  :  8822  accuracy =   0.9659  loss =  148.955\n",
      "training :  8823  accuracy =   0.9700  loss =  147.797\n",
      "testing  :  8823  accuracy =   0.9663  loss =  148.9\n",
      "training :  8824  accuracy =   1.0000  loss =  146.791\n",
      "testing  :  8824  accuracy =   0.9665  loss =  148.861\n",
      "training :  8825  accuracy =   0.9800  loss =  147.695\n",
      "testing  :  8825  accuracy =   0.9666  loss =  148.835\n",
      "training :  8826  accuracy =   0.9900  loss =  147.558\n",
      "testing  :  8826  accuracy =   0.9669  loss =  148.816\n",
      "training :  8827  accuracy =   1.0000  loss =  146.396\n",
      "testing  :  8827  accuracy =   0.9670  loss =  148.807\n",
      "training :  8828  accuracy =   0.9600  loss =  149.961\n",
      "testing  :  8828  accuracy =   0.9675  loss =  148.798\n",
      "training :  8829  accuracy =   0.9900  loss =  146.642\n",
      "testing  :  8829  accuracy =   0.9681  loss =  148.794\n",
      "training :  8830  accuracy =   0.9800  loss =  148.419\n",
      "testing  :  8830  accuracy =   0.9688  loss =  148.799\n",
      "training :  8831  accuracy =   0.9600  loss =  148.756\n",
      "testing  :  8831  accuracy =   0.9683  loss =  148.811\n",
      "training :  8832  accuracy =   0.9600  loss =  148.833\n",
      "testing  :  8832  accuracy =   0.9683  loss =  148.81\n",
      "training :  8833  accuracy =   0.9800  loss =  147.383\n",
      "testing  :  8833  accuracy =   0.9679  loss =  148.809\n",
      "training :  8834  accuracy =   1.0000  loss =  146.155\n",
      "testing  :  8834  accuracy =   0.9679  loss =  148.815\n",
      "training :  8835  accuracy =   1.0000  loss =  146.437\n",
      "testing  :  8835  accuracy =   0.9682  loss =  148.824\n",
      "training :  8836  accuracy =   0.9800  loss =  148.086\n",
      "testing  :  8836  accuracy =   0.9677  loss =  148.833\n",
      "training :  8837  accuracy =   0.9800  loss =  148.073\n",
      "testing  :  8837  accuracy =   0.9683  loss =  148.834\n",
      "training :  8838  accuracy =   0.9900  loss =  147.447\n",
      "testing  :  8838  accuracy =   0.9691  loss =  148.837\n",
      "training :  8839  accuracy =   0.9700  loss =  147.037\n",
      "testing  :  8839  accuracy =   0.9690  loss =  148.839\n",
      "training :  8840  accuracy =   1.0000  loss =  146.167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8840  accuracy =   0.9686  loss =  148.851\n",
      "training :  8841  accuracy =   1.0000  loss =  146.509\n",
      "testing  :  8841  accuracy =   0.9682  loss =  148.866\n",
      "training :  8842  accuracy =   0.9900  loss =  147.401\n",
      "testing  :  8842  accuracy =   0.9682  loss =  148.883\n",
      "training :  8843  accuracy =   1.0000  loss =  146.287\n",
      "testing  :  8843  accuracy =   0.9683  loss =  148.897\n",
      "training :  8844  accuracy =   0.9900  loss =  147.405\n",
      "testing  :  8844  accuracy =   0.9682  loss =  148.899\n",
      "training :  8845  accuracy =   0.9900  loss =  146.474\n",
      "testing  :  8845  accuracy =   0.9679  loss =  148.896\n",
      "training :  8846  accuracy =   0.9800  loss =  147.658\n",
      "testing  :  8846  accuracy =   0.9682  loss =  148.889\n",
      "training :  8847  accuracy =   0.9800  loss =  148.119\n",
      "testing  :  8847  accuracy =   0.9681  loss =  148.894\n",
      "training :  8848  accuracy =   0.9700  loss =  147.853\n",
      "testing  :  8848  accuracy =   0.9681  loss =  148.906\n",
      "training :  8849  accuracy =   0.9800  loss =  148.304\n",
      "testing  :  8849  accuracy =   0.9678  loss =  148.905\n",
      "training :  8850  accuracy =   1.0000  loss =  146.569\n",
      "testing  :  8850  accuracy =   0.9683  loss =  148.906\n",
      "training :  8851  accuracy =   0.9800  loss =  148.385\n",
      "testing  :  8851  accuracy =   0.9685  loss =  148.89\n",
      "training :  8852  accuracy =   0.9500  loss =  150.419\n",
      "testing  :  8852  accuracy =   0.9685  loss =  148.88\n",
      "training :  8853  accuracy =   1.0000  loss =  146.4\n",
      "testing  :  8853  accuracy =   0.9689  loss =  148.86\n",
      "training :  8854  accuracy =   0.9900  loss =  147.221\n",
      "testing  :  8854  accuracy =   0.9686  loss =  148.835\n",
      "training :  8855  accuracy =   0.9700  loss =  149.526\n",
      "testing  :  8855  accuracy =   0.9681  loss =  148.811\n",
      "training :  8856  accuracy =   0.9900  loss =  146.543\n",
      "testing  :  8856  accuracy =   0.9671  loss =  148.805\n",
      "training :  8857  accuracy =   0.9900  loss =  147.252\n",
      "testing  :  8857  accuracy =   0.9670  loss =  148.828\n",
      "training :  8858  accuracy =   1.0000  loss =  146.177\n",
      "testing  :  8858  accuracy =   0.9673  loss =  148.874\n",
      "training :  8859  accuracy =   0.9800  loss =  148.439\n",
      "testing  :  8859  accuracy =   0.9668  loss =  148.923\n",
      "training :  8860  accuracy =   0.9800  loss =  147.648\n",
      "testing  :  8860  accuracy =   0.9667  loss =  148.927\n",
      "training :  8861  accuracy =   0.9800  loss =  147.791\n",
      "testing  :  8861  accuracy =   0.9670  loss =  148.921\n",
      "training :  8862  accuracy =   1.0000  loss =  146.603\n",
      "testing  :  8862  accuracy =   0.9671  loss =  148.919\n",
      "training :  8863  accuracy =   0.9900  loss =  146.932\n",
      "testing  :  8863  accuracy =   0.9670  loss =  148.921\n",
      "training :  8864  accuracy =   0.9700  loss =  148.488\n",
      "testing  :  8864  accuracy =   0.9675  loss =  148.882\n",
      "training :  8865  accuracy =   0.9800  loss =  147.834\n",
      "testing  :  8865  accuracy =   0.9674  loss =  148.873\n",
      "training :  8866  accuracy =   1.0000  loss =  146.275\n",
      "testing  :  8866  accuracy =   0.9672  loss =  148.881\n",
      "training :  8867  accuracy =   1.0000  loss =  146.454\n",
      "testing  :  8867  accuracy =   0.9675  loss =  148.893\n",
      "training :  8868  accuracy =   0.9900  loss =  147.57\n",
      "testing  :  8868  accuracy =   0.9674  loss =  148.897\n",
      "training :  8869  accuracy =   0.9700  loss =  148.886\n",
      "testing  :  8869  accuracy =   0.9676  loss =  148.902\n",
      "training :  8870  accuracy =   0.9600  loss =  150.516\n",
      "testing  :  8870  accuracy =   0.9673  loss =  148.906\n",
      "training :  8871  accuracy =   0.9500  loss =  149.626\n",
      "testing  :  8871  accuracy =   0.9675  loss =  148.905\n",
      "training :  8872  accuracy =   0.9700  loss =  149.46\n",
      "testing  :  8872  accuracy =   0.9678  loss =  148.9\n",
      "training :  8873  accuracy =   0.9700  loss =  149.404\n",
      "testing  :  8873  accuracy =   0.9684  loss =  148.889\n",
      "training :  8874  accuracy =   1.0000  loss =  146.236\n",
      "testing  :  8874  accuracy =   0.9689  loss =  148.879\n",
      "training :  8875  accuracy =   1.0000  loss =  146.144\n",
      "testing  :  8875  accuracy =   0.9692  loss =  148.874\n",
      "training :  8876  accuracy =   0.9800  loss =  147.741\n",
      "testing  :  8876  accuracy =   0.9690  loss =  148.87\n",
      "training :  8877  accuracy =   1.0000  loss =  146.186\n",
      "testing  :  8877  accuracy =   0.9688  loss =  148.847\n",
      "training :  8878  accuracy =   0.9900  loss =  147.115\n",
      "testing  :  8878  accuracy =   0.9693  loss =  148.826\n",
      "training :  8879  accuracy =   0.9700  loss =  148.717\n",
      "testing  :  8879  accuracy =   0.9694  loss =  148.805\n",
      "training :  8880  accuracy =   0.9500  loss =  148.332\n",
      "testing  :  8880  accuracy =   0.9697  loss =  148.782\n",
      "training :  8881  accuracy =   0.9600  loss =  149.519\n",
      "testing  :  8881  accuracy =   0.9699  loss =  148.763\n",
      "training :  8882  accuracy =   0.9800  loss =  148.309\n",
      "testing  :  8882  accuracy =   0.9693  loss =  148.754\n",
      "training :  8883  accuracy =   0.9900  loss =  147.554\n",
      "testing  :  8883  accuracy =   0.9693  loss =  148.757\n",
      "training :  8884  accuracy =   0.9800  loss =  148.442\n",
      "testing  :  8884  accuracy =   0.9684  loss =  148.786\n",
      "training :  8885  accuracy =   1.0000  loss =  146.291\n",
      "testing  :  8885  accuracy =   0.9684  loss =  148.836\n",
      "training :  8886  accuracy =   1.0000  loss =  146.384\n",
      "testing  :  8886  accuracy =   0.9679  loss =  148.9\n",
      "training :  8887  accuracy =   0.9900  loss =  146.49\n",
      "testing  :  8887  accuracy =   0.9677  loss =  148.957\n",
      "training :  8888  accuracy =   1.0000  loss =  146.637\n",
      "testing  :  8888  accuracy =   0.9673  loss =  148.993\n",
      "training :  8889  accuracy =   0.9900  loss =  147.11\n",
      "testing  :  8889  accuracy =   0.9667  loss =  149.023\n",
      "training :  8890  accuracy =   0.9800  loss =  148.327\n",
      "testing  :  8890  accuracy =   0.9665  loss =  149.034\n",
      "training :  8891  accuracy =   0.9800  loss =  147.542\n",
      "testing  :  8891  accuracy =   0.9663  loss =  149.043\n",
      "training :  8892  accuracy =   0.9600  loss =  149.446\n",
      "testing  :  8892  accuracy =   0.9657  loss =  149.048\n",
      "training :  8893  accuracy =   0.9900  loss =  147.361\n",
      "testing  :  8893  accuracy =   0.9657  loss =  149.051\n",
      "training :  8894  accuracy =   1.0000  loss =  146.166\n",
      "testing  :  8894  accuracy =   0.9658  loss =  149.049\n",
      "training :  8895  accuracy =   0.9800  loss =  147.62\n",
      "testing  :  8895  accuracy =   0.9655  loss =  149.045\n",
      "training :  8896  accuracy =   1.0000  loss =  146.393\n",
      "testing  :  8896  accuracy =   0.9660  loss =  149.018\n",
      "training :  8897  accuracy =   0.9900  loss =  147.348\n",
      "testing  :  8897  accuracy =   0.9664  loss =  148.986\n",
      "training :  8898  accuracy =   0.9900  loss =  147.465\n",
      "testing  :  8898  accuracy =   0.9665  loss =  148.957\n",
      "training :  8899  accuracy =   0.9800  loss =  147.676\n",
      "testing  :  8899  accuracy =   0.9668  loss =  148.919\n",
      "training :  8900  accuracy =   0.9900  loss =  147.178\n",
      "testing  :  8900  accuracy =   0.9673  loss =  148.88\n",
      "training :  8901  accuracy =   0.9800  loss =  147.744\n",
      "testing  :  8901  accuracy =   0.9675  loss =  148.849\n",
      "training :  8902  accuracy =   0.9700  loss =  147.792\n",
      "testing  :  8902  accuracy =   0.9675  loss =  148.823\n",
      "training :  8903  accuracy =   0.9600  loss =  149.335\n",
      "testing  :  8903  accuracy =   0.9681  loss =  148.806\n",
      "training :  8904  accuracy =   0.9800  loss =  146.694\n",
      "testing  :  8904  accuracy =   0.9684  loss =  148.804\n",
      "training :  8905  accuracy =   0.9800  loss =  147.441\n",
      "testing  :  8905  accuracy =   0.9689  loss =  148.81\n",
      "training :  8906  accuracy =   0.9800  loss =  147.743\n",
      "testing  :  8906  accuracy =   0.9693  loss =  148.814\n",
      "training :  8907  accuracy =   0.9800  loss =  146.969\n",
      "testing  :  8907  accuracy =   0.9691  loss =  148.825\n",
      "training :  8908  accuracy =   0.9700  loss =  149.398\n",
      "testing  :  8908  accuracy =   0.9692  loss =  148.837\n",
      "training :  8909  accuracy =   1.0000  loss =  146.628\n",
      "testing  :  8909  accuracy =   0.9682  loss =  148.847\n",
      "training :  8910  accuracy =   0.9900  loss =  146.437\n",
      "testing  :  8910  accuracy =   0.9676  loss =  148.861\n",
      "training :  8911  accuracy =   0.9800  loss =  148.277\n",
      "testing  :  8911  accuracy =   0.9673  loss =  148.868\n",
      "training :  8912  accuracy =   0.9700  loss =  147.624\n",
      "testing  :  8912  accuracy =   0.9674  loss =  148.879\n",
      "training :  8913  accuracy =   0.9500  loss =  149.685\n",
      "testing  :  8913  accuracy =   0.9675  loss =  148.903\n",
      "training :  8914  accuracy =   0.9900  loss =  146.529\n",
      "testing  :  8914  accuracy =   0.9667  loss =  148.908\n",
      "training :  8915  accuracy =   0.9900  loss =  146.9\n",
      "testing  :  8915  accuracy =   0.9662  loss =  148.925\n",
      "training :  8916  accuracy =   0.9900  loss =  147.111\n",
      "testing  :  8916  accuracy =   0.9664  loss =  148.907\n",
      "training :  8917  accuracy =   0.9800  loss =  148.561\n",
      "testing  :  8917  accuracy =   0.9670  loss =  148.9\n",
      "training :  8918  accuracy =   0.9800  loss =  146.705\n",
      "testing  :  8918  accuracy =   0.9670  loss =  148.885\n",
      "training :  8919  accuracy =   1.0000  loss =  146.565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8919  accuracy =   0.9672  loss =  148.874\n",
      "training :  8920  accuracy =   0.9900  loss =  147.254\n",
      "testing  :  8920  accuracy =   0.9674  loss =  148.869\n",
      "training :  8921  accuracy =   1.0000  loss =  146.249\n",
      "testing  :  8921  accuracy =   0.9668  loss =  148.876\n",
      "training :  8922  accuracy =   0.9800  loss =  148.28\n",
      "testing  :  8922  accuracy =   0.9667  loss =  148.892\n",
      "training :  8923  accuracy =   1.0000  loss =  146.23\n",
      "testing  :  8923  accuracy =   0.9671  loss =  148.911\n",
      "training :  8924  accuracy =   0.9900  loss =  146.492\n",
      "testing  :  8924  accuracy =   0.9676  loss =  148.922\n",
      "training :  8925  accuracy =   0.9400  loss =  151.419\n",
      "testing  :  8925  accuracy =   0.9677  loss =  148.929\n",
      "training :  8926  accuracy =   0.9800  loss =  147.281\n",
      "testing  :  8926  accuracy =   0.9670  loss =  148.927\n",
      "training :  8927  accuracy =   0.9900  loss =  146.606\n",
      "testing  :  8927  accuracy =   0.9668  loss =  148.941\n",
      "training :  8928  accuracy =   0.9900  loss =  146.459\n",
      "testing  :  8928  accuracy =   0.9665  loss =  148.952\n",
      "training :  8929  accuracy =   0.9500  loss =  150.299\n",
      "testing  :  8929  accuracy =   0.9667  loss =  148.984\n",
      "training :  8930  accuracy =   0.9800  loss =  147.675\n",
      "testing  :  8930  accuracy =   0.9663  loss =  148.957\n",
      "training :  8931  accuracy =   0.9800  loss =  148.19\n",
      "testing  :  8931  accuracy =   0.9668  loss =  148.935\n",
      "training :  8932  accuracy =   0.9900  loss =  147.45\n",
      "testing  :  8932  accuracy =   0.9669  loss =  148.918\n",
      "training :  8933  accuracy =   0.9900  loss =  146.51\n",
      "testing  :  8933  accuracy =   0.9670  loss =  148.911\n",
      "training :  8934  accuracy =   0.9800  loss =  147.555\n",
      "testing  :  8934  accuracy =   0.9671  loss =  148.907\n",
      "training :  8935  accuracy =   1.0000  loss =  146.405\n",
      "testing  :  8935  accuracy =   0.9671  loss =  148.899\n",
      "training :  8936  accuracy =   0.9900  loss =  146.811\n",
      "testing  :  8936  accuracy =   0.9669  loss =  148.895\n",
      "training :  8937  accuracy =   1.0000  loss =  146.353\n",
      "testing  :  8937  accuracy =   0.9667  loss =  148.891\n",
      "training :  8938  accuracy =   0.9700  loss =  149.285\n",
      "testing  :  8938  accuracy =   0.9666  loss =  148.888\n",
      "training :  8939  accuracy =   1.0000  loss =  146.161\n",
      "testing  :  8939  accuracy =   0.9666  loss =  148.882\n",
      "training :  8940  accuracy =   0.9600  loss =  150.059\n",
      "testing  :  8940  accuracy =   0.9669  loss =  148.878\n",
      "training :  8941  accuracy =   1.0000  loss =  146.176\n",
      "testing  :  8941  accuracy =   0.9667  loss =  148.88\n",
      "training :  8942  accuracy =   1.0000  loss =  146.282\n",
      "testing  :  8942  accuracy =   0.9665  loss =  148.887\n",
      "training :  8943  accuracy =   0.9300  loss =  150.902\n",
      "testing  :  8943  accuracy =   0.9670  loss =  148.895\n",
      "training :  8944  accuracy =   0.9900  loss =  147.047\n",
      "testing  :  8944  accuracy =   0.9667  loss =  148.907\n",
      "training :  8945  accuracy =   1.0000  loss =  146.377\n",
      "testing  :  8945  accuracy =   0.9665  loss =  148.928\n",
      "training :  8946  accuracy =   0.9900  loss =  146.427\n",
      "testing  :  8946  accuracy =   0.9667  loss =  148.942\n",
      "training :  8947  accuracy =   0.9900  loss =  147.149\n",
      "testing  :  8947  accuracy =   0.9662  loss =  148.963\n",
      "training :  8948  accuracy =   0.9800  loss =  148.382\n",
      "testing  :  8948  accuracy =   0.9662  loss =  148.969\n",
      "training :  8949  accuracy =   1.0000  loss =  146.291\n",
      "testing  :  8949  accuracy =   0.9660  loss =  148.977\n",
      "training :  8950  accuracy =   0.9900  loss =  146.612\n",
      "testing  :  8950  accuracy =   0.9657  loss =  148.98\n",
      "training :  8951  accuracy =   1.0000  loss =  146.649\n",
      "testing  :  8951  accuracy =   0.9657  loss =  148.973\n",
      "training :  8952  accuracy =   0.9900  loss =  146.558\n",
      "testing  :  8952  accuracy =   0.9666  loss =  148.945\n",
      "training :  8953  accuracy =   0.9600  loss =  148.644\n",
      "testing  :  8953  accuracy =   0.9667  loss =  148.911\n",
      "training :  8954  accuracy =   1.0000  loss =  146.151\n",
      "testing  :  8954  accuracy =   0.9666  loss =  148.894\n",
      "training :  8955  accuracy =   1.0000  loss =  146.479\n",
      "testing  :  8955  accuracy =   0.9671  loss =  148.896\n",
      "training :  8956  accuracy =   1.0000  loss =  146.392\n",
      "testing  :  8956  accuracy =   0.9672  loss =  148.91\n",
      "training :  8957  accuracy =   0.9900  loss =  147.179\n",
      "testing  :  8957  accuracy =   0.9669  loss =  148.916\n",
      "training :  8958  accuracy =   0.9800  loss =  147.473\n",
      "testing  :  8958  accuracy =   0.9667  loss =  148.921\n",
      "training :  8959  accuracy =   0.9800  loss =  147.967\n",
      "testing  :  8959  accuracy =   0.9672  loss =  148.93\n",
      "training :  8960  accuracy =   0.9700  loss =  149.414\n",
      "testing  :  8960  accuracy =   0.9668  loss =  148.942\n",
      "training :  8961  accuracy =   1.0000  loss =  146.33\n",
      "testing  :  8961  accuracy =   0.9658  loss =  148.954\n",
      "training :  8962  accuracy =   0.9800  loss =  148.286\n",
      "testing  :  8962  accuracy =   0.9654  loss =  148.966\n",
      "training :  8963  accuracy =   0.9700  loss =  147.099\n",
      "testing  :  8963  accuracy =   0.9653  loss =  148.987\n",
      "training :  8964  accuracy =   1.0000  loss =  146.547\n",
      "testing  :  8964  accuracy =   0.9654  loss =  148.995\n",
      "training :  8965  accuracy =   1.0000  loss =  146.347\n",
      "testing  :  8965  accuracy =   0.9645  loss =  148.994\n",
      "training :  8966  accuracy =   0.9800  loss =  148.383\n",
      "testing  :  8966  accuracy =   0.9646  loss =  148.994\n",
      "training :  8967  accuracy =   0.9800  loss =  148.468\n",
      "testing  :  8967  accuracy =   0.9654  loss =  148.972\n",
      "training :  8968  accuracy =   0.9900  loss =  146.874\n",
      "testing  :  8968  accuracy =   0.9657  loss =  148.962\n",
      "training :  8969  accuracy =   0.9900  loss =  147.511\n",
      "testing  :  8969  accuracy =   0.9663  loss =  148.938\n",
      "training :  8970  accuracy =   0.9700  loss =  148.501\n",
      "testing  :  8970  accuracy =   0.9667  loss =  148.928\n",
      "training :  8971  accuracy =   1.0000  loss =  146.241\n",
      "testing  :  8971  accuracy =   0.9674  loss =  148.932\n",
      "training :  8972  accuracy =   0.9900  loss =  147.213\n",
      "testing  :  8972  accuracy =   0.9673  loss =  148.94\n",
      "training :  8973  accuracy =   1.0000  loss =  146.292\n",
      "testing  :  8973  accuracy =   0.9670  loss =  148.949\n",
      "training :  8974  accuracy =   0.9900  loss =  147.155\n",
      "testing  :  8974  accuracy =   0.9668  loss =  148.963\n",
      "training :  8975  accuracy =   0.9500  loss =  151.055\n",
      "testing  :  8975  accuracy =   0.9664  loss =  148.991\n",
      "training :  8976  accuracy =   0.9900  loss =  146.687\n",
      "testing  :  8976  accuracy =   0.9662  loss =  149.021\n",
      "training :  8977  accuracy =   0.9800  loss =  148.25\n",
      "testing  :  8977  accuracy =   0.9658  loss =  149.067\n",
      "training :  8978  accuracy =   0.9900  loss =  147.262\n",
      "testing  :  8978  accuracy =   0.9654  loss =  149.105\n",
      "training :  8979  accuracy =   0.9900  loss =  146.709\n",
      "testing  :  8979  accuracy =   0.9648  loss =  149.132\n",
      "training :  8980  accuracy =   1.0000  loss =  146.357\n",
      "testing  :  8980  accuracy =   0.9644  loss =  149.153\n",
      "training :  8981  accuracy =   0.9900  loss =  147.554\n",
      "testing  :  8981  accuracy =   0.9643  loss =  149.175\n",
      "training :  8982  accuracy =   0.9900  loss =  147.335\n",
      "testing  :  8982  accuracy =   0.9648  loss =  149.156\n",
      "training :  8983  accuracy =   0.9900  loss =  147.011\n",
      "testing  :  8983  accuracy =   0.9651  loss =  149.139\n",
      "training :  8984  accuracy =   0.9900  loss =  147.318\n",
      "testing  :  8984  accuracy =   0.9653  loss =  149.152\n",
      "training :  8985  accuracy =   0.9800  loss =  147.84\n",
      "testing  :  8985  accuracy =   0.9647  loss =  149.158\n",
      "training :  8986  accuracy =   0.9500  loss =  150.298\n",
      "testing  :  8986  accuracy =   0.9655  loss =  149.146\n",
      "training :  8987  accuracy =   0.9800  loss =  148.435\n",
      "testing  :  8987  accuracy =   0.9657  loss =  149.124\n",
      "training :  8988  accuracy =   0.9700  loss =  148.237\n",
      "testing  :  8988  accuracy =   0.9661  loss =  149.101\n",
      "training :  8989  accuracy =   0.9800  loss =  147.758\n",
      "testing  :  8989  accuracy =   0.9656  loss =  149.135\n",
      "training :  8990  accuracy =   0.9900  loss =  147.337\n",
      "testing  :  8990  accuracy =   0.9657  loss =  149.109\n",
      "training :  8991  accuracy =   1.0000  loss =  146.356\n",
      "testing  :  8991  accuracy =   0.9658  loss =  149.094\n",
      "training :  8992  accuracy =   0.9700  loss =  148.522\n",
      "testing  :  8992  accuracy =   0.9664  loss =  149.085\n",
      "training :  8993  accuracy =   0.9700  loss =  148.582\n",
      "testing  :  8993  accuracy =   0.9671  loss =  149.049\n",
      "training :  8994  accuracy =   0.9800  loss =  147.483\n",
      "testing  :  8994  accuracy =   0.9672  loss =  149.013\n",
      "training :  8995  accuracy =   1.0000  loss =  146.363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  8995  accuracy =   0.9677  loss =  148.981\n",
      "training :  8996  accuracy =   0.9600  loss =  148.695\n",
      "testing  :  8996  accuracy =   0.9677  loss =  148.963\n",
      "training :  8997  accuracy =   0.9700  loss =  147.6\n",
      "testing  :  8997  accuracy =   0.9681  loss =  148.919\n",
      "training :  8998  accuracy =   1.0000  loss =  146.325\n",
      "testing  :  8998  accuracy =   0.9690  loss =  148.872\n",
      "training :  8999  accuracy =   0.9900  loss =  146.421\n",
      "testing  :  8999  accuracy =   0.9693  loss =  148.84\n",
      "training :  9000  accuracy =   0.9900  loss =  147.434\n",
      "testing  :  9000  accuracy =   0.9691  loss =  148.813\n",
      "training :  9001  accuracy =   1.0000  loss =  146.169\n",
      "testing  :  9001  accuracy =   0.9695  loss =  148.777\n",
      "training :  9002  accuracy =   0.9900  loss =  147.647\n",
      "testing  :  9002  accuracy =   0.9685  loss =  148.777\n",
      "training :  9003  accuracy =   0.9800  loss =  148.156\n",
      "testing  :  9003  accuracy =   0.9680  loss =  148.801\n",
      "training :  9004  accuracy =   0.9800  loss =  147.673\n",
      "testing  :  9004  accuracy =   0.9664  loss =  148.852\n",
      "training :  9005  accuracy =   0.9700  loss =  147.872\n",
      "testing  :  9005  accuracy =   0.9662  loss =  148.89\n",
      "training :  9006  accuracy =   0.9600  loss =  149.589\n",
      "testing  :  9006  accuracy =   0.9659  loss =  148.908\n",
      "training :  9007  accuracy =   0.9900  loss =  146.413\n",
      "testing  :  9007  accuracy =   0.9659  loss =  148.916\n",
      "training :  9008  accuracy =   1.0000  loss =  146.398\n",
      "testing  :  9008  accuracy =   0.9657  loss =  148.903\n",
      "training :  9009  accuracy =   0.9900  loss =  147.412\n",
      "testing  :  9009  accuracy =   0.9660  loss =  148.896\n",
      "training :  9010  accuracy =   0.9900  loss =  147.683\n",
      "testing  :  9010  accuracy =   0.9667  loss =  148.891\n",
      "training :  9011  accuracy =   0.9700  loss =  147.7\n",
      "testing  :  9011  accuracy =   0.9667  loss =  148.882\n",
      "training :  9012  accuracy =   0.9900  loss =  147.482\n",
      "testing  :  9012  accuracy =   0.9663  loss =  148.892\n",
      "training :  9013  accuracy =   0.9800  loss =  147.56\n",
      "testing  :  9013  accuracy =   0.9665  loss =  148.901\n",
      "training :  9014  accuracy =   1.0000  loss =  146.194\n",
      "testing  :  9014  accuracy =   0.9667  loss =  148.903\n",
      "training :  9015  accuracy =   1.0000  loss =  146.303\n",
      "testing  :  9015  accuracy =   0.9668  loss =  148.911\n",
      "training :  9016  accuracy =   1.0000  loss =  146.36\n",
      "testing  :  9016  accuracy =   0.9668  loss =  148.92\n",
      "training :  9017  accuracy =   0.9700  loss =  146.859\n",
      "testing  :  9017  accuracy =   0.9668  loss =  148.924\n",
      "training :  9018  accuracy =   0.9800  loss =  147.787\n",
      "testing  :  9018  accuracy =   0.9668  loss =  148.898\n",
      "training :  9019  accuracy =   1.0000  loss =  146.446\n",
      "testing  :  9019  accuracy =   0.9665  loss =  148.863\n",
      "training :  9020  accuracy =   1.0000  loss =  146.287\n",
      "testing  :  9020  accuracy =   0.9672  loss =  148.834\n",
      "training :  9021  accuracy =   0.9700  loss =  147.797\n",
      "testing  :  9021  accuracy =   0.9674  loss =  148.812\n",
      "training :  9022  accuracy =   0.9900  loss =  146.557\n",
      "testing  :  9022  accuracy =   0.9681  loss =  148.784\n",
      "training :  9023  accuracy =   1.0000  loss =  146.408\n",
      "testing  :  9023  accuracy =   0.9686  loss =  148.767\n",
      "training :  9024  accuracy =   1.0000  loss =  146.405\n",
      "testing  :  9024  accuracy =   0.9687  loss =  148.758\n",
      "training :  9025  accuracy =   1.0000  loss =  146.264\n",
      "testing  :  9025  accuracy =   0.9691  loss =  148.757\n",
      "training :  9026  accuracy =   1.0000  loss =  146.306\n",
      "testing  :  9026  accuracy =   0.9693  loss =  148.76\n",
      "training :  9027  accuracy =   0.9900  loss =  147.208\n",
      "testing  :  9027  accuracy =   0.9695  loss =  148.765\n",
      "training :  9028  accuracy =   1.0000  loss =  146.28\n",
      "testing  :  9028  accuracy =   0.9697  loss =  148.77\n",
      "training :  9029  accuracy =   0.9800  loss =  148.165\n",
      "testing  :  9029  accuracy =   0.9700  loss =  148.774\n",
      "training :  9030  accuracy =   0.9900  loss =  147.066\n",
      "testing  :  9030  accuracy =   0.9702  loss =  148.777\n",
      "training :  9031  accuracy =   0.9900  loss =  147.218\n",
      "testing  :  9031  accuracy =   0.9701  loss =  148.772\n",
      "training :  9032  accuracy =   0.9800  loss =  148.399\n",
      "testing  :  9032  accuracy =   0.9697  loss =  148.768\n",
      "training :  9033  accuracy =   0.9700  loss =  148.313\n",
      "testing  :  9033  accuracy =   0.9695  loss =  148.761\n",
      "training :  9034  accuracy =   0.9700  loss =  149.387\n",
      "testing  :  9034  accuracy =   0.9697  loss =  148.761\n",
      "training :  9035  accuracy =   0.9800  loss =  147.867\n",
      "testing  :  9035  accuracy =   0.9699  loss =  148.759\n",
      "training :  9036  accuracy =   0.9900  loss =  147.488\n",
      "testing  :  9036  accuracy =   0.9701  loss =  148.742\n",
      "training :  9037  accuracy =   0.9900  loss =  147.536\n",
      "testing  :  9037  accuracy =   0.9702  loss =  148.734\n",
      "training :  9038  accuracy =   0.9800  loss =  148.178\n",
      "testing  :  9038  accuracy =   0.9707  loss =  148.73\n",
      "training :  9039  accuracy =   1.0000  loss =  146.278\n",
      "testing  :  9039  accuracy =   0.9705  loss =  148.745\n",
      "training :  9040  accuracy =   0.9900  loss =  146.629\n",
      "testing  :  9040  accuracy =   0.9697  loss =  148.764\n",
      "training :  9041  accuracy =   1.0000  loss =  146.278\n",
      "testing  :  9041  accuracy =   0.9695  loss =  148.767\n",
      "training :  9042  accuracy =   0.9900  loss =  147.109\n",
      "testing  :  9042  accuracy =   0.9698  loss =  148.766\n",
      "training :  9043  accuracy =   0.9900  loss =  147.216\n",
      "testing  :  9043  accuracy =   0.9702  loss =  148.761\n",
      "training :  9044  accuracy =   0.9900  loss =  147.252\n",
      "testing  :  9044  accuracy =   0.9706  loss =  148.761\n",
      "training :  9045  accuracy =   0.9800  loss =  147.535\n",
      "testing  :  9045  accuracy =   0.9703  loss =  148.762\n",
      "training :  9046  accuracy =   0.9600  loss =  148.908\n",
      "testing  :  9046  accuracy =   0.9702  loss =  148.765\n",
      "training :  9047  accuracy =   1.0000  loss =  146.837\n",
      "testing  :  9047  accuracy =   0.9707  loss =  148.766\n",
      "training :  9048  accuracy =   0.9900  loss =  147.192\n",
      "testing  :  9048  accuracy =   0.9707  loss =  148.763\n",
      "training :  9049  accuracy =   0.9800  loss =  147.405\n",
      "testing  :  9049  accuracy =   0.9701  loss =  148.776\n",
      "training :  9050  accuracy =   0.9900  loss =  147.313\n",
      "testing  :  9050  accuracy =   0.9696  loss =  148.806\n",
      "training :  9051  accuracy =   0.9800  loss =  148.209\n",
      "testing  :  9051  accuracy =   0.9689  loss =  148.842\n",
      "training :  9052  accuracy =   0.9800  loss =  148.3\n",
      "testing  :  9052  accuracy =   0.9687  loss =  148.879\n",
      "training :  9053  accuracy =   0.9800  loss =  147.689\n",
      "testing  :  9053  accuracy =   0.9682  loss =  148.916\n",
      "training :  9054  accuracy =   0.9500  loss =  149.277\n",
      "testing  :  9054  accuracy =   0.9686  loss =  148.908\n",
      "training :  9055  accuracy =   1.0000  loss =  146.397\n",
      "testing  :  9055  accuracy =   0.9689  loss =  148.883\n",
      "training :  9056  accuracy =   1.0000  loss =  146.327\n",
      "testing  :  9056  accuracy =   0.9698  loss =  148.87\n",
      "training :  9057  accuracy =   0.9800  loss =  146.871\n",
      "testing  :  9057  accuracy =   0.9699  loss =  148.868\n",
      "training :  9058  accuracy =   0.9900  loss =  147.141\n",
      "testing  :  9058  accuracy =   0.9695  loss =  148.87\n",
      "training :  9059  accuracy =   0.9900  loss =  146.584\n",
      "testing  :  9059  accuracy =   0.9691  loss =  148.873\n",
      "training :  9060  accuracy =   0.9700  loss =  147.865\n",
      "testing  :  9060  accuracy =   0.9689  loss =  148.909\n",
      "training :  9061  accuracy =   0.9800  loss =  148.317\n",
      "testing  :  9061  accuracy =   0.9683  loss =  148.943\n",
      "training :  9062  accuracy =   1.0000  loss =  146.188\n",
      "testing  :  9062  accuracy =   0.9662  loss =  149.007\n",
      "training :  9063  accuracy =   0.9900  loss =  146.723\n",
      "testing  :  9063  accuracy =   0.9653  loss =  149.101\n",
      "training :  9064  accuracy =   0.9700  loss =  148.948\n",
      "testing  :  9064  accuracy =   0.9655  loss =  149.101\n",
      "training :  9065  accuracy =   1.0000  loss =  146.286\n",
      "testing  :  9065  accuracy =   0.9666  loss =  148.979\n",
      "training :  9066  accuracy =   0.9900  loss =  147.568\n",
      "testing  :  9066  accuracy =   0.9672  loss =  148.913\n",
      "training :  9067  accuracy =   0.9800  loss =  148.446\n",
      "testing  :  9067  accuracy =   0.9683  loss =  148.903\n",
      "training :  9068  accuracy =   1.0000  loss =  146.384\n",
      "testing  :  9068  accuracy =   0.9681  loss =  148.892\n",
      "training :  9069  accuracy =   0.9900  loss =  146.55\n",
      "testing  :  9069  accuracy =   0.9672  loss =  148.888\n",
      "training :  9070  accuracy =   0.9800  loss =  147.575\n",
      "testing  :  9070  accuracy =   0.9671  loss =  148.919\n",
      "training :  9071  accuracy =   0.9900  loss =  146.661\n",
      "testing  :  9071  accuracy =   0.9670  loss =  148.943\n",
      "training :  9072  accuracy =   0.9800  loss =  148.3\n",
      "testing  :  9072  accuracy =   0.9663  loss =  148.971\n",
      "training :  9073  accuracy =   1.0000  loss =  146.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9073  accuracy =   0.9654  loss =  149.004\n",
      "training :  9074  accuracy =   0.9700  loss =  149.16\n",
      "testing  :  9074  accuracy =   0.9650  loss =  149.045\n",
      "training :  9075  accuracy =   0.9700  loss =  148.444\n",
      "testing  :  9075  accuracy =   0.9638  loss =  149.1\n",
      "training :  9076  accuracy =   0.9700  loss =  148.078\n",
      "testing  :  9076  accuracy =   0.9630  loss =  149.162\n",
      "training :  9077  accuracy =   0.9800  loss =  147.541\n",
      "testing  :  9077  accuracy =   0.9620  loss =  149.227\n",
      "training :  9078  accuracy =   0.9700  loss =  148.203\n",
      "testing  :  9078  accuracy =   0.9627  loss =  149.116\n",
      "training :  9079  accuracy =   1.0000  loss =  146.272\n",
      "testing  :  9079  accuracy =   0.9633  loss =  149.072\n",
      "training :  9080  accuracy =   0.9600  loss =  149.558\n",
      "testing  :  9080  accuracy =   0.9637  loss =  149.042\n",
      "training :  9081  accuracy =   0.9800  loss =  148.215\n",
      "testing  :  9081  accuracy =   0.9633  loss =  149.017\n",
      "training :  9082  accuracy =   0.9800  loss =  147.35\n",
      "testing  :  9082  accuracy =   0.9643  loss =  149.007\n",
      "training :  9083  accuracy =   0.9800  loss =  147.467\n",
      "testing  :  9083  accuracy =   0.9655  loss =  148.979\n",
      "training :  9084  accuracy =   0.9800  loss =  147.258\n",
      "testing  :  9084  accuracy =   0.9660  loss =  148.946\n",
      "training :  9085  accuracy =   0.9600  loss =  147.898\n",
      "testing  :  9085  accuracy =   0.9657  loss =  148.948\n",
      "training :  9086  accuracy =   0.9800  loss =  147.914\n",
      "testing  :  9086  accuracy =   0.9662  loss =  148.925\n",
      "training :  9087  accuracy =   1.0000  loss =  146.139\n",
      "testing  :  9087  accuracy =   0.9667  loss =  148.891\n",
      "training :  9088  accuracy =   0.9900  loss =  146.354\n",
      "testing  :  9088  accuracy =   0.9671  loss =  148.862\n",
      "training :  9089  accuracy =   0.9900  loss =  147.293\n",
      "testing  :  9089  accuracy =   0.9674  loss =  148.831\n",
      "training :  9090  accuracy =   0.9900  loss =  147.148\n",
      "testing  :  9090  accuracy =   0.9681  loss =  148.806\n",
      "training :  9091  accuracy =   1.0000  loss =  146.468\n",
      "testing  :  9091  accuracy =   0.9686  loss =  148.779\n",
      "training :  9092  accuracy =   0.9500  loss =  150.15\n",
      "testing  :  9092  accuracy =   0.9690  loss =  148.752\n",
      "training :  9093  accuracy =   0.9800  loss =  147.692\n",
      "testing  :  9093  accuracy =   0.9689  loss =  148.728\n",
      "training :  9094  accuracy =   0.9700  loss =  148.393\n",
      "testing  :  9094  accuracy =   0.9687  loss =  148.729\n",
      "training :  9095  accuracy =   1.0000  loss =  146.456\n",
      "testing  :  9095  accuracy =   0.9687  loss =  148.771\n",
      "training :  9096  accuracy =   0.9700  loss =  149.158\n",
      "testing  :  9096  accuracy =   0.9668  loss =  148.832\n",
      "training :  9097  accuracy =   0.9800  loss =  148.457\n",
      "testing  :  9097  accuracy =   0.9649  loss =  148.91\n",
      "training :  9098  accuracy =   1.0000  loss =  146.367\n",
      "testing  :  9098  accuracy =   0.9643  loss =  148.997\n",
      "training :  9099  accuracy =   0.9500  loss =  151.013\n",
      "testing  :  9099  accuracy =   0.9629  loss =  149.079\n",
      "training :  9100  accuracy =   0.9700  loss =  148.491\n",
      "testing  :  9100  accuracy =   0.9624  loss =  149.098\n",
      "training :  9101  accuracy =   0.9800  loss =  146.99\n",
      "testing  :  9101  accuracy =   0.9621  loss =  149.127\n",
      "training :  9102  accuracy =   0.9500  loss =  150.195\n",
      "testing  :  9102  accuracy =   0.9621  loss =  149.115\n",
      "training :  9103  accuracy =   0.9900  loss =  146.838\n",
      "testing  :  9103  accuracy =   0.9636  loss =  149.052\n",
      "training :  9104  accuracy =   0.9700  loss =  148.789\n",
      "testing  :  9104  accuracy =   0.9643  loss =  149.003\n",
      "training :  9105  accuracy =   0.9700  loss =  149.037\n",
      "testing  :  9105  accuracy =   0.9648  loss =  148.974\n",
      "training :  9106  accuracy =   0.9900  loss =  147.483\n",
      "testing  :  9106  accuracy =   0.9653  loss =  148.962\n",
      "training :  9107  accuracy =   1.0000  loss =  146.398\n",
      "testing  :  9107  accuracy =   0.9657  loss =  148.963\n",
      "training :  9108  accuracy =   0.9900  loss =  147.455\n",
      "testing  :  9108  accuracy =   0.9660  loss =  148.954\n",
      "training :  9109  accuracy =   1.0000  loss =  146.59\n",
      "testing  :  9109  accuracy =   0.9661  loss =  148.957\n",
      "training :  9110  accuracy =   0.9500  loss =  149.917\n",
      "testing  :  9110  accuracy =   0.9656  loss =  148.974\n",
      "training :  9111  accuracy =   1.0000  loss =  146.208\n",
      "testing  :  9111  accuracy =   0.9661  loss =  148.965\n",
      "training :  9112  accuracy =   0.9800  loss =  147.808\n",
      "testing  :  9112  accuracy =   0.9660  loss =  148.96\n",
      "training :  9113  accuracy =   0.9900  loss =  147.306\n",
      "testing  :  9113  accuracy =   0.9668  loss =  148.914\n",
      "training :  9114  accuracy =   0.9700  loss =  148.205\n",
      "testing  :  9114  accuracy =   0.9677  loss =  148.861\n",
      "training :  9115  accuracy =   0.9800  loss =  148.611\n",
      "testing  :  9115  accuracy =   0.9679  loss =  148.81\n",
      "training :  9116  accuracy =   0.9600  loss =  149.44\n",
      "testing  :  9116  accuracy =   0.9685  loss =  148.774\n",
      "training :  9117  accuracy =   0.9800  loss =  147.629\n",
      "testing  :  9117  accuracy =   0.9690  loss =  148.748\n",
      "training :  9118  accuracy =   0.9700  loss =  149.212\n",
      "testing  :  9118  accuracy =   0.9685  loss =  148.729\n",
      "training :  9119  accuracy =   0.9900  loss =  147.595\n",
      "testing  :  9119  accuracy =   0.9684  loss =  148.726\n",
      "training :  9120  accuracy =   1.0000  loss =  146.139\n",
      "testing  :  9120  accuracy =   0.9682  loss =  148.741\n",
      "training :  9121  accuracy =   0.9600  loss =  149.602\n",
      "testing  :  9121  accuracy =   0.9680  loss =  148.772\n",
      "training :  9122  accuracy =   0.9800  loss =  148.584\n",
      "testing  :  9122  accuracy =   0.9682  loss =  148.805\n",
      "training :  9123  accuracy =   0.9900  loss =  146.448\n",
      "testing  :  9123  accuracy =   0.9680  loss =  148.836\n",
      "training :  9124  accuracy =   0.9800  loss =  147.362\n",
      "testing  :  9124  accuracy =   0.9677  loss =  148.861\n",
      "training :  9125  accuracy =   0.9800  loss =  146.635\n",
      "testing  :  9125  accuracy =   0.9674  loss =  148.871\n",
      "training :  9126  accuracy =   1.0000  loss =  146.227\n",
      "testing  :  9126  accuracy =   0.9672  loss =  148.876\n",
      "training :  9127  accuracy =   1.0000  loss =  146.429\n",
      "testing  :  9127  accuracy =   0.9675  loss =  148.881\n",
      "training :  9128  accuracy =   0.9600  loss =  149.234\n",
      "testing  :  9128  accuracy =   0.9675  loss =  148.885\n",
      "training :  9129  accuracy =   0.9900  loss =  147.389\n",
      "testing  :  9129  accuracy =   0.9676  loss =  148.892\n",
      "training :  9130  accuracy =   0.9800  loss =  147.917\n",
      "testing  :  9130  accuracy =   0.9678  loss =  148.902\n",
      "training :  9131  accuracy =   0.9800  loss =  147.957\n",
      "testing  :  9131  accuracy =   0.9672  loss =  148.901\n",
      "training :  9132  accuracy =   0.9800  loss =  147.538\n",
      "testing  :  9132  accuracy =   0.9679  loss =  148.878\n",
      "training :  9133  accuracy =   0.9700  loss =  148.104\n",
      "testing  :  9133  accuracy =   0.9675  loss =  148.837\n",
      "training :  9134  accuracy =   0.9600  loss =  148.729\n",
      "testing  :  9134  accuracy =   0.9669  loss =  148.844\n",
      "training :  9135  accuracy =   0.9900  loss =  147.162\n",
      "testing  :  9135  accuracy =   0.9668  loss =  148.865\n",
      "training :  9136  accuracy =   0.9700  loss =  147.89\n",
      "testing  :  9136  accuracy =   0.9672  loss =  148.897\n",
      "training :  9137  accuracy =   0.9800  loss =  148.229\n",
      "testing  :  9137  accuracy =   0.9668  loss =  148.936\n",
      "training :  9138  accuracy =   0.9700  loss =  149.084\n",
      "testing  :  9138  accuracy =   0.9664  loss =  148.992\n",
      "training :  9139  accuracy =   0.9700  loss =  150.361\n",
      "testing  :  9139  accuracy =   0.9666  loss =  149.016\n",
      "training :  9140  accuracy =   0.9800  loss =  146.742\n",
      "testing  :  9140  accuracy =   0.9661  loss =  149.031\n",
      "training :  9141  accuracy =   0.9800  loss =  149.381\n",
      "testing  :  9141  accuracy =   0.9652  loss =  149.038\n",
      "training :  9142  accuracy =   0.9700  loss =  149.046\n",
      "testing  :  9142  accuracy =   0.9651  loss =  149.036\n",
      "training :  9143  accuracy =   0.9900  loss =  146.588\n",
      "testing  :  9143  accuracy =   0.9653  loss =  149.019\n",
      "training :  9144  accuracy =   0.9600  loss =  148.191\n",
      "testing  :  9144  accuracy =   0.9652  loss =  149.004\n",
      "training :  9145  accuracy =   0.9900  loss =  147.311\n",
      "testing  :  9145  accuracy =   0.9662  loss =  148.966\n",
      "training :  9146  accuracy =   0.9900  loss =  146.537\n",
      "testing  :  9146  accuracy =   0.9667  loss =  148.938\n",
      "training :  9147  accuracy =   0.9800  loss =  148.629\n",
      "testing  :  9147  accuracy =   0.9674  loss =  148.908\n",
      "training :  9148  accuracy =   0.9900  loss =  147.277\n",
      "testing  :  9148  accuracy =   0.9681  loss =  148.869\n",
      "training :  9149  accuracy =   1.0000  loss =  146.424\n",
      "testing  :  9149  accuracy =   0.9680  loss =  148.836\n",
      "training :  9150  accuracy =   1.0000  loss =  146.159\n",
      "testing  :  9150  accuracy =   0.9677  loss =  148.809\n",
      "training :  9151  accuracy =   1.0000  loss =  146.248\n",
      "testing  :  9151  accuracy =   0.9682  loss =  148.789\n",
      "training :  9152  accuracy =   0.9700  loss =  148.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9152  accuracy =   0.9680  loss =  148.767\n",
      "training :  9153  accuracy =   0.9800  loss =  148.461\n",
      "testing  :  9153  accuracy =   0.9677  loss =  148.747\n",
      "training :  9154  accuracy =   1.0000  loss =  146.299\n",
      "testing  :  9154  accuracy =   0.9677  loss =  148.733\n",
      "training :  9155  accuracy =   0.9700  loss =  147.496\n",
      "testing  :  9155  accuracy =   0.9679  loss =  148.72\n",
      "training :  9156  accuracy =   0.9700  loss =  149.236\n",
      "testing  :  9156  accuracy =   0.9683  loss =  148.708\n",
      "training :  9157  accuracy =   1.0000  loss =  146.389\n",
      "testing  :  9157  accuracy =   0.9683  loss =  148.698\n",
      "training :  9158  accuracy =   1.0000  loss =  146.594\n",
      "testing  :  9158  accuracy =   0.9686  loss =  148.696\n",
      "training :  9159  accuracy =   0.9800  loss =  148.051\n",
      "testing  :  9159  accuracy =   0.9687  loss =  148.7\n",
      "training :  9160  accuracy =   0.9900  loss =  146.517\n",
      "testing  :  9160  accuracy =   0.9686  loss =  148.722\n",
      "training :  9161  accuracy =   0.9800  loss =  148.529\n",
      "testing  :  9161  accuracy =   0.9686  loss =  148.747\n",
      "training :  9162  accuracy =   0.9800  loss =  147.288\n",
      "testing  :  9162  accuracy =   0.9686  loss =  148.767\n",
      "training :  9163  accuracy =   0.9900  loss =  147.191\n",
      "testing  :  9163  accuracy =   0.9686  loss =  148.787\n",
      "training :  9164  accuracy =   0.9800  loss =  147.625\n",
      "testing  :  9164  accuracy =   0.9679  loss =  148.806\n",
      "training :  9165  accuracy =   0.9800  loss =  147.764\n",
      "testing  :  9165  accuracy =   0.9679  loss =  148.825\n",
      "training :  9166  accuracy =   0.9700  loss =  148.821\n",
      "testing  :  9166  accuracy =   0.9681  loss =  148.835\n",
      "training :  9167  accuracy =   1.0000  loss =  146.408\n",
      "testing  :  9167  accuracy =   0.9686  loss =  148.842\n",
      "training :  9168  accuracy =   0.9600  loss =  149.75\n",
      "testing  :  9168  accuracy =   0.9683  loss =  148.853\n",
      "training :  9169  accuracy =   0.9700  loss =  149.341\n",
      "testing  :  9169  accuracy =   0.9682  loss =  148.872\n",
      "training :  9170  accuracy =   0.9900  loss =  146.537\n",
      "testing  :  9170  accuracy =   0.9677  loss =  148.886\n",
      "training :  9171  accuracy =   1.0000  loss =  146.292\n",
      "testing  :  9171  accuracy =   0.9678  loss =  148.902\n",
      "training :  9172  accuracy =   0.9900  loss =  147.234\n",
      "testing  :  9172  accuracy =   0.9673  loss =  148.915\n",
      "training :  9173  accuracy =   0.9700  loss =  149.16\n",
      "testing  :  9173  accuracy =   0.9673  loss =  148.929\n",
      "training :  9174  accuracy =   0.9700  loss =  149.085\n",
      "testing  :  9174  accuracy =   0.9672  loss =  148.967\n",
      "training :  9175  accuracy =   0.9700  loss =  148.062\n",
      "testing  :  9175  accuracy =   0.9672  loss =  148.996\n",
      "training :  9176  accuracy =   0.9600  loss =  148.824\n",
      "testing  :  9176  accuracy =   0.9664  loss =  149.022\n",
      "training :  9177  accuracy =   0.9700  loss =  148.586\n",
      "testing  :  9177  accuracy =   0.9660  loss =  149.052\n",
      "training :  9178  accuracy =   1.0000  loss =  146.254\n",
      "testing  :  9178  accuracy =   0.9655  loss =  149.074\n",
      "training :  9179  accuracy =   0.9700  loss =  148.046\n",
      "testing  :  9179  accuracy =   0.9655  loss =  149.095\n",
      "training :  9180  accuracy =   1.0000  loss =  146.71\n",
      "testing  :  9180  accuracy =   0.9654  loss =  149.077\n",
      "training :  9181  accuracy =   0.9700  loss =  149.34\n",
      "testing  :  9181  accuracy =   0.9656  loss =  149.058\n",
      "training :  9182  accuracy =   1.0000  loss =  146.483\n",
      "testing  :  9182  accuracy =   0.9662  loss =  149.013\n",
      "training :  9183  accuracy =   0.9700  loss =  148.584\n",
      "testing  :  9183  accuracy =   0.9665  loss =  148.981\n",
      "training :  9184  accuracy =   0.9700  loss =  147.441\n",
      "testing  :  9184  accuracy =   0.9671  loss =  148.948\n",
      "training :  9185  accuracy =   0.9800  loss =  147.441\n",
      "testing  :  9185  accuracy =   0.9672  loss =  148.906\n",
      "training :  9186  accuracy =   1.0000  loss =  146.16\n",
      "testing  :  9186  accuracy =   0.9681  loss =  148.85\n",
      "training :  9187  accuracy =   1.0000  loss =  146.425\n",
      "testing  :  9187  accuracy =   0.9686  loss =  148.809\n",
      "training :  9188  accuracy =   0.9800  loss =  147.672\n",
      "testing  :  9188  accuracy =   0.9692  loss =  148.772\n",
      "training :  9189  accuracy =   0.9700  loss =  147.203\n",
      "testing  :  9189  accuracy =   0.9690  loss =  148.741\n",
      "training :  9190  accuracy =   0.9900  loss =  146.45\n",
      "testing  :  9190  accuracy =   0.9692  loss =  148.719\n",
      "training :  9191  accuracy =   0.9700  loss =  148.507\n",
      "testing  :  9191  accuracy =   0.9691  loss =  148.698\n",
      "training :  9192  accuracy =   0.9500  loss =  148.935\n",
      "testing  :  9192  accuracy =   0.9688  loss =  148.676\n",
      "training :  9193  accuracy =   1.0000  loss =  146.323\n",
      "testing  :  9193  accuracy =   0.9688  loss =  148.671\n",
      "training :  9194  accuracy =   0.9900  loss =  147.509\n",
      "testing  :  9194  accuracy =   0.9695  loss =  148.682\n",
      "training :  9195  accuracy =   0.9900  loss =  146.706\n",
      "testing  :  9195  accuracy =   0.9696  loss =  148.694\n",
      "training :  9196  accuracy =   0.9900  loss =  147.175\n",
      "testing  :  9196  accuracy =   0.9695  loss =  148.669\n",
      "training :  9197  accuracy =   1.0000  loss =  146.186\n",
      "testing  :  9197  accuracy =   0.9700  loss =  148.67\n",
      "training :  9198  accuracy =   0.9900  loss =  146.625\n",
      "testing  :  9198  accuracy =   0.9703  loss =  148.69\n",
      "training :  9199  accuracy =   0.9900  loss =  146.878\n",
      "testing  :  9199  accuracy =   0.9699  loss =  148.694\n",
      "training :  9200  accuracy =   1.0000  loss =  146.136\n",
      "testing  :  9200  accuracy =   0.9698  loss =  148.694\n",
      "training :  9201  accuracy =   0.9700  loss =  148.624\n",
      "testing  :  9201  accuracy =   0.9694  loss =  148.706\n",
      "training :  9202  accuracy =   0.9800  loss =  148.195\n",
      "testing  :  9202  accuracy =   0.9689  loss =  148.729\n",
      "training :  9203  accuracy =   0.9900  loss =  147.262\n",
      "testing  :  9203  accuracy =   0.9689  loss =  148.772\n",
      "training :  9204  accuracy =   1.0000  loss =  146.154\n",
      "testing  :  9204  accuracy =   0.9681  loss =  148.822\n",
      "training :  9205  accuracy =   0.9900  loss =  146.451\n",
      "testing  :  9205  accuracy =   0.9676  loss =  148.862\n",
      "training :  9206  accuracy =   0.9800  loss =  148.051\n",
      "testing  :  9206  accuracy =   0.9676  loss =  148.899\n",
      "training :  9207  accuracy =   0.9900  loss =  146.634\n",
      "testing  :  9207  accuracy =   0.9672  loss =  148.933\n",
      "training :  9208  accuracy =   0.9900  loss =  147.022\n",
      "testing  :  9208  accuracy =   0.9668  loss =  148.92\n",
      "training :  9209  accuracy =   0.9800  loss =  147.423\n",
      "testing  :  9209  accuracy =   0.9674  loss =  148.902\n",
      "training :  9210  accuracy =   0.9900  loss =  146.28\n",
      "testing  :  9210  accuracy =   0.9684  loss =  148.89\n",
      "training :  9211  accuracy =   1.0000  loss =  146.283\n",
      "testing  :  9211  accuracy =   0.9681  loss =  148.891\n",
      "training :  9212  accuracy =   0.9400  loss =  150.375\n",
      "testing  :  9212  accuracy =   0.9678  loss =  148.896\n",
      "training :  9213  accuracy =   0.9800  loss =  147.324\n",
      "testing  :  9213  accuracy =   0.9685  loss =  148.872\n",
      "training :  9214  accuracy =   1.0000  loss =  146.288\n",
      "testing  :  9214  accuracy =   0.9684  loss =  148.849\n",
      "training :  9215  accuracy =   0.9700  loss =  147.699\n",
      "testing  :  9215  accuracy =   0.9683  loss =  148.833\n",
      "training :  9216  accuracy =   0.9900  loss =  147.173\n",
      "testing  :  9216  accuracy =   0.9680  loss =  148.827\n",
      "training :  9217  accuracy =   0.9900  loss =  147.058\n",
      "testing  :  9217  accuracy =   0.9682  loss =  148.827\n",
      "training :  9218  accuracy =   0.9500  loss =  149.886\n",
      "testing  :  9218  accuracy =   0.9682  loss =  148.831\n",
      "training :  9219  accuracy =   1.0000  loss =  146.142\n",
      "testing  :  9219  accuracy =   0.9688  loss =  148.818\n",
      "training :  9220  accuracy =   1.0000  loss =  146.157\n",
      "testing  :  9220  accuracy =   0.9689  loss =  148.838\n",
      "training :  9221  accuracy =   0.9800  loss =  146.572\n",
      "testing  :  9221  accuracy =   0.9691  loss =  148.871\n",
      "training :  9222  accuracy =   0.9600  loss =  148.218\n",
      "testing  :  9222  accuracy =   0.9691  loss =  148.897\n",
      "training :  9223  accuracy =   1.0000  loss =  146.217\n",
      "testing  :  9223  accuracy =   0.9690  loss =  148.897\n",
      "training :  9224  accuracy =   1.0000  loss =  146.445\n",
      "testing  :  9224  accuracy =   0.9683  loss =  148.905\n",
      "training :  9225  accuracy =   0.9800  loss =  146.658\n",
      "testing  :  9225  accuracy =   0.9681  loss =  148.925\n",
      "training :  9226  accuracy =   0.9800  loss =  147.838\n",
      "testing  :  9226  accuracy =   0.9677  loss =  148.941\n",
      "training :  9227  accuracy =   0.9300  loss =  153.453\n",
      "testing  :  9227  accuracy =   0.9677  loss =  148.927\n",
      "training :  9228  accuracy =   0.9800  loss =  147.812\n",
      "testing  :  9228  accuracy =   0.9670  loss =  148.917\n",
      "training :  9229  accuracy =   0.9300  loss =  151.641\n",
      "testing  :  9229  accuracy =   0.9664  loss =  148.936\n",
      "training :  9230  accuracy =   1.0000  loss =  146.631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9230  accuracy =   0.9667  loss =  148.846\n",
      "training :  9231  accuracy =   0.9800  loss =  147.671\n",
      "testing  :  9231  accuracy =   0.9682  loss =  148.77\n",
      "training :  9232  accuracy =   1.0000  loss =  146.629\n",
      "testing  :  9232  accuracy =   0.9694  loss =  148.723\n",
      "training :  9233  accuracy =   0.9900  loss =  146.55\n",
      "testing  :  9233  accuracy =   0.9695  loss =  148.702\n",
      "training :  9234  accuracy =   1.0000  loss =  146.373\n",
      "testing  :  9234  accuracy =   0.9694  loss =  148.725\n",
      "training :  9235  accuracy =   0.9600  loss =  148.547\n",
      "testing  :  9235  accuracy =   0.9686  loss =  148.755\n",
      "training :  9236  accuracy =   0.9800  loss =  148.611\n",
      "testing  :  9236  accuracy =   0.9689  loss =  148.78\n",
      "training :  9237  accuracy =   0.9900  loss =  146.583\n",
      "testing  :  9237  accuracy =   0.9683  loss =  148.794\n",
      "training :  9238  accuracy =   1.0000  loss =  146.801\n",
      "testing  :  9238  accuracy =   0.9681  loss =  148.805\n",
      "training :  9239  accuracy =   0.9800  loss =  147.35\n",
      "testing  :  9239  accuracy =   0.9677  loss =  148.812\n",
      "training :  9240  accuracy =   0.9900  loss =  147.49\n",
      "testing  :  9240  accuracy =   0.9675  loss =  148.818\n",
      "training :  9241  accuracy =   0.9600  loss =  149.432\n",
      "testing  :  9241  accuracy =   0.9678  loss =  148.808\n",
      "training :  9242  accuracy =   0.9900  loss =  146.558\n",
      "testing  :  9242  accuracy =   0.9682  loss =  148.798\n",
      "training :  9243  accuracy =   0.9900  loss =  147.227\n",
      "testing  :  9243  accuracy =   0.9678  loss =  148.795\n",
      "training :  9244  accuracy =   0.9800  loss =  146.666\n",
      "testing  :  9244  accuracy =   0.9684  loss =  148.791\n",
      "training :  9245  accuracy =   0.9900  loss =  146.618\n",
      "testing  :  9245  accuracy =   0.9684  loss =  148.79\n",
      "training :  9246  accuracy =   0.9900  loss =  146.455\n",
      "testing  :  9246  accuracy =   0.9690  loss =  148.788\n",
      "training :  9247  accuracy =   1.0000  loss =  146.294\n",
      "testing  :  9247  accuracy =   0.9689  loss =  148.779\n",
      "training :  9248  accuracy =   0.9900  loss =  146.646\n",
      "testing  :  9248  accuracy =   0.9688  loss =  148.776\n",
      "training :  9249  accuracy =   1.0000  loss =  146.353\n",
      "testing  :  9249  accuracy =   0.9687  loss =  148.778\n",
      "training :  9250  accuracy =   0.9800  loss =  147.432\n",
      "testing  :  9250  accuracy =   0.9686  loss =  148.781\n",
      "training :  9251  accuracy =   0.9900  loss =  147.303\n",
      "testing  :  9251  accuracy =   0.9683  loss =  148.788\n",
      "training :  9252  accuracy =   0.9900  loss =  147.266\n",
      "testing  :  9252  accuracy =   0.9680  loss =  148.801\n",
      "training :  9253  accuracy =   0.9700  loss =  147.672\n",
      "testing  :  9253  accuracy =   0.9677  loss =  148.818\n",
      "training :  9254  accuracy =   1.0000  loss =  146.337\n",
      "testing  :  9254  accuracy =   0.9677  loss =  148.826\n",
      "training :  9255  accuracy =   1.0000  loss =  146.34\n",
      "testing  :  9255  accuracy =   0.9682  loss =  148.825\n",
      "training :  9256  accuracy =   1.0000  loss =  146.296\n",
      "testing  :  9256  accuracy =   0.9688  loss =  148.821\n",
      "training :  9257  accuracy =   0.9800  loss =  148.374\n",
      "testing  :  9257  accuracy =   0.9693  loss =  148.823\n",
      "training :  9258  accuracy =   0.9900  loss =  147.403\n",
      "testing  :  9258  accuracy =   0.9693  loss =  148.83\n",
      "training :  9259  accuracy =   1.0000  loss =  146.502\n",
      "testing  :  9259  accuracy =   0.9695  loss =  148.831\n",
      "training :  9260  accuracy =   0.9800  loss =  147.743\n",
      "testing  :  9260  accuracy =   0.9695  loss =  148.833\n",
      "training :  9261  accuracy =   0.9900  loss =  147.397\n",
      "testing  :  9261  accuracy =   0.9695  loss =  148.83\n",
      "training :  9262  accuracy =   1.0000  loss =  146.367\n",
      "testing  :  9262  accuracy =   0.9690  loss =  148.831\n",
      "training :  9263  accuracy =   0.9800  loss =  147.517\n",
      "testing  :  9263  accuracy =   0.9688  loss =  148.841\n",
      "training :  9264  accuracy =   0.9900  loss =  147.242\n",
      "testing  :  9264  accuracy =   0.9687  loss =  148.836\n",
      "training :  9265  accuracy =   0.9800  loss =  146.455\n",
      "testing  :  9265  accuracy =   0.9689  loss =  148.816\n",
      "training :  9266  accuracy =   1.0000  loss =  146.166\n",
      "testing  :  9266  accuracy =   0.9684  loss =  148.809\n",
      "training :  9267  accuracy =   0.9800  loss =  147.624\n",
      "testing  :  9267  accuracy =   0.9685  loss =  148.811\n",
      "training :  9268  accuracy =   0.9900  loss =  146.349\n",
      "testing  :  9268  accuracy =   0.9683  loss =  148.797\n",
      "training :  9269  accuracy =   1.0000  loss =  146.288\n",
      "testing  :  9269  accuracy =   0.9685  loss =  148.781\n",
      "training :  9270  accuracy =   0.9900  loss =  147.205\n",
      "testing  :  9270  accuracy =   0.9686  loss =  148.777\n",
      "training :  9271  accuracy =   1.0000  loss =  146.309\n",
      "testing  :  9271  accuracy =   0.9685  loss =  148.798\n",
      "training :  9272  accuracy =   0.9900  loss =  146.551\n",
      "testing  :  9272  accuracy =   0.9686  loss =  148.835\n",
      "training :  9273  accuracy =   0.9800  loss =  147.47\n",
      "testing  :  9273  accuracy =   0.9679  loss =  148.861\n",
      "training :  9274  accuracy =   0.9800  loss =  148.144\n",
      "testing  :  9274  accuracy =   0.9675  loss =  148.849\n",
      "training :  9275  accuracy =   0.9700  loss =  148.728\n",
      "testing  :  9275  accuracy =   0.9677  loss =  148.825\n",
      "training :  9276  accuracy =   0.9900  loss =  147.139\n",
      "testing  :  9276  accuracy =   0.9678  loss =  148.84\n",
      "training :  9277  accuracy =   0.9800  loss =  146.523\n",
      "testing  :  9277  accuracy =   0.9668  loss =  148.868\n",
      "training :  9278  accuracy =   0.9800  loss =  146.482\n",
      "testing  :  9278  accuracy =   0.9668  loss =  148.877\n",
      "training :  9279  accuracy =   0.9800  loss =  148.439\n",
      "testing  :  9279  accuracy =   0.9663  loss =  148.879\n",
      "training :  9280  accuracy =   0.9600  loss =  148.685\n",
      "testing  :  9280  accuracy =   0.9665  loss =  148.883\n",
      "training :  9281  accuracy =   0.9800  loss =  147.786\n",
      "testing  :  9281  accuracy =   0.9668  loss =  148.873\n",
      "training :  9282  accuracy =   0.9800  loss =  147.276\n",
      "testing  :  9282  accuracy =   0.9667  loss =  148.886\n",
      "training :  9283  accuracy =   1.0000  loss =  146.229\n",
      "testing  :  9283  accuracy =   0.9671  loss =  148.885\n",
      "training :  9284  accuracy =   0.9800  loss =  147.929\n",
      "testing  :  9284  accuracy =   0.9663  loss =  148.93\n",
      "training :  9285  accuracy =   1.0000  loss =  146.16\n",
      "testing  :  9285  accuracy =   0.9664  loss =  148.952\n",
      "training :  9286  accuracy =   0.9700  loss =  148.366\n",
      "testing  :  9286  accuracy =   0.9666  loss =  149.004\n",
      "training :  9287  accuracy =   0.9700  loss =  148.655\n",
      "testing  :  9287  accuracy =   0.9667  loss =  149.031\n",
      "training :  9288  accuracy =   0.9800  loss =  146.551\n",
      "testing  :  9288  accuracy =   0.9667  loss =  149.053\n",
      "training :  9289  accuracy =   0.9900  loss =  147.33\n",
      "testing  :  9289  accuracy =   0.9667  loss =  149.072\n",
      "training :  9290  accuracy =   0.9900  loss =  146.822\n",
      "testing  :  9290  accuracy =   0.9661  loss =  149.097\n",
      "training :  9291  accuracy =   0.9900  loss =  146.529\n",
      "testing  :  9291  accuracy =   0.9659  loss =  149.129\n",
      "training :  9292  accuracy =   0.9500  loss =  149.327\n",
      "testing  :  9292  accuracy =   0.9656  loss =  149.132\n",
      "training :  9293  accuracy =   1.0000  loss =  146.404\n",
      "testing  :  9293  accuracy =   0.9657  loss =  149.117\n",
      "training :  9294  accuracy =   0.9600  loss =  148.721\n",
      "testing  :  9294  accuracy =   0.9656  loss =  149.106\n",
      "training :  9295  accuracy =   0.9700  loss =  148.71\n",
      "testing  :  9295  accuracy =   0.9663  loss =  149.104\n",
      "training :  9296  accuracy =   0.9900  loss =  147.17\n",
      "testing  :  9296  accuracy =   0.9664  loss =  149.1\n",
      "training :  9297  accuracy =   0.9800  loss =  148.354\n",
      "testing  :  9297  accuracy =   0.9658  loss =  149.09\n",
      "training :  9298  accuracy =   0.9700  loss =  148.481\n",
      "testing  :  9298  accuracy =   0.9653  loss =  149.074\n",
      "training :  9299  accuracy =   0.9900  loss =  147.173\n",
      "testing  :  9299  accuracy =   0.9656  loss =  149.059\n",
      "training :  9300  accuracy =   0.9700  loss =  147.599\n",
      "testing  :  9300  accuracy =   0.9655  loss =  149.07\n",
      "training :  9301  accuracy =   0.9800  loss =  146.906\n",
      "testing  :  9301  accuracy =   0.9658  loss =  149.003\n",
      "training :  9302  accuracy =   1.0000  loss =  146.559\n",
      "testing  :  9302  accuracy =   0.9657  loss =  148.986\n",
      "training :  9303  accuracy =   1.0000  loss =  146.506\n",
      "testing  :  9303  accuracy =   0.9661  loss =  148.992\n",
      "training :  9304  accuracy =   0.9900  loss =  146.868\n",
      "testing  :  9304  accuracy =   0.9664  loss =  148.985\n",
      "training :  9305  accuracy =   0.9800  loss =  146.661\n",
      "testing  :  9305  accuracy =   0.9663  loss =  148.999\n",
      "training :  9306  accuracy =   0.9900  loss =  147.521\n",
      "testing  :  9306  accuracy =   0.9659  loss =  149.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  9307  accuracy =   0.9900  loss =  147.734\n",
      "testing  :  9307  accuracy =   0.9658  loss =  149.048\n",
      "training :  9308  accuracy =   0.9600  loss =  150.293\n",
      "testing  :  9308  accuracy =   0.9661  loss =  149.052\n",
      "training :  9309  accuracy =   0.9800  loss =  148.485\n",
      "testing  :  9309  accuracy =   0.9657  loss =  149.065\n",
      "training :  9310  accuracy =   0.9600  loss =  149.673\n",
      "testing  :  9310  accuracy =   0.9653  loss =  149.1\n",
      "training :  9311  accuracy =   1.0000  loss =  146.605\n",
      "testing  :  9311  accuracy =   0.9654  loss =  149.074\n",
      "training :  9312  accuracy =   0.9800  loss =  148.291\n",
      "testing  :  9312  accuracy =   0.9656  loss =  149.046\n",
      "training :  9313  accuracy =   0.9700  loss =  147.177\n",
      "testing  :  9313  accuracy =   0.9655  loss =  149.005\n",
      "training :  9314  accuracy =   0.9700  loss =  148.69\n",
      "testing  :  9314  accuracy =   0.9666  loss =  148.96\n",
      "training :  9315  accuracy =   0.9800  loss =  148.517\n",
      "testing  :  9315  accuracy =   0.9666  loss =  148.916\n",
      "training :  9316  accuracy =   0.9800  loss =  147.052\n",
      "testing  :  9316  accuracy =   0.9668  loss =  148.886\n",
      "training :  9317  accuracy =   0.9900  loss =  146.945\n",
      "testing  :  9317  accuracy =   0.9673  loss =  148.853\n",
      "training :  9318  accuracy =   0.9600  loss =  148.921\n",
      "testing  :  9318  accuracy =   0.9675  loss =  148.835\n",
      "training :  9319  accuracy =   0.9700  loss =  148.509\n",
      "testing  :  9319  accuracy =   0.9678  loss =  148.81\n",
      "training :  9320  accuracy =   0.9900  loss =  147.273\n",
      "testing  :  9320  accuracy =   0.9681  loss =  148.774\n",
      "training :  9321  accuracy =   1.0000  loss =  146.223\n",
      "testing  :  9321  accuracy =   0.9683  loss =  148.756\n",
      "training :  9322  accuracy =   0.9800  loss =  147.749\n",
      "testing  :  9322  accuracy =   0.9688  loss =  148.746\n",
      "training :  9323  accuracy =   0.9900  loss =  147.011\n",
      "testing  :  9323  accuracy =   0.9686  loss =  148.758\n",
      "training :  9324  accuracy =   0.9800  loss =  148.289\n",
      "testing  :  9324  accuracy =   0.9686  loss =  148.771\n",
      "training :  9325  accuracy =   0.9700  loss =  147.774\n",
      "testing  :  9325  accuracy =   0.9683  loss =  148.79\n",
      "training :  9326  accuracy =   0.9900  loss =  146.537\n",
      "testing  :  9326  accuracy =   0.9688  loss =  148.812\n",
      "training :  9327  accuracy =   0.9800  loss =  147.742\n",
      "testing  :  9327  accuracy =   0.9690  loss =  148.829\n",
      "training :  9328  accuracy =   0.9800  loss =  147.425\n",
      "testing  :  9328  accuracy =   0.9689  loss =  148.816\n",
      "training :  9329  accuracy =   1.0000  loss =  146.53\n",
      "testing  :  9329  accuracy =   0.9686  loss =  148.803\n",
      "training :  9330  accuracy =   1.0000  loss =  146.278\n",
      "testing  :  9330  accuracy =   0.9690  loss =  148.79\n",
      "training :  9331  accuracy =   0.9900  loss =  147.546\n",
      "testing  :  9331  accuracy =   0.9693  loss =  148.778\n",
      "training :  9332  accuracy =   0.9900  loss =  147.29\n",
      "testing  :  9332  accuracy =   0.9693  loss =  148.766\n",
      "training :  9333  accuracy =   0.9800  loss =  148.302\n",
      "testing  :  9333  accuracy =   0.9690  loss =  148.754\n",
      "training :  9334  accuracy =   0.9800  loss =  147.529\n",
      "testing  :  9334  accuracy =   0.9689  loss =  148.75\n",
      "training :  9335  accuracy =   0.9900  loss =  147.522\n",
      "testing  :  9335  accuracy =   0.9683  loss =  148.75\n",
      "training :  9336  accuracy =   0.9700  loss =  148.521\n",
      "testing  :  9336  accuracy =   0.9686  loss =  148.745\n",
      "training :  9337  accuracy =   0.9500  loss =  148.331\n",
      "testing  :  9337  accuracy =   0.9685  loss =  148.741\n",
      "training :  9338  accuracy =   0.9800  loss =  146.847\n",
      "testing  :  9338  accuracy =   0.9697  loss =  148.705\n",
      "training :  9339  accuracy =   1.0000  loss =  146.139\n",
      "testing  :  9339  accuracy =   0.9698  loss =  148.691\n",
      "training :  9340  accuracy =   0.9800  loss =  148.682\n",
      "testing  :  9340  accuracy =   0.9698  loss =  148.681\n",
      "training :  9341  accuracy =   0.9900  loss =  147.592\n",
      "testing  :  9341  accuracy =   0.9700  loss =  148.667\n",
      "training :  9342  accuracy =   0.9900  loss =  147.49\n",
      "testing  :  9342  accuracy =   0.9699  loss =  148.662\n",
      "training :  9343  accuracy =   0.9800  loss =  147.506\n",
      "testing  :  9343  accuracy =   0.9700  loss =  148.664\n",
      "training :  9344  accuracy =   0.9900  loss =  146.679\n",
      "testing  :  9344  accuracy =   0.9699  loss =  148.664\n",
      "training :  9345  accuracy =   0.9800  loss =  147.483\n",
      "testing  :  9345  accuracy =   0.9696  loss =  148.689\n",
      "training :  9346  accuracy =   0.9900  loss =  147.368\n",
      "testing  :  9346  accuracy =   0.9695  loss =  148.728\n",
      "training :  9347  accuracy =   1.0000  loss =  146.146\n",
      "testing  :  9347  accuracy =   0.9696  loss =  148.798\n",
      "training :  9348  accuracy =   0.9800  loss =  147.328\n",
      "testing  :  9348  accuracy =   0.9685  loss =  148.883\n",
      "training :  9349  accuracy =   0.9800  loss =  146.94\n",
      "testing  :  9349  accuracy =   0.9663  loss =  148.959\n",
      "training :  9350  accuracy =   0.9900  loss =  146.984\n",
      "testing  :  9350  accuracy =   0.9649  loss =  149.01\n",
      "training :  9351  accuracy =   0.9900  loss =  146.879\n",
      "testing  :  9351  accuracy =   0.9651  loss =  149.026\n",
      "training :  9352  accuracy =   0.9900  loss =  146.935\n",
      "testing  :  9352  accuracy =   0.9654  loss =  149.018\n",
      "training :  9353  accuracy =   0.9700  loss =  149.242\n",
      "testing  :  9353  accuracy =   0.9657  loss =  149.037\n",
      "training :  9354  accuracy =   0.9700  loss =  147.85\n",
      "testing  :  9354  accuracy =   0.9649  loss =  149.04\n",
      "training :  9355  accuracy =   0.9500  loss =  148.44\n",
      "testing  :  9355  accuracy =   0.9650  loss =  149.028\n",
      "training :  9356  accuracy =   0.9700  loss =  149.04\n",
      "testing  :  9356  accuracy =   0.9652  loss =  149.018\n",
      "training :  9357  accuracy =   0.9600  loss =  149.287\n",
      "testing  :  9357  accuracy =   0.9647  loss =  148.962\n",
      "training :  9358  accuracy =   0.9700  loss =  147.693\n",
      "testing  :  9358  accuracy =   0.9657  loss =  148.902\n",
      "training :  9359  accuracy =   0.9900  loss =  147.489\n",
      "testing  :  9359  accuracy =   0.9662  loss =  148.904\n",
      "training :  9360  accuracy =   0.9900  loss =  147.508\n",
      "testing  :  9360  accuracy =   0.9652  loss =  148.942\n",
      "training :  9361  accuracy =   1.0000  loss =  146.229\n",
      "testing  :  9361  accuracy =   0.9651  loss =  149.016\n",
      "training :  9362  accuracy =   0.9900  loss =  147.198\n",
      "testing  :  9362  accuracy =   0.9645  loss =  149.084\n",
      "training :  9363  accuracy =   1.0000  loss =  146.379\n",
      "testing  :  9363  accuracy =   0.9635  loss =  149.167\n",
      "training :  9364  accuracy =   0.9700  loss =  148.711\n",
      "testing  :  9364  accuracy =   0.9626  loss =  149.252\n",
      "training :  9365  accuracy =   0.9900  loss =  147.864\n",
      "testing  :  9365  accuracy =   0.9617  loss =  149.302\n",
      "training :  9366  accuracy =   0.9800  loss =  146.991\n",
      "testing  :  9366  accuracy =   0.9623  loss =  149.297\n",
      "training :  9367  accuracy =   0.9600  loss =  149.309\n",
      "testing  :  9367  accuracy =   0.9625  loss =  149.272\n",
      "training :  9368  accuracy =   0.9900  loss =  147.253\n",
      "testing  :  9368  accuracy =   0.9640  loss =  149.21\n",
      "training :  9369  accuracy =   0.9900  loss =  146.784\n",
      "testing  :  9369  accuracy =   0.9638  loss =  149.165\n",
      "training :  9370  accuracy =   0.9800  loss =  147.751\n",
      "testing  :  9370  accuracy =   0.9643  loss =  149.089\n",
      "training :  9371  accuracy =   1.0000  loss =  146.229\n",
      "testing  :  9371  accuracy =   0.9650  loss =  149.018\n",
      "training :  9372  accuracy =   1.0000  loss =  146.292\n",
      "testing  :  9372  accuracy =   0.9652  loss =  148.964\n",
      "training :  9373  accuracy =   0.9900  loss =  147.673\n",
      "testing  :  9373  accuracy =   0.9659  loss =  148.925\n",
      "training :  9374  accuracy =   0.9500  loss =  149.653\n",
      "testing  :  9374  accuracy =   0.9666  loss =  148.89\n",
      "training :  9375  accuracy =   1.0000  loss =  146.142\n",
      "testing  :  9375  accuracy =   0.9669  loss =  148.859\n",
      "training :  9376  accuracy =   1.0000  loss =  146.276\n",
      "testing  :  9376  accuracy =   0.9678  loss =  148.835\n",
      "training :  9377  accuracy =   0.9800  loss =  147.425\n",
      "testing  :  9377  accuracy =   0.9679  loss =  148.823\n",
      "training :  9378  accuracy =   0.9700  loss =  147.837\n",
      "testing  :  9378  accuracy =   0.9679  loss =  148.825\n",
      "training :  9379  accuracy =   1.0000  loss =  146.281\n",
      "testing  :  9379  accuracy =   0.9676  loss =  148.846\n",
      "training :  9380  accuracy =   0.9600  loss =  148.819\n",
      "testing  :  9380  accuracy =   0.9678  loss =  148.87\n",
      "training :  9381  accuracy =   0.9700  loss =  149.246\n",
      "testing  :  9381  accuracy =   0.9677  loss =  148.87\n",
      "training :  9382  accuracy =   0.9600  loss =  150.227\n",
      "testing  :  9382  accuracy =   0.9673  loss =  148.829\n",
      "training :  9383  accuracy =   0.9800  loss =  146.852\n",
      "testing  :  9383  accuracy =   0.9695  loss =  148.724\n",
      "training :  9384  accuracy =   0.9900  loss =  146.487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9384  accuracy =   0.9700  loss =  148.657\n",
      "training :  9385  accuracy =   1.0000  loss =  146.336\n",
      "testing  :  9385  accuracy =   0.9711  loss =  148.641\n",
      "training :  9386  accuracy =   1.0000  loss =  146.412\n",
      "testing  :  9386  accuracy =   0.9706  loss =  148.653\n",
      "training :  9387  accuracy =   0.9700  loss =  148.732\n",
      "testing  :  9387  accuracy =   0.9693  loss =  148.693\n",
      "training :  9388  accuracy =   0.9900  loss =  147.148\n",
      "testing  :  9388  accuracy =   0.9692  loss =  148.714\n",
      "training :  9389  accuracy =   1.0000  loss =  146.234\n",
      "testing  :  9389  accuracy =   0.9689  loss =  148.737\n",
      "training :  9390  accuracy =   0.9700  loss =  149.171\n",
      "testing  :  9390  accuracy =   0.9686  loss =  148.761\n",
      "training :  9391  accuracy =   0.9800  loss =  147.903\n",
      "testing  :  9391  accuracy =   0.9686  loss =  148.81\n",
      "training :  9392  accuracy =   0.9900  loss =  147.442\n",
      "testing  :  9392  accuracy =   0.9687  loss =  148.851\n",
      "training :  9393  accuracy =   0.9900  loss =  147.356\n",
      "testing  :  9393  accuracy =   0.9681  loss =  148.892\n",
      "training :  9394  accuracy =   1.0000  loss =  146.334\n",
      "testing  :  9394  accuracy =   0.9681  loss =  148.908\n",
      "training :  9395  accuracy =   0.9900  loss =  147.43\n",
      "testing  :  9395  accuracy =   0.9682  loss =  148.921\n",
      "training :  9396  accuracy =   0.9800  loss =  148.024\n",
      "testing  :  9396  accuracy =   0.9680  loss =  148.928\n",
      "training :  9397  accuracy =   0.9700  loss =  149.418\n",
      "testing  :  9397  accuracy =   0.9678  loss =  148.966\n",
      "training :  9398  accuracy =   0.9900  loss =  147.276\n",
      "testing  :  9398  accuracy =   0.9668  loss =  149.0\n",
      "training :  9399  accuracy =   0.9600  loss =  150.387\n",
      "testing  :  9399  accuracy =   0.9661  loss =  149.031\n",
      "training :  9400  accuracy =   0.9400  loss =  149.695\n",
      "testing  :  9400  accuracy =   0.9659  loss =  149.043\n",
      "training :  9401  accuracy =   0.9700  loss =  146.731\n",
      "testing  :  9401  accuracy =   0.9655  loss =  149.05\n",
      "training :  9402  accuracy =   1.0000  loss =  146.17\n",
      "testing  :  9402  accuracy =   0.9657  loss =  149.069\n",
      "training :  9403  accuracy =   1.0000  loss =  146.174\n",
      "testing  :  9403  accuracy =   0.9652  loss =  149.105\n",
      "training :  9404  accuracy =   0.9600  loss =  149.62\n",
      "testing  :  9404  accuracy =   0.9652  loss =  149.142\n",
      "training :  9405  accuracy =   1.0000  loss =  146.226\n",
      "testing  :  9405  accuracy =   0.9648  loss =  149.175\n",
      "training :  9406  accuracy =   1.0000  loss =  146.842\n",
      "testing  :  9406  accuracy =   0.9644  loss =  149.208\n",
      "training :  9407  accuracy =   0.9600  loss =  149.577\n",
      "testing  :  9407  accuracy =   0.9647  loss =  149.203\n",
      "training :  9408  accuracy =   0.9900  loss =  147.437\n",
      "testing  :  9408  accuracy =   0.9657  loss =  149.142\n",
      "training :  9409  accuracy =   0.9800  loss =  147.497\n",
      "testing  :  9409  accuracy =   0.9658  loss =  149.124\n",
      "training :  9410  accuracy =   0.9700  loss =  148.451\n",
      "testing  :  9410  accuracy =   0.9654  loss =  149.104\n",
      "training :  9411  accuracy =   0.9500  loss =  148.036\n",
      "testing  :  9411  accuracy =   0.9661  loss =  149.061\n",
      "training :  9412  accuracy =   0.9600  loss =  147.747\n",
      "testing  :  9412  accuracy =   0.9678  loss =  148.979\n",
      "training :  9413  accuracy =   1.0000  loss =  146.263\n",
      "testing  :  9413  accuracy =   0.9679  loss =  148.941\n",
      "training :  9414  accuracy =   1.0000  loss =  146.654\n",
      "testing  :  9414  accuracy =   0.9673  loss =  148.933\n",
      "training :  9415  accuracy =   0.9800  loss =  147.831\n",
      "testing  :  9415  accuracy =   0.9668  loss =  148.949\n",
      "training :  9416  accuracy =   0.9700  loss =  148.494\n",
      "testing  :  9416  accuracy =   0.9674  loss =  148.966\n",
      "training :  9417  accuracy =   0.9700  loss =  147.801\n",
      "testing  :  9417  accuracy =   0.9670  loss =  149.004\n",
      "training :  9418  accuracy =   0.9600  loss =  149.227\n",
      "testing  :  9418  accuracy =   0.9667  loss =  148.993\n",
      "training :  9419  accuracy =   0.9500  loss =  148.02\n",
      "testing  :  9419  accuracy =   0.9666  loss =  148.926\n",
      "training :  9420  accuracy =   0.9700  loss =  149.63\n",
      "testing  :  9420  accuracy =   0.9672  loss =  148.855\n",
      "training :  9421  accuracy =   0.9800  loss =  147.819\n",
      "testing  :  9421  accuracy =   0.9677  loss =  148.805\n",
      "training :  9422  accuracy =   1.0000  loss =  146.275\n",
      "testing  :  9422  accuracy =   0.9681  loss =  148.77\n",
      "training :  9423  accuracy =   0.9800  loss =  147.458\n",
      "testing  :  9423  accuracy =   0.9687  loss =  148.766\n",
      "training :  9424  accuracy =   1.0000  loss =  146.747\n",
      "testing  :  9424  accuracy =   0.9689  loss =  148.78\n",
      "training :  9425  accuracy =   0.9700  loss =  148.374\n",
      "testing  :  9425  accuracy =   0.9684  loss =  148.785\n",
      "training :  9426  accuracy =   0.9800  loss =  147.472\n",
      "testing  :  9426  accuracy =   0.9674  loss =  148.845\n",
      "training :  9427  accuracy =   0.9900  loss =  147.215\n",
      "testing  :  9427  accuracy =   0.9652  loss =  148.989\n",
      "training :  9428  accuracy =   0.9600  loss =  150.784\n",
      "testing  :  9428  accuracy =   0.9637  loss =  149.129\n",
      "training :  9429  accuracy =   0.9900  loss =  146.986\n",
      "testing  :  9429  accuracy =   0.9614  loss =  149.256\n",
      "training :  9430  accuracy =   0.9800  loss =  147.052\n",
      "testing  :  9430  accuracy =   0.9602  loss =  149.382\n",
      "training :  9431  accuracy =   0.9500  loss =  151.125\n",
      "testing  :  9431  accuracy =   0.9599  loss =  149.419\n",
      "training :  9432  accuracy =   0.9500  loss =  149.761\n",
      "testing  :  9432  accuracy =   0.9595  loss =  149.441\n",
      "training :  9433  accuracy =   0.9900  loss =  146.719\n",
      "testing  :  9433  accuracy =   0.9598  loss =  149.422\n",
      "training :  9434  accuracy =   1.0000  loss =  146.228\n",
      "testing  :  9434  accuracy =   0.9599  loss =  149.399\n",
      "training :  9435  accuracy =   0.9900  loss =  147.552\n",
      "testing  :  9435  accuracy =   0.9602  loss =  149.376\n",
      "training :  9436  accuracy =   0.9700  loss =  148.157\n",
      "testing  :  9436  accuracy =   0.9612  loss =  149.332\n",
      "training :  9437  accuracy =   0.9800  loss =  148.602\n",
      "testing  :  9437  accuracy =   0.9629  loss =  149.228\n",
      "training :  9438  accuracy =   0.9700  loss =  148.074\n",
      "testing  :  9438  accuracy =   0.9646  loss =  149.134\n",
      "training :  9439  accuracy =   0.9800  loss =  147.848\n",
      "testing  :  9439  accuracy =   0.9661  loss =  148.993\n",
      "training :  9440  accuracy =   1.0000  loss =  146.142\n",
      "testing  :  9440  accuracy =   0.9664  loss =  148.89\n",
      "training :  9441  accuracy =   0.9900  loss =  146.278\n",
      "testing  :  9441  accuracy =   0.9673  loss =  148.817\n",
      "training :  9442  accuracy =   0.9800  loss =  147.302\n",
      "testing  :  9442  accuracy =   0.9691  loss =  148.789\n",
      "training :  9443  accuracy =   0.9900  loss =  146.994\n",
      "testing  :  9443  accuracy =   0.9690  loss =  148.793\n",
      "training :  9444  accuracy =   0.9900  loss =  147.161\n",
      "testing  :  9444  accuracy =   0.9687  loss =  148.799\n",
      "training :  9445  accuracy =   1.0000  loss =  146.313\n",
      "testing  :  9445  accuracy =   0.9683  loss =  148.81\n",
      "training :  9446  accuracy =   0.9800  loss =  147.755\n",
      "testing  :  9446  accuracy =   0.9679  loss =  148.815\n",
      "training :  9447  accuracy =   0.9800  loss =  148.439\n",
      "testing  :  9447  accuracy =   0.9678  loss =  148.807\n",
      "training :  9448  accuracy =   0.9900  loss =  147.462\n",
      "testing  :  9448  accuracy =   0.9678  loss =  148.804\n",
      "training :  9449  accuracy =   0.9700  loss =  148.484\n",
      "testing  :  9449  accuracy =   0.9674  loss =  148.803\n",
      "training :  9450  accuracy =   1.0000  loss =  146.537\n",
      "testing  :  9450  accuracy =   0.9671  loss =  148.808\n",
      "training :  9451  accuracy =   0.9800  loss =  148.301\n",
      "testing  :  9451  accuracy =   0.9675  loss =  148.812\n",
      "training :  9452  accuracy =   0.9800  loss =  148.688\n",
      "testing  :  9452  accuracy =   0.9676  loss =  148.815\n",
      "training :  9453  accuracy =   0.9900  loss =  147.168\n",
      "testing  :  9453  accuracy =   0.9677  loss =  148.817\n",
      "training :  9454  accuracy =   0.9800  loss =  148.486\n",
      "testing  :  9454  accuracy =   0.9679  loss =  148.804\n",
      "training :  9455  accuracy =   0.9800  loss =  147.687\n",
      "testing  :  9455  accuracy =   0.9678  loss =  148.794\n",
      "training :  9456  accuracy =   0.9900  loss =  146.734\n",
      "testing  :  9456  accuracy =   0.9678  loss =  148.787\n",
      "training :  9457  accuracy =   0.9900  loss =  147.19\n",
      "testing  :  9457  accuracy =   0.9679  loss =  148.758\n",
      "training :  9458  accuracy =   1.0000  loss =  146.274\n",
      "testing  :  9458  accuracy =   0.9683  loss =  148.735\n",
      "training :  9459  accuracy =   0.9900  loss =  147.546\n",
      "testing  :  9459  accuracy =   0.9687  loss =  148.716\n",
      "training :  9460  accuracy =   0.9900  loss =  147.39\n",
      "testing  :  9460  accuracy =   0.9691  loss =  148.704\n",
      "training :  9461  accuracy =   0.9600  loss =  149.67\n",
      "testing  :  9461  accuracy =   0.9699  loss =  148.691\n",
      "training :  9462  accuracy =   1.0000  loss =  146.362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9462  accuracy =   0.9706  loss =  148.677\n",
      "training :  9463  accuracy =   0.9900  loss =  146.386\n",
      "testing  :  9463  accuracy =   0.9708  loss =  148.667\n",
      "training :  9464  accuracy =   0.9600  loss =  149.564\n",
      "testing  :  9464  accuracy =   0.9710  loss =  148.658\n",
      "training :  9465  accuracy =   0.9800  loss =  147.365\n",
      "testing  :  9465  accuracy =   0.9716  loss =  148.652\n",
      "training :  9466  accuracy =   0.9900  loss =  146.783\n",
      "testing  :  9466  accuracy =   0.9715  loss =  148.644\n",
      "training :  9467  accuracy =   1.0000  loss =  146.313\n",
      "testing  :  9467  accuracy =   0.9715  loss =  148.64\n",
      "training :  9468  accuracy =   0.9800  loss =  147.597\n",
      "testing  :  9468  accuracy =   0.9705  loss =  148.632\n",
      "training :  9469  accuracy =   0.9700  loss =  149.036\n",
      "testing  :  9469  accuracy =   0.9703  loss =  148.629\n",
      "training :  9470  accuracy =   0.9700  loss =  149.45\n",
      "testing  :  9470  accuracy =   0.9703  loss =  148.638\n",
      "training :  9471  accuracy =   0.9600  loss =  149.455\n",
      "testing  :  9471  accuracy =   0.9706  loss =  148.655\n",
      "training :  9472  accuracy =   0.9800  loss =  147.931\n",
      "testing  :  9472  accuracy =   0.9710  loss =  148.655\n",
      "training :  9473  accuracy =   0.9700  loss =  149.123\n",
      "testing  :  9473  accuracy =   0.9714  loss =  148.615\n",
      "training :  9474  accuracy =   1.0000  loss =  146.216\n",
      "testing  :  9474  accuracy =   0.9715  loss =  148.617\n",
      "training :  9475  accuracy =   1.0000  loss =  146.174\n",
      "testing  :  9475  accuracy =   0.9715  loss =  148.656\n",
      "training :  9476  accuracy =   0.9900  loss =  146.489\n",
      "testing  :  9476  accuracy =   0.9708  loss =  148.709\n",
      "training :  9477  accuracy =   1.0000  loss =  146.37\n",
      "testing  :  9477  accuracy =   0.9692  loss =  148.766\n",
      "training :  9478  accuracy =   0.9900  loss =  147.331\n",
      "testing  :  9478  accuracy =   0.9689  loss =  148.81\n",
      "training :  9479  accuracy =   0.9700  loss =  147.735\n",
      "testing  :  9479  accuracy =   0.9690  loss =  148.845\n",
      "training :  9480  accuracy =   0.9600  loss =  148.902\n",
      "testing  :  9480  accuracy =   0.9690  loss =  148.869\n",
      "training :  9481  accuracy =   0.9700  loss =  149.176\n",
      "testing  :  9481  accuracy =   0.9686  loss =  148.874\n",
      "training :  9482  accuracy =   0.9700  loss =  148.938\n",
      "testing  :  9482  accuracy =   0.9672  loss =  148.906\n",
      "training :  9483  accuracy =   0.9800  loss =  148.273\n",
      "testing  :  9483  accuracy =   0.9669  loss =  148.958\n",
      "training :  9484  accuracy =   0.9700  loss =  148.641\n",
      "testing  :  9484  accuracy =   0.9655  loss =  149.03\n",
      "training :  9485  accuracy =   0.9900  loss =  146.995\n",
      "testing  :  9485  accuracy =   0.9638  loss =  149.122\n",
      "training :  9486  accuracy =   0.9800  loss =  146.859\n",
      "testing  :  9486  accuracy =   0.9633  loss =  149.192\n",
      "training :  9487  accuracy =   0.9800  loss =  146.614\n",
      "testing  :  9487  accuracy =   0.9638  loss =  149.275\n",
      "training :  9488  accuracy =   0.9900  loss =  147.484\n",
      "testing  :  9488  accuracy =   0.9632  loss =  149.353\n",
      "training :  9489  accuracy =   1.0000  loss =  146.527\n",
      "testing  :  9489  accuracy =   0.9622  loss =  149.378\n",
      "training :  9490  accuracy =   0.9800  loss =  148.751\n",
      "testing  :  9490  accuracy =   0.9625  loss =  149.386\n",
      "training :  9491  accuracy =   0.9900  loss =  147.66\n",
      "testing  :  9491  accuracy =   0.9618  loss =  149.403\n",
      "training :  9492  accuracy =   0.9500  loss =  150.403\n",
      "testing  :  9492  accuracy =   0.9619  loss =  149.379\n",
      "training :  9493  accuracy =   0.9800  loss =  147.615\n",
      "testing  :  9493  accuracy =   0.9626  loss =  149.331\n",
      "training :  9494  accuracy =   1.0000  loss =  146.162\n",
      "testing  :  9494  accuracy =   0.9625  loss =  149.26\n",
      "training :  9495  accuracy =   0.9800  loss =  147.57\n",
      "testing  :  9495  accuracy =   0.9629  loss =  149.209\n",
      "training :  9496  accuracy =   0.9900  loss =  147.152\n",
      "testing  :  9496  accuracy =   0.9644  loss =  149.151\n",
      "training :  9497  accuracy =   0.9800  loss =  147.634\n",
      "testing  :  9497  accuracy =   0.9646  loss =  149.104\n",
      "training :  9498  accuracy =   0.9800  loss =  148.221\n",
      "testing  :  9498  accuracy =   0.9649  loss =  149.072\n",
      "training :  9499  accuracy =   0.9800  loss =  147.587\n",
      "testing  :  9499  accuracy =   0.9655  loss =  149.041\n",
      "training :  9500  accuracy =   0.9900  loss =  147.19\n",
      "testing  :  9500  accuracy =   0.9652  loss =  149.01\n",
      "training :  9501  accuracy =   0.9700  loss =  148.148\n",
      "testing  :  9501  accuracy =   0.9655  loss =  148.979\n",
      "training :  9502  accuracy =   0.9800  loss =  147.42\n",
      "testing  :  9502  accuracy =   0.9662  loss =  148.946\n",
      "training :  9503  accuracy =   0.9800  loss =  148.207\n",
      "testing  :  9503  accuracy =   0.9666  loss =  148.918\n",
      "training :  9504  accuracy =   1.0000  loss =  146.277\n",
      "testing  :  9504  accuracy =   0.9670  loss =  148.89\n",
      "training :  9505  accuracy =   1.0000  loss =  146.181\n",
      "testing  :  9505  accuracy =   0.9673  loss =  148.868\n",
      "training :  9506  accuracy =   0.9900  loss =  147.196\n",
      "testing  :  9506  accuracy =   0.9674  loss =  148.85\n",
      "training :  9507  accuracy =   0.9900  loss =  147.389\n",
      "testing  :  9507  accuracy =   0.9674  loss =  148.837\n",
      "training :  9508  accuracy =   0.9700  loss =  149.864\n",
      "testing  :  9508  accuracy =   0.9683  loss =  148.82\n",
      "training :  9509  accuracy =   0.9900  loss =  146.78\n",
      "testing  :  9509  accuracy =   0.9685  loss =  148.812\n",
      "training :  9510  accuracy =   0.9800  loss =  147.051\n",
      "testing  :  9510  accuracy =   0.9685  loss =  148.806\n",
      "training :  9511  accuracy =   0.9900  loss =  147.292\n",
      "testing  :  9511  accuracy =   0.9689  loss =  148.802\n",
      "training :  9512  accuracy =   0.9700  loss =  148.067\n",
      "testing  :  9512  accuracy =   0.9684  loss =  148.804\n",
      "training :  9513  accuracy =   0.9700  loss =  149.203\n",
      "testing  :  9513  accuracy =   0.9685  loss =  148.785\n",
      "training :  9514  accuracy =   0.9900  loss =  146.506\n",
      "testing  :  9514  accuracy =   0.9680  loss =  148.765\n",
      "training :  9515  accuracy =   1.0000  loss =  146.154\n",
      "testing  :  9515  accuracy =   0.9677  loss =  148.753\n",
      "training :  9516  accuracy =   0.9900  loss =  146.742\n",
      "testing  :  9516  accuracy =   0.9675  loss =  148.756\n",
      "training :  9517  accuracy =   0.9700  loss =  149.417\n",
      "testing  :  9517  accuracy =   0.9672  loss =  148.763\n",
      "training :  9518  accuracy =   1.0000  loss =  146.254\n",
      "testing  :  9518  accuracy =   0.9678  loss =  148.786\n",
      "training :  9519  accuracy =   1.0000  loss =  146.406\n",
      "testing  :  9519  accuracy =   0.9684  loss =  148.815\n",
      "training :  9520  accuracy =   0.9800  loss =  147.863\n",
      "testing  :  9520  accuracy =   0.9683  loss =  148.845\n",
      "training :  9521  accuracy =   1.0000  loss =  146.334\n",
      "testing  :  9521  accuracy =   0.9683  loss =  148.898\n",
      "training :  9522  accuracy =   0.9600  loss =  148.555\n",
      "testing  :  9522  accuracy =   0.9672  loss =  148.956\n",
      "training :  9523  accuracy =   1.0000  loss =  146.372\n",
      "testing  :  9523  accuracy =   0.9666  loss =  148.997\n",
      "training :  9524  accuracy =   0.9800  loss =  147.884\n",
      "testing  :  9524  accuracy =   0.9660  loss =  149.04\n",
      "training :  9525  accuracy =   0.9500  loss =  150.834\n",
      "testing  :  9525  accuracy =   0.9652  loss =  149.036\n",
      "training :  9526  accuracy =   0.9800  loss =  147.949\n",
      "testing  :  9526  accuracy =   0.9653  loss =  149.024\n",
      "training :  9527  accuracy =   0.9900  loss =  146.655\n",
      "testing  :  9527  accuracy =   0.9658  loss =  149.006\n",
      "training :  9528  accuracy =   0.9700  loss =  147.813\n",
      "testing  :  9528  accuracy =   0.9650  loss =  149.009\n",
      "training :  9529  accuracy =   0.9700  loss =  149.156\n",
      "testing  :  9529  accuracy =   0.9661  loss =  148.97\n",
      "training :  9530  accuracy =   0.9700  loss =  147.756\n",
      "testing  :  9530  accuracy =   0.9666  loss =  148.945\n",
      "training :  9531  accuracy =   0.9700  loss =  148.668\n",
      "testing  :  9531  accuracy =   0.9666  loss =  148.905\n",
      "training :  9532  accuracy =   0.9800  loss =  148.212\n",
      "testing  :  9532  accuracy =   0.9671  loss =  148.885\n",
      "training :  9533  accuracy =   0.9800  loss =  147.19\n",
      "testing  :  9533  accuracy =   0.9665  loss =  148.88\n",
      "training :  9534  accuracy =   0.9800  loss =  147.68\n",
      "testing  :  9534  accuracy =   0.9666  loss =  148.875\n",
      "training :  9535  accuracy =   1.0000  loss =  146.322\n",
      "testing  :  9535  accuracy =   0.9675  loss =  148.867\n",
      "training :  9536  accuracy =   0.9900  loss =  146.785\n",
      "testing  :  9536  accuracy =   0.9668  loss =  148.87\n",
      "training :  9537  accuracy =   1.0000  loss =  146.393\n",
      "testing  :  9537  accuracy =   0.9666  loss =  148.886\n",
      "training :  9538  accuracy =   0.9600  loss =  148.838\n",
      "testing  :  9538  accuracy =   0.9663  loss =  148.904\n",
      "training :  9539  accuracy =   1.0000  loss =  146.571\n",
      "testing  :  9539  accuracy =   0.9662  loss =  148.944\n",
      "training :  9540  accuracy =   0.9600  loss =  149.314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9540  accuracy =   0.9655  loss =  148.982\n",
      "training :  9541  accuracy =   0.9900  loss =  146.654\n",
      "testing  :  9541  accuracy =   0.9654  loss =  148.976\n",
      "training :  9542  accuracy =   0.9900  loss =  146.923\n",
      "testing  :  9542  accuracy =   0.9655  loss =  148.958\n",
      "training :  9543  accuracy =   0.9300  loss =  151.444\n",
      "testing  :  9543  accuracy =   0.9662  loss =  148.936\n",
      "training :  9544  accuracy =   0.9900  loss =  146.442\n",
      "testing  :  9544  accuracy =   0.9664  loss =  148.914\n",
      "training :  9545  accuracy =   0.9900  loss =  146.939\n",
      "testing  :  9545  accuracy =   0.9666  loss =  148.895\n",
      "training :  9546  accuracy =   1.0000  loss =  146.692\n",
      "testing  :  9546  accuracy =   0.9671  loss =  148.832\n",
      "training :  9547  accuracy =   1.0000  loss =  146.198\n",
      "testing  :  9547  accuracy =   0.9679  loss =  148.798\n",
      "training :  9548  accuracy =   0.9800  loss =  148.142\n",
      "testing  :  9548  accuracy =   0.9677  loss =  148.792\n",
      "training :  9549  accuracy =   1.0000  loss =  146.375\n",
      "testing  :  9549  accuracy =   0.9682  loss =  148.805\n",
      "training :  9550  accuracy =   1.0000  loss =  146.256\n",
      "testing  :  9550  accuracy =   0.9686  loss =  148.817\n",
      "training :  9551  accuracy =   0.9900  loss =  147.145\n",
      "testing  :  9551  accuracy =   0.9685  loss =  148.826\n",
      "training :  9552  accuracy =   1.0000  loss =  146.144\n",
      "testing  :  9552  accuracy =   0.9687  loss =  148.826\n",
      "training :  9553  accuracy =   0.9700  loss =  148.345\n",
      "testing  :  9553  accuracy =   0.9685  loss =  148.825\n",
      "training :  9554  accuracy =   1.0000  loss =  146.485\n",
      "testing  :  9554  accuracy =   0.9688  loss =  148.827\n",
      "training :  9555  accuracy =   1.0000  loss =  146.304\n",
      "testing  :  9555  accuracy =   0.9689  loss =  148.829\n",
      "training :  9556  accuracy =   0.9900  loss =  147.235\n",
      "testing  :  9556  accuracy =   0.9688  loss =  148.831\n",
      "training :  9557  accuracy =   0.9900  loss =  147.292\n",
      "testing  :  9557  accuracy =   0.9686  loss =  148.838\n",
      "training :  9558  accuracy =   0.9700  loss =  148.35\n",
      "testing  :  9558  accuracy =   0.9681  loss =  148.849\n",
      "training :  9559  accuracy =   0.9800  loss =  147.75\n",
      "testing  :  9559  accuracy =   0.9688  loss =  148.831\n",
      "training :  9560  accuracy =   0.9800  loss =  148.899\n",
      "testing  :  9560  accuracy =   0.9689  loss =  148.808\n",
      "training :  9561  accuracy =   0.9900  loss =  147.2\n",
      "testing  :  9561  accuracy =   0.9690  loss =  148.793\n",
      "training :  9562  accuracy =   0.9800  loss =  148.151\n",
      "testing  :  9562  accuracy =   0.9691  loss =  148.795\n",
      "training :  9563  accuracy =   0.9900  loss =  146.708\n",
      "testing  :  9563  accuracy =   0.9691  loss =  148.813\n",
      "training :  9564  accuracy =   0.9900  loss =  147.117\n",
      "testing  :  9564  accuracy =   0.9688  loss =  148.838\n",
      "training :  9565  accuracy =   0.9900  loss =  146.709\n",
      "testing  :  9565  accuracy =   0.9690  loss =  148.866\n",
      "training :  9566  accuracy =   0.9700  loss =  148.429\n",
      "testing  :  9566  accuracy =   0.9686  loss =  148.897\n",
      "training :  9567  accuracy =   0.9600  loss =  148.519\n",
      "testing  :  9567  accuracy =   0.9685  loss =  148.91\n",
      "training :  9568  accuracy =   1.0000  loss =  146.417\n",
      "testing  :  9568  accuracy =   0.9689  loss =  148.886\n",
      "training :  9569  accuracy =   0.9800  loss =  148.231\n",
      "testing  :  9569  accuracy =   0.9684  loss =  148.867\n",
      "training :  9570  accuracy =   0.9800  loss =  148.498\n",
      "testing  :  9570  accuracy =   0.9681  loss =  148.842\n",
      "training :  9571  accuracy =   1.0000  loss =  146.37\n",
      "testing  :  9571  accuracy =   0.9678  loss =  148.833\n",
      "training :  9572  accuracy =   0.9800  loss =  147.655\n",
      "testing  :  9572  accuracy =   0.9675  loss =  148.852\n",
      "training :  9573  accuracy =   1.0000  loss =  146.333\n",
      "testing  :  9573  accuracy =   0.9664  loss =  148.878\n",
      "training :  9574  accuracy =   0.9800  loss =  147.541\n",
      "testing  :  9574  accuracy =   0.9656  loss =  148.95\n",
      "training :  9575  accuracy =   0.9700  loss =  149.074\n",
      "testing  :  9575  accuracy =   0.9654  loss =  149.021\n",
      "training :  9576  accuracy =   0.9900  loss =  147.613\n",
      "testing  :  9576  accuracy =   0.9652  loss =  149.055\n",
      "training :  9577  accuracy =   0.9800  loss =  148.349\n",
      "testing  :  9577  accuracy =   0.9651  loss =  149.08\n",
      "training :  9578  accuracy =   0.9600  loss =  147.96\n",
      "testing  :  9578  accuracy =   0.9647  loss =  149.099\n",
      "training :  9579  accuracy =   0.9800  loss =  147.759\n",
      "testing  :  9579  accuracy =   0.9650  loss =  149.086\n",
      "training :  9580  accuracy =   0.9900  loss =  146.349\n",
      "testing  :  9580  accuracy =   0.9655  loss =  149.056\n",
      "training :  9581  accuracy =   0.9900  loss =  147.523\n",
      "testing  :  9581  accuracy =   0.9654  loss =  149.024\n",
      "training :  9582  accuracy =   0.9900  loss =  147.32\n",
      "testing  :  9582  accuracy =   0.9659  loss =  148.998\n",
      "training :  9583  accuracy =   0.9800  loss =  147.403\n",
      "testing  :  9583  accuracy =   0.9657  loss =  148.971\n",
      "training :  9584  accuracy =   0.9900  loss =  147.353\n",
      "testing  :  9584  accuracy =   0.9670  loss =  148.905\n",
      "training :  9585  accuracy =   0.9900  loss =  147.42\n",
      "testing  :  9585  accuracy =   0.9668  loss =  148.852\n",
      "training :  9586  accuracy =   0.9600  loss =  149.524\n",
      "testing  :  9586  accuracy =   0.9670  loss =  148.821\n",
      "training :  9587  accuracy =   0.9900  loss =  147.399\n",
      "testing  :  9587  accuracy =   0.9674  loss =  148.83\n",
      "training :  9588  accuracy =   0.9800  loss =  147.954\n",
      "testing  :  9588  accuracy =   0.9673  loss =  148.842\n",
      "training :  9589  accuracy =   0.9900  loss =  147.348\n",
      "testing  :  9589  accuracy =   0.9666  loss =  148.884\n",
      "training :  9590  accuracy =   0.9900  loss =  147.202\n",
      "testing  :  9590  accuracy =   0.9651  loss =  148.944\n",
      "training :  9591  accuracy =   0.9900  loss =  146.81\n",
      "testing  :  9591  accuracy =   0.9645  loss =  149.032\n",
      "training :  9592  accuracy =   0.9800  loss =  148.576\n",
      "testing  :  9592  accuracy =   0.9635  loss =  149.075\n",
      "training :  9593  accuracy =   0.9800  loss =  148.605\n",
      "testing  :  9593  accuracy =   0.9633  loss =  149.115\n",
      "training :  9594  accuracy =   0.9900  loss =  147.472\n",
      "testing  :  9594  accuracy =   0.9625  loss =  149.16\n",
      "training :  9595  accuracy =   0.9900  loss =  146.552\n",
      "testing  :  9595  accuracy =   0.9630  loss =  149.183\n",
      "training :  9596  accuracy =   0.9700  loss =  148.488\n",
      "testing  :  9596  accuracy =   0.9629  loss =  149.215\n",
      "training :  9597  accuracy =   0.9600  loss =  148.637\n",
      "testing  :  9597  accuracy =   0.9626  loss =  149.228\n",
      "training :  9598  accuracy =   0.9800  loss =  148.405\n",
      "testing  :  9598  accuracy =   0.9630  loss =  149.234\n",
      "training :  9599  accuracy =   0.9700  loss =  148.661\n",
      "testing  :  9599  accuracy =   0.9635  loss =  149.218\n",
      "training :  9600  accuracy =   0.9800  loss =  147.719\n",
      "testing  :  9600  accuracy =   0.9648  loss =  149.142\n",
      "training :  9601  accuracy =   1.0000  loss =  146.145\n",
      "testing  :  9601  accuracy =   0.9658  loss =  149.053\n",
      "training :  9602  accuracy =   0.9800  loss =  147.42\n",
      "testing  :  9602  accuracy =   0.9652  loss =  148.99\n",
      "training :  9603  accuracy =   0.9700  loss =  148.356\n",
      "testing  :  9603  accuracy =   0.9654  loss =  148.953\n",
      "training :  9604  accuracy =   0.9900  loss =  146.416\n",
      "testing  :  9604  accuracy =   0.9662  loss =  148.918\n",
      "training :  9605  accuracy =   0.9600  loss =  148.718\n",
      "testing  :  9605  accuracy =   0.9673  loss =  148.907\n",
      "training :  9606  accuracy =   0.9600  loss =  149.449\n",
      "testing  :  9606  accuracy =   0.9673  loss =  148.89\n",
      "training :  9607  accuracy =   1.0000  loss =  146.172\n",
      "testing  :  9607  accuracy =   0.9680  loss =  148.816\n",
      "training :  9608  accuracy =   0.9900  loss =  147.084\n",
      "testing  :  9608  accuracy =   0.9692  loss =  148.774\n",
      "training :  9609  accuracy =   0.9900  loss =  147.355\n",
      "testing  :  9609  accuracy =   0.9695  loss =  148.729\n",
      "training :  9610  accuracy =   0.9900  loss =  146.689\n",
      "testing  :  9610  accuracy =   0.9698  loss =  148.691\n",
      "training :  9611  accuracy =   0.9900  loss =  146.582\n",
      "testing  :  9611  accuracy =   0.9693  loss =  148.677\n",
      "training :  9612  accuracy =   0.9900  loss =  147.189\n",
      "testing  :  9612  accuracy =   0.9696  loss =  148.673\n",
      "training :  9613  accuracy =   0.9800  loss =  148.38\n",
      "testing  :  9613  accuracy =   0.9695  loss =  148.686\n",
      "training :  9614  accuracy =   1.0000  loss =  146.41\n",
      "testing  :  9614  accuracy =   0.9693  loss =  148.714\n",
      "training :  9615  accuracy =   1.0000  loss =  146.282\n",
      "testing  :  9615  accuracy =   0.9683  loss =  148.752\n",
      "training :  9616  accuracy =   1.0000  loss =  146.385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9616  accuracy =   0.9682  loss =  148.794\n",
      "training :  9617  accuracy =   1.0000  loss =  146.698\n",
      "testing  :  9617  accuracy =   0.9677  loss =  148.833\n",
      "training :  9618  accuracy =   0.9900  loss =  147.411\n",
      "testing  :  9618  accuracy =   0.9675  loss =  148.823\n",
      "training :  9619  accuracy =   0.9900  loss =  146.452\n",
      "testing  :  9619  accuracy =   0.9673  loss =  148.815\n",
      "training :  9620  accuracy =   0.9800  loss =  146.487\n",
      "testing  :  9620  accuracy =   0.9673  loss =  148.789\n",
      "training :  9621  accuracy =   0.9900  loss =  147.525\n",
      "testing  :  9621  accuracy =   0.9678  loss =  148.772\n",
      "training :  9622  accuracy =   1.0000  loss =  146.284\n",
      "testing  :  9622  accuracy =   0.9675  loss =  148.766\n",
      "training :  9623  accuracy =   1.0000  loss =  146.426\n",
      "testing  :  9623  accuracy =   0.9670  loss =  148.761\n",
      "training :  9624  accuracy =   0.9900  loss =  146.641\n",
      "testing  :  9624  accuracy =   0.9677  loss =  148.744\n",
      "training :  9625  accuracy =   1.0000  loss =  146.258\n",
      "testing  :  9625  accuracy =   0.9682  loss =  148.733\n",
      "training :  9626  accuracy =   1.0000  loss =  146.261\n",
      "testing  :  9626  accuracy =   0.9677  loss =  148.726\n",
      "training :  9627  accuracy =   0.9800  loss =  148.128\n",
      "testing  :  9627  accuracy =   0.9677  loss =  148.724\n",
      "training :  9628  accuracy =   0.9900  loss =  146.413\n",
      "testing  :  9628  accuracy =   0.9684  loss =  148.698\n",
      "training :  9629  accuracy =   0.9800  loss =  148.281\n",
      "testing  :  9629  accuracy =   0.9687  loss =  148.682\n",
      "training :  9630  accuracy =   0.9800  loss =  146.608\n",
      "testing  :  9630  accuracy =   0.9689  loss =  148.674\n",
      "training :  9631  accuracy =   0.9800  loss =  147.607\n",
      "testing  :  9631  accuracy =   0.9687  loss =  148.671\n",
      "training :  9632  accuracy =   0.9700  loss =  148.589\n",
      "testing  :  9632  accuracy =   0.9694  loss =  148.665\n",
      "training :  9633  accuracy =   0.9900  loss =  147.356\n",
      "testing  :  9633  accuracy =   0.9696  loss =  148.664\n",
      "training :  9634  accuracy =   0.9600  loss =  149.24\n",
      "testing  :  9634  accuracy =   0.9697  loss =  148.671\n",
      "training :  9635  accuracy =   0.9900  loss =  146.488\n",
      "testing  :  9635  accuracy =   0.9689  loss =  148.676\n",
      "training :  9636  accuracy =   0.9700  loss =  148.484\n",
      "testing  :  9636  accuracy =   0.9690  loss =  148.692\n",
      "training :  9637  accuracy =   0.9700  loss =  149.181\n",
      "testing  :  9637  accuracy =   0.9686  loss =  148.725\n",
      "training :  9638  accuracy =   0.9900  loss =  147.269\n",
      "testing  :  9638  accuracy =   0.9683  loss =  148.764\n",
      "training :  9639  accuracy =   1.0000  loss =  146.384\n",
      "testing  :  9639  accuracy =   0.9681  loss =  148.802\n",
      "training :  9640  accuracy =   1.0000  loss =  146.34\n",
      "testing  :  9640  accuracy =   0.9678  loss =  148.835\n",
      "training :  9641  accuracy =   1.0000  loss =  146.195\n",
      "testing  :  9641  accuracy =   0.9678  loss =  148.858\n",
      "training :  9642  accuracy =   0.9900  loss =  146.336\n",
      "testing  :  9642  accuracy =   0.9677  loss =  148.875\n",
      "training :  9643  accuracy =   0.9900  loss =  146.495\n",
      "testing  :  9643  accuracy =   0.9673  loss =  148.892\n",
      "training :  9644  accuracy =   0.9700  loss =  147.491\n",
      "testing  :  9644  accuracy =   0.9674  loss =  148.903\n",
      "training :  9645  accuracy =   0.9800  loss =  147.671\n",
      "testing  :  9645  accuracy =   0.9668  loss =  148.909\n",
      "training :  9646  accuracy =   0.9600  loss =  148.939\n",
      "testing  :  9646  accuracy =   0.9668  loss =  148.867\n",
      "training :  9647  accuracy =   1.0000  loss =  146.198\n",
      "testing  :  9647  accuracy =   0.9671  loss =  148.808\n",
      "training :  9648  accuracy =   0.9700  loss =  147.929\n",
      "testing  :  9648  accuracy =   0.9681  loss =  148.774\n",
      "training :  9649  accuracy =   0.9800  loss =  147.695\n",
      "testing  :  9649  accuracy =   0.9695  loss =  148.72\n",
      "training :  9650  accuracy =   0.9900  loss =  146.403\n",
      "testing  :  9650  accuracy =   0.9697  loss =  148.681\n",
      "training :  9651  accuracy =   0.9900  loss =  147.327\n",
      "testing  :  9651  accuracy =   0.9694  loss =  148.661\n",
      "training :  9652  accuracy =   0.9900  loss =  147.137\n",
      "testing  :  9652  accuracy =   0.9695  loss =  148.65\n",
      "training :  9653  accuracy =   0.9700  loss =  147.602\n",
      "testing  :  9653  accuracy =   0.9697  loss =  148.647\n",
      "training :  9654  accuracy =   0.9800  loss =  147.642\n",
      "testing  :  9654  accuracy =   0.9694  loss =  148.655\n",
      "training :  9655  accuracy =   1.0000  loss =  146.309\n",
      "testing  :  9655  accuracy =   0.9693  loss =  148.675\n",
      "training :  9656  accuracy =   0.9900  loss =  147.162\n",
      "testing  :  9656  accuracy =   0.9695  loss =  148.699\n",
      "training :  9657  accuracy =   0.9900  loss =  146.537\n",
      "testing  :  9657  accuracy =   0.9696  loss =  148.718\n",
      "training :  9658  accuracy =   0.9900  loss =  147.268\n",
      "testing  :  9658  accuracy =   0.9697  loss =  148.725\n",
      "training :  9659  accuracy =   1.0000  loss =  146.25\n",
      "testing  :  9659  accuracy =   0.9695  loss =  148.73\n",
      "training :  9660  accuracy =   0.9900  loss =  146.761\n",
      "testing  :  9660  accuracy =   0.9696  loss =  148.732\n",
      "training :  9661  accuracy =   0.9800  loss =  148.442\n",
      "testing  :  9661  accuracy =   0.9698  loss =  148.722\n",
      "training :  9662  accuracy =   1.0000  loss =  146.15\n",
      "testing  :  9662  accuracy =   0.9696  loss =  148.716\n",
      "training :  9663  accuracy =   0.9900  loss =  146.36\n",
      "testing  :  9663  accuracy =   0.9697  loss =  148.715\n",
      "training :  9664  accuracy =   0.9900  loss =  147.126\n",
      "testing  :  9664  accuracy =   0.9695  loss =  148.713\n",
      "training :  9665  accuracy =   0.9900  loss =  147.327\n",
      "testing  :  9665  accuracy =   0.9692  loss =  148.717\n",
      "training :  9666  accuracy =   0.9900  loss =  147.398\n",
      "testing  :  9666  accuracy =   0.9689  loss =  148.723\n",
      "training :  9667  accuracy =   0.9600  loss =  148.689\n",
      "testing  :  9667  accuracy =   0.9688  loss =  148.724\n",
      "training :  9668  accuracy =   0.9900  loss =  146.373\n",
      "testing  :  9668  accuracy =   0.9692  loss =  148.74\n",
      "training :  9669  accuracy =   1.0000  loss =  146.153\n",
      "testing  :  9669  accuracy =   0.9693  loss =  148.79\n",
      "training :  9670  accuracy =   0.9800  loss =  148.162\n",
      "testing  :  9670  accuracy =   0.9677  loss =  148.838\n",
      "training :  9671  accuracy =   0.9900  loss =  146.388\n",
      "testing  :  9671  accuracy =   0.9670  loss =  148.903\n",
      "training :  9672  accuracy =   0.9800  loss =  148.285\n",
      "testing  :  9672  accuracy =   0.9657  loss =  149.001\n",
      "training :  9673  accuracy =   1.0000  loss =  146.218\n",
      "testing  :  9673  accuracy =   0.9651  loss =  149.122\n",
      "training :  9674  accuracy =   0.9600  loss =  148.739\n",
      "testing  :  9674  accuracy =   0.9635  loss =  149.238\n",
      "training :  9675  accuracy =   0.9900  loss =  147.346\n",
      "testing  :  9675  accuracy =   0.9650  loss =  149.119\n",
      "training :  9676  accuracy =   0.9700  loss =  148.002\n",
      "testing  :  9676  accuracy =   0.9661  loss =  149.028\n",
      "training :  9677  accuracy =   1.0000  loss =  146.328\n",
      "testing  :  9677  accuracy =   0.9665  loss =  148.961\n",
      "training :  9678  accuracy =   0.9800  loss =  147.566\n",
      "testing  :  9678  accuracy =   0.9673  loss =  148.904\n",
      "training :  9679  accuracy =   0.9900  loss =  146.719\n",
      "testing  :  9679  accuracy =   0.9676  loss =  148.873\n",
      "training :  9680  accuracy =   0.9700  loss =  148.969\n",
      "testing  :  9680  accuracy =   0.9684  loss =  148.854\n",
      "training :  9681  accuracy =   0.9800  loss =  148.271\n",
      "testing  :  9681  accuracy =   0.9688  loss =  148.849\n",
      "training :  9682  accuracy =   1.0000  loss =  146.274\n",
      "testing  :  9682  accuracy =   0.9685  loss =  148.851\n",
      "training :  9683  accuracy =   0.9800  loss =  148.417\n",
      "testing  :  9683  accuracy =   0.9687  loss =  148.85\n",
      "training :  9684  accuracy =   0.9900  loss =  146.336\n",
      "testing  :  9684  accuracy =   0.9681  loss =  148.852\n",
      "training :  9685  accuracy =   0.9800  loss =  147.426\n",
      "testing  :  9685  accuracy =   0.9672  loss =  148.862\n",
      "training :  9686  accuracy =   0.9900  loss =  147.465\n",
      "testing  :  9686  accuracy =   0.9672  loss =  148.884\n",
      "training :  9687  accuracy =   1.0000  loss =  146.13\n",
      "testing  :  9687  accuracy =   0.9662  loss =  148.921\n",
      "training :  9688  accuracy =   1.0000  loss =  146.387\n",
      "testing  :  9688  accuracy =   0.9663  loss =  148.963\n",
      "training :  9689  accuracy =   0.9900  loss =  147.158\n",
      "testing  :  9689  accuracy =   0.9660  loss =  148.999\n",
      "training :  9690  accuracy =   0.9900  loss =  146.979\n",
      "testing  :  9690  accuracy =   0.9657  loss =  149.03\n",
      "training :  9691  accuracy =   1.0000  loss =  146.188\n",
      "testing  :  9691  accuracy =   0.9656  loss =  148.999\n",
      "training :  9692  accuracy =   0.9900  loss =  147.341\n",
      "testing  :  9692  accuracy =   0.9656  loss =  148.964\n",
      "training :  9693  accuracy =   0.9800  loss =  146.962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9693  accuracy =   0.9662  loss =  148.93\n",
      "training :  9694  accuracy =   0.9700  loss =  147.636\n",
      "testing  :  9694  accuracy =   0.9674  loss =  148.877\n",
      "training :  9695  accuracy =   0.9900  loss =  146.481\n",
      "testing  :  9695  accuracy =   0.9679  loss =  148.819\n",
      "training :  9696  accuracy =   0.9800  loss =  148.003\n",
      "testing  :  9696  accuracy =   0.9679  loss =  148.787\n",
      "training :  9697  accuracy =   0.9700  loss =  147.989\n",
      "testing  :  9697  accuracy =   0.9682  loss =  148.773\n",
      "training :  9698  accuracy =   1.0000  loss =  146.403\n",
      "testing  :  9698  accuracy =   0.9691  loss =  148.785\n",
      "training :  9699  accuracy =   0.9600  loss =  150.075\n",
      "testing  :  9699  accuracy =   0.9684  loss =  148.809\n",
      "training :  9700  accuracy =   0.9700  loss =  148.675\n",
      "testing  :  9700  accuracy =   0.9676  loss =  148.84\n",
      "training :  9701  accuracy =   1.0000  loss =  146.423\n",
      "testing  :  9701  accuracy =   0.9676  loss =  148.88\n",
      "training :  9702  accuracy =   0.9400  loss =  151.334\n",
      "testing  :  9702  accuracy =   0.9672  loss =  148.919\n",
      "training :  9703  accuracy =   0.9800  loss =  147.605\n",
      "testing  :  9703  accuracy =   0.9667  loss =  148.936\n",
      "training :  9704  accuracy =   0.9900  loss =  147.432\n",
      "testing  :  9704  accuracy =   0.9670  loss =  148.943\n",
      "training :  9705  accuracy =   0.9800  loss =  148.126\n",
      "testing  :  9705  accuracy =   0.9672  loss =  148.947\n",
      "training :  9706  accuracy =   0.9800  loss =  147.391\n",
      "testing  :  9706  accuracy =   0.9674  loss =  148.944\n",
      "training :  9707  accuracy =   1.0000  loss =  146.309\n",
      "testing  :  9707  accuracy =   0.9676  loss =  148.936\n",
      "training :  9708  accuracy =   0.9800  loss =  147.436\n",
      "testing  :  9708  accuracy =   0.9676  loss =  148.933\n",
      "training :  9709  accuracy =   0.9900  loss =  147.308\n",
      "testing  :  9709  accuracy =   0.9675  loss =  148.931\n",
      "training :  9710  accuracy =   0.9600  loss =  149.536\n",
      "testing  :  9710  accuracy =   0.9678  loss =  148.875\n",
      "training :  9711  accuracy =   0.9900  loss =  146.287\n",
      "testing  :  9711  accuracy =   0.9681  loss =  148.846\n",
      "training :  9712  accuracy =   0.9900  loss =  147.345\n",
      "testing  :  9712  accuracy =   0.9679  loss =  148.855\n",
      "training :  9713  accuracy =   0.9900  loss =  146.602\n",
      "testing  :  9713  accuracy =   0.9676  loss =  148.894\n",
      "training :  9714  accuracy =   0.9900  loss =  147.253\n",
      "testing  :  9714  accuracy =   0.9672  loss =  148.938\n",
      "training :  9715  accuracy =   0.9700  loss =  148.293\n",
      "testing  :  9715  accuracy =   0.9668  loss =  148.994\n",
      "training :  9716  accuracy =   0.9800  loss =  148.337\n",
      "testing  :  9716  accuracy =   0.9662  loss =  149.046\n",
      "training :  9717  accuracy =   0.9900  loss =  147.157\n",
      "testing  :  9717  accuracy =   0.9645  loss =  149.105\n",
      "training :  9718  accuracy =   0.9700  loss =  148.693\n",
      "testing  :  9718  accuracy =   0.9639  loss =  149.163\n",
      "training :  9719  accuracy =   0.9800  loss =  147.422\n",
      "testing  :  9719  accuracy =   0.9634  loss =  149.212\n",
      "training :  9720  accuracy =   1.0000  loss =  146.317\n",
      "testing  :  9720  accuracy =   0.9632  loss =  149.261\n",
      "training :  9721  accuracy =   0.9500  loss =  149.753\n",
      "testing  :  9721  accuracy =   0.9627  loss =  149.298\n",
      "training :  9722  accuracy =   0.9600  loss =  148.395\n",
      "testing  :  9722  accuracy =   0.9626  loss =  149.295\n",
      "training :  9723  accuracy =   0.9900  loss =  146.345\n",
      "testing  :  9723  accuracy =   0.9624  loss =  149.287\n",
      "training :  9724  accuracy =   0.9800  loss =  148.09\n",
      "testing  :  9724  accuracy =   0.9628  loss =  149.281\n",
      "training :  9725  accuracy =   1.0000  loss =  146.319\n",
      "testing  :  9725  accuracy =   0.9629  loss =  149.265\n",
      "training :  9726  accuracy =   1.0000  loss =  146.169\n",
      "testing  :  9726  accuracy =   0.9634  loss =  149.246\n",
      "training :  9727  accuracy =   0.9900  loss =  146.625\n",
      "testing  :  9727  accuracy =   0.9632  loss =  149.233\n",
      "training :  9728  accuracy =   0.9600  loss =  149.646\n",
      "testing  :  9728  accuracy =   0.9640  loss =  149.217\n",
      "training :  9729  accuracy =   0.9800  loss =  147.78\n",
      "testing  :  9729  accuracy =   0.9641  loss =  149.203\n",
      "training :  9730  accuracy =   0.9900  loss =  147.112\n",
      "testing  :  9730  accuracy =   0.9644  loss =  149.178\n",
      "training :  9731  accuracy =   0.9900  loss =  147.154\n",
      "testing  :  9731  accuracy =   0.9651  loss =  149.154\n",
      "training :  9732  accuracy =   0.9900  loss =  147.42\n",
      "testing  :  9732  accuracy =   0.9655  loss =  149.14\n",
      "training :  9733  accuracy =   0.9700  loss =  148.982\n",
      "testing  :  9733  accuracy =   0.9658  loss =  149.118\n",
      "training :  9734  accuracy =   0.9700  loss =  149.364\n",
      "testing  :  9734  accuracy =   0.9666  loss =  149.086\n",
      "training :  9735  accuracy =   0.9800  loss =  147.56\n",
      "testing  :  9735  accuracy =   0.9667  loss =  149.059\n",
      "training :  9736  accuracy =   0.9900  loss =  147.721\n",
      "testing  :  9736  accuracy =   0.9664  loss =  149.02\n",
      "training :  9737  accuracy =   0.9700  loss =  148.699\n",
      "testing  :  9737  accuracy =   0.9670  loss =  148.985\n",
      "training :  9738  accuracy =   0.9700  loss =  149.161\n",
      "testing  :  9738  accuracy =   0.9672  loss =  148.979\n",
      "training :  9739  accuracy =   0.9600  loss =  149.98\n",
      "testing  :  9739  accuracy =   0.9672  loss =  148.957\n",
      "training :  9740  accuracy =   0.9900  loss =  146.623\n",
      "testing  :  9740  accuracy =   0.9662  loss =  148.942\n",
      "training :  9741  accuracy =   0.9600  loss =  148.869\n",
      "testing  :  9741  accuracy =   0.9662  loss =  148.943\n",
      "training :  9742  accuracy =   0.9700  loss =  148.494\n",
      "testing  :  9742  accuracy =   0.9666  loss =  148.931\n",
      "training :  9743  accuracy =   1.0000  loss =  146.383\n",
      "testing  :  9743  accuracy =   0.9667  loss =  148.922\n",
      "training :  9744  accuracy =   0.9900  loss =  147.633\n",
      "testing  :  9744  accuracy =   0.9670  loss =  148.913\n",
      "training :  9745  accuracy =   0.9900  loss =  147.159\n",
      "testing  :  9745  accuracy =   0.9668  loss =  148.903\n",
      "training :  9746  accuracy =   0.9800  loss =  147.039\n",
      "testing  :  9746  accuracy =   0.9663  loss =  148.902\n",
      "training :  9747  accuracy =   0.9800  loss =  148.341\n",
      "testing  :  9747  accuracy =   0.9668  loss =  148.901\n",
      "training :  9748  accuracy =   0.9900  loss =  147.269\n",
      "testing  :  9748  accuracy =   0.9669  loss =  148.905\n",
      "training :  9749  accuracy =   1.0000  loss =  146.24\n",
      "testing  :  9749  accuracy =   0.9666  loss =  148.913\n",
      "training :  9750  accuracy =   1.0000  loss =  146.179\n",
      "testing  :  9750  accuracy =   0.9667  loss =  148.917\n",
      "training :  9751  accuracy =   0.9900  loss =  146.415\n",
      "testing  :  9751  accuracy =   0.9666  loss =  148.92\n",
      "training :  9752  accuracy =   0.9700  loss =  149.256\n",
      "testing  :  9752  accuracy =   0.9665  loss =  148.927\n",
      "training :  9753  accuracy =   0.9800  loss =  148.199\n",
      "testing  :  9753  accuracy =   0.9665  loss =  148.93\n",
      "training :  9754  accuracy =   1.0000  loss =  146.275\n",
      "testing  :  9754  accuracy =   0.9663  loss =  148.937\n",
      "training :  9755  accuracy =   0.9800  loss =  146.766\n",
      "testing  :  9755  accuracy =   0.9666  loss =  148.94\n",
      "training :  9756  accuracy =   0.9600  loss =  150.274\n",
      "testing  :  9756  accuracy =   0.9664  loss =  148.95\n",
      "training :  9757  accuracy =   1.0000  loss =  146.333\n",
      "testing  :  9757  accuracy =   0.9663  loss =  148.935\n",
      "training :  9758  accuracy =   0.9900  loss =  146.598\n",
      "testing  :  9758  accuracy =   0.9664  loss =  148.949\n",
      "training :  9759  accuracy =   0.9800  loss =  147.759\n",
      "testing  :  9759  accuracy =   0.9660  loss =  148.983\n",
      "training :  9760  accuracy =   0.9800  loss =  147.3\n",
      "testing  :  9760  accuracy =   0.9660  loss =  149.003\n",
      "training :  9761  accuracy =   0.9600  loss =  148.828\n",
      "testing  :  9761  accuracy =   0.9668  loss =  148.974\n",
      "training :  9762  accuracy =   0.9800  loss =  147.513\n",
      "testing  :  9762  accuracy =   0.9665  loss =  148.914\n",
      "training :  9763  accuracy =   0.9800  loss =  147.696\n",
      "testing  :  9763  accuracy =   0.9673  loss =  148.894\n",
      "training :  9764  accuracy =   0.9700  loss =  148.183\n",
      "testing  :  9764  accuracy =   0.9674  loss =  148.878\n",
      "training :  9765  accuracy =   0.9900  loss =  147.277\n",
      "testing  :  9765  accuracy =   0.9680  loss =  148.876\n",
      "training :  9766  accuracy =   0.9500  loss =  149.039\n",
      "testing  :  9766  accuracy =   0.9670  loss =  148.884\n",
      "training :  9767  accuracy =   0.9900  loss =  146.769\n",
      "testing  :  9767  accuracy =   0.9661  loss =  148.88\n",
      "training :  9768  accuracy =   0.9400  loss =  150.419\n",
      "testing  :  9768  accuracy =   0.9659  loss =  148.901\n",
      "training :  9769  accuracy =   0.9700  loss =  149.198\n",
      "testing  :  9769  accuracy =   0.9646  loss =  148.953\n",
      "training :  9770  accuracy =   0.9800  loss =  147.469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9770  accuracy =   0.9640  loss =  149.02\n",
      "training :  9771  accuracy =   0.9800  loss =  147.482\n",
      "testing  :  9771  accuracy =   0.9640  loss =  149.054\n",
      "training :  9772  accuracy =   0.9800  loss =  147.95\n",
      "testing  :  9772  accuracy =   0.9634  loss =  149.08\n",
      "training :  9773  accuracy =   0.9800  loss =  147.979\n",
      "testing  :  9773  accuracy =   0.9634  loss =  149.094\n",
      "training :  9774  accuracy =   0.9700  loss =  148.81\n",
      "testing  :  9774  accuracy =   0.9632  loss =  149.083\n",
      "training :  9775  accuracy =   0.9700  loss =  148.103\n",
      "testing  :  9775  accuracy =   0.9638  loss =  149.076\n",
      "training :  9776  accuracy =   0.9500  loss =  149.395\n",
      "testing  :  9776  accuracy =   0.9647  loss =  149.065\n",
      "training :  9777  accuracy =   0.9800  loss =  148.664\n",
      "testing  :  9777  accuracy =   0.9655  loss =  149.005\n",
      "training :  9778  accuracy =   1.0000  loss =  146.307\n",
      "testing  :  9778  accuracy =   0.9662  loss =  148.969\n",
      "training :  9779  accuracy =   1.0000  loss =  146.458\n",
      "testing  :  9779  accuracy =   0.9672  loss =  148.955\n",
      "training :  9780  accuracy =   0.9900  loss =  146.368\n",
      "testing  :  9780  accuracy =   0.9678  loss =  148.951\n",
      "training :  9781  accuracy =   0.9600  loss =  147.826\n",
      "testing  :  9781  accuracy =   0.9678  loss =  148.952\n",
      "training :  9782  accuracy =   0.9800  loss =  148.557\n",
      "testing  :  9782  accuracy =   0.9680  loss =  148.955\n",
      "training :  9783  accuracy =   0.9700  loss =  147.716\n",
      "testing  :  9783  accuracy =   0.9682  loss =  148.936\n",
      "training :  9784  accuracy =   0.9900  loss =  146.43\n",
      "testing  :  9784  accuracy =   0.9683  loss =  148.905\n",
      "training :  9785  accuracy =   1.0000  loss =  146.379\n",
      "testing  :  9785  accuracy =   0.9687  loss =  148.881\n",
      "training :  9786  accuracy =   0.9900  loss =  146.539\n",
      "testing  :  9786  accuracy =   0.9691  loss =  148.856\n",
      "training :  9787  accuracy =   0.9900  loss =  146.484\n",
      "testing  :  9787  accuracy =   0.9689  loss =  148.814\n",
      "training :  9788  accuracy =   0.9800  loss =  147.826\n",
      "testing  :  9788  accuracy =   0.9685  loss =  148.787\n",
      "training :  9789  accuracy =   0.9900  loss =  147.56\n",
      "testing  :  9789  accuracy =   0.9693  loss =  148.756\n",
      "training :  9790  accuracy =   0.9900  loss =  146.741\n",
      "testing  :  9790  accuracy =   0.9682  loss =  148.747\n",
      "training :  9791  accuracy =   0.9900  loss =  147.405\n",
      "testing  :  9791  accuracy =   0.9690  loss =  148.732\n",
      "training :  9792  accuracy =   0.9600  loss =  148.834\n",
      "testing  :  9792  accuracy =   0.9689  loss =  148.731\n",
      "training :  9793  accuracy =   0.9900  loss =  146.396\n",
      "testing  :  9793  accuracy =   0.9691  loss =  148.725\n",
      "training :  9794  accuracy =   0.9800  loss =  148.124\n",
      "testing  :  9794  accuracy =   0.9685  loss =  148.726\n",
      "training :  9795  accuracy =   0.9900  loss =  147.217\n",
      "testing  :  9795  accuracy =   0.9693  loss =  148.701\n",
      "training :  9796  accuracy =   0.9900  loss =  147.226\n",
      "testing  :  9796  accuracy =   0.9693  loss =  148.667\n",
      "training :  9797  accuracy =   0.9900  loss =  146.429\n",
      "testing  :  9797  accuracy =   0.9693  loss =  148.649\n",
      "training :  9798  accuracy =   1.0000  loss =  146.368\n",
      "testing  :  9798  accuracy =   0.9694  loss =  148.64\n",
      "training :  9799  accuracy =   1.0000  loss =  146.415\n",
      "testing  :  9799  accuracy =   0.9690  loss =  148.641\n",
      "training :  9800  accuracy =   1.0000  loss =  146.159\n",
      "testing  :  9800  accuracy =   0.9691  loss =  148.648\n",
      "training :  9801  accuracy =   0.9600  loss =  149.815\n",
      "testing  :  9801  accuracy =   0.9690  loss =  148.66\n",
      "training :  9802  accuracy =   0.9800  loss =  148.743\n",
      "testing  :  9802  accuracy =   0.9693  loss =  148.658\n",
      "training :  9803  accuracy =   0.9800  loss =  147.017\n",
      "testing  :  9803  accuracy =   0.9693  loss =  148.659\n",
      "training :  9804  accuracy =   1.0000  loss =  146.404\n",
      "testing  :  9804  accuracy =   0.9692  loss =  148.661\n",
      "training :  9805  accuracy =   1.0000  loss =  146.383\n",
      "testing  :  9805  accuracy =   0.9695  loss =  148.667\n",
      "training :  9806  accuracy =   0.9700  loss =  149.109\n",
      "testing  :  9806  accuracy =   0.9694  loss =  148.674\n",
      "training :  9807  accuracy =   0.9900  loss =  147.265\n",
      "testing  :  9807  accuracy =   0.9695  loss =  148.681\n",
      "training :  9808  accuracy =   0.9900  loss =  146.534\n",
      "testing  :  9808  accuracy =   0.9695  loss =  148.693\n",
      "training :  9809  accuracy =   0.9900  loss =  147.199\n",
      "testing  :  9809  accuracy =   0.9695  loss =  148.706\n",
      "training :  9810  accuracy =   1.0000  loss =  146.222\n",
      "testing  :  9810  accuracy =   0.9692  loss =  148.721\n",
      "training :  9811  accuracy =   1.0000  loss =  146.276\n",
      "testing  :  9811  accuracy =   0.9692  loss =  148.739\n",
      "training :  9812  accuracy =   0.9800  loss =  147.539\n",
      "testing  :  9812  accuracy =   0.9688  loss =  148.755\n",
      "training :  9813  accuracy =   0.9800  loss =  147.463\n",
      "testing  :  9813  accuracy =   0.9687  loss =  148.772\n",
      "training :  9814  accuracy =   0.9800  loss =  147.422\n",
      "testing  :  9814  accuracy =   0.9683  loss =  148.781\n",
      "training :  9815  accuracy =   0.9700  loss =  147.681\n",
      "testing  :  9815  accuracy =   0.9680  loss =  148.76\n",
      "training :  9816  accuracy =   0.9800  loss =  147.401\n",
      "testing  :  9816  accuracy =   0.9678  loss =  148.747\n",
      "training :  9817  accuracy =   1.0000  loss =  146.44\n",
      "testing  :  9817  accuracy =   0.9682  loss =  148.733\n",
      "training :  9818  accuracy =   0.9800  loss =  148.396\n",
      "testing  :  9818  accuracy =   0.9680  loss =  148.722\n",
      "training :  9819  accuracy =   1.0000  loss =  146.274\n",
      "testing  :  9819  accuracy =   0.9677  loss =  148.717\n",
      "training :  9820  accuracy =   0.9900  loss =  147.185\n",
      "testing  :  9820  accuracy =   0.9675  loss =  148.714\n",
      "training :  9821  accuracy =   1.0000  loss =  146.429\n",
      "testing  :  9821  accuracy =   0.9681  loss =  148.709\n",
      "training :  9822  accuracy =   0.9800  loss =  148.102\n",
      "testing  :  9822  accuracy =   0.9683  loss =  148.706\n",
      "training :  9823  accuracy =   0.9900  loss =  146.512\n",
      "testing  :  9823  accuracy =   0.9684  loss =  148.703\n",
      "training :  9824  accuracy =   0.9800  loss =  146.847\n",
      "testing  :  9824  accuracy =   0.9689  loss =  148.697\n",
      "training :  9825  accuracy =   0.9800  loss =  147.379\n",
      "testing  :  9825  accuracy =   0.9688  loss =  148.69\n",
      "training :  9826  accuracy =   0.9900  loss =  146.606\n",
      "testing  :  9826  accuracy =   0.9692  loss =  148.677\n",
      "training :  9827  accuracy =   0.9400  loss =  151.473\n",
      "testing  :  9827  accuracy =   0.9692  loss =  148.66\n",
      "training :  9828  accuracy =   0.9800  loss =  147.376\n",
      "testing  :  9828  accuracy =   0.9696  loss =  148.644\n",
      "training :  9829  accuracy =   0.9300  loss =  151.207\n",
      "testing  :  9829  accuracy =   0.9697  loss =  148.639\n",
      "training :  9830  accuracy =   0.9900  loss =  146.633\n",
      "testing  :  9830  accuracy =   0.9701  loss =  148.646\n",
      "training :  9831  accuracy =   0.9700  loss =  147.764\n",
      "testing  :  9831  accuracy =   0.9708  loss =  148.648\n",
      "training :  9832  accuracy =   1.0000  loss =  146.509\n",
      "testing  :  9832  accuracy =   0.9711  loss =  148.65\n",
      "training :  9833  accuracy =   0.9900  loss =  147.59\n",
      "testing  :  9833  accuracy =   0.9710  loss =  148.653\n",
      "training :  9834  accuracy =   1.0000  loss =  146.615\n",
      "testing  :  9834  accuracy =   0.9706  loss =  148.658\n",
      "training :  9835  accuracy =   0.9800  loss =  146.738\n",
      "testing  :  9835  accuracy =   0.9705  loss =  148.66\n",
      "training :  9836  accuracy =   0.9800  loss =  147.584\n",
      "testing  :  9836  accuracy =   0.9703  loss =  148.667\n",
      "training :  9837  accuracy =   0.9900  loss =  146.549\n",
      "testing  :  9837  accuracy =   0.9702  loss =  148.675\n",
      "training :  9838  accuracy =   1.0000  loss =  146.421\n",
      "testing  :  9838  accuracy =   0.9705  loss =  148.685\n",
      "training :  9839  accuracy =   0.9900  loss =  147.28\n",
      "testing  :  9839  accuracy =   0.9703  loss =  148.694\n",
      "training :  9840  accuracy =   0.9900  loss =  146.871\n",
      "testing  :  9840  accuracy =   0.9697  loss =  148.701\n",
      "training :  9841  accuracy =   0.9700  loss =  149.436\n",
      "testing  :  9841  accuracy =   0.9699  loss =  148.721\n",
      "training :  9842  accuracy =   0.9800  loss =  148.225\n",
      "testing  :  9842  accuracy =   0.9697  loss =  148.726\n",
      "training :  9843  accuracy =   0.9900  loss =  147.199\n",
      "testing  :  9843  accuracy =   0.9690  loss =  148.743\n",
      "training :  9844  accuracy =   0.9700  loss =  147.886\n",
      "testing  :  9844  accuracy =   0.9685  loss =  148.831\n",
      "training :  9845  accuracy =   0.9900  loss =  147.502\n",
      "testing  :  9845  accuracy =   0.9681  loss =  148.87\n",
      "training :  9846  accuracy =   0.9800  loss =  147.559\n",
      "testing  :  9846  accuracy =   0.9676  loss =  148.892\n",
      "training :  9847  accuracy =   0.9900  loss =  146.787\n",
      "testing  :  9847  accuracy =   0.9679  loss =  148.856\n",
      "training :  9848  accuracy =   1.0000  loss =  146.157\n",
      "testing  :  9848  accuracy =   0.9683  loss =  148.817\n",
      "training :  9849  accuracy =   0.9900  loss =  147.057\n",
      "testing  :  9849  accuracy =   0.9678  loss =  148.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training :  9850  accuracy =   0.9900  loss =  147.346\n",
      "testing  :  9850  accuracy =   0.9681  loss =  148.766\n",
      "training :  9851  accuracy =   0.9800  loss =  147.353\n",
      "testing  :  9851  accuracy =   0.9678  loss =  148.764\n",
      "training :  9852  accuracy =   0.9900  loss =  147.091\n",
      "testing  :  9852  accuracy =   0.9676  loss =  148.765\n",
      "training :  9853  accuracy =   0.9600  loss =  148.958\n",
      "testing  :  9853  accuracy =   0.9672  loss =  148.781\n",
      "training :  9854  accuracy =   1.0000  loss =  146.418\n",
      "testing  :  9854  accuracy =   0.9664  loss =  148.781\n",
      "training :  9855  accuracy =   1.0000  loss =  146.351\n",
      "testing  :  9855  accuracy =   0.9661  loss =  148.8\n",
      "training :  9856  accuracy =   0.9900  loss =  146.678\n",
      "testing  :  9856  accuracy =   0.9658  loss =  148.823\n",
      "training :  9857  accuracy =   0.9600  loss =  149.337\n",
      "testing  :  9857  accuracy =   0.9651  loss =  148.844\n",
      "training :  9858  accuracy =   0.9900  loss =  147.638\n",
      "testing  :  9858  accuracy =   0.9654  loss =  148.799\n",
      "training :  9859  accuracy =   1.0000  loss =  146.428\n",
      "testing  :  9859  accuracy =   0.9659  loss =  148.77\n",
      "training :  9860  accuracy =   0.9800  loss =  147.579\n",
      "testing  :  9860  accuracy =   0.9663  loss =  148.743\n",
      "training :  9861  accuracy =   0.9800  loss =  147.504\n",
      "testing  :  9861  accuracy =   0.9669  loss =  148.722\n",
      "training :  9862  accuracy =   0.9800  loss =  147.223\n",
      "testing  :  9862  accuracy =   0.9679  loss =  148.714\n",
      "training :  9863  accuracy =   0.9900  loss =  147.455\n",
      "testing  :  9863  accuracy =   0.9686  loss =  148.701\n",
      "training :  9864  accuracy =   0.9800  loss =  147.041\n",
      "testing  :  9864  accuracy =   0.9695  loss =  148.695\n",
      "training :  9865  accuracy =   0.9900  loss =  146.287\n",
      "testing  :  9865  accuracy =   0.9695  loss =  148.682\n",
      "training :  9866  accuracy =   1.0000  loss =  146.167\n",
      "testing  :  9866  accuracy =   0.9695  loss =  148.672\n",
      "training :  9867  accuracy =   0.9900  loss =  147.343\n",
      "testing  :  9867  accuracy =   0.9696  loss =  148.667\n",
      "training :  9868  accuracy =   1.0000  loss =  146.134\n",
      "testing  :  9868  accuracy =   0.9698  loss =  148.673\n",
      "training :  9869  accuracy =   0.9900  loss =  146.38\n",
      "testing  :  9869  accuracy =   0.9691  loss =  148.686\n",
      "training :  9870  accuracy =   0.9900  loss =  147.475\n",
      "testing  :  9870  accuracy =   0.9688  loss =  148.701\n",
      "training :  9871  accuracy =   1.0000  loss =  146.313\n",
      "testing  :  9871  accuracy =   0.9679  loss =  148.716\n",
      "training :  9872  accuracy =   1.0000  loss =  146.224\n",
      "testing  :  9872  accuracy =   0.9681  loss =  148.733\n",
      "training :  9873  accuracy =   0.9800  loss =  146.744\n",
      "testing  :  9873  accuracy =   0.9679  loss =  148.755\n",
      "training :  9874  accuracy =   0.9800  loss =  147.634\n",
      "testing  :  9874  accuracy =   0.9673  loss =  148.774\n",
      "training :  9875  accuracy =   0.9900  loss =  147.085\n",
      "testing  :  9875  accuracy =   0.9671  loss =  148.757\n",
      "training :  9876  accuracy =   0.9900  loss =  147.363\n",
      "testing  :  9876  accuracy =   0.9678  loss =  148.736\n",
      "training :  9877  accuracy =   0.9900  loss =  146.303\n",
      "testing  :  9877  accuracy =   0.9678  loss =  148.728\n",
      "training :  9878  accuracy =   1.0000  loss =  146.163\n",
      "testing  :  9878  accuracy =   0.9679  loss =  148.731\n",
      "training :  9879  accuracy =   0.9700  loss =  148.615\n",
      "testing  :  9879  accuracy =   0.9683  loss =  148.738\n",
      "training :  9880  accuracy =   0.9800  loss =  148.896\n",
      "testing  :  9880  accuracy =   0.9680  loss =  148.745\n",
      "training :  9881  accuracy =   0.9800  loss =  147.475\n",
      "testing  :  9881  accuracy =   0.9682  loss =  148.73\n",
      "training :  9882  accuracy =   1.0000  loss =  146.447\n",
      "testing  :  9882  accuracy =   0.9687  loss =  148.713\n",
      "training :  9883  accuracy =   1.0000  loss =  146.141\n",
      "testing  :  9883  accuracy =   0.9685  loss =  148.703\n",
      "training :  9884  accuracy =   0.9800  loss =  147.982\n",
      "testing  :  9884  accuracy =   0.9687  loss =  148.698\n",
      "training :  9885  accuracy =   1.0000  loss =  146.258\n",
      "testing  :  9885  accuracy =   0.9691  loss =  148.673\n",
      "training :  9886  accuracy =   0.9700  loss =  148.686\n",
      "testing  :  9886  accuracy =   0.9694  loss =  148.655\n",
      "training :  9887  accuracy =   0.9800  loss =  148.227\n",
      "testing  :  9887  accuracy =   0.9701  loss =  148.637\n",
      "training :  9888  accuracy =   1.0000  loss =  146.359\n",
      "testing  :  9888  accuracy =   0.9701  loss =  148.656\n",
      "training :  9889  accuracy =   0.9800  loss =  147.547\n",
      "testing  :  9889  accuracy =   0.9700  loss =  148.662\n",
      "training :  9890  accuracy =   0.9900  loss =  147.419\n",
      "testing  :  9890  accuracy =   0.9700  loss =  148.666\n",
      "training :  9891  accuracy =   1.0000  loss =  146.396\n",
      "testing  :  9891  accuracy =   0.9694  loss =  148.673\n",
      "training :  9892  accuracy =   0.9800  loss =  148.774\n",
      "testing  :  9892  accuracy =   0.9694  loss =  148.682\n",
      "training :  9893  accuracy =   0.9900  loss =  146.583\n",
      "testing  :  9893  accuracy =   0.9692  loss =  148.692\n",
      "training :  9894  accuracy =   0.9900  loss =  147.336\n",
      "testing  :  9894  accuracy =   0.9687  loss =  148.696\n",
      "training :  9895  accuracy =   0.9700  loss =  148.44\n",
      "testing  :  9895  accuracy =   0.9686  loss =  148.7\n",
      "training :  9896  accuracy =   1.0000  loss =  146.157\n",
      "testing  :  9896  accuracy =   0.9686  loss =  148.705\n",
      "training :  9897  accuracy =   0.9600  loss =  148.094\n",
      "testing  :  9897  accuracy =   0.9688  loss =  148.714\n",
      "training :  9898  accuracy =   0.9900  loss =  147.258\n",
      "testing  :  9898  accuracy =   0.9686  loss =  148.695\n",
      "training :  9899  accuracy =   0.9900  loss =  147.205\n",
      "testing  :  9899  accuracy =   0.9688  loss =  148.679\n",
      "training :  9900  accuracy =   1.0000  loss =  146.314\n",
      "testing  :  9900  accuracy =   0.9692  loss =  148.66\n",
      "training :  9901  accuracy =   1.0000  loss =  146.377\n",
      "testing  :  9901  accuracy =   0.9697  loss =  148.643\n",
      "training :  9902  accuracy =   1.0000  loss =  146.355\n",
      "testing  :  9902  accuracy =   0.9700  loss =  148.631\n",
      "training :  9903  accuracy =   0.9900  loss =  146.363\n",
      "testing  :  9903  accuracy =   0.9705  loss =  148.618\n",
      "training :  9904  accuracy =   0.9900  loss =  146.621\n",
      "testing  :  9904  accuracy =   0.9703  loss =  148.608\n",
      "training :  9905  accuracy =   0.9800  loss =  147.795\n",
      "testing  :  9905  accuracy =   0.9704  loss =  148.598\n",
      "training :  9906  accuracy =   0.9800  loss =  148.262\n",
      "testing  :  9906  accuracy =   0.9706  loss =  148.579\n",
      "training :  9907  accuracy =   0.9900  loss =  147.235\n",
      "testing  :  9907  accuracy =   0.9706  loss =  148.572\n",
      "training :  9908  accuracy =   0.9600  loss =  150.324\n",
      "testing  :  9908  accuracy =   0.9707  loss =  148.575\n",
      "training :  9909  accuracy =   0.9700  loss =  148.098\n",
      "testing  :  9909  accuracy =   0.9706  loss =  148.578\n",
      "training :  9910  accuracy =   0.9800  loss =  148.29\n",
      "testing  :  9910  accuracy =   0.9708  loss =  148.562\n",
      "training :  9911  accuracy =   1.0000  loss =  146.432\n",
      "testing  :  9911  accuracy =   0.9709  loss =  148.553\n",
      "training :  9912  accuracy =   0.9900  loss =  147.005\n",
      "testing  :  9912  accuracy =   0.9716  loss =  148.552\n",
      "training :  9913  accuracy =   0.9900  loss =  146.802\n",
      "testing  :  9913  accuracy =   0.9717  loss =  148.553\n",
      "training :  9914  accuracy =   0.9800  loss =  148.246\n",
      "testing  :  9914  accuracy =   0.9706  loss =  148.562\n",
      "training :  9915  accuracy =   0.9800  loss =  148.369\n",
      "testing  :  9915  accuracy =   0.9708  loss =  148.591\n",
      "training :  9916  accuracy =   0.9900  loss =  146.702\n",
      "testing  :  9916  accuracy =   0.9700  loss =  148.65\n",
      "training :  9917  accuracy =   0.9900  loss =  146.7\n",
      "testing  :  9917  accuracy =   0.9696  loss =  148.706\n",
      "training :  9918  accuracy =   0.9700  loss =  148.528\n",
      "testing  :  9918  accuracy =   0.9680  loss =  148.766\n",
      "training :  9919  accuracy =   0.9700  loss =  148.303\n",
      "testing  :  9919  accuracy =   0.9671  loss =  148.847\n",
      "training :  9920  accuracy =   0.9800  loss =  147.542\n",
      "testing  :  9920  accuracy =   0.9663  loss =  148.935\n",
      "training :  9921  accuracy =   1.0000  loss =  146.172\n",
      "testing  :  9921  accuracy =   0.9663  loss =  149.006\n",
      "training :  9922  accuracy =   0.9900  loss =  147.063\n",
      "testing  :  9922  accuracy =   0.9656  loss =  149.064\n",
      "training :  9923  accuracy =   0.9800  loss =  148.219\n",
      "testing  :  9923  accuracy =   0.9652  loss =  149.07\n",
      "training :  9924  accuracy =   0.9700  loss =  148.467\n",
      "testing  :  9924  accuracy =   0.9653  loss =  149.06\n",
      "training :  9925  accuracy =   0.9800  loss =  147.537\n",
      "testing  :  9925  accuracy =   0.9656  loss =  149.025\n",
      "training :  9926  accuracy =   0.9700  loss =  148.007\n",
      "testing  :  9926  accuracy =   0.9662  loss =  148.982\n",
      "training :  9927  accuracy =   0.9700  loss =  147.478\n",
      "testing  :  9927  accuracy =   0.9667  loss =  148.925\n",
      "training :  9928  accuracy =   0.9800  loss =  147.515\n",
      "testing  :  9928  accuracy =   0.9683  loss =  148.813\n",
      "training :  9929  accuracy =   1.0000  loss =  146.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  9929  accuracy =   0.9697  loss =  148.707\n",
      "training :  9930  accuracy =   0.9800  loss =  146.763\n",
      "testing  :  9930  accuracy =   0.9711  loss =  148.647\n",
      "training :  9931  accuracy =   0.9900  loss =  147.592\n",
      "testing  :  9931  accuracy =   0.9712  loss =  148.591\n",
      "training :  9932  accuracy =   1.0000  loss =  146.398\n",
      "testing  :  9932  accuracy =   0.9715  loss =  148.579\n",
      "training :  9933  accuracy =   0.9600  loss =  148.151\n",
      "testing  :  9933  accuracy =   0.9708  loss =  148.59\n",
      "training :  9934  accuracy =   0.9800  loss =  147.454\n",
      "testing  :  9934  accuracy =   0.9709  loss =  148.568\n",
      "training :  9935  accuracy =   0.9900  loss =  147.176\n",
      "testing  :  9935  accuracy =   0.9705  loss =  148.611\n",
      "training :  9936  accuracy =   0.9700  loss =  148.606\n",
      "testing  :  9936  accuracy =   0.9690  loss =  148.703\n",
      "training :  9937  accuracy =   0.9600  loss =  149.563\n",
      "testing  :  9937  accuracy =   0.9681  loss =  148.846\n",
      "training :  9938  accuracy =   0.9800  loss =  147.485\n",
      "testing  :  9938  accuracy =   0.9669  loss =  148.969\n",
      "training :  9939  accuracy =   0.9900  loss =  147.421\n",
      "testing  :  9939  accuracy =   0.9648  loss =  149.092\n",
      "training :  9940  accuracy =   0.9700  loss =  148.605\n",
      "testing  :  9940  accuracy =   0.9629  loss =  149.22\n",
      "training :  9941  accuracy =   0.9600  loss =  148.205\n",
      "testing  :  9941  accuracy =   0.9616  loss =  149.342\n",
      "training :  9942  accuracy =   0.9800  loss =  147.705\n",
      "testing  :  9942  accuracy =   0.9609  loss =  149.382\n",
      "training :  9943  accuracy =   0.9700  loss =  148.792\n",
      "testing  :  9943  accuracy =   0.9608  loss =  149.355\n",
      "training :  9944  accuracy =   1.0000  loss =  146.33\n",
      "testing  :  9944  accuracy =   0.9617  loss =  149.28\n",
      "training :  9945  accuracy =   0.9800  loss =  147.782\n",
      "testing  :  9945  accuracy =   0.9623  loss =  149.233\n",
      "training :  9946  accuracy =   0.9800  loss =  148.516\n",
      "testing  :  9946  accuracy =   0.9625  loss =  149.162\n",
      "training :  9947  accuracy =   1.0000  loss =  146.135\n",
      "testing  :  9947  accuracy =   0.9634  loss =  149.114\n",
      "training :  9948  accuracy =   0.9600  loss =  149.551\n",
      "testing  :  9948  accuracy =   0.9639  loss =  149.09\n",
      "training :  9949  accuracy =   1.0000  loss =  146.303\n",
      "testing  :  9949  accuracy =   0.9643  loss =  149.055\n",
      "training :  9950  accuracy =   0.9800  loss =  147.329\n",
      "testing  :  9950  accuracy =   0.9642  loss =  149.038\n",
      "training :  9951  accuracy =   0.9900  loss =  146.782\n",
      "testing  :  9951  accuracy =   0.9645  loss =  149.025\n",
      "training :  9952  accuracy =   0.9900  loss =  146.366\n",
      "testing  :  9952  accuracy =   0.9649  loss =  149.002\n",
      "training :  9953  accuracy =   0.9900  loss =  147.603\n",
      "testing  :  9953  accuracy =   0.9658  loss =  148.99\n",
      "training :  9954  accuracy =   0.9700  loss =  148.395\n",
      "testing  :  9954  accuracy =   0.9662  loss =  148.978\n",
      "training :  9955  accuracy =   0.9800  loss =  148.206\n",
      "testing  :  9955  accuracy =   0.9668  loss =  148.968\n",
      "training :  9956  accuracy =   0.9800  loss =  148.467\n",
      "testing  :  9956  accuracy =   0.9673  loss =  148.939\n",
      "training :  9957  accuracy =   0.9800  loss =  147.538\n",
      "testing  :  9957  accuracy =   0.9676  loss =  148.901\n",
      "training :  9958  accuracy =   0.9800  loss =  147.056\n",
      "testing  :  9958  accuracy =   0.9679  loss =  148.868\n",
      "training :  9959  accuracy =   0.9900  loss =  146.954\n",
      "testing  :  9959  accuracy =   0.9688  loss =  148.817\n",
      "training :  9960  accuracy =   0.9900  loss =  147.393\n",
      "testing  :  9960  accuracy =   0.9689  loss =  148.751\n",
      "training :  9961  accuracy =   1.0000  loss =  146.264\n",
      "testing  :  9961  accuracy =   0.9692  loss =  148.699\n",
      "training :  9962  accuracy =   0.9900  loss =  147.133\n",
      "testing  :  9962  accuracy =   0.9699  loss =  148.662\n",
      "training :  9963  accuracy =   0.9800  loss =  148.195\n",
      "testing  :  9963  accuracy =   0.9701  loss =  148.636\n",
      "training :  9964  accuracy =   0.9800  loss =  148.444\n",
      "testing  :  9964  accuracy =   0.9700  loss =  148.621\n",
      "training :  9965  accuracy =   0.9800  loss =  147.314\n",
      "testing  :  9965  accuracy =   0.9705  loss =  148.613\n",
      "training :  9966  accuracy =   0.9900  loss =  147.131\n",
      "testing  :  9966  accuracy =   0.9703  loss =  148.607\n",
      "training :  9967  accuracy =   0.9900  loss =  146.437\n",
      "testing  :  9967  accuracy =   0.9703  loss =  148.608\n",
      "training :  9968  accuracy =   0.9900  loss =  147.227\n",
      "testing  :  9968  accuracy =   0.9707  loss =  148.606\n",
      "training :  9969  accuracy =   1.0000  loss =  146.144\n",
      "testing  :  9969  accuracy =   0.9704  loss =  148.605\n",
      "training :  9970  accuracy =   0.9800  loss =  147.722\n",
      "testing  :  9970  accuracy =   0.9707  loss =  148.603\n",
      "training :  9971  accuracy =   1.0000  loss =  146.412\n",
      "testing  :  9971  accuracy =   0.9707  loss =  148.6\n",
      "training :  9972  accuracy =   0.9900  loss =  147.157\n",
      "testing  :  9972  accuracy =   0.9705  loss =  148.6\n",
      "training :  9973  accuracy =   0.9900  loss =  146.338\n",
      "testing  :  9973  accuracy =   0.9705  loss =  148.603\n",
      "training :  9974  accuracy =   0.9600  loss =  149.663\n",
      "testing  :  9974  accuracy =   0.9700  loss =  148.616\n",
      "training :  9975  accuracy =   1.0000  loss =  146.144\n",
      "testing  :  9975  accuracy =   0.9697  loss =  148.631\n",
      "training :  9976  accuracy =   1.0000  loss =  146.325\n",
      "testing  :  9976  accuracy =   0.9700  loss =  148.651\n",
      "training :  9977  accuracy =   0.9900  loss =  146.664\n",
      "testing  :  9977  accuracy =   0.9696  loss =  148.672\n",
      "training :  9978  accuracy =   0.9800  loss =  147.328\n",
      "testing  :  9978  accuracy =   0.9701  loss =  148.694\n",
      "training :  9979  accuracy =   0.9800  loss =  147.429\n",
      "testing  :  9979  accuracy =   0.9690  loss =  148.708\n",
      "training :  9980  accuracy =   0.9600  loss =  149.117\n",
      "testing  :  9980  accuracy =   0.9692  loss =  148.726\n",
      "training :  9981  accuracy =   0.9800  loss =  148.173\n",
      "testing  :  9981  accuracy =   0.9689  loss =  148.733\n",
      "training :  9982  accuracy =   0.9700  loss =  149.213\n",
      "testing  :  9982  accuracy =   0.9682  loss =  148.816\n",
      "training :  9983  accuracy =   1.0000  loss =  146.381\n",
      "testing  :  9983  accuracy =   0.9671  loss =  148.924\n",
      "training :  9984  accuracy =   1.0000  loss =  146.42\n",
      "testing  :  9984  accuracy =   0.9656  loss =  149.047\n",
      "training :  9985  accuracy =   0.9800  loss =  147.071\n",
      "testing  :  9985  accuracy =   0.9633  loss =  149.164\n",
      "training :  9986  accuracy =   0.9700  loss =  148.223\n",
      "testing  :  9986  accuracy =   0.9629  loss =  149.187\n",
      "training :  9987  accuracy =   0.9800  loss =  148.616\n",
      "testing  :  9987  accuracy =   0.9622  loss =  149.182\n",
      "training :  9988  accuracy =   0.9900  loss =  146.772\n",
      "testing  :  9988  accuracy =   0.9617  loss =  149.201\n",
      "training :  9989  accuracy =   0.9900  loss =  147.365\n",
      "testing  :  9989  accuracy =   0.9617  loss =  149.201\n",
      "training :  9990  accuracy =   0.9500  loss =  149.422\n",
      "testing  :  9990  accuracy =   0.9618  loss =  149.185\n",
      "training :  9991  accuracy =   0.9900  loss =  148.033\n",
      "testing  :  9991  accuracy =   0.9640  loss =  149.096\n",
      "training :  9992  accuracy =   0.9800  loss =  148.46\n",
      "testing  :  9992  accuracy =   0.9656  loss =  149.016\n",
      "training :  9993  accuracy =   0.9800  loss =  147.502\n",
      "testing  :  9993  accuracy =   0.9672  loss =  148.951\n",
      "training :  9994  accuracy =   0.9800  loss =  147.347\n",
      "testing  :  9994  accuracy =   0.9682  loss =  148.907\n",
      "training :  9995  accuracy =   0.9700  loss =  148.307\n",
      "testing  :  9995  accuracy =   0.9683  loss =  148.877\n",
      "training :  9996  accuracy =   0.9800  loss =  147.813\n",
      "testing  :  9996  accuracy =   0.9684  loss =  148.859\n",
      "training :  9997  accuracy =   0.9800  loss =  148.381\n",
      "testing  :  9997  accuracy =   0.9687  loss =  148.826\n",
      "training :  9998  accuracy =   0.9900  loss =  146.736\n",
      "testing  :  9998  accuracy =   0.9689  loss =  148.793\n",
      "training :  9999  accuracy =   0.9700  loss =  149.457\n",
      "testing  :  9999  accuracy =   0.9685  loss =  148.767\n",
      "training :  10000  accuracy =   0.9700  loss =  146.876\n",
      "testing  :  10000  accuracy =   0.9686  loss =  148.752\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e4c8d73f28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e4c9307cf8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encoding: UTF-8\n",
    "# original source : https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd/tree/master/tensorflow-mnist-tutorial\n",
    "# 2018.12 : modified by Seungkwon Lee(kahnlee@naver.com)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflowvisu\n",
    "import mnistdata\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "# neural network with 5 layers\n",
    "#\n",
    "# · · · · · · · · · ·          (input data, flattened pixels)       X [batch, 784]   # 784 = 28*28\n",
    "# \\x/x\\x/x\\x/x\\x/x\\x/       -- fully connected layer (sigmoid)      W1 [784, 200]      B1[200]\n",
    "#  · · · · · · · · ·                                                Y1 [batch, 200]\n",
    "#   \\x/x\\x/x\\x/x\\x/         -- fully connected layer (sigmoid)      W2 [200, 100]      B2[100]\n",
    "#    · · · · · · ·                                                  Y2 [batch, 100]\n",
    "#     \\x/x\\x/x\\x/           -- fully connected layer (sigmoid)      W3 [100, 60]       B3[60]\n",
    "#      · · · · ·                                                    Y3 [batch, 60]\n",
    "#       \\x/x\\x/             -- fully connected layer (sigmoid)      W4 [60, 30]        B4[30]\n",
    "#        · · ·                                                      Y4 [batch, 30]\n",
    "#         \\x/               -- fully connected layer (softmax)      W5 [30, 10]        B5[10]\n",
    "#          ·                                                        Y5 [batch, 10]\n",
    "\n",
    "# Download images and labels into mnist.test (10K images+labels) and mnist.train (60K images+labels)\n",
    "mnist = mnistdata.read_data_sets(\"data\", one_hot=True, reshape=False)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep = 3)\n",
    "\n",
    "# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "# correct answers will go here\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#neuron 개수\n",
    "# five layers and their number of neurons (tha last layer has 10 softmax neurons)\n",
    "L = 200\n",
    "M = 100\n",
    "N = 60\n",
    "O = 30\n",
    "# Weights initialised with small random values between -0.2 and +0.2\n",
    "# When using RELUs, make sure biases are initialised with small *positive* values for example 0.1 = tf.ones([K])/10\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1))  # 784 = 28 * 28\n",
    "B1 = tf.Variable(tf.zeros([L]))\n",
    "W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "B2 = tf.Variable(tf.zeros([M]))\n",
    "W3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\n",
    "B3 = tf.Variable(tf.zeros([N]))\n",
    "W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))\n",
    "B4 = tf.Variable(tf.zeros([O]))\n",
    "W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# The model\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "Y1 = tf.nn.sigmoid(tf.matmul(XX, W1) + B1)\n",
    "Y2 = tf.nn.sigmoid(tf.matmul(Y1, W2) + B2)\n",
    "Y3 = tf.nn.sigmoid(tf.matmul(Y2, W3) + B3)\n",
    "Y4 = tf.nn.sigmoid(tf.matmul(Y3, W4) + B4)\n",
    "Ylogits = tf.nn.sigmoid(tf.matmul(Y4, W5) + B5)\n",
    "Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "# cross-entropy loss function (= -sum(Y_i * log(Yi)) ), normalised for batches of 100  images\n",
    "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
    "# problems with log(0) which is NaN\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "# training step, learning rate = 0.003\n",
    "learning_rate = 0.003\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "# run\n",
    "for i in range(10000 + 1) :\n",
    "\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
    "    a, c = sess.run([accuracy, cross_entropy], feed_dict={X : batch_X, Y_ : batch_Y})\n",
    "    print(\"training : \", i, ' accuracy = ', '{:7.4f}'.format(a), ' loss = ', c)\n",
    "    train_acc_list.append(a)\n",
    "    train_loss_list.append(c)\n",
    "\n",
    "    # test_batch_X, test_batch_Y = mnist.test.next_batch(100)  ==> never use mini batch!!\n",
    "    # sess.run(train_step, feed_dict={X: test_batch_X, Y_: test_batch_Y})  ==> never run train_step on test data!!\n",
    "    a, c = sess.run([accuracy, cross_entropy], feed_dict={X: mnist.test.images, Y_: mnist.test.labels})\n",
    "    print(\"testing  : \",i, ' accuracy = ', '{:7.4f}'.format(a), ' loss = ', c)\n",
    "    test_acc_list.append(a)\n",
    "    test_loss_list.append(c)\n",
    "\n",
    "    sess.run(train_step, feed_dict={X : batch_X, Y_ : batch_Y} )\n",
    "    \n",
    "    if(i%500 ==0 and i!=0):\n",
    "        saver.save(sess, '../model/mnist_HL5_sigmoid')\n",
    "\n",
    "# draw graph : accuracy\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.figure(1) \n",
    "plt.plot(x, train_acc_list,  label='train', markevery=1)\n",
    "plt.plot(x, test_acc_list, label='test', markevery=1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "# draw graph : loss\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.figure(2) \n",
    "plt.plot(x, train_loss_list,  label='train', markevery=1)\n",
    "plt.plot(x, test_loss_list, label='test', markevery=1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(0, 100)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
