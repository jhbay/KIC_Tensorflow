{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.8.0\n",
      "testing  :  0  accuracy =   0.0980  loss =  90.0066\n",
      "testing  :  1  accuracy =   0.5921  loss =  87.7853\n",
      "testing  :  2  accuracy =   0.3094  loss =  85.29\n",
      "testing  :  3  accuracy =   0.4337  loss =  82.0471\n",
      "testing  :  4  accuracy =   0.5693  loss =  78.4645\n",
      "testing  :  5  accuracy =   0.4571  loss =  75.547\n",
      "testing  :  6  accuracy =   0.5575  loss =  71.7095\n",
      "testing  :  7  accuracy =   0.5247  loss =  69.2852\n",
      "testing  :  8  accuracy =   0.6310  loss =  64.1759\n",
      "testing  :  9  accuracy =   0.6227  loss =  61.3306\n",
      "testing  :  10  accuracy =   0.6408  loss =  58.5095\n",
      "testing  :  11  accuracy =   0.6699  loss =  56.3062\n",
      "testing  :  12  accuracy =   0.7323  loss =  52.9001\n",
      "testing  :  13  accuracy =   0.7466  loss =  50.6623\n",
      "testing  :  14  accuracy =   0.7387  loss =  48.8533\n",
      "testing  :  15  accuracy =   0.7481  loss =  47.2022\n",
      "testing  :  16  accuracy =   0.7339  loss =  45.8101\n",
      "testing  :  17  accuracy =   0.7480  loss =  44.514\n",
      "testing  :  18  accuracy =   0.7509  loss =  42.607\n",
      "testing  :  19  accuracy =   0.7583  loss =  41.8488\n",
      "testing  :  20  accuracy =   0.7497  loss =  41.6238\n",
      "testing  :  21  accuracy =   0.7829  loss =  39.3893\n",
      "testing  :  22  accuracy =   0.7821  loss =  38.4702\n",
      "testing  :  23  accuracy =   0.8017  loss =  37.5307\n",
      "testing  :  24  accuracy =   0.8197  loss =  36.195\n",
      "testing  :  25  accuracy =   0.8261  loss =  35.7365\n",
      "testing  :  26  accuracy =   0.8036  loss =  35.4278\n",
      "testing  :  27  accuracy =   0.8374  loss =  34.4474\n",
      "testing  :  28  accuracy =   0.8124  loss =  34.1844\n",
      "testing  :  29  accuracy =   0.8249  loss =  33.1383\n",
      "testing  :  30  accuracy =   0.8255  loss =  32.7059\n",
      "testing  :  31  accuracy =   0.8287  loss =  32.3653\n",
      "testing  :  32  accuracy =   0.8318  loss =  31.6808\n",
      "testing  :  33  accuracy =   0.8301  loss =  31.7406\n",
      "testing  :  34  accuracy =   0.8414  loss =  31.1293\n",
      "testing  :  35  accuracy =   0.8598  loss =  29.6665\n",
      "testing  :  36  accuracy =   0.8573  loss =  29.4257\n",
      "testing  :  37  accuracy =   0.8536  loss =  28.9142\n",
      "testing  :  38  accuracy =   0.8504  loss =  28.6375\n",
      "testing  :  39  accuracy =   0.8496  loss =  28.3567\n",
      "testing  :  40  accuracy =   0.8515  loss =  28.1611\n",
      "testing  :  41  accuracy =   0.8321  loss =  29.1031\n",
      "testing  :  42  accuracy =   0.8561  loss =  27.4381\n",
      "testing  :  43  accuracy =   0.8494  loss =  27.2605\n",
      "testing  :  44  accuracy =   0.8576  loss =  26.7785\n",
      "testing  :  45  accuracy =   0.8532  loss =  26.8074\n",
      "testing  :  46  accuracy =   0.8587  loss =  26.9141\n",
      "testing  :  47  accuracy =   0.8609  loss =  26.7878\n",
      "testing  :  48  accuracy =   0.8605  loss =  26.6906\n",
      "testing  :  49  accuracy =   0.8636  loss =  25.9488\n",
      "testing  :  50  accuracy =   0.8630  loss =  25.3859\n",
      "testing  :  51  accuracy =   0.8521  loss =  26.0585\n",
      "testing  :  52  accuracy =   0.8534  loss =  25.887\n",
      "testing  :  53  accuracy =   0.8687  loss =  25.2322\n",
      "testing  :  54  accuracy =   0.8672  loss =  24.7878\n",
      "testing  :  55  accuracy =   0.8732  loss =  24.4552\n",
      "testing  :  56  accuracy =   0.8676  loss =  24.5626\n",
      "testing  :  57  accuracy =   0.8650  loss =  24.7279\n",
      "testing  :  58  accuracy =   0.8660  loss =  24.3204\n",
      "testing  :  59  accuracy =   0.8613  loss =  25.3979\n",
      "testing  :  60  accuracy =   0.8734  loss =  23.6141\n",
      "testing  :  61  accuracy =   0.8770  loss =  23.2303\n",
      "testing  :  62  accuracy =   0.8741  loss =  23.6181\n",
      "testing  :  63  accuracy =   0.8664  loss =  23.8753\n",
      "testing  :  64  accuracy =   0.8732  loss =  23.4427\n",
      "testing  :  65  accuracy =   0.8738  loss =  23.0883\n",
      "testing  :  66  accuracy =   0.8764  loss =  22.7411\n",
      "testing  :  67  accuracy =   0.8690  loss =  23.3444\n",
      "testing  :  68  accuracy =   0.8759  loss =  22.9673\n",
      "testing  :  69  accuracy =   0.8757  loss =  22.678\n",
      "testing  :  70  accuracy =   0.8819  loss =  22.2871\n",
      "testing  :  71  accuracy =   0.8783  loss =  22.1664\n",
      "testing  :  72  accuracy =   0.8721  loss =  23.2105\n",
      "testing  :  73  accuracy =   0.8812  loss =  21.9909\n",
      "testing  :  74  accuracy =   0.8740  loss =  22.1881\n",
      "testing  :  75  accuracy =   0.8768  loss =  22.1779\n",
      "testing  :  76  accuracy =   0.8718  loss =  22.7436\n",
      "testing  :  77  accuracy =   0.8761  loss =  21.7659\n",
      "testing  :  78  accuracy =   0.8818  loss =  21.4149\n",
      "testing  :  79  accuracy =   0.8774  loss =  21.8403\n",
      "testing  :  80  accuracy =   0.8801  loss =  21.7144\n",
      "testing  :  81  accuracy =   0.8817  loss =  21.1634\n",
      "testing  :  82  accuracy =   0.8801  loss =  21.5447\n",
      "testing  :  83  accuracy =   0.8847  loss =  21.1273\n",
      "testing  :  84  accuracy =   0.8823  loss =  21.0557\n",
      "testing  :  85  accuracy =   0.8828  loss =  20.9012\n",
      "testing  :  86  accuracy =   0.8789  loss =  20.865\n",
      "testing  :  87  accuracy =   0.8785  loss =  20.7636\n",
      "testing  :  88  accuracy =   0.8832  loss =  20.58\n",
      "testing  :  89  accuracy =   0.8784  loss =  21.172\n",
      "testing  :  90  accuracy =   0.8826  loss =  20.4328\n",
      "testing  :  91  accuracy =   0.8852  loss =  20.2519\n",
      "testing  :  92  accuracy =   0.8837  loss =  20.1875\n",
      "testing  :  93  accuracy =   0.8848  loss =  20.2976\n",
      "testing  :  94  accuracy =   0.8848  loss =  20.183\n",
      "testing  :  95  accuracy =   0.8849  loss =  19.998\n",
      "testing  :  96  accuracy =   0.8795  loss =  20.4388\n",
      "testing  :  97  accuracy =   0.8841  loss =  20.1397\n",
      "testing  :  98  accuracy =   0.8812  loss =  20.1244\n",
      "testing  :  99  accuracy =   0.8830  loss =  19.9176\n",
      "testing  :  100  accuracy =   0.8818  loss =  20.1829\n",
      "testing  :  101  accuracy =   0.8862  loss =  19.7189\n",
      "testing  :  102  accuracy =   0.8844  loss =  19.6153\n",
      "testing  :  103  accuracy =   0.8880  loss =  19.6422\n",
      "testing  :  104  accuracy =   0.8863  loss =  19.8336\n",
      "testing  :  105  accuracy =   0.8825  loss =  19.9329\n",
      "testing  :  106  accuracy =   0.8851  loss =  20.0073\n",
      "testing  :  107  accuracy =   0.8870  loss =  19.7265\n",
      "testing  :  108  accuracy =   0.8834  loss =  19.9572\n",
      "testing  :  109  accuracy =   0.8842  loss =  19.5493\n",
      "testing  :  110  accuracy =   0.8877  loss =  19.3225\n",
      "testing  :  111  accuracy =   0.8859  loss =  19.8509\n",
      "testing  :  112  accuracy =   0.8903  loss =  19.189\n",
      "testing  :  113  accuracy =   0.8894  loss =  19.3507\n",
      "testing  :  114  accuracy =   0.8900  loss =  19.0668\n",
      "testing  :  115  accuracy =   0.8853  loss =  19.5893\n",
      "testing  :  116  accuracy =   0.8825  loss =  19.5813\n",
      "testing  :  117  accuracy =   0.8891  loss =  18.9585\n",
      "testing  :  118  accuracy =   0.8935  loss =  18.6697\n",
      "testing  :  119  accuracy =   0.8865  loss =  19.0735\n",
      "testing  :  120  accuracy =   0.8874  loss =  19.0046\n",
      "testing  :  121  accuracy =   0.8927  loss =  18.5716\n",
      "testing  :  122  accuracy =   0.8951  loss =  18.5016\n",
      "testing  :  123  accuracy =   0.8949  loss =  18.4844\n",
      "testing  :  124  accuracy =   0.8955  loss =  18.5393\n",
      "testing  :  125  accuracy =   0.8897  loss =  18.5703\n",
      "testing  :  126  accuracy =   0.8900  loss =  18.6215\n",
      "testing  :  127  accuracy =   0.8881  loss =  18.8685\n",
      "testing  :  128  accuracy =   0.8929  loss =  18.5023\n",
      "testing  :  129  accuracy =   0.8949  loss =  18.3619\n",
      "testing  :  130  accuracy =   0.8897  loss =  18.6273\n",
      "testing  :  131  accuracy =   0.8911  loss =  18.4712\n",
      "testing  :  132  accuracy =   0.8908  loss =  18.5928\n",
      "testing  :  133  accuracy =   0.8906  loss =  18.4794\n",
      "testing  :  134  accuracy =   0.8908  loss =  18.5593\n",
      "testing  :  135  accuracy =   0.8923  loss =  18.3638\n",
      "testing  :  136  accuracy =   0.8925  loss =  18.2488\n",
      "testing  :  137  accuracy =   0.8913  loss =  18.4024\n",
      "testing  :  138  accuracy =   0.8944  loss =  18.0504\n",
      "testing  :  139  accuracy =   0.8920  loss =  18.3204\n",
      "testing  :  140  accuracy =   0.8948  loss =  18.035\n",
      "testing  :  141  accuracy =   0.8943  loss =  17.9535\n",
      "testing  :  142  accuracy =   0.8956  loss =  17.9181\n",
      "testing  :  143  accuracy =   0.8927  loss =  18.0513\n",
      "testing  :  144  accuracy =   0.8929  loss =  18.001\n",
      "testing  :  145  accuracy =   0.8933  loss =  17.9018\n",
      "testing  :  146  accuracy =   0.8919  loss =  17.984\n",
      "testing  :  147  accuracy =   0.8920  loss =  17.9997\n",
      "testing  :  148  accuracy =   0.8958  loss =  17.7834\n",
      "testing  :  149  accuracy =   0.8962  loss =  17.7528\n",
      "testing  :  150  accuracy =   0.8972  loss =  17.6451\n",
      "testing  :  151  accuracy =   0.8950  loss =  17.8768\n",
      "testing  :  152  accuracy =   0.8931  loss =  17.9029\n",
      "testing  :  153  accuracy =   0.8925  loss =  17.7391\n",
      "testing  :  154  accuracy =   0.8920  loss =  17.6862\n",
      "testing  :  155  accuracy =   0.8938  loss =  17.8438\n",
      "testing  :  156  accuracy =   0.8925  loss =  17.8392\n",
      "testing  :  157  accuracy =   0.8903  loss =  17.9685\n",
      "testing  :  158  accuracy =   0.8845  loss =  18.5539\n",
      "testing  :  159  accuracy =   0.8959  loss =  17.3879\n",
      "testing  :  160  accuracy =   0.8913  loss =  17.9125\n",
      "testing  :  161  accuracy =   0.8945  loss =  17.5358\n",
      "testing  :  162  accuracy =   0.8916  loss =  17.6305\n",
      "testing  :  163  accuracy =   0.8961  loss =  17.336\n",
      "testing  :  164  accuracy =   0.8964  loss =  17.2645\n",
      "testing  :  165  accuracy =   0.8957  loss =  17.3209\n",
      "testing  :  166  accuracy =   0.8951  loss =  17.393\n",
      "testing  :  167  accuracy =   0.8965  loss =  17.3653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  168  accuracy =   0.8970  loss =  17.2712\n",
      "testing  :  169  accuracy =   0.8981  loss =  17.0643\n",
      "testing  :  170  accuracy =   0.8979  loss =  17.1447\n",
      "testing  :  171  accuracy =   0.8972  loss =  17.1255\n",
      "testing  :  172  accuracy =   0.8981  loss =  17.1067\n",
      "testing  :  173  accuracy =   0.8973  loss =  17.0977\n",
      "testing  :  174  accuracy =   0.8958  loss =  17.2919\n",
      "testing  :  175  accuracy =   0.8974  loss =  17.1508\n",
      "testing  :  176  accuracy =   0.8979  loss =  17.0142\n",
      "testing  :  177  accuracy =   0.8977  loss =  16.9852\n",
      "testing  :  178  accuracy =   0.8997  loss =  16.8102\n",
      "testing  :  179  accuracy =   0.8975  loss =  17.3173\n",
      "testing  :  180  accuracy =   0.9000  loss =  16.8416\n",
      "testing  :  181  accuracy =   0.9012  loss =  16.8071\n",
      "testing  :  182  accuracy =   0.8979  loss =  17.1251\n",
      "testing  :  183  accuracy =   0.8998  loss =  16.7746\n",
      "testing  :  184  accuracy =   0.9005  loss =  16.7416\n",
      "testing  :  185  accuracy =   0.9000  loss =  16.7956\n",
      "testing  :  186  accuracy =   0.9031  loss =  16.638\n",
      "testing  :  187  accuracy =   0.9003  loss =  16.6549\n",
      "testing  :  188  accuracy =   0.9013  loss =  16.5836\n",
      "testing  :  189  accuracy =   0.8989  loss =  16.7731\n",
      "testing  :  190  accuracy =   0.8987  loss =  16.7791\n",
      "testing  :  191  accuracy =   0.9004  loss =  16.7521\n",
      "testing  :  192  accuracy =   0.9016  loss =  16.5407\n",
      "testing  :  193  accuracy =   0.9023  loss =  16.5322\n",
      "testing  :  194  accuracy =   0.9002  loss =  16.631\n",
      "testing  :  195  accuracy =   0.8991  loss =  16.6943\n",
      "testing  :  196  accuracy =   0.8991  loss =  16.5812\n",
      "testing  :  197  accuracy =   0.8997  loss =  16.6141\n",
      "testing  :  198  accuracy =   0.8981  loss =  16.7879\n",
      "testing  :  199  accuracy =   0.9004  loss =  16.5467\n",
      "testing  :  200  accuracy =   0.8973  loss =  16.8362\n",
      "testing  :  201  accuracy =   0.8990  loss =  16.6316\n",
      "testing  :  202  accuracy =   0.8975  loss =  16.7761\n",
      "testing  :  203  accuracy =   0.9000  loss =  16.6639\n",
      "testing  :  204  accuracy =   0.8988  loss =  16.694\n",
      "testing  :  205  accuracy =   0.9000  loss =  16.5188\n",
      "testing  :  206  accuracy =   0.8989  loss =  16.6736\n",
      "testing  :  207  accuracy =   0.9024  loss =  16.4433\n",
      "testing  :  208  accuracy =   0.9020  loss =  16.3435\n",
      "testing  :  209  accuracy =   0.9017  loss =  16.3775\n",
      "testing  :  210  accuracy =   0.9005  loss =  16.6148\n",
      "testing  :  211  accuracy =   0.9021  loss =  16.3623\n",
      "testing  :  212  accuracy =   0.9026  loss =  16.1714\n",
      "testing  :  213  accuracy =   0.8990  loss =  16.3985\n",
      "testing  :  214  accuracy =   0.8980  loss =  16.6271\n",
      "testing  :  215  accuracy =   0.9020  loss =  16.3585\n",
      "testing  :  216  accuracy =   0.9004  loss =  16.6063\n",
      "testing  :  217  accuracy =   0.9009  loss =  16.2899\n",
      "testing  :  218  accuracy =   0.9032  loss =  16.1113\n",
      "testing  :  219  accuracy =   0.9025  loss =  16.1291\n",
      "testing  :  220  accuracy =   0.9051  loss =  16.1044\n",
      "testing  :  221  accuracy =   0.9008  loss =  16.4229\n",
      "testing  :  222  accuracy =   0.8976  loss =  16.5726\n",
      "testing  :  223  accuracy =   0.9007  loss =  16.3023\n",
      "testing  :  224  accuracy =   0.8982  loss =  16.4912\n",
      "testing  :  225  accuracy =   0.9032  loss =  16.1765\n",
      "testing  :  226  accuracy =   0.9010  loss =  16.2368\n",
      "testing  :  227  accuracy =   0.9006  loss =  16.4585\n",
      "testing  :  228  accuracy =   0.9023  loss =  16.1975\n",
      "testing  :  229  accuracy =   0.9035  loss =  16.1118\n",
      "testing  :  230  accuracy =   0.9019  loss =  16.2613\n",
      "testing  :  231  accuracy =   0.9039  loss =  16.0694\n",
      "testing  :  232  accuracy =   0.9024  loss =  16.1266\n",
      "testing  :  233  accuracy =   0.9035  loss =  16.2339\n",
      "testing  :  234  accuracy =   0.9040  loss =  16.0416\n",
      "testing  :  235  accuracy =   0.9046  loss =  15.9487\n",
      "testing  :  236  accuracy =   0.9026  loss =  16.0781\n",
      "testing  :  237  accuracy =   0.9015  loss =  16.0087\n",
      "testing  :  238  accuracy =   0.9043  loss =  15.9502\n",
      "testing  :  239  accuracy =   0.9024  loss =  16.2049\n",
      "testing  :  240  accuracy =   0.9027  loss =  16.0069\n",
      "testing  :  241  accuracy =   0.9044  loss =  15.9365\n",
      "testing  :  242  accuracy =   0.9014  loss =  16.1646\n",
      "testing  :  243  accuracy =   0.9042  loss =  15.876\n",
      "testing  :  244  accuracy =   0.9024  loss =  16.0488\n",
      "testing  :  245  accuracy =   0.9030  loss =  16.0347\n",
      "testing  :  246  accuracy =   0.8995  loss =  16.2215\n",
      "testing  :  247  accuracy =   0.8988  loss =  16.3961\n",
      "testing  :  248  accuracy =   0.8985  loss =  16.5312\n",
      "testing  :  249  accuracy =   0.9027  loss =  15.8856\n",
      "testing  :  250  accuracy =   0.9034  loss =  15.9374\n",
      "testing  :  251  accuracy =   0.9033  loss =  15.7916\n",
      "testing  :  252  accuracy =   0.9022  loss =  15.8297\n",
      "testing  :  253  accuracy =   0.9058  loss =  15.7071\n",
      "testing  :  254  accuracy =   0.9053  loss =  15.7318\n",
      "testing  :  255  accuracy =   0.9049  loss =  15.6674\n",
      "testing  :  256  accuracy =   0.9031  loss =  16.0108\n",
      "testing  :  257  accuracy =   0.9032  loss =  16.0048\n",
      "testing  :  258  accuracy =   0.9056  loss =  15.6445\n",
      "testing  :  259  accuracy =   0.9041  loss =  15.6755\n",
      "testing  :  260  accuracy =   0.9001  loss =  16.0534\n",
      "testing  :  261  accuracy =   0.9032  loss =  15.8798\n",
      "testing  :  262  accuracy =   0.9035  loss =  15.8323\n",
      "testing  :  263  accuracy =   0.9062  loss =  15.5078\n",
      "testing  :  264  accuracy =   0.9068  loss =  15.4812\n",
      "testing  :  265  accuracy =   0.9063  loss =  15.5414\n",
      "testing  :  266  accuracy =   0.9071  loss =  15.5004\n",
      "testing  :  267  accuracy =   0.9045  loss =  15.7393\n",
      "testing  :  268  accuracy =   0.9024  loss =  15.9797\n",
      "testing  :  269  accuracy =   0.9075  loss =  15.4705\n",
      "testing  :  270  accuracy =   0.9071  loss =  15.5691\n",
      "testing  :  271  accuracy =   0.9028  loss =  15.8554\n",
      "testing  :  272  accuracy =   0.9040  loss =  15.6563\n",
      "testing  :  273  accuracy =   0.9069  loss =  15.421\n",
      "testing  :  274  accuracy =   0.9074  loss =  15.4034\n",
      "testing  :  275  accuracy =   0.9077  loss =  15.4108\n",
      "testing  :  276  accuracy =   0.9016  loss =  16.0637\n",
      "testing  :  277  accuracy =   0.9040  loss =  15.5016\n",
      "testing  :  278  accuracy =   0.9050  loss =  15.5862\n",
      "testing  :  279  accuracy =   0.9053  loss =  15.509\n",
      "testing  :  280  accuracy =   0.9049  loss =  15.5529\n",
      "testing  :  281  accuracy =   0.9057  loss =  15.537\n",
      "testing  :  282  accuracy =   0.9006  loss =  16.1983\n",
      "testing  :  283  accuracy =   0.9038  loss =  15.87\n",
      "testing  :  284  accuracy =   0.9043  loss =  15.4514\n",
      "testing  :  285  accuracy =   0.9035  loss =  15.5423\n",
      "testing  :  286  accuracy =   0.9068  loss =  15.1563\n",
      "testing  :  287  accuracy =   0.9044  loss =  15.6555\n",
      "testing  :  288  accuracy =   0.9079  loss =  15.1337\n",
      "testing  :  289  accuracy =   0.9078  loss =  15.1712\n",
      "testing  :  290  accuracy =   0.9074  loss =  15.2309\n",
      "testing  :  291  accuracy =   0.9074  loss =  15.2358\n",
      "testing  :  292  accuracy =   0.9088  loss =  15.1847\n",
      "testing  :  293  accuracy =   0.9079  loss =  15.2853\n",
      "testing  :  294  accuracy =   0.9034  loss =  15.6645\n",
      "testing  :  295  accuracy =   0.9078  loss =  15.0949\n",
      "testing  :  296  accuracy =   0.9027  loss =  15.6068\n",
      "testing  :  297  accuracy =   0.9061  loss =  15.2468\n",
      "testing  :  298  accuracy =   0.9053  loss =  15.3465\n",
      "testing  :  299  accuracy =   0.9038  loss =  15.402\n",
      "testing  :  300  accuracy =   0.9040  loss =  15.5545\n",
      "testing  :  301  accuracy =   0.9053  loss =  15.2936\n",
      "testing  :  302  accuracy =   0.9048  loss =  15.4201\n",
      "testing  :  303  accuracy =   0.9050  loss =  15.2798\n",
      "testing  :  304  accuracy =   0.9064  loss =  15.2339\n",
      "testing  :  305  accuracy =   0.9066  loss =  15.1822\n",
      "testing  :  306  accuracy =   0.9073  loss =  15.108\n",
      "testing  :  307  accuracy =   0.9056  loss =  15.2418\n",
      "testing  :  308  accuracy =   0.9076  loss =  15.1147\n",
      "testing  :  309  accuracy =   0.9057  loss =  15.2682\n",
      "testing  :  310  accuracy =   0.9065  loss =  15.0807\n",
      "testing  :  311  accuracy =   0.9063  loss =  15.0991\n",
      "testing  :  312  accuracy =   0.9059  loss =  15.1223\n",
      "testing  :  313  accuracy =   0.9062  loss =  15.0306\n",
      "testing  :  314  accuracy =   0.9057  loss =  15.3056\n",
      "testing  :  315  accuracy =   0.9094  loss =  14.9539\n",
      "testing  :  316  accuracy =   0.9075  loss =  14.9319\n",
      "testing  :  317  accuracy =   0.9066  loss =  15.0692\n",
      "testing  :  318  accuracy =   0.9059  loss =  15.4852\n",
      "testing  :  319  accuracy =   0.9091  loss =  14.9019\n",
      "testing  :  320  accuracy =   0.9098  loss =  14.8764\n",
      "testing  :  321  accuracy =   0.9098  loss =  15.0225\n",
      "testing  :  322  accuracy =   0.9084  loss =  15.0931\n",
      "testing  :  323  accuracy =   0.9062  loss =  15.3836\n",
      "testing  :  324  accuracy =   0.9071  loss =  15.1616\n",
      "testing  :  325  accuracy =   0.9057  loss =  15.3477\n",
      "testing  :  326  accuracy =   0.9082  loss =  15.1655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  327  accuracy =   0.9078  loss =  15.1868\n",
      "testing  :  328  accuracy =   0.9047  loss =  15.4073\n",
      "testing  :  329  accuracy =   0.9076  loss =  14.9181\n",
      "testing  :  330  accuracy =   0.9068  loss =  15.0536\n",
      "testing  :  331  accuracy =   0.9043  loss =  15.3901\n",
      "testing  :  332  accuracy =   0.9077  loss =  15.0387\n",
      "testing  :  333  accuracy =   0.9088  loss =  14.8316\n",
      "testing  :  334  accuracy =   0.9072  loss =  14.9653\n",
      "testing  :  335  accuracy =   0.9061  loss =  14.9914\n",
      "testing  :  336  accuracy =   0.9080  loss =  14.7579\n",
      "testing  :  337  accuracy =   0.9067  loss =  14.9615\n",
      "testing  :  338  accuracy =   0.9057  loss =  14.9501\n",
      "testing  :  339  accuracy =   0.9061  loss =  15.1868\n",
      "testing  :  340  accuracy =   0.9067  loss =  14.93\n",
      "testing  :  341  accuracy =   0.9080  loss =  15.0205\n",
      "testing  :  342  accuracy =   0.9041  loss =  15.2587\n",
      "testing  :  343  accuracy =   0.9055  loss =  15.0587\n",
      "testing  :  344  accuracy =   0.9075  loss =  14.8347\n",
      "testing  :  345  accuracy =   0.9091  loss =  14.7781\n",
      "testing  :  346  accuracy =   0.9091  loss =  14.8011\n",
      "testing  :  347  accuracy =   0.9074  loss =  14.8798\n",
      "testing  :  348  accuracy =   0.9084  loss =  14.7095\n",
      "testing  :  349  accuracy =   0.9072  loss =  15.1537\n",
      "testing  :  350  accuracy =   0.9081  loss =  15.0321\n",
      "testing  :  351  accuracy =   0.9049  loss =  15.347\n",
      "testing  :  352  accuracy =   0.9081  loss =  14.9753\n",
      "testing  :  353  accuracy =   0.9090  loss =  14.8823\n",
      "testing  :  354  accuracy =   0.9086  loss =  14.8738\n",
      "testing  :  355  accuracy =   0.9079  loss =  14.9081\n",
      "testing  :  356  accuracy =   0.9069  loss =  15.1579\n",
      "testing  :  357  accuracy =   0.9085  loss =  14.7546\n",
      "testing  :  358  accuracy =   0.9072  loss =  14.7823\n",
      "testing  :  359  accuracy =   0.9068  loss =  15.0247\n",
      "testing  :  360  accuracy =   0.9062  loss =  14.8337\n",
      "testing  :  361  accuracy =   0.9077  loss =  14.5957\n",
      "testing  :  362  accuracy =   0.9084  loss =  14.6301\n",
      "testing  :  363  accuracy =   0.9071  loss =  14.6945\n",
      "testing  :  364  accuracy =   0.9085  loss =  14.6054\n",
      "testing  :  365  accuracy =   0.9085  loss =  14.8107\n",
      "testing  :  366  accuracy =   0.9072  loss =  14.8069\n",
      "testing  :  367  accuracy =   0.9100  loss =  14.6216\n",
      "testing  :  368  accuracy =   0.9090  loss =  14.5864\n",
      "testing  :  369  accuracy =   0.9092  loss =  14.5647\n",
      "testing  :  370  accuracy =   0.9099  loss =  14.6118\n",
      "testing  :  371  accuracy =   0.9091  loss =  14.5589\n",
      "testing  :  372  accuracy =   0.9103  loss =  14.5696\n",
      "testing  :  373  accuracy =   0.9082  loss =  14.5985\n",
      "testing  :  374  accuracy =   0.9104  loss =  14.5683\n",
      "testing  :  375  accuracy =   0.9069  loss =  14.8365\n",
      "testing  :  376  accuracy =   0.9076  loss =  14.7602\n",
      "testing  :  377  accuracy =   0.9076  loss =  14.7538\n",
      "testing  :  378  accuracy =   0.9059  loss =  14.9539\n",
      "testing  :  379  accuracy =   0.9064  loss =  14.7004\n",
      "testing  :  380  accuracy =   0.9073  loss =  14.6428\n",
      "testing  :  381  accuracy =   0.9072  loss =  14.7257\n",
      "testing  :  382  accuracy =   0.9069  loss =  14.8654\n",
      "testing  :  383  accuracy =   0.9084  loss =  14.7341\n",
      "testing  :  384  accuracy =   0.9080  loss =  14.8312\n",
      "testing  :  385  accuracy =   0.9082  loss =  14.7922\n",
      "testing  :  386  accuracy =   0.9060  loss =  14.9261\n",
      "testing  :  387  accuracy =   0.9061  loss =  14.7928\n",
      "testing  :  388  accuracy =   0.9036  loss =  15.1501\n",
      "testing  :  389  accuracy =   0.9042  loss =  15.169\n",
      "testing  :  390  accuracy =   0.9062  loss =  14.7837\n",
      "testing  :  391  accuracy =   0.9056  loss =  14.7525\n",
      "testing  :  392  accuracy =   0.9086  loss =  14.5459\n",
      "testing  :  393  accuracy =   0.9065  loss =  14.8293\n",
      "testing  :  394  accuracy =   0.9074  loss =  14.7364\n",
      "testing  :  395  accuracy =   0.9053  loss =  14.9108\n",
      "testing  :  396  accuracy =   0.9091  loss =  14.462\n",
      "testing  :  397  accuracy =   0.9086  loss =  14.5532\n",
      "testing  :  398  accuracy =   0.9071  loss =  14.5279\n",
      "testing  :  399  accuracy =   0.9115  loss =  14.3104\n",
      "testing  :  400  accuracy =   0.9097  loss =  14.3519\n",
      "testing  :  401  accuracy =   0.9101  loss =  14.3204\n",
      "testing  :  402  accuracy =   0.9071  loss =  14.8111\n",
      "testing  :  403  accuracy =   0.9072  loss =  14.7243\n",
      "testing  :  404  accuracy =   0.9091  loss =  14.709\n",
      "testing  :  405  accuracy =   0.9099  loss =  14.5356\n",
      "testing  :  406  accuracy =   0.9103  loss =  14.5718\n",
      "testing  :  407  accuracy =   0.9107  loss =  14.4869\n",
      "testing  :  408  accuracy =   0.9102  loss =  14.368\n",
      "testing  :  409  accuracy =   0.9105  loss =  14.3331\n",
      "testing  :  410  accuracy =   0.9102  loss =  14.3786\n",
      "testing  :  411  accuracy =   0.9108  loss =  14.3094\n",
      "testing  :  412  accuracy =   0.9096  loss =  14.3289\n",
      "testing  :  413  accuracy =   0.9107  loss =  14.3583\n",
      "testing  :  414  accuracy =   0.9104  loss =  14.4006\n",
      "testing  :  415  accuracy =   0.9090  loss =  14.6189\n",
      "testing  :  416  accuracy =   0.9089  loss =  14.4613\n",
      "testing  :  417  accuracy =   0.9097  loss =  14.4644\n",
      "testing  :  418  accuracy =   0.9086  loss =  14.5197\n",
      "testing  :  419  accuracy =   0.9093  loss =  14.4297\n",
      "testing  :  420  accuracy =   0.9083  loss =  14.4826\n",
      "testing  :  421  accuracy =   0.9089  loss =  14.4346\n",
      "testing  :  422  accuracy =   0.9092  loss =  14.3772\n",
      "testing  :  423  accuracy =   0.9082  loss =  14.3599\n",
      "testing  :  424  accuracy =   0.9103  loss =  14.3184\n",
      "testing  :  425  accuracy =   0.9089  loss =  14.2941\n",
      "testing  :  426  accuracy =   0.9090  loss =  14.2667\n",
      "testing  :  427  accuracy =   0.9095  loss =  14.3332\n",
      "testing  :  428  accuracy =   0.9083  loss =  14.2767\n",
      "testing  :  429  accuracy =   0.9096  loss =  14.3188\n",
      "testing  :  430  accuracy =   0.9102  loss =  14.2417\n",
      "testing  :  431  accuracy =   0.9073  loss =  14.8005\n",
      "testing  :  432  accuracy =   0.9070  loss =  14.6752\n",
      "testing  :  433  accuracy =   0.9094  loss =  14.3304\n",
      "testing  :  434  accuracy =   0.9117  loss =  14.1645\n",
      "testing  :  435  accuracy =   0.9103  loss =  14.1879\n",
      "testing  :  436  accuracy =   0.9097  loss =  14.2248\n",
      "testing  :  437  accuracy =   0.9116  loss =  14.2892\n",
      "testing  :  438  accuracy =   0.9100  loss =  14.4924\n",
      "testing  :  439  accuracy =   0.9104  loss =  14.6754\n",
      "testing  :  440  accuracy =   0.9105  loss =  14.355\n",
      "testing  :  441  accuracy =   0.9088  loss =  14.6187\n",
      "testing  :  442  accuracy =   0.9098  loss =  14.2211\n",
      "testing  :  443  accuracy =   0.9103  loss =  14.3093\n",
      "testing  :  444  accuracy =   0.9113  loss =  14.3047\n",
      "testing  :  445  accuracy =   0.9097  loss =  14.3527\n",
      "testing  :  446  accuracy =   0.9086  loss =  14.3729\n",
      "testing  :  447  accuracy =   0.9079  loss =  14.6212\n",
      "testing  :  448  accuracy =   0.9103  loss =  14.4812\n",
      "testing  :  449  accuracy =   0.9096  loss =  14.3409\n",
      "testing  :  450  accuracy =   0.9110  loss =  14.1184\n",
      "testing  :  451  accuracy =   0.9109  loss =  14.0759\n",
      "testing  :  452  accuracy =   0.9075  loss =  14.4825\n",
      "testing  :  453  accuracy =   0.9095  loss =  14.4232\n",
      "testing  :  454  accuracy =   0.9105  loss =  14.331\n",
      "testing  :  455  accuracy =   0.9121  loss =  14.1021\n",
      "testing  :  456  accuracy =   0.9123  loss =  14.1418\n",
      "testing  :  457  accuracy =   0.9127  loss =  14.19\n",
      "testing  :  458  accuracy =   0.9118  loss =  14.3296\n",
      "testing  :  459  accuracy =   0.9124  loss =  14.1008\n",
      "testing  :  460  accuracy =   0.9121  loss =  14.1081\n",
      "testing  :  461  accuracy =   0.9105  loss =  14.1526\n",
      "testing  :  462  accuracy =   0.9121  loss =  14.0078\n",
      "testing  :  463  accuracy =   0.9123  loss =  14.1395\n",
      "testing  :  464  accuracy =   0.9105  loss =  14.2624\n",
      "testing  :  465  accuracy =   0.9111  loss =  14.3598\n",
      "testing  :  466  accuracy =   0.9125  loss =  14.0924\n",
      "testing  :  467  accuracy =   0.9120  loss =  14.0977\n",
      "testing  :  468  accuracy =   0.9108  loss =  14.1393\n",
      "testing  :  469  accuracy =   0.9118  loss =  14.0894\n",
      "testing  :  470  accuracy =   0.9116  loss =  14.0044\n",
      "testing  :  471  accuracy =   0.9117  loss =  14.2133\n",
      "testing  :  472  accuracy =   0.9108  loss =  14.2075\n",
      "testing  :  473  accuracy =   0.9114  loss =  14.1507\n",
      "testing  :  474  accuracy =   0.9106  loss =  14.2313\n",
      "testing  :  475  accuracy =   0.9107  loss =  14.2488\n",
      "testing  :  476  accuracy =   0.9095  loss =  14.2032\n",
      "testing  :  477  accuracy =   0.9115  loss =  14.1449\n",
      "testing  :  478  accuracy =   0.9118  loss =  14.0624\n",
      "testing  :  479  accuracy =   0.9127  loss =  13.9268\n",
      "testing  :  480  accuracy =   0.9125  loss =  14.0587\n",
      "testing  :  481  accuracy =   0.9119  loss =  14.1348\n",
      "testing  :  482  accuracy =   0.9076  loss =  14.8011\n",
      "testing  :  483  accuracy =   0.9111  loss =  14.0982\n",
      "testing  :  484  accuracy =   0.9116  loss =  13.9401\n",
      "testing  :  485  accuracy =   0.9116  loss =  14.0371\n",
      "testing  :  486  accuracy =   0.9118  loss =  14.0202\n",
      "testing  :  487  accuracy =   0.9116  loss =  13.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  488  accuracy =   0.9121  loss =  14.0385\n",
      "testing  :  489  accuracy =   0.9111  loss =  14.1514\n",
      "testing  :  490  accuracy =   0.9121  loss =  13.9551\n",
      "testing  :  491  accuracy =   0.9119  loss =  13.9886\n",
      "testing  :  492  accuracy =   0.9095  loss =  14.1982\n",
      "testing  :  493  accuracy =   0.9086  loss =  14.2057\n",
      "testing  :  494  accuracy =   0.9114  loss =  14.0095\n",
      "testing  :  495  accuracy =   0.9117  loss =  14.0933\n",
      "testing  :  496  accuracy =   0.9112  loss =  13.9744\n",
      "testing  :  497  accuracy =   0.9106  loss =  14.1322\n",
      "testing  :  498  accuracy =   0.9105  loss =  14.0344\n",
      "testing  :  499  accuracy =   0.9112  loss =  14.0202\n",
      "testing  :  500  accuracy =   0.9116  loss =  13.9496\n",
      "testing  :  501  accuracy =   0.9122  loss =  13.9405\n",
      "testing  :  502  accuracy =   0.9108  loss =  14.1186\n",
      "testing  :  503  accuracy =   0.9104  loss =  14.1019\n",
      "testing  :  504  accuracy =   0.9098  loss =  14.2113\n",
      "testing  :  505  accuracy =   0.9100  loss =  14.3368\n",
      "testing  :  506  accuracy =   0.9123  loss =  14.1016\n",
      "testing  :  507  accuracy =   0.9111  loss =  14.1446\n",
      "testing  :  508  accuracy =   0.9130  loss =  14.1108\n",
      "testing  :  509  accuracy =   0.9108  loss =  14.2459\n",
      "testing  :  510  accuracy =   0.9122  loss =  13.9053\n",
      "testing  :  511  accuracy =   0.9149  loss =  13.8195\n",
      "testing  :  512  accuracy =   0.9141  loss =  13.8937\n",
      "testing  :  513  accuracy =   0.9112  loss =  14.0969\n",
      "testing  :  514  accuracy =   0.9124  loss =  13.9377\n",
      "testing  :  515  accuracy =   0.9099  loss =  14.1239\n",
      "testing  :  516  accuracy =   0.9141  loss =  13.7511\n",
      "testing  :  517  accuracy =   0.9119  loss =  13.9192\n",
      "testing  :  518  accuracy =   0.9126  loss =  13.9509\n",
      "testing  :  519  accuracy =   0.9129  loss =  13.9002\n",
      "testing  :  520  accuracy =   0.9122  loss =  13.8784\n",
      "testing  :  521  accuracy =   0.9143  loss =  13.8371\n",
      "testing  :  522  accuracy =   0.9121  loss =  14.0355\n",
      "testing  :  523  accuracy =   0.9149  loss =  13.7953\n",
      "testing  :  524  accuracy =   0.9154  loss =  13.7598\n",
      "testing  :  525  accuracy =   0.9153  loss =  13.7846\n",
      "testing  :  526  accuracy =   0.9142  loss =  13.8032\n",
      "testing  :  527  accuracy =   0.9139  loss =  13.8377\n",
      "testing  :  528  accuracy =   0.9131  loss =  13.902\n",
      "testing  :  529  accuracy =   0.9118  loss =  13.992\n",
      "testing  :  530  accuracy =   0.9121  loss =  13.9753\n",
      "testing  :  531  accuracy =   0.9108  loss =  14.0256\n",
      "testing  :  532  accuracy =   0.9110  loss =  14.0067\n",
      "testing  :  533  accuracy =   0.9117  loss =  13.9334\n",
      "testing  :  534  accuracy =   0.9113  loss =  13.9553\n",
      "testing  :  535  accuracy =   0.9120  loss =  13.9792\n",
      "testing  :  536  accuracy =   0.9128  loss =  13.8665\n",
      "testing  :  537  accuracy =   0.9112  loss =  13.9208\n",
      "testing  :  538  accuracy =   0.9128  loss =  13.8815\n",
      "testing  :  539  accuracy =   0.9125  loss =  13.9316\n",
      "testing  :  540  accuracy =   0.9119  loss =  14.0483\n",
      "testing  :  541  accuracy =   0.9118  loss =  14.0693\n",
      "testing  :  542  accuracy =   0.9126  loss =  14.0947\n",
      "testing  :  543  accuracy =   0.9125  loss =  13.9257\n",
      "testing  :  544  accuracy =   0.9112  loss =  13.8877\n",
      "testing  :  545  accuracy =   0.9114  loss =  14.0434\n",
      "testing  :  546  accuracy =   0.9132  loss =  13.8532\n",
      "testing  :  547  accuracy =   0.9133  loss =  13.7088\n",
      "testing  :  548  accuracy =   0.9133  loss =  13.7097\n",
      "testing  :  549  accuracy =   0.9133  loss =  13.7285\n",
      "testing  :  550  accuracy =   0.9084  loss =  14.338\n",
      "testing  :  551  accuracy =   0.9111  loss =  14.1424\n",
      "testing  :  552  accuracy =   0.9127  loss =  13.8018\n",
      "testing  :  553  accuracy =   0.9133  loss =  13.7978\n",
      "testing  :  554  accuracy =   0.9117  loss =  13.6937\n",
      "testing  :  555  accuracy =   0.9124  loss =  13.8377\n",
      "testing  :  556  accuracy =   0.9119  loss =  13.8205\n",
      "testing  :  557  accuracy =   0.9135  loss =  13.7018\n",
      "testing  :  558  accuracy =   0.9124  loss =  13.8689\n",
      "testing  :  559  accuracy =   0.9122  loss =  13.8501\n",
      "testing  :  560  accuracy =   0.9119  loss =  13.8872\n",
      "testing  :  561  accuracy =   0.9109  loss =  13.94\n",
      "testing  :  562  accuracy =   0.9116  loss =  13.8418\n",
      "testing  :  563  accuracy =   0.9110  loss =  13.9021\n",
      "testing  :  564  accuracy =   0.9112  loss =  13.8293\n",
      "testing  :  565  accuracy =   0.9097  loss =  14.1034\n",
      "testing  :  566  accuracy =   0.9106  loss =  13.992\n",
      "testing  :  567  accuracy =   0.9121  loss =  13.8283\n",
      "testing  :  568  accuracy =   0.9115  loss =  13.9445\n",
      "testing  :  569  accuracy =   0.9125  loss =  13.746\n",
      "testing  :  570  accuracy =   0.9097  loss =  13.9183\n",
      "testing  :  571  accuracy =   0.9089  loss =  13.9531\n",
      "testing  :  572  accuracy =   0.9108  loss =  13.8573\n",
      "testing  :  573  accuracy =   0.9112  loss =  14.0992\n",
      "testing  :  574  accuracy =   0.9127  loss =  13.8701\n",
      "testing  :  575  accuracy =   0.9131  loss =  13.8395\n",
      "testing  :  576  accuracy =   0.9133  loss =  13.6458\n",
      "testing  :  577  accuracy =   0.9135  loss =  13.7238\n",
      "testing  :  578  accuracy =   0.9143  loss =  13.6801\n",
      "testing  :  579  accuracy =   0.9115  loss =  13.8349\n",
      "testing  :  580  accuracy =   0.9127  loss =  13.6877\n",
      "testing  :  581  accuracy =   0.9113  loss =  13.8852\n",
      "testing  :  582  accuracy =   0.9127  loss =  13.8136\n",
      "testing  :  583  accuracy =   0.9123  loss =  13.8849\n",
      "testing  :  584  accuracy =   0.9112  loss =  14.2381\n",
      "testing  :  585  accuracy =   0.9128  loss =  13.7602\n",
      "testing  :  586  accuracy =   0.9141  loss =  13.6764\n",
      "testing  :  587  accuracy =   0.9127  loss =  13.9651\n",
      "testing  :  588  accuracy =   0.9110  loss =  14.1352\n",
      "testing  :  589  accuracy =   0.9090  loss =  14.3663\n",
      "testing  :  590  accuracy =   0.9120  loss =  14.0243\n",
      "testing  :  591  accuracy =   0.9111  loss =  14.2329\n",
      "testing  :  592  accuracy =   0.9125  loss =  13.8776\n",
      "testing  :  593  accuracy =   0.9119  loss =  13.9156\n",
      "testing  :  594  accuracy =   0.9105  loss =  14.2165\n",
      "testing  :  595  accuracy =   0.9105  loss =  13.8827\n",
      "testing  :  596  accuracy =   0.9117  loss =  13.7446\n",
      "testing  :  597  accuracy =   0.9120  loss =  13.9604\n",
      "testing  :  598  accuracy =   0.9116  loss =  13.8782\n",
      "testing  :  599  accuracy =   0.9117  loss =  13.7984\n",
      "testing  :  600  accuracy =   0.9117  loss =  13.8622\n",
      "testing  :  601  accuracy =   0.9106  loss =  13.7961\n",
      "testing  :  602  accuracy =   0.9086  loss =  14.3257\n",
      "testing  :  603  accuracy =   0.9112  loss =  13.8443\n",
      "testing  :  604  accuracy =   0.9138  loss =  13.832\n",
      "testing  :  605  accuracy =   0.9125  loss =  13.7872\n",
      "testing  :  606  accuracy =   0.9137  loss =  13.6731\n",
      "testing  :  607  accuracy =   0.9150  loss =  13.6822\n",
      "testing  :  608  accuracy =   0.9153  loss =  13.6251\n",
      "testing  :  609  accuracy =   0.9152  loss =  13.555\n",
      "testing  :  610  accuracy =   0.9151  loss =  13.5216\n",
      "testing  :  611  accuracy =   0.9158  loss =  13.4941\n",
      "testing  :  612  accuracy =   0.9162  loss =  13.5114\n",
      "testing  :  613  accuracy =   0.9148  loss =  13.5389\n",
      "testing  :  614  accuracy =   0.9147  loss =  13.5851\n",
      "testing  :  615  accuracy =   0.9142  loss =  13.5855\n",
      "testing  :  616  accuracy =   0.9137  loss =  13.622\n",
      "testing  :  617  accuracy =   0.9145  loss =  13.683\n",
      "testing  :  618  accuracy =   0.9140  loss =  13.5575\n",
      "testing  :  619  accuracy =   0.9151  loss =  13.581\n",
      "testing  :  620  accuracy =   0.9142  loss =  13.6253\n",
      "testing  :  621  accuracy =   0.9158  loss =  13.5065\n",
      "testing  :  622  accuracy =   0.9147  loss =  13.5767\n",
      "testing  :  623  accuracy =   0.9143  loss =  13.6493\n",
      "testing  :  624  accuracy =   0.9131  loss =  13.579\n",
      "testing  :  625  accuracy =   0.9134  loss =  13.6902\n",
      "testing  :  626  accuracy =   0.9115  loss =  13.6691\n",
      "testing  :  627  accuracy =   0.9136  loss =  13.5111\n",
      "testing  :  628  accuracy =   0.9142  loss =  13.5318\n",
      "testing  :  629  accuracy =   0.9141  loss =  13.5797\n",
      "testing  :  630  accuracy =   0.9138  loss =  13.5174\n",
      "testing  :  631  accuracy =   0.9153  loss =  13.5545\n",
      "testing  :  632  accuracy =   0.9140  loss =  13.5599\n",
      "testing  :  633  accuracy =   0.9146  loss =  13.488\n",
      "testing  :  634  accuracy =   0.9142  loss =  13.6494\n",
      "testing  :  635  accuracy =   0.9153  loss =  13.5733\n",
      "testing  :  636  accuracy =   0.9136  loss =  13.6237\n",
      "testing  :  637  accuracy =   0.9147  loss =  13.6087\n",
      "testing  :  638  accuracy =   0.9156  loss =  13.6961\n",
      "testing  :  639  accuracy =   0.9124  loss =  13.9601\n",
      "testing  :  640  accuracy =   0.9126  loss =  13.8105\n",
      "testing  :  641  accuracy =   0.9133  loss =  13.6509\n",
      "testing  :  642  accuracy =   0.9146  loss =  13.55\n",
      "testing  :  643  accuracy =   0.9135  loss =  13.7589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  644  accuracy =   0.9146  loss =  13.5629\n",
      "testing  :  645  accuracy =   0.9152  loss =  13.483\n",
      "testing  :  646  accuracy =   0.9138  loss =  13.6048\n",
      "testing  :  647  accuracy =   0.9131  loss =  13.5977\n",
      "testing  :  648  accuracy =   0.9130  loss =  13.6832\n",
      "testing  :  649  accuracy =   0.9139  loss =  13.6319\n",
      "testing  :  650  accuracy =   0.9137  loss =  13.5639\n",
      "testing  :  651  accuracy =   0.9117  loss =  13.79\n",
      "testing  :  652  accuracy =   0.9123  loss =  13.7712\n",
      "testing  :  653  accuracy =   0.9122  loss =  13.7905\n",
      "testing  :  654  accuracy =   0.9119  loss =  13.9219\n",
      "testing  :  655  accuracy =   0.9124  loss =  13.7614\n",
      "testing  :  656  accuracy =   0.9126  loss =  13.7706\n",
      "testing  :  657  accuracy =   0.9078  loss =  14.4413\n",
      "testing  :  658  accuracy =   0.9125  loss =  13.6501\n",
      "testing  :  659  accuracy =   0.9125  loss =  14.001\n",
      "testing  :  660  accuracy =   0.9144  loss =  13.6231\n",
      "testing  :  661  accuracy =   0.9139  loss =  13.5876\n",
      "testing  :  662  accuracy =   0.9136  loss =  13.524\n",
      "testing  :  663  accuracy =   0.9147  loss =  13.5232\n",
      "testing  :  664  accuracy =   0.9144  loss =  13.5354\n",
      "testing  :  665  accuracy =   0.9151  loss =  13.4614\n",
      "testing  :  666  accuracy =   0.9152  loss =  13.4832\n",
      "testing  :  667  accuracy =   0.9174  loss =  13.4326\n",
      "testing  :  668  accuracy =   0.9156  loss =  13.5647\n",
      "testing  :  669  accuracy =   0.9176  loss =  13.3874\n",
      "testing  :  670  accuracy =   0.9170  loss =  13.3347\n",
      "testing  :  671  accuracy =   0.9154  loss =  13.4462\n",
      "testing  :  672  accuracy =   0.9137  loss =  13.73\n",
      "testing  :  673  accuracy =   0.9160  loss =  13.4314\n",
      "testing  :  674  accuracy =   0.9170  loss =  13.4477\n",
      "testing  :  675  accuracy =   0.9156  loss =  13.5396\n",
      "testing  :  676  accuracy =   0.9153  loss =  13.4405\n",
      "testing  :  677  accuracy =   0.9150  loss =  13.491\n",
      "testing  :  678  accuracy =   0.9144  loss =  13.4904\n",
      "testing  :  679  accuracy =   0.9141  loss =  13.6508\n",
      "testing  :  680  accuracy =   0.9130  loss =  13.6152\n",
      "testing  :  681  accuracy =   0.9143  loss =  13.4901\n",
      "testing  :  682  accuracy =   0.9114  loss =  13.7815\n",
      "testing  :  683  accuracy =   0.9129  loss =  13.6671\n",
      "testing  :  684  accuracy =   0.9148  loss =  13.608\n",
      "testing  :  685  accuracy =   0.9153  loss =  13.443\n",
      "testing  :  686  accuracy =   0.9163  loss =  13.2645\n",
      "testing  :  687  accuracy =   0.9156  loss =  13.3335\n",
      "testing  :  688  accuracy =   0.9160  loss =  13.3256\n",
      "testing  :  689  accuracy =   0.9149  loss =  13.4848\n",
      "testing  :  690  accuracy =   0.9145  loss =  13.3268\n",
      "testing  :  691  accuracy =   0.9155  loss =  13.3284\n",
      "testing  :  692  accuracy =   0.9157  loss =  13.3126\n",
      "testing  :  693  accuracy =   0.9154  loss =  13.368\n",
      "testing  :  694  accuracy =   0.9159  loss =  13.3073\n",
      "testing  :  695  accuracy =   0.9157  loss =  13.3471\n",
      "testing  :  696  accuracy =   0.9159  loss =  13.4173\n",
      "testing  :  697  accuracy =   0.9147  loss =  13.4778\n",
      "testing  :  698  accuracy =   0.9122  loss =  13.6931\n",
      "testing  :  699  accuracy =   0.9138  loss =  13.4691\n",
      "testing  :  700  accuracy =   0.9134  loss =  13.5372\n",
      "testing  :  701  accuracy =   0.9140  loss =  13.4239\n",
      "testing  :  702  accuracy =   0.9140  loss =  13.4212\n",
      "testing  :  703  accuracy =   0.9147  loss =  13.394\n",
      "testing  :  704  accuracy =   0.9149  loss =  13.3714\n",
      "testing  :  705  accuracy =   0.9141  loss =  13.4827\n",
      "testing  :  706  accuracy =   0.9128  loss =  13.5282\n",
      "testing  :  707  accuracy =   0.9142  loss =  13.5447\n",
      "testing  :  708  accuracy =   0.9151  loss =  13.5451\n",
      "testing  :  709  accuracy =   0.9157  loss =  13.4314\n",
      "testing  :  710  accuracy =   0.9164  loss =  13.2541\n",
      "testing  :  711  accuracy =   0.9165  loss =  13.4393\n",
      "testing  :  712  accuracy =   0.9160  loss =  13.3139\n",
      "testing  :  713  accuracy =   0.9171  loss =  13.232\n",
      "testing  :  714  accuracy =   0.9164  loss =  13.1968\n",
      "testing  :  715  accuracy =   0.9151  loss =  13.5145\n",
      "testing  :  716  accuracy =   0.9127  loss =  13.7196\n",
      "testing  :  717  accuracy =   0.9143  loss =  13.5422\n",
      "testing  :  718  accuracy =   0.9154  loss =  13.2537\n",
      "testing  :  719  accuracy =   0.9152  loss =  13.4038\n",
      "testing  :  720  accuracy =   0.9132  loss =  13.5183\n",
      "testing  :  721  accuracy =   0.9166  loss =  13.2618\n",
      "testing  :  722  accuracy =   0.9160  loss =  13.2911\n",
      "testing  :  723  accuracy =   0.9169  loss =  13.1999\n",
      "testing  :  724  accuracy =   0.9159  loss =  13.2199\n",
      "testing  :  725  accuracy =   0.9147  loss =  13.241\n",
      "testing  :  726  accuracy =   0.9132  loss =  13.4288\n",
      "testing  :  727  accuracy =   0.9152  loss =  13.3571\n",
      "testing  :  728  accuracy =   0.9158  loss =  13.2174\n",
      "testing  :  729  accuracy =   0.9158  loss =  13.1877\n",
      "testing  :  730  accuracy =   0.9156  loss =  13.2113\n",
      "testing  :  731  accuracy =   0.9149  loss =  13.3316\n",
      "testing  :  732  accuracy =   0.9128  loss =  13.3666\n",
      "testing  :  733  accuracy =   0.9134  loss =  13.408\n",
      "testing  :  734  accuracy =   0.9140  loss =  13.3771\n",
      "testing  :  735  accuracy =   0.9150  loss =  13.3497\n",
      "testing  :  736  accuracy =   0.9150  loss =  13.2388\n",
      "testing  :  737  accuracy =   0.9125  loss =  13.3358\n",
      "testing  :  738  accuracy =   0.9149  loss =  13.2166\n",
      "testing  :  739  accuracy =   0.9144  loss =  13.346\n",
      "testing  :  740  accuracy =   0.9158  loss =  13.2922\n",
      "testing  :  741  accuracy =   0.9153  loss =  13.2253\n",
      "testing  :  742  accuracy =   0.9160  loss =  13.1827\n",
      "testing  :  743  accuracy =   0.9149  loss =  13.2178\n",
      "testing  :  744  accuracy =   0.9150  loss =  13.3441\n",
      "testing  :  745  accuracy =   0.9157  loss =  13.3467\n",
      "testing  :  746  accuracy =   0.9126  loss =  13.5031\n",
      "testing  :  747  accuracy =   0.9119  loss =  13.771\n",
      "testing  :  748  accuracy =   0.9144  loss =  13.3833\n",
      "testing  :  749  accuracy =   0.9167  loss =  13.1823\n",
      "testing  :  750  accuracy =   0.9166  loss =  13.2629\n",
      "testing  :  751  accuracy =   0.9160  loss =  13.2449\n",
      "testing  :  752  accuracy =   0.9152  loss =  13.2676\n",
      "testing  :  753  accuracy =   0.9169  loss =  13.1137\n",
      "testing  :  754  accuracy =   0.9166  loss =  13.1845\n",
      "testing  :  755  accuracy =   0.9152  loss =  13.3592\n",
      "testing  :  756  accuracy =   0.9134  loss =  13.4882\n",
      "testing  :  757  accuracy =   0.9158  loss =  13.3155\n",
      "testing  :  758  accuracy =   0.9107  loss =  13.7828\n",
      "testing  :  759  accuracy =   0.9151  loss =  13.2666\n",
      "testing  :  760  accuracy =   0.9135  loss =  13.4072\n",
      "testing  :  761  accuracy =   0.9153  loss =  13.2378\n",
      "testing  :  762  accuracy =   0.9141  loss =  13.2454\n",
      "testing  :  763  accuracy =   0.9158  loss =  13.1756\n",
      "testing  :  764  accuracy =   0.9165  loss =  13.1782\n",
      "testing  :  765  accuracy =   0.9151  loss =  13.22\n",
      "testing  :  766  accuracy =   0.9171  loss =  13.1356\n",
      "testing  :  767  accuracy =   0.9165  loss =  13.194\n",
      "testing  :  768  accuracy =   0.9168  loss =  13.0978\n",
      "testing  :  769  accuracy =   0.9171  loss =  13.0423\n",
      "testing  :  770  accuracy =   0.9166  loss =  13.1137\n",
      "testing  :  771  accuracy =   0.9157  loss =  13.0968\n",
      "testing  :  772  accuracy =   0.9178  loss =  13.0924\n",
      "testing  :  773  accuracy =   0.9164  loss =  13.1125\n",
      "testing  :  774  accuracy =   0.9160  loss =  13.2654\n",
      "testing  :  775  accuracy =   0.9184  loss =  13.0326\n",
      "testing  :  776  accuracy =   0.9179  loss =  12.9712\n",
      "testing  :  777  accuracy =   0.9177  loss =  13.0955\n",
      "testing  :  778  accuracy =   0.9189  loss =  12.978\n",
      "testing  :  779  accuracy =   0.9174  loss =  13.3373\n",
      "testing  :  780  accuracy =   0.9183  loss =  13.0224\n",
      "testing  :  781  accuracy =   0.9190  loss =  12.9554\n",
      "testing  :  782  accuracy =   0.9177  loss =  13.1139\n",
      "testing  :  783  accuracy =   0.9174  loss =  13.0266\n",
      "testing  :  784  accuracy =   0.9167  loss =  12.9886\n",
      "testing  :  785  accuracy =   0.9176  loss =  13.033\n",
      "testing  :  786  accuracy =   0.9169  loss =  13.0295\n",
      "testing  :  787  accuracy =   0.9179  loss =  12.981\n",
      "testing  :  788  accuracy =   0.9190  loss =  12.9491\n",
      "testing  :  789  accuracy =   0.9172  loss =  13.0018\n",
      "testing  :  790  accuracy =   0.9173  loss =  13.0645\n",
      "testing  :  791  accuracy =   0.9174  loss =  13.0899\n",
      "testing  :  792  accuracy =   0.9170  loss =  13.0164\n",
      "testing  :  793  accuracy =   0.9182  loss =  12.9654\n",
      "testing  :  794  accuracy =   0.9174  loss =  12.9806\n",
      "testing  :  795  accuracy =   0.9175  loss =  13.0041\n",
      "testing  :  796  accuracy =   0.9163  loss =  13.1212\n",
      "testing  :  797  accuracy =   0.9165  loss =  13.0299\n",
      "testing  :  798  accuracy =   0.9160  loss =  13.05\n",
      "testing  :  799  accuracy =   0.9145  loss =  13.1626\n",
      "testing  :  800  accuracy =   0.9149  loss =  13.2328\n",
      "testing  :  801  accuracy =   0.9168  loss =  13.0862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  802  accuracy =   0.9151  loss =  13.2788\n",
      "testing  :  803  accuracy =   0.9146  loss =  13.2461\n",
      "testing  :  804  accuracy =   0.9154  loss =  13.1337\n",
      "testing  :  805  accuracy =   0.9169  loss =  13.0236\n",
      "testing  :  806  accuracy =   0.9166  loss =  13.0606\n",
      "testing  :  807  accuracy =   0.9190  loss =  13.0466\n",
      "testing  :  808  accuracy =   0.9178  loss =  12.966\n",
      "testing  :  809  accuracy =   0.9181  loss =  12.9573\n",
      "testing  :  810  accuracy =   0.9173  loss =  13.0445\n",
      "testing  :  811  accuracy =   0.9189  loss =  12.9405\n",
      "testing  :  812  accuracy =   0.9172  loss =  12.9169\n",
      "testing  :  813  accuracy =   0.9159  loss =  13.0578\n",
      "testing  :  814  accuracy =   0.9167  loss =  13.116\n",
      "testing  :  815  accuracy =   0.9173  loss =  13.0108\n",
      "testing  :  816  accuracy =   0.9173  loss =  13.0549\n",
      "testing  :  817  accuracy =   0.9187  loss =  13.007\n",
      "testing  :  818  accuracy =   0.9195  loss =  12.9543\n",
      "testing  :  819  accuracy =   0.9183  loss =  13.0236\n",
      "testing  :  820  accuracy =   0.9191  loss =  12.9157\n",
      "testing  :  821  accuracy =   0.9174  loss =  13.0701\n",
      "testing  :  822  accuracy =   0.9158  loss =  13.2679\n",
      "testing  :  823  accuracy =   0.9175  loss =  13.1633\n",
      "testing  :  824  accuracy =   0.9157  loss =  13.3486\n",
      "testing  :  825  accuracy =   0.9183  loss =  13.0071\n",
      "testing  :  826  accuracy =   0.9174  loss =  12.9744\n",
      "testing  :  827  accuracy =   0.9170  loss =  13.1174\n",
      "testing  :  828  accuracy =   0.9187  loss =  12.9816\n",
      "testing  :  829  accuracy =   0.9192  loss =  12.939\n",
      "testing  :  830  accuracy =   0.9194  loss =  12.9647\n",
      "testing  :  831  accuracy =   0.9191  loss =  12.9256\n",
      "testing  :  832  accuracy =   0.9181  loss =  13.1088\n",
      "testing  :  833  accuracy =   0.9188  loss =  13.0712\n",
      "testing  :  834  accuracy =   0.9198  loss =  12.975\n",
      "testing  :  835  accuracy =   0.9188  loss =  12.9236\n",
      "testing  :  836  accuracy =   0.9182  loss =  13.0131\n",
      "testing  :  837  accuracy =   0.9195  loss =  12.9655\n",
      "testing  :  838  accuracy =   0.9193  loss =  12.9378\n",
      "testing  :  839  accuracy =   0.9191  loss =  13.0865\n",
      "testing  :  840  accuracy =   0.9199  loss =  13.0175\n",
      "testing  :  841  accuracy =   0.9197  loss =  12.9754\n",
      "testing  :  842  accuracy =   0.9184  loss =  13.1076\n",
      "testing  :  843  accuracy =   0.9184  loss =  12.9213\n",
      "testing  :  844  accuracy =   0.9184  loss =  13.0657\n",
      "testing  :  845  accuracy =   0.9172  loss =  13.0473\n",
      "testing  :  846  accuracy =   0.9175  loss =  13.0859\n",
      "testing  :  847  accuracy =   0.9157  loss =  13.4463\n",
      "testing  :  848  accuracy =   0.9145  loss =  13.4983\n",
      "testing  :  849  accuracy =   0.9172  loss =  12.9491\n",
      "testing  :  850  accuracy =   0.9166  loss =  12.9415\n",
      "testing  :  851  accuracy =   0.9171  loss =  12.9908\n",
      "testing  :  852  accuracy =   0.9147  loss =  13.1258\n",
      "testing  :  853  accuracy =   0.9177  loss =  12.9662\n",
      "testing  :  854  accuracy =   0.9169  loss =  13.0564\n",
      "testing  :  855  accuracy =   0.9182  loss =  12.9158\n",
      "testing  :  856  accuracy =   0.9180  loss =  13.0126\n",
      "testing  :  857  accuracy =   0.9171  loss =  13.1352\n",
      "testing  :  858  accuracy =   0.9179  loss =  12.9217\n",
      "testing  :  859  accuracy =   0.9165  loss =  12.8956\n",
      "testing  :  860  accuracy =   0.9172  loss =  13.0343\n",
      "testing  :  861  accuracy =   0.9169  loss =  13.0008\n",
      "testing  :  862  accuracy =   0.9169  loss =  12.9491\n",
      "testing  :  863  accuracy =   0.9186  loss =  12.8129\n",
      "testing  :  864  accuracy =   0.9201  loss =  12.8596\n",
      "testing  :  865  accuracy =   0.9191  loss =  12.9069\n",
      "testing  :  866  accuracy =   0.9188  loss =  12.8234\n",
      "testing  :  867  accuracy =   0.9186  loss =  12.9329\n",
      "testing  :  868  accuracy =   0.9175  loss =  13.0475\n",
      "testing  :  869  accuracy =   0.9204  loss =  12.8862\n",
      "testing  :  870  accuracy =   0.9186  loss =  12.9674\n",
      "testing  :  871  accuracy =   0.9169  loss =  13.0878\n",
      "testing  :  872  accuracy =   0.9179  loss =  12.9235\n",
      "testing  :  873  accuracy =   0.9190  loss =  12.8026\n",
      "testing  :  874  accuracy =   0.9198  loss =  12.7546\n",
      "testing  :  875  accuracy =   0.9189  loss =  12.8066\n",
      "testing  :  876  accuracy =   0.9162  loss =  13.2685\n",
      "testing  :  877  accuracy =   0.9165  loss =  13.157\n",
      "testing  :  878  accuracy =   0.9176  loss =  13.1499\n",
      "testing  :  879  accuracy =   0.9164  loss =  13.1626\n",
      "testing  :  880  accuracy =   0.9185  loss =  13.0127\n",
      "testing  :  881  accuracy =   0.9192  loss =  12.9687\n",
      "testing  :  882  accuracy =   0.9178  loss =  13.1769\n",
      "testing  :  883  accuracy =   0.9163  loss =  13.2623\n",
      "testing  :  884  accuracy =   0.9178  loss =  13.0825\n",
      "testing  :  885  accuracy =   0.9174  loss =  13.0329\n",
      "testing  :  886  accuracy =   0.9192  loss =  12.7057\n",
      "testing  :  887  accuracy =   0.9171  loss =  13.0893\n",
      "testing  :  888  accuracy =   0.9196  loss =  12.7257\n",
      "testing  :  889  accuracy =   0.9198  loss =  12.7221\n",
      "testing  :  890  accuracy =   0.9183  loss =  12.9595\n",
      "testing  :  891  accuracy =   0.9194  loss =  12.8012\n",
      "testing  :  892  accuracy =   0.9185  loss =  12.7324\n",
      "testing  :  893  accuracy =   0.9179  loss =  12.7237\n",
      "testing  :  894  accuracy =   0.9166  loss =  13.1655\n",
      "testing  :  895  accuracy =   0.9191  loss =  12.8704\n",
      "testing  :  896  accuracy =   0.9176  loss =  13.1144\n",
      "testing  :  897  accuracy =   0.9167  loss =  12.9266\n",
      "testing  :  898  accuracy =   0.9173  loss =  12.9409\n",
      "testing  :  899  accuracy =   0.9176  loss =  13.0033\n",
      "testing  :  900  accuracy =   0.9171  loss =  13.034\n",
      "testing  :  901  accuracy =   0.9173  loss =  12.882\n",
      "testing  :  902  accuracy =   0.9173  loss =  13.0142\n",
      "testing  :  903  accuracy =   0.9175  loss =  12.8653\n",
      "testing  :  904  accuracy =   0.9169  loss =  12.9057\n",
      "testing  :  905  accuracy =   0.9174  loss =  12.8678\n",
      "testing  :  906  accuracy =   0.9171  loss =  12.8163\n",
      "testing  :  907  accuracy =   0.9172  loss =  12.858\n",
      "testing  :  908  accuracy =   0.9166  loss =  12.7797\n",
      "testing  :  909  accuracy =   0.9175  loss =  12.875\n",
      "testing  :  910  accuracy =   0.9174  loss =  12.8518\n",
      "testing  :  911  accuracy =   0.9185  loss =  12.8366\n",
      "testing  :  912  accuracy =   0.9179  loss =  12.8679\n",
      "testing  :  913  accuracy =   0.9179  loss =  12.8876\n",
      "testing  :  914  accuracy =   0.9174  loss =  12.9386\n",
      "testing  :  915  accuracy =   0.9195  loss =  12.7139\n",
      "testing  :  916  accuracy =   0.9197  loss =  12.6865\n",
      "testing  :  917  accuracy =   0.9180  loss =  12.8056\n",
      "testing  :  918  accuracy =   0.9173  loss =  13.0589\n",
      "testing  :  919  accuracy =   0.9193  loss =  12.7267\n",
      "testing  :  920  accuracy =   0.9191  loss =  12.7342\n",
      "testing  :  921  accuracy =   0.9187  loss =  12.8422\n",
      "testing  :  922  accuracy =   0.9192  loss =  12.8399\n",
      "testing  :  923  accuracy =   0.9170  loss =  13.1542\n",
      "testing  :  924  accuracy =   0.9177  loss =  12.9621\n",
      "testing  :  925  accuracy =   0.9180  loss =  12.9343\n",
      "testing  :  926  accuracy =   0.9170  loss =  12.9412\n",
      "testing  :  927  accuracy =   0.9178  loss =  12.9906\n",
      "testing  :  928  accuracy =   0.9164  loss =  13.192\n",
      "testing  :  929  accuracy =   0.9187  loss =  12.8112\n",
      "testing  :  930  accuracy =   0.9179  loss =  12.9499\n",
      "testing  :  931  accuracy =   0.9180  loss =  12.9817\n",
      "testing  :  932  accuracy =   0.9183  loss =  12.8284\n",
      "testing  :  933  accuracy =   0.9182  loss =  12.798\n",
      "testing  :  934  accuracy =   0.9176  loss =  12.9142\n",
      "testing  :  935  accuracy =   0.9177  loss =  12.8368\n",
      "testing  :  936  accuracy =   0.9198  loss =  12.6605\n",
      "testing  :  937  accuracy =   0.9191  loss =  12.7591\n",
      "testing  :  938  accuracy =   0.9190  loss =  12.8297\n",
      "testing  :  939  accuracy =   0.9168  loss =  13.0105\n",
      "testing  :  940  accuracy =   0.9183  loss =  12.8236\n",
      "testing  :  941  accuracy =   0.9172  loss =  12.8716\n",
      "testing  :  942  accuracy =   0.9157  loss =  13.2141\n",
      "testing  :  943  accuracy =   0.9181  loss =  13.0678\n",
      "testing  :  944  accuracy =   0.9192  loss =  12.9042\n",
      "testing  :  945  accuracy =   0.9188  loss =  12.8204\n",
      "testing  :  946  accuracy =   0.9185  loss =  12.7304\n",
      "testing  :  947  accuracy =   0.9189  loss =  12.7201\n",
      "testing  :  948  accuracy =   0.9184  loss =  12.6811\n",
      "testing  :  949  accuracy =   0.9172  loss =  12.8798\n",
      "testing  :  950  accuracy =   0.9192  loss =  12.9362\n",
      "testing  :  951  accuracy =   0.9170  loss =  13.104\n",
      "testing  :  952  accuracy =   0.9188  loss =  12.8622\n",
      "testing  :  953  accuracy =   0.9185  loss =  12.7882\n",
      "testing  :  954  accuracy =   0.9188  loss =  12.8784\n",
      "testing  :  955  accuracy =   0.9182  loss =  12.9412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  956  accuracy =   0.9191  loss =  13.0617\n",
      "testing  :  957  accuracy =   0.9185  loss =  12.8415\n",
      "testing  :  958  accuracy =   0.9189  loss =  12.8827\n",
      "testing  :  959  accuracy =   0.9168  loss =  13.0482\n",
      "testing  :  960  accuracy =   0.9182  loss =  12.9328\n",
      "testing  :  961  accuracy =   0.9195  loss =  12.7445\n",
      "testing  :  962  accuracy =   0.9185  loss =  12.7642\n",
      "testing  :  963  accuracy =   0.9192  loss =  12.67\n",
      "testing  :  964  accuracy =   0.9207  loss =  12.659\n",
      "testing  :  965  accuracy =   0.9201  loss =  12.7322\n",
      "testing  :  966  accuracy =   0.9192  loss =  12.8297\n",
      "testing  :  967  accuracy =   0.9194  loss =  12.7345\n",
      "testing  :  968  accuracy =   0.9201  loss =  12.6503\n",
      "testing  :  969  accuracy =   0.9203  loss =  12.6398\n",
      "testing  :  970  accuracy =   0.9198  loss =  12.6579\n",
      "testing  :  971  accuracy =   0.9200  loss =  12.6572\n",
      "testing  :  972  accuracy =   0.9202  loss =  12.683\n",
      "testing  :  973  accuracy =   0.9197  loss =  12.7302\n",
      "testing  :  974  accuracy =   0.9205  loss =  12.6784\n",
      "testing  :  975  accuracy =   0.9200  loss =  12.827\n",
      "testing  :  976  accuracy =   0.9205  loss =  12.7336\n",
      "testing  :  977  accuracy =   0.9194  loss =  12.8344\n",
      "testing  :  978  accuracy =   0.9183  loss =  12.9323\n",
      "testing  :  979  accuracy =   0.9178  loss =  12.7871\n",
      "testing  :  980  accuracy =   0.9176  loss =  12.7721\n",
      "testing  :  981  accuracy =   0.9186  loss =  12.7661\n",
      "testing  :  982  accuracy =   0.9185  loss =  12.8475\n",
      "testing  :  983  accuracy =   0.9189  loss =  12.7857\n",
      "testing  :  984  accuracy =   0.9179  loss =  12.96\n",
      "testing  :  985  accuracy =   0.9182  loss =  12.8984\n",
      "testing  :  986  accuracy =   0.9158  loss =  13.0363\n",
      "testing  :  987  accuracy =   0.9169  loss =  12.9935\n",
      "testing  :  988  accuracy =   0.9154  loss =  13.2614\n",
      "testing  :  989  accuracy =   0.9171  loss =  13.1945\n",
      "testing  :  990  accuracy =   0.9175  loss =  12.9016\n",
      "testing  :  991  accuracy =   0.9193  loss =  12.8116\n",
      "testing  :  992  accuracy =   0.9194  loss =  12.7105\n",
      "testing  :  993  accuracy =   0.9189  loss =  12.9086\n",
      "testing  :  994  accuracy =   0.9207  loss =  12.8846\n",
      "testing  :  995  accuracy =   0.9192  loss =  12.952\n",
      "testing  :  996  accuracy =   0.9194  loss =  12.755\n",
      "testing  :  997  accuracy =   0.9190  loss =  12.7499\n",
      "testing  :  998  accuracy =   0.9174  loss =  12.8067\n",
      "testing  :  999  accuracy =   0.9189  loss =  12.5792\n",
      "testing  :  1000  accuracy =   0.9189  loss =  12.6256\n",
      "testing  :  1001  accuracy =   0.9194  loss =  12.6122\n",
      "testing  :  1002  accuracy =   0.9174  loss =  12.9199\n",
      "testing  :  1003  accuracy =   0.9178  loss =  12.8945\n",
      "testing  :  1004  accuracy =   0.9191  loss =  12.9178\n",
      "testing  :  1005  accuracy =   0.9192  loss =  12.7171\n",
      "testing  :  1006  accuracy =   0.9189  loss =  12.685\n",
      "testing  :  1007  accuracy =   0.9186  loss =  12.7136\n",
      "testing  :  1008  accuracy =   0.9186  loss =  12.6631\n",
      "testing  :  1009  accuracy =   0.9194  loss =  12.6806\n",
      "testing  :  1010  accuracy =   0.9189  loss =  12.7112\n",
      "testing  :  1011  accuracy =   0.9188  loss =  12.655\n",
      "testing  :  1012  accuracy =   0.9194  loss =  12.7106\n",
      "testing  :  1013  accuracy =   0.9194  loss =  12.6717\n",
      "testing  :  1014  accuracy =   0.9196  loss =  12.7088\n",
      "testing  :  1015  accuracy =   0.9188  loss =  12.8395\n",
      "testing  :  1016  accuracy =   0.9189  loss =  12.7997\n",
      "testing  :  1017  accuracy =   0.9185  loss =  12.8524\n",
      "testing  :  1018  accuracy =   0.9185  loss =  12.8167\n",
      "testing  :  1019  accuracy =   0.9186  loss =  12.8249\n",
      "testing  :  1020  accuracy =   0.9182  loss =  12.8199\n",
      "testing  :  1021  accuracy =   0.9170  loss =  12.7952\n",
      "testing  :  1022  accuracy =   0.9190  loss =  12.6998\n",
      "testing  :  1023  accuracy =   0.9182  loss =  12.7312\n",
      "testing  :  1024  accuracy =   0.9201  loss =  12.6356\n",
      "testing  :  1025  accuracy =   0.9183  loss =  12.6851\n",
      "testing  :  1026  accuracy =   0.9184  loss =  12.6508\n",
      "testing  :  1027  accuracy =   0.9179  loss =  12.7441\n",
      "testing  :  1028  accuracy =   0.9177  loss =  12.7324\n",
      "testing  :  1029  accuracy =   0.9172  loss =  12.7632\n",
      "testing  :  1030  accuracy =   0.9178  loss =  12.6644\n",
      "testing  :  1031  accuracy =   0.9160  loss =  12.9966\n",
      "testing  :  1032  accuracy =   0.9169  loss =  12.9138\n",
      "testing  :  1033  accuracy =   0.9190  loss =  12.7\n",
      "testing  :  1034  accuracy =   0.9193  loss =  12.62\n",
      "testing  :  1035  accuracy =   0.9183  loss =  12.5919\n",
      "testing  :  1036  accuracy =   0.9187  loss =  12.5956\n",
      "testing  :  1037  accuracy =   0.9194  loss =  12.6723\n",
      "testing  :  1038  accuracy =   0.9187  loss =  12.8762\n",
      "testing  :  1039  accuracy =   0.9181  loss =  12.9506\n",
      "testing  :  1040  accuracy =   0.9192  loss =  12.714\n",
      "testing  :  1041  accuracy =   0.9186  loss =  12.9015\n",
      "testing  :  1042  accuracy =   0.9191  loss =  12.6052\n",
      "testing  :  1043  accuracy =   0.9190  loss =  12.6837\n",
      "testing  :  1044  accuracy =   0.9185  loss =  12.6739\n",
      "testing  :  1045  accuracy =   0.9175  loss =  12.8112\n",
      "testing  :  1046  accuracy =   0.9175  loss =  12.7395\n",
      "testing  :  1047  accuracy =   0.9171  loss =  12.8233\n",
      "testing  :  1048  accuracy =   0.9179  loss =  12.8709\n",
      "testing  :  1049  accuracy =   0.9166  loss =  12.8289\n",
      "testing  :  1050  accuracy =   0.9189  loss =  12.6165\n",
      "testing  :  1051  accuracy =   0.9200  loss =  12.5785\n",
      "testing  :  1052  accuracy =   0.9179  loss =  12.8847\n",
      "testing  :  1053  accuracy =   0.9183  loss =  12.871\n",
      "testing  :  1054  accuracy =   0.9187  loss =  12.8307\n",
      "testing  :  1055  accuracy =   0.9196  loss =  12.6797\n",
      "testing  :  1056  accuracy =   0.9184  loss =  12.782\n",
      "testing  :  1057  accuracy =   0.9187  loss =  12.8113\n",
      "testing  :  1058  accuracy =   0.9185  loss =  12.9364\n",
      "testing  :  1059  accuracy =   0.9194  loss =  12.6298\n",
      "testing  :  1060  accuracy =   0.9188  loss =  12.6782\n",
      "testing  :  1061  accuracy =   0.9211  loss =  12.5719\n",
      "testing  :  1062  accuracy =   0.9201  loss =  12.5392\n",
      "testing  :  1063  accuracy =   0.9211  loss =  12.5555\n",
      "testing  :  1064  accuracy =   0.9209  loss =  12.674\n",
      "testing  :  1065  accuracy =   0.9208  loss =  12.6765\n",
      "testing  :  1066  accuracy =   0.9194  loss =  12.569\n",
      "testing  :  1067  accuracy =   0.9187  loss =  12.6123\n",
      "testing  :  1068  accuracy =   0.9195  loss =  12.661\n",
      "testing  :  1069  accuracy =   0.9189  loss =  12.6607\n",
      "testing  :  1070  accuracy =   0.9201  loss =  12.59\n",
      "testing  :  1071  accuracy =   0.9179  loss =  12.7721\n",
      "testing  :  1072  accuracy =   0.9190  loss =  12.6622\n",
      "testing  :  1073  accuracy =   0.9184  loss =  12.6964\n",
      "testing  :  1074  accuracy =   0.9191  loss =  12.7331\n",
      "testing  :  1075  accuracy =   0.9181  loss =  12.7907\n",
      "testing  :  1076  accuracy =   0.9190  loss =  12.6934\n",
      "testing  :  1077  accuracy =   0.9186  loss =  12.7072\n",
      "testing  :  1078  accuracy =   0.9192  loss =  12.6406\n",
      "testing  :  1079  accuracy =   0.9197  loss =  12.541\n",
      "testing  :  1080  accuracy =   0.9199  loss =  12.5956\n",
      "testing  :  1081  accuracy =   0.9194  loss =  12.6563\n",
      "testing  :  1082  accuracy =   0.9153  loss =  13.1275\n",
      "testing  :  1083  accuracy =   0.9195  loss =  12.6969\n",
      "testing  :  1084  accuracy =   0.9199  loss =  12.5433\n",
      "testing  :  1085  accuracy =   0.9198  loss =  12.6199\n",
      "testing  :  1086  accuracy =   0.9194  loss =  12.6106\n",
      "testing  :  1087  accuracy =   0.9202  loss =  12.5962\n",
      "testing  :  1088  accuracy =   0.9196  loss =  12.6039\n",
      "testing  :  1089  accuracy =   0.9187  loss =  12.6974\n",
      "testing  :  1090  accuracy =   0.9188  loss =  12.5864\n",
      "testing  :  1091  accuracy =   0.9197  loss =  12.5888\n",
      "testing  :  1092  accuracy =   0.9181  loss =  12.7012\n",
      "testing  :  1093  accuracy =   0.9175  loss =  12.7246\n",
      "testing  :  1094  accuracy =   0.9197  loss =  12.5849\n",
      "testing  :  1095  accuracy =   0.9187  loss =  12.6738\n",
      "testing  :  1096  accuracy =   0.9198  loss =  12.6244\n",
      "testing  :  1097  accuracy =   0.9181  loss =  12.7384\n",
      "testing  :  1098  accuracy =   0.9189  loss =  12.6922\n",
      "testing  :  1099  accuracy =   0.9203  loss =  12.6595\n",
      "testing  :  1100  accuracy =   0.9208  loss =  12.59\n",
      "testing  :  1101  accuracy =   0.9191  loss =  12.6119\n",
      "testing  :  1102  accuracy =   0.9197  loss =  12.6267\n",
      "testing  :  1103  accuracy =   0.9186  loss =  12.701\n",
      "testing  :  1104  accuracy =   0.9181  loss =  12.8609\n",
      "testing  :  1105  accuracy =   0.9164  loss =  12.9341\n",
      "testing  :  1106  accuracy =   0.9174  loss =  12.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1107  accuracy =   0.9176  loss =  12.7727\n",
      "testing  :  1108  accuracy =   0.9172  loss =  12.8232\n",
      "testing  :  1109  accuracy =   0.9178  loss =  12.9618\n",
      "testing  :  1110  accuracy =   0.9185  loss =  12.6289\n",
      "testing  :  1111  accuracy =   0.9189  loss =  12.5501\n",
      "testing  :  1112  accuracy =   0.9192  loss =  12.5496\n",
      "testing  :  1113  accuracy =   0.9198  loss =  12.6254\n",
      "testing  :  1114  accuracy =   0.9194  loss =  12.5715\n",
      "testing  :  1115  accuracy =   0.9190  loss =  12.6816\n",
      "testing  :  1116  accuracy =   0.9203  loss =  12.4399\n",
      "testing  :  1117  accuracy =   0.9192  loss =  12.593\n",
      "testing  :  1118  accuracy =   0.9189  loss =  12.6206\n",
      "testing  :  1119  accuracy =   0.9188  loss =  12.6009\n",
      "testing  :  1120  accuracy =   0.9188  loss =  12.6194\n",
      "testing  :  1121  accuracy =   0.9197  loss =  12.5525\n",
      "testing  :  1122  accuracy =   0.9179  loss =  12.7295\n",
      "testing  :  1123  accuracy =   0.9205  loss =  12.5355\n",
      "testing  :  1124  accuracy =   0.9199  loss =  12.5114\n",
      "testing  :  1125  accuracy =   0.9212  loss =  12.4816\n",
      "testing  :  1126  accuracy =   0.9198  loss =  12.5293\n",
      "testing  :  1127  accuracy =   0.9196  loss =  12.5621\n",
      "testing  :  1128  accuracy =   0.9195  loss =  12.6177\n",
      "testing  :  1129  accuracy =   0.9190  loss =  12.6875\n",
      "testing  :  1130  accuracy =   0.9183  loss =  12.6861\n",
      "testing  :  1131  accuracy =   0.9181  loss =  12.6854\n",
      "testing  :  1132  accuracy =   0.9191  loss =  12.6558\n",
      "testing  :  1133  accuracy =   0.9192  loss =  12.6197\n",
      "testing  :  1134  accuracy =   0.9183  loss =  12.668\n",
      "testing  :  1135  accuracy =   0.9188  loss =  12.7023\n",
      "testing  :  1136  accuracy =   0.9184  loss =  12.6134\n",
      "testing  :  1137  accuracy =   0.9185  loss =  12.6458\n",
      "testing  :  1138  accuracy =   0.9194  loss =  12.6129\n",
      "testing  :  1139  accuracy =   0.9198  loss =  12.6562\n",
      "testing  :  1140  accuracy =   0.9184  loss =  12.7336\n",
      "testing  :  1141  accuracy =   0.9189  loss =  12.7278\n",
      "testing  :  1142  accuracy =   0.9183  loss =  12.7506\n",
      "testing  :  1143  accuracy =   0.9198  loss =  12.6213\n",
      "testing  :  1144  accuracy =   0.9183  loss =  12.5615\n",
      "testing  :  1145  accuracy =   0.9182  loss =  12.61\n",
      "testing  :  1146  accuracy =   0.9206  loss =  12.573\n",
      "testing  :  1147  accuracy =   0.9206  loss =  12.4634\n",
      "testing  :  1148  accuracy =   0.9203  loss =  12.4941\n",
      "testing  :  1149  accuracy =   0.9197  loss =  12.5197\n",
      "testing  :  1150  accuracy =   0.9159  loss =  12.9506\n",
      "testing  :  1151  accuracy =   0.9165  loss =  12.8859\n",
      "testing  :  1152  accuracy =   0.9173  loss =  12.669\n",
      "testing  :  1153  accuracy =   0.9180  loss =  12.6344\n",
      "testing  :  1154  accuracy =   0.9188  loss =  12.4947\n",
      "testing  :  1155  accuracy =   0.9187  loss =  12.5677\n",
      "testing  :  1156  accuracy =   0.9198  loss =  12.5264\n",
      "testing  :  1157  accuracy =   0.9204  loss =  12.4815\n",
      "testing  :  1158  accuracy =   0.9196  loss =  12.607\n",
      "testing  :  1159  accuracy =   0.9202  loss =  12.5649\n",
      "testing  :  1160  accuracy =   0.9195  loss =  12.5979\n",
      "testing  :  1161  accuracy =   0.9195  loss =  12.6353\n",
      "testing  :  1162  accuracy =   0.9190  loss =  12.5418\n",
      "testing  :  1163  accuracy =   0.9184  loss =  12.6339\n",
      "testing  :  1164  accuracy =   0.9190  loss =  12.5961\n",
      "testing  :  1165  accuracy =   0.9169  loss =  12.8291\n",
      "testing  :  1166  accuracy =   0.9179  loss =  12.7635\n",
      "testing  :  1167  accuracy =   0.9177  loss =  12.6512\n",
      "testing  :  1168  accuracy =   0.9168  loss =  12.7507\n",
      "testing  :  1169  accuracy =   0.9175  loss =  12.597\n",
      "testing  :  1170  accuracy =   0.9170  loss =  12.7482\n",
      "testing  :  1171  accuracy =   0.9173  loss =  12.7816\n",
      "testing  :  1172  accuracy =   0.9175  loss =  12.7184\n",
      "testing  :  1173  accuracy =   0.9166  loss =  12.9083\n",
      "testing  :  1174  accuracy =   0.9188  loss =  12.7127\n",
      "testing  :  1175  accuracy =   0.9192  loss =  12.7003\n",
      "testing  :  1176  accuracy =   0.9206  loss =  12.5253\n",
      "testing  :  1177  accuracy =   0.9198  loss =  12.5419\n",
      "testing  :  1178  accuracy =   0.9207  loss =  12.5022\n",
      "testing  :  1179  accuracy =   0.9185  loss =  12.6323\n",
      "testing  :  1180  accuracy =   0.9182  loss =  12.5585\n",
      "testing  :  1181  accuracy =   0.9178  loss =  12.7581\n",
      "testing  :  1182  accuracy =   0.9176  loss =  12.7494\n",
      "testing  :  1183  accuracy =   0.9182  loss =  12.7846\n",
      "testing  :  1184  accuracy =   0.9171  loss =  13.0013\n",
      "testing  :  1185  accuracy =   0.9182  loss =  12.6768\n",
      "testing  :  1186  accuracy =   0.9198  loss =  12.5871\n",
      "testing  :  1187  accuracy =   0.9179  loss =  12.8333\n",
      "testing  :  1188  accuracy =   0.9175  loss =  12.9289\n",
      "testing  :  1189  accuracy =   0.9159  loss =  13.1426\n",
      "testing  :  1190  accuracy =   0.9173  loss =  12.9014\n",
      "testing  :  1191  accuracy =   0.9163  loss =  13.135\n",
      "testing  :  1192  accuracy =   0.9176  loss =  12.7944\n",
      "testing  :  1193  accuracy =   0.9172  loss =  12.8021\n",
      "testing  :  1194  accuracy =   0.9155  loss =  13.035\n",
      "testing  :  1195  accuracy =   0.9170  loss =  12.8011\n",
      "testing  :  1196  accuracy =   0.9174  loss =  12.6671\n",
      "testing  :  1197  accuracy =   0.9159  loss =  12.7561\n",
      "testing  :  1198  accuracy =   0.9182  loss =  12.6417\n",
      "testing  :  1199  accuracy =   0.9186  loss =  12.6219\n",
      "testing  :  1200  accuracy =   0.9184  loss =  12.6707\n",
      "testing  :  1201  accuracy =   0.9188  loss =  12.6014\n",
      "testing  :  1202  accuracy =   0.9157  loss =  13.1086\n",
      "testing  :  1203  accuracy =   0.9176  loss =  12.7371\n",
      "testing  :  1204  accuracy =   0.9189  loss =  12.6731\n",
      "testing  :  1205  accuracy =   0.9196  loss =  12.5881\n",
      "testing  :  1206  accuracy =   0.9202  loss =  12.5003\n",
      "testing  :  1207  accuracy =   0.9202  loss =  12.5987\n",
      "testing  :  1208  accuracy =   0.9201  loss =  12.5933\n",
      "testing  :  1209  accuracy =   0.9195  loss =  12.4905\n",
      "testing  :  1210  accuracy =   0.9205  loss =  12.4903\n",
      "testing  :  1211  accuracy =   0.9222  loss =  12.4103\n",
      "testing  :  1212  accuracy =   0.9218  loss =  12.4487\n",
      "testing  :  1213  accuracy =   0.9206  loss =  12.468\n",
      "testing  :  1214  accuracy =   0.9202  loss =  12.5357\n",
      "testing  :  1215  accuracy =   0.9204  loss =  12.4863\n",
      "testing  :  1216  accuracy =   0.9194  loss =  12.5795\n",
      "testing  :  1217  accuracy =   0.9195  loss =  12.6801\n",
      "testing  :  1218  accuracy =   0.9194  loss =  12.5605\n",
      "testing  :  1219  accuracy =   0.9203  loss =  12.4917\n",
      "testing  :  1220  accuracy =   0.9188  loss =  12.5312\n",
      "testing  :  1221  accuracy =   0.9202  loss =  12.4246\n",
      "testing  :  1222  accuracy =   0.9191  loss =  12.4866\n",
      "testing  :  1223  accuracy =   0.9189  loss =  12.538\n",
      "testing  :  1224  accuracy =   0.9195  loss =  12.5132\n",
      "testing  :  1225  accuracy =   0.9188  loss =  12.5661\n",
      "testing  :  1226  accuracy =   0.9162  loss =  12.6791\n",
      "testing  :  1227  accuracy =   0.9189  loss =  12.4745\n",
      "testing  :  1228  accuracy =   0.9194  loss =  12.5186\n",
      "testing  :  1229  accuracy =   0.9195  loss =  12.5278\n",
      "testing  :  1230  accuracy =   0.9192  loss =  12.4664\n",
      "testing  :  1231  accuracy =   0.9191  loss =  12.4868\n",
      "testing  :  1232  accuracy =   0.9195  loss =  12.4866\n",
      "testing  :  1233  accuracy =   0.9194  loss =  12.4501\n",
      "testing  :  1234  accuracy =   0.9196  loss =  12.5079\n",
      "testing  :  1235  accuracy =   0.9201  loss =  12.5384\n",
      "testing  :  1236  accuracy =   0.9189  loss =  12.5898\n",
      "testing  :  1237  accuracy =   0.9203  loss =  12.5148\n",
      "testing  :  1238  accuracy =   0.9195  loss =  12.5969\n",
      "testing  :  1239  accuracy =   0.9179  loss =  12.8124\n",
      "testing  :  1240  accuracy =   0.9187  loss =  12.707\n",
      "testing  :  1241  accuracy =   0.9191  loss =  12.6096\n",
      "testing  :  1242  accuracy =   0.9205  loss =  12.5495\n",
      "testing  :  1243  accuracy =   0.9199  loss =  12.7132\n",
      "testing  :  1244  accuracy =   0.9198  loss =  12.5935\n",
      "testing  :  1245  accuracy =   0.9203  loss =  12.4752\n",
      "testing  :  1246  accuracy =   0.9192  loss =  12.5767\n",
      "testing  :  1247  accuracy =   0.9189  loss =  12.5572\n",
      "testing  :  1248  accuracy =   0.9180  loss =  12.5795\n",
      "testing  :  1249  accuracy =   0.9186  loss =  12.5689\n",
      "testing  :  1250  accuracy =   0.9198  loss =  12.5184\n",
      "testing  :  1251  accuracy =   0.9168  loss =  12.7274\n",
      "testing  :  1252  accuracy =   0.9170  loss =  12.7117\n",
      "testing  :  1253  accuracy =   0.9195  loss =  12.6926\n",
      "testing  :  1254  accuracy =   0.9174  loss =  12.927\n",
      "testing  :  1255  accuracy =   0.9190  loss =  12.766\n",
      "testing  :  1256  accuracy =   0.9176  loss =  12.781\n",
      "testing  :  1257  accuracy =   0.9139  loss =  13.3611\n",
      "testing  :  1258  accuracy =   0.9192  loss =  12.6572\n",
      "testing  :  1259  accuracy =   0.9172  loss =  13.0051\n",
      "testing  :  1260  accuracy =   0.9196  loss =  12.6309\n",
      "testing  :  1261  accuracy =   0.9186  loss =  12.6562\n",
      "testing  :  1262  accuracy =   0.9196  loss =  12.5493\n",
      "testing  :  1263  accuracy =   0.9202  loss =  12.4491\n",
      "testing  :  1264  accuracy =   0.9199  loss =  12.5259\n",
      "testing  :  1265  accuracy =   0.9209  loss =  12.4584\n",
      "testing  :  1266  accuracy =   0.9210  loss =  12.4831\n",
      "testing  :  1267  accuracy =   0.9214  loss =  12.4136\n",
      "testing  :  1268  accuracy =   0.9199  loss =  12.5674\n",
      "testing  :  1269  accuracy =   0.9217  loss =  12.4314\n",
      "testing  :  1270  accuracy =   0.9215  loss =  12.374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1271  accuracy =   0.9208  loss =  12.4111\n",
      "testing  :  1272  accuracy =   0.9185  loss =  12.6689\n",
      "testing  :  1273  accuracy =   0.9207  loss =  12.4574\n",
      "testing  :  1274  accuracy =   0.9193  loss =  12.4806\n",
      "testing  :  1275  accuracy =   0.9186  loss =  12.585\n",
      "testing  :  1276  accuracy =   0.9202  loss =  12.4261\n",
      "testing  :  1277  accuracy =   0.9204  loss =  12.5058\n",
      "testing  :  1278  accuracy =   0.9200  loss =  12.5536\n",
      "testing  :  1279  accuracy =   0.9188  loss =  12.5991\n",
      "testing  :  1280  accuracy =   0.9194  loss =  12.5803\n",
      "testing  :  1281  accuracy =   0.9205  loss =  12.5048\n",
      "testing  :  1282  accuracy =   0.9181  loss =  12.7942\n",
      "testing  :  1283  accuracy =   0.9191  loss =  12.6721\n",
      "testing  :  1284  accuracy =   0.9184  loss =  12.6967\n",
      "testing  :  1285  accuracy =   0.9191  loss =  12.5447\n",
      "testing  :  1286  accuracy =   0.9205  loss =  12.3201\n",
      "testing  :  1287  accuracy =   0.9207  loss =  12.3431\n",
      "testing  :  1288  accuracy =   0.9204  loss =  12.3794\n",
      "testing  :  1289  accuracy =   0.9183  loss =  12.537\n",
      "testing  :  1290  accuracy =   0.9193  loss =  12.4122\n",
      "testing  :  1291  accuracy =   0.9199  loss =  12.3915\n",
      "testing  :  1292  accuracy =   0.9196  loss =  12.375\n",
      "testing  :  1293  accuracy =   0.9191  loss =  12.4103\n",
      "testing  :  1294  accuracy =   0.9198  loss =  12.3804\n",
      "testing  :  1295  accuracy =   0.9193  loss =  12.4245\n",
      "testing  :  1296  accuracy =   0.9195  loss =  12.4769\n",
      "testing  :  1297  accuracy =   0.9186  loss =  12.5426\n",
      "testing  :  1298  accuracy =   0.9173  loss =  12.7396\n",
      "testing  :  1299  accuracy =   0.9186  loss =  12.4893\n",
      "testing  :  1300  accuracy =   0.9175  loss =  12.5365\n",
      "testing  :  1301  accuracy =   0.9175  loss =  12.4937\n",
      "testing  :  1302  accuracy =   0.9188  loss =  12.4893\n",
      "testing  :  1303  accuracy =   0.9197  loss =  12.4288\n",
      "testing  :  1304  accuracy =   0.9191  loss =  12.4224\n",
      "testing  :  1305  accuracy =   0.9194  loss =  12.502\n",
      "testing  :  1306  accuracy =   0.9178  loss =  12.5279\n",
      "testing  :  1307  accuracy =   0.9181  loss =  12.5594\n",
      "testing  :  1308  accuracy =   0.9190  loss =  12.5479\n",
      "testing  :  1309  accuracy =   0.9199  loss =  12.4909\n",
      "testing  :  1310  accuracy =   0.9201  loss =  12.3485\n",
      "testing  :  1311  accuracy =   0.9223  loss =  12.4653\n",
      "testing  :  1312  accuracy =   0.9203  loss =  12.4223\n",
      "testing  :  1313  accuracy =   0.9202  loss =  12.3595\n",
      "testing  :  1314  accuracy =   0.9201  loss =  12.3034\n",
      "testing  :  1315  accuracy =   0.9199  loss =  12.5458\n",
      "testing  :  1316  accuracy =   0.9181  loss =  12.7068\n",
      "testing  :  1317  accuracy =   0.9195  loss =  12.604\n",
      "testing  :  1318  accuracy =   0.9195  loss =  12.4444\n",
      "testing  :  1319  accuracy =   0.9187  loss =  12.5307\n",
      "testing  :  1320  accuracy =   0.9188  loss =  12.6478\n",
      "testing  :  1321  accuracy =   0.9194  loss =  12.4396\n",
      "testing  :  1322  accuracy =   0.9197  loss =  12.4572\n",
      "testing  :  1323  accuracy =   0.9212  loss =  12.3596\n",
      "testing  :  1324  accuracy =   0.9208  loss =  12.4016\n",
      "testing  :  1325  accuracy =   0.9193  loss =  12.4068\n",
      "testing  :  1326  accuracy =   0.9185  loss =  12.5701\n",
      "testing  :  1327  accuracy =   0.9195  loss =  12.4906\n",
      "testing  :  1328  accuracy =   0.9193  loss =  12.3977\n",
      "testing  :  1329  accuracy =   0.9204  loss =  12.3259\n",
      "testing  :  1330  accuracy =   0.9204  loss =  12.3204\n",
      "testing  :  1331  accuracy =   0.9192  loss =  12.4716\n",
      "testing  :  1332  accuracy =   0.9179  loss =  12.5007\n",
      "testing  :  1333  accuracy =   0.9183  loss =  12.5181\n",
      "testing  :  1334  accuracy =   0.9186  loss =  12.4934\n",
      "testing  :  1335  accuracy =   0.9183  loss =  12.4773\n",
      "testing  :  1336  accuracy =   0.9194  loss =  12.3757\n",
      "testing  :  1337  accuracy =   0.9184  loss =  12.4708\n",
      "testing  :  1338  accuracy =   0.9192  loss =  12.3811\n",
      "testing  :  1339  accuracy =   0.9201  loss =  12.5134\n",
      "testing  :  1340  accuracy =   0.9196  loss =  12.4357\n",
      "testing  :  1341  accuracy =   0.9208  loss =  12.3845\n",
      "testing  :  1342  accuracy =   0.9208  loss =  12.3348\n",
      "testing  :  1343  accuracy =   0.9196  loss =  12.3475\n",
      "testing  :  1344  accuracy =   0.9192  loss =  12.4246\n",
      "testing  :  1345  accuracy =   0.9198  loss =  12.4585\n",
      "testing  :  1346  accuracy =   0.9187  loss =  12.5801\n",
      "testing  :  1347  accuracy =   0.9168  loss =  12.8473\n",
      "testing  :  1348  accuracy =   0.9192  loss =  12.5236\n",
      "testing  :  1349  accuracy =   0.9198  loss =  12.3486\n",
      "testing  :  1350  accuracy =   0.9198  loss =  12.4377\n",
      "testing  :  1351  accuracy =   0.9213  loss =  12.3573\n",
      "testing  :  1352  accuracy =   0.9206  loss =  12.3899\n",
      "testing  :  1353  accuracy =   0.9208  loss =  12.2857\n",
      "testing  :  1354  accuracy =   0.9217  loss =  12.3448\n",
      "testing  :  1355  accuracy =   0.9197  loss =  12.5105\n",
      "testing  :  1356  accuracy =   0.9183  loss =  12.6682\n",
      "testing  :  1357  accuracy =   0.9207  loss =  12.4383\n",
      "testing  :  1358  accuracy =   0.9160  loss =  12.8631\n",
      "testing  :  1359  accuracy =   0.9197  loss =  12.4278\n",
      "testing  :  1360  accuracy =   0.9181  loss =  12.5901\n",
      "testing  :  1361  accuracy =   0.9193  loss =  12.5014\n",
      "testing  :  1362  accuracy =   0.9193  loss =  12.4093\n",
      "testing  :  1363  accuracy =   0.9199  loss =  12.3938\n",
      "testing  :  1364  accuracy =   0.9217  loss =  12.3409\n",
      "testing  :  1365  accuracy =   0.9197  loss =  12.4066\n",
      "testing  :  1366  accuracy =   0.9204  loss =  12.3282\n",
      "testing  :  1367  accuracy =   0.9219  loss =  12.3762\n",
      "testing  :  1368  accuracy =   0.9221  loss =  12.2999\n",
      "testing  :  1369  accuracy =   0.9213  loss =  12.2583\n",
      "testing  :  1370  accuracy =   0.9210  loss =  12.3073\n",
      "testing  :  1371  accuracy =   0.9202  loss =  12.2823\n",
      "testing  :  1372  accuracy =   0.9216  loss =  12.2843\n",
      "testing  :  1373  accuracy =   0.9210  loss =  12.3085\n",
      "testing  :  1374  accuracy =   0.9201  loss =  12.4594\n",
      "testing  :  1375  accuracy =   0.9221  loss =  12.2314\n",
      "testing  :  1376  accuracy =   0.9226  loss =  12.1593\n",
      "testing  :  1377  accuracy =   0.9210  loss =  12.2699\n",
      "testing  :  1378  accuracy =   0.9220  loss =  12.1666\n",
      "testing  :  1379  accuracy =   0.9211  loss =  12.4697\n",
      "testing  :  1380  accuracy =   0.9223  loss =  12.2021\n",
      "testing  :  1381  accuracy =   0.9227  loss =  12.1533\n",
      "testing  :  1382  accuracy =   0.9214  loss =  12.2663\n",
      "testing  :  1383  accuracy =   0.9215  loss =  12.2101\n",
      "testing  :  1384  accuracy =   0.9213  loss =  12.1902\n",
      "testing  :  1385  accuracy =   0.9219  loss =  12.2333\n",
      "testing  :  1386  accuracy =   0.9215  loss =  12.2481\n",
      "testing  :  1387  accuracy =   0.9234  loss =  12.19\n",
      "testing  :  1388  accuracy =   0.9236  loss =  12.1886\n",
      "testing  :  1389  accuracy =   0.9222  loss =  12.1911\n",
      "testing  :  1390  accuracy =   0.9211  loss =  12.2746\n",
      "testing  :  1391  accuracy =   0.9211  loss =  12.3317\n",
      "testing  :  1392  accuracy =   0.9217  loss =  12.264\n",
      "testing  :  1393  accuracy =   0.9218  loss =  12.2101\n",
      "testing  :  1394  accuracy =   0.9225  loss =  12.1815\n",
      "testing  :  1395  accuracy =   0.9222  loss =  12.2073\n",
      "testing  :  1396  accuracy =   0.9216  loss =  12.3033\n",
      "testing  :  1397  accuracy =   0.9222  loss =  12.2371\n",
      "testing  :  1398  accuracy =   0.9216  loss =  12.2471\n",
      "testing  :  1399  accuracy =   0.9196  loss =  12.4053\n",
      "testing  :  1400  accuracy =   0.9196  loss =  12.4449\n",
      "testing  :  1401  accuracy =   0.9206  loss =  12.3374\n",
      "testing  :  1402  accuracy =   0.9196  loss =  12.5292\n",
      "testing  :  1403  accuracy =   0.9201  loss =  12.531\n",
      "testing  :  1404  accuracy =   0.9215  loss =  12.3359\n",
      "testing  :  1405  accuracy =   0.9208  loss =  12.2658\n",
      "testing  :  1406  accuracy =   0.9224  loss =  12.2682\n",
      "testing  :  1407  accuracy =   0.9219  loss =  12.2403\n",
      "testing  :  1408  accuracy =   0.9223  loss =  12.1941\n",
      "testing  :  1409  accuracy =   0.9217  loss =  12.181\n",
      "testing  :  1410  accuracy =   0.9218  loss =  12.2452\n",
      "testing  :  1411  accuracy =   0.9223  loss =  12.1842\n",
      "testing  :  1412  accuracy =   0.9212  loss =  12.1872\n",
      "testing  :  1413  accuracy =   0.9205  loss =  12.298\n",
      "testing  :  1414  accuracy =   0.9204  loss =  12.3124\n",
      "testing  :  1415  accuracy =   0.9221  loss =  12.2465\n",
      "testing  :  1416  accuracy =   0.9215  loss =  12.2684\n",
      "testing  :  1417  accuracy =   0.9216  loss =  12.244\n",
      "testing  :  1418  accuracy =   0.9215  loss =  12.2052\n",
      "testing  :  1419  accuracy =   0.9217  loss =  12.2696\n",
      "testing  :  1420  accuracy =   0.9222  loss =  12.1723\n",
      "testing  :  1421  accuracy =   0.9212  loss =  12.2786\n",
      "testing  :  1422  accuracy =   0.9213  loss =  12.4602\n",
      "testing  :  1423  accuracy =   0.9213  loss =  12.4123\n",
      "testing  :  1424  accuracy =   0.9191  loss =  12.5653\n",
      "testing  :  1425  accuracy =   0.9230  loss =  12.2694\n",
      "testing  :  1426  accuracy =   0.9211  loss =  12.2134\n",
      "testing  :  1427  accuracy =   0.9197  loss =  12.3303\n",
      "testing  :  1428  accuracy =   0.9226  loss =  12.2504\n",
      "testing  :  1429  accuracy =   0.9228  loss =  12.1971\n",
      "testing  :  1430  accuracy =   0.9239  loss =  12.1901\n",
      "testing  :  1431  accuracy =   0.9243  loss =  12.1711\n",
      "testing  :  1432  accuracy =   0.9212  loss =  12.3875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1433  accuracy =   0.9226  loss =  12.2902\n",
      "testing  :  1434  accuracy =   0.9230  loss =  12.2341\n",
      "testing  :  1435  accuracy =   0.9232  loss =  12.2016\n",
      "testing  :  1436  accuracy =   0.9216  loss =  12.2816\n",
      "testing  :  1437  accuracy =   0.9228  loss =  12.2083\n",
      "testing  :  1438  accuracy =   0.9228  loss =  12.1972\n",
      "testing  :  1439  accuracy =   0.9219  loss =  12.2985\n",
      "testing  :  1440  accuracy =   0.9229  loss =  12.2747\n",
      "testing  :  1441  accuracy =   0.9234  loss =  12.2396\n",
      "testing  :  1442  accuracy =   0.9222  loss =  12.3495\n",
      "testing  :  1443  accuracy =   0.9228  loss =  12.1938\n",
      "testing  :  1444  accuracy =   0.9210  loss =  12.3333\n",
      "testing  :  1445  accuracy =   0.9218  loss =  12.2981\n",
      "testing  :  1446  accuracy =   0.9218  loss =  12.3306\n",
      "testing  :  1447  accuracy =   0.9196  loss =  12.7241\n",
      "testing  :  1448  accuracy =   0.9182  loss =  12.6778\n",
      "testing  :  1449  accuracy =   0.9209  loss =  12.2203\n",
      "testing  :  1450  accuracy =   0.9222  loss =  12.2017\n",
      "testing  :  1451  accuracy =   0.9209  loss =  12.2738\n",
      "testing  :  1452  accuracy =   0.9200  loss =  12.4326\n",
      "testing  :  1453  accuracy =   0.9217  loss =  12.289\n",
      "testing  :  1454  accuracy =   0.9199  loss =  12.3728\n",
      "testing  :  1455  accuracy =   0.9214  loss =  12.2506\n",
      "testing  :  1456  accuracy =   0.9210  loss =  12.2785\n",
      "testing  :  1457  accuracy =   0.9192  loss =  12.38\n",
      "testing  :  1458  accuracy =   0.9214  loss =  12.2006\n",
      "testing  :  1459  accuracy =   0.9209  loss =  12.196\n",
      "testing  :  1460  accuracy =   0.9209  loss =  12.2663\n",
      "testing  :  1461  accuracy =   0.9225  loss =  12.2331\n",
      "testing  :  1462  accuracy =   0.9218  loss =  12.1961\n",
      "testing  :  1463  accuracy =   0.9225  loss =  12.1101\n",
      "testing  :  1464  accuracy =   0.9217  loss =  12.148\n",
      "testing  :  1465  accuracy =   0.9229  loss =  12.188\n",
      "testing  :  1466  accuracy =   0.9219  loss =  12.1248\n",
      "testing  :  1467  accuracy =   0.9213  loss =  12.1883\n",
      "testing  :  1468  accuracy =   0.9223  loss =  12.247\n",
      "testing  :  1469  accuracy =   0.9205  loss =  12.1876\n",
      "testing  :  1470  accuracy =   0.9210  loss =  12.2577\n",
      "testing  :  1471  accuracy =   0.9216  loss =  12.3371\n",
      "testing  :  1472  accuracy =   0.9219  loss =  12.2287\n",
      "testing  :  1473  accuracy =   0.9230  loss =  12.1407\n",
      "testing  :  1474  accuracy =   0.9238  loss =  12.0701\n",
      "testing  :  1475  accuracy =   0.9221  loss =  12.1255\n",
      "testing  :  1476  accuracy =   0.9200  loss =  12.476\n",
      "testing  :  1477  accuracy =   0.9197  loss =  12.4779\n",
      "testing  :  1478  accuracy =   0.9203  loss =  12.4295\n",
      "testing  :  1479  accuracy =   0.9202  loss =  12.471\n",
      "testing  :  1480  accuracy =   0.9214  loss =  12.3017\n",
      "testing  :  1481  accuracy =   0.9224  loss =  12.2755\n",
      "testing  :  1482  accuracy =   0.9210  loss =  12.3786\n",
      "testing  :  1483  accuracy =   0.9187  loss =  12.522\n",
      "testing  :  1484  accuracy =   0.9206  loss =  12.4316\n",
      "testing  :  1485  accuracy =   0.9214  loss =  12.4178\n",
      "testing  :  1486  accuracy =   0.9228  loss =  12.0711\n",
      "testing  :  1487  accuracy =   0.9204  loss =  12.4375\n",
      "testing  :  1488  accuracy =   0.9236  loss =  12.0888\n",
      "testing  :  1489  accuracy =   0.9236  loss =  12.0558\n",
      "testing  :  1490  accuracy =   0.9217  loss =  12.3587\n",
      "testing  :  1491  accuracy =   0.9235  loss =  12.1241\n",
      "testing  :  1492  accuracy =   0.9225  loss =  12.0862\n",
      "testing  :  1493  accuracy =   0.9222  loss =  12.0596\n",
      "testing  :  1494  accuracy =   0.9199  loss =  12.4774\n",
      "testing  :  1495  accuracy =   0.9221  loss =  12.2549\n",
      "testing  :  1496  accuracy =   0.9204  loss =  12.4184\n",
      "testing  :  1497  accuracy =   0.9212  loss =  12.2575\n",
      "testing  :  1498  accuracy =   0.9210  loss =  12.2598\n",
      "testing  :  1499  accuracy =   0.9216  loss =  12.307\n",
      "testing  :  1500  accuracy =   0.9215  loss =  12.3291\n",
      "testing  :  1501  accuracy =   0.9203  loss =  12.1958\n",
      "testing  :  1502  accuracy =   0.9202  loss =  12.3266\n",
      "testing  :  1503  accuracy =   0.9220  loss =  12.184\n",
      "testing  :  1504  accuracy =   0.9215  loss =  12.2358\n",
      "testing  :  1505  accuracy =   0.9205  loss =  12.2099\n",
      "testing  :  1506  accuracy =   0.9205  loss =  12.1747\n",
      "testing  :  1507  accuracy =   0.9207  loss =  12.1996\n",
      "testing  :  1508  accuracy =   0.9207  loss =  12.1321\n",
      "testing  :  1509  accuracy =   0.9212  loss =  12.2013\n",
      "testing  :  1510  accuracy =   0.9204  loss =  12.201\n",
      "testing  :  1511  accuracy =   0.9215  loss =  12.1935\n",
      "testing  :  1512  accuracy =   0.9212  loss =  12.2204\n",
      "testing  :  1513  accuracy =   0.9216  loss =  12.2562\n",
      "testing  :  1514  accuracy =   0.9201  loss =  12.2814\n",
      "testing  :  1515  accuracy =   0.9221  loss =  12.0939\n",
      "testing  :  1516  accuracy =   0.9219  loss =  12.0507\n",
      "testing  :  1517  accuracy =   0.9226  loss =  12.139\n",
      "testing  :  1518  accuracy =   0.9217  loss =  12.3117\n",
      "testing  :  1519  accuracy =   0.9224  loss =  12.0866\n",
      "testing  :  1520  accuracy =   0.9233  loss =  12.0867\n",
      "testing  :  1521  accuracy =   0.9209  loss =  12.1777\n",
      "testing  :  1522  accuracy =   0.9222  loss =  12.1207\n",
      "testing  :  1523  accuracy =   0.9210  loss =  12.3956\n",
      "testing  :  1524  accuracy =   0.9209  loss =  12.2747\n",
      "testing  :  1525  accuracy =   0.9221  loss =  12.2127\n",
      "testing  :  1526  accuracy =   0.9206  loss =  12.2388\n",
      "testing  :  1527  accuracy =   0.9221  loss =  12.2992\n",
      "testing  :  1528  accuracy =   0.9205  loss =  12.4881\n",
      "testing  :  1529  accuracy =   0.9228  loss =  12.1667\n",
      "testing  :  1530  accuracy =   0.9212  loss =  12.2933\n",
      "testing  :  1531  accuracy =   0.9214  loss =  12.2504\n",
      "testing  :  1532  accuracy =   0.9219  loss =  12.1531\n",
      "testing  :  1533  accuracy =   0.9214  loss =  12.1729\n",
      "testing  :  1534  accuracy =   0.9213  loss =  12.2619\n",
      "testing  :  1535  accuracy =   0.9213  loss =  12.1936\n",
      "testing  :  1536  accuracy =   0.9228  loss =  12.0305\n",
      "testing  :  1537  accuracy =   0.9221  loss =  12.1003\n",
      "testing  :  1538  accuracy =   0.9215  loss =  12.1698\n",
      "testing  :  1539  accuracy =   0.9215  loss =  12.3164\n",
      "testing  :  1540  accuracy =   0.9211  loss =  12.1816\n",
      "testing  :  1541  accuracy =   0.9217  loss =  12.1725\n",
      "testing  :  1542  accuracy =   0.9198  loss =  12.5098\n",
      "testing  :  1543  accuracy =   0.9211  loss =  12.4265\n",
      "testing  :  1544  accuracy =   0.9224  loss =  12.2784\n",
      "testing  :  1545  accuracy =   0.9223  loss =  12.1903\n",
      "testing  :  1546  accuracy =   0.9225  loss =  12.0745\n",
      "testing  :  1547  accuracy =   0.9230  loss =  12.0646\n",
      "testing  :  1548  accuracy =   0.9218  loss =  12.0532\n",
      "testing  :  1549  accuracy =   0.9204  loss =  12.2051\n",
      "testing  :  1550  accuracy =   0.9202  loss =  12.3113\n",
      "testing  :  1551  accuracy =   0.9197  loss =  12.4462\n",
      "testing  :  1552  accuracy =   0.9213  loss =  12.2169\n",
      "testing  :  1553  accuracy =   0.9215  loss =  12.1343\n",
      "testing  :  1554  accuracy =   0.9217  loss =  12.2507\n",
      "testing  :  1555  accuracy =   0.9217  loss =  12.312\n",
      "testing  :  1556  accuracy =   0.9221  loss =  12.3812\n",
      "testing  :  1557  accuracy =   0.9215  loss =  12.2204\n",
      "testing  :  1558  accuracy =   0.9215  loss =  12.2595\n",
      "testing  :  1559  accuracy =   0.9198  loss =  12.3974\n",
      "testing  :  1560  accuracy =   0.9200  loss =  12.3327\n",
      "testing  :  1561  accuracy =   0.9222  loss =  12.1499\n",
      "testing  :  1562  accuracy =   0.9225  loss =  12.164\n",
      "testing  :  1563  accuracy =   0.9220  loss =  12.0608\n",
      "testing  :  1564  accuracy =   0.9237  loss =  12.0735\n",
      "testing  :  1565  accuracy =   0.9237  loss =  12.1052\n",
      "testing  :  1566  accuracy =   0.9240  loss =  12.2194\n",
      "testing  :  1567  accuracy =   0.9238  loss =  12.1411\n",
      "testing  :  1568  accuracy =   0.9236  loss =  12.0437\n",
      "testing  :  1569  accuracy =   0.9238  loss =  12.0239\n",
      "testing  :  1570  accuracy =   0.9234  loss =  12.0424\n",
      "testing  :  1571  accuracy =   0.9236  loss =  12.0469\n",
      "testing  :  1572  accuracy =   0.9239  loss =  12.0649\n",
      "testing  :  1573  accuracy =   0.9226  loss =  12.1175\n",
      "testing  :  1574  accuracy =   0.9246  loss =  12.054\n",
      "testing  :  1575  accuracy =   0.9237  loss =  12.1482\n",
      "testing  :  1576  accuracy =   0.9231  loss =  12.0756\n",
      "testing  :  1577  accuracy =   0.9227  loss =  12.2109\n",
      "testing  :  1578  accuracy =   0.9223  loss =  12.2807\n",
      "testing  :  1579  accuracy =   0.9214  loss =  12.1685\n",
      "testing  :  1580  accuracy =   0.9208  loss =  12.1611\n",
      "testing  :  1581  accuracy =   0.9214  loss =  12.1265\n",
      "testing  :  1582  accuracy =   0.9219  loss =  12.1613\n",
      "testing  :  1583  accuracy =   0.9215  loss =  12.1229\n",
      "testing  :  1584  accuracy =   0.9210  loss =  12.2899\n",
      "testing  :  1585  accuracy =   0.9210  loss =  12.2481\n",
      "testing  :  1586  accuracy =   0.9211  loss =  12.3788\n",
      "testing  :  1587  accuracy =   0.9207  loss =  12.3701\n",
      "testing  :  1588  accuracy =   0.9187  loss =  12.612\n",
      "testing  :  1589  accuracy =   0.9210  loss =  12.5122\n",
      "testing  :  1590  accuracy =   0.9207  loss =  12.2679\n",
      "testing  :  1591  accuracy =   0.9225  loss =  12.1565\n",
      "testing  :  1592  accuracy =   0.9222  loss =  12.093\n",
      "testing  :  1593  accuracy =   0.9222  loss =  12.2465\n",
      "testing  :  1594  accuracy =   0.9218  loss =  12.2389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1595  accuracy =   0.9212  loss =  12.2549\n",
      "testing  :  1596  accuracy =   0.9221  loss =  12.1373\n",
      "testing  :  1597  accuracy =   0.9215  loss =  12.1363\n",
      "testing  :  1598  accuracy =   0.9207  loss =  12.1886\n",
      "testing  :  1599  accuracy =   0.9221  loss =  11.9831\n",
      "testing  :  1600  accuracy =   0.9227  loss =  12.0278\n",
      "testing  :  1601  accuracy =   0.9223  loss =  12.0237\n",
      "testing  :  1602  accuracy =   0.9212  loss =  12.2898\n",
      "testing  :  1603  accuracy =   0.9221  loss =  12.2732\n",
      "testing  :  1604  accuracy =   0.9218  loss =  12.3122\n",
      "testing  :  1605  accuracy =   0.9232  loss =  12.1126\n",
      "testing  :  1606  accuracy =   0.9222  loss =  12.06\n",
      "testing  :  1607  accuracy =   0.9217  loss =  12.1013\n",
      "testing  :  1608  accuracy =   0.9209  loss =  12.0837\n",
      "testing  :  1609  accuracy =   0.9214  loss =  12.0747\n",
      "testing  :  1610  accuracy =   0.9214  loss =  12.1045\n",
      "testing  :  1611  accuracy =   0.9218  loss =  12.0651\n",
      "testing  :  1612  accuracy =   0.9205  loss =  12.1325\n",
      "testing  :  1613  accuracy =   0.9213  loss =  12.0913\n",
      "testing  :  1614  accuracy =   0.9223  loss =  12.1189\n",
      "testing  :  1615  accuracy =   0.9218  loss =  12.2533\n",
      "testing  :  1616  accuracy =   0.9217  loss =  12.2254\n",
      "testing  :  1617  accuracy =   0.9207  loss =  12.2976\n",
      "testing  :  1618  accuracy =   0.9217  loss =  12.2214\n",
      "testing  :  1619  accuracy =   0.9221  loss =  12.2453\n",
      "testing  :  1620  accuracy =   0.9218  loss =  12.2443\n",
      "testing  :  1621  accuracy =   0.9213  loss =  12.1979\n",
      "testing  :  1622  accuracy =   0.9221  loss =  12.109\n",
      "testing  :  1623  accuracy =   0.9223  loss =  12.1351\n",
      "testing  :  1624  accuracy =   0.9225  loss =  12.0421\n",
      "testing  :  1625  accuracy =   0.9210  loss =  12.1078\n",
      "testing  :  1626  accuracy =   0.9203  loss =  12.0775\n",
      "testing  :  1627  accuracy =   0.9210  loss =  12.1808\n",
      "testing  :  1628  accuracy =   0.9195  loss =  12.1824\n",
      "testing  :  1629  accuracy =   0.9200  loss =  12.2156\n",
      "testing  :  1630  accuracy =   0.9204  loss =  12.1246\n",
      "testing  :  1631  accuracy =   0.9195  loss =  12.3573\n",
      "testing  :  1632  accuracy =   0.9196  loss =  12.2907\n",
      "testing  :  1633  accuracy =   0.9218  loss =  12.1221\n",
      "testing  :  1634  accuracy =   0.9218  loss =  12.0812\n",
      "testing  :  1635  accuracy =   0.9223  loss =  12.0415\n",
      "testing  :  1636  accuracy =   0.9228  loss =  12.0201\n",
      "testing  :  1637  accuracy =   0.9240  loss =  12.075\n",
      "testing  :  1638  accuracy =   0.9225  loss =  12.2622\n",
      "testing  :  1639  accuracy =   0.9215  loss =  12.303\n",
      "testing  :  1640  accuracy =   0.9222  loss =  12.1203\n",
      "testing  :  1641  accuracy =   0.9208  loss =  12.284\n",
      "testing  :  1642  accuracy =   0.9231  loss =  12.0329\n",
      "testing  :  1643  accuracy =   0.9227  loss =  12.1075\n",
      "testing  :  1644  accuracy =   0.9225  loss =  12.0921\n",
      "testing  :  1645  accuracy =   0.9217  loss =  12.2426\n",
      "testing  :  1646  accuracy =   0.9209  loss =  12.1514\n",
      "testing  :  1647  accuracy =   0.9214  loss =  12.1705\n",
      "testing  :  1648  accuracy =   0.9216  loss =  12.262\n",
      "testing  :  1649  accuracy =   0.9209  loss =  12.2439\n",
      "testing  :  1650  accuracy =   0.9231  loss =  12.0684\n",
      "testing  :  1651  accuracy =   0.9239  loss =  12.0341\n",
      "testing  :  1652  accuracy =   0.9221  loss =  12.2656\n",
      "testing  :  1653  accuracy =   0.9209  loss =  12.2883\n",
      "testing  :  1654  accuracy =   0.9219  loss =  12.2584\n",
      "testing  :  1655  accuracy =   0.9220  loss =  12.159\n",
      "testing  :  1656  accuracy =   0.9218  loss =  12.281\n",
      "testing  :  1657  accuracy =   0.9215  loss =  12.3068\n",
      "testing  :  1658  accuracy =   0.9196  loss =  12.3997\n",
      "testing  :  1659  accuracy =   0.9236  loss =  12.0753\n",
      "testing  :  1660  accuracy =   0.9212  loss =  12.1833\n",
      "testing  :  1661  accuracy =   0.9236  loss =  12.0065\n",
      "testing  :  1662  accuracy =   0.9242  loss =  12.0115\n",
      "testing  :  1663  accuracy =   0.9249  loss =  11.9728\n",
      "testing  :  1664  accuracy =   0.9243  loss =  12.0654\n",
      "testing  :  1665  accuracy =   0.9234  loss =  12.0465\n",
      "testing  :  1666  accuracy =   0.9234  loss =  11.9995\n",
      "testing  :  1667  accuracy =   0.9236  loss =  12.0539\n",
      "testing  :  1668  accuracy =   0.9235  loss =  12.087\n",
      "testing  :  1669  accuracy =   0.9222  loss =  12.1175\n",
      "testing  :  1670  accuracy =   0.9218  loss =  12.066\n",
      "testing  :  1671  accuracy =   0.9198  loss =  12.2566\n",
      "testing  :  1672  accuracy =   0.9228  loss =  12.0944\n",
      "testing  :  1673  accuracy =   0.9226  loss =  12.1205\n",
      "testing  :  1674  accuracy =   0.9224  loss =  12.1581\n",
      "testing  :  1675  accuracy =   0.9209  loss =  12.246\n",
      "testing  :  1676  accuracy =   0.9224  loss =  12.1441\n",
      "testing  :  1677  accuracy =   0.9216  loss =  12.1582\n",
      "testing  :  1678  accuracy =   0.9224  loss =  12.1054\n",
      "testing  :  1679  accuracy =   0.9235  loss =  12.0251\n",
      "testing  :  1680  accuracy =   0.9220  loss =  12.0569\n",
      "testing  :  1681  accuracy =   0.9222  loss =  12.0933\n",
      "testing  :  1682  accuracy =   0.9192  loss =  12.4686\n",
      "testing  :  1683  accuracy =   0.9224  loss =  12.1661\n",
      "testing  :  1684  accuracy =   0.9228  loss =  12.0341\n",
      "testing  :  1685  accuracy =   0.9225  loss =  12.1097\n",
      "testing  :  1686  accuracy =   0.9222  loss =  12.0905\n",
      "testing  :  1687  accuracy =   0.9232  loss =  12.0582\n",
      "testing  :  1688  accuracy =   0.9228  loss =  12.0568\n",
      "testing  :  1689  accuracy =   0.9217  loss =  12.1406\n",
      "testing  :  1690  accuracy =   0.9232  loss =  12.0721\n",
      "testing  :  1691  accuracy =   0.9229  loss =  12.0726\n",
      "testing  :  1692  accuracy =   0.9229  loss =  12.141\n",
      "testing  :  1693  accuracy =   0.9216  loss =  12.1573\n",
      "testing  :  1694  accuracy =   0.9225  loss =  12.0399\n",
      "testing  :  1695  accuracy =   0.9214  loss =  12.137\n",
      "testing  :  1696  accuracy =   0.9213  loss =  12.1045\n",
      "testing  :  1697  accuracy =   0.9218  loss =  12.1829\n",
      "testing  :  1698  accuracy =   0.9213  loss =  12.1708\n",
      "testing  :  1699  accuracy =   0.9213  loss =  12.1372\n",
      "testing  :  1700  accuracy =   0.9219  loss =  12.0628\n",
      "testing  :  1701  accuracy =   0.9229  loss =  12.0848\n",
      "testing  :  1702  accuracy =   0.9229  loss =  12.0571\n",
      "testing  :  1703  accuracy =   0.9229  loss =  12.1517\n",
      "testing  :  1704  accuracy =   0.9218  loss =  12.3257\n",
      "testing  :  1705  accuracy =   0.9205  loss =  12.3708\n",
      "testing  :  1706  accuracy =   0.9204  loss =  12.2455\n",
      "testing  :  1707  accuracy =   0.9205  loss =  12.2345\n",
      "testing  :  1708  accuracy =   0.9200  loss =  12.2796\n",
      "testing  :  1709  accuracy =   0.9202  loss =  12.4476\n",
      "testing  :  1710  accuracy =   0.9220  loss =  12.1243\n",
      "testing  :  1711  accuracy =   0.9217  loss =  12.0613\n",
      "testing  :  1712  accuracy =   0.9229  loss =  12.0437\n",
      "testing  :  1713  accuracy =   0.9227  loss =  12.0726\n",
      "testing  :  1714  accuracy =   0.9229  loss =  12.0337\n",
      "testing  :  1715  accuracy =   0.9223  loss =  12.1174\n",
      "testing  :  1716  accuracy =   0.9230  loss =  11.9332\n",
      "testing  :  1717  accuracy =   0.9218  loss =  12.0905\n",
      "testing  :  1718  accuracy =   0.9211  loss =  12.1059\n",
      "testing  :  1719  accuracy =   0.9216  loss =  12.1103\n",
      "testing  :  1720  accuracy =   0.9221  loss =  12.1537\n",
      "testing  :  1721  accuracy =   0.9219  loss =  12.0862\n",
      "testing  :  1722  accuracy =   0.9207  loss =  12.1968\n",
      "testing  :  1723  accuracy =   0.9224  loss =  12.0334\n",
      "testing  :  1724  accuracy =   0.9232  loss =  12.0051\n",
      "testing  :  1725  accuracy =   0.9236  loss =  11.9685\n",
      "testing  :  1726  accuracy =   0.9228  loss =  12.0297\n",
      "testing  :  1727  accuracy =   0.9224  loss =  12.0532\n",
      "testing  :  1728  accuracy =   0.9226  loss =  12.099\n",
      "testing  :  1729  accuracy =   0.9217  loss =  12.1529\n",
      "testing  :  1730  accuracy =   0.9216  loss =  12.1694\n",
      "testing  :  1731  accuracy =   0.9214  loss =  12.1485\n",
      "testing  :  1732  accuracy =   0.9212  loss =  12.1237\n",
      "testing  :  1733  accuracy =   0.9212  loss =  12.0938\n",
      "testing  :  1734  accuracy =   0.9215  loss =  12.1446\n",
      "testing  :  1735  accuracy =   0.9217  loss =  12.1826\n",
      "testing  :  1736  accuracy =   0.9216  loss =  12.1108\n",
      "testing  :  1737  accuracy =   0.9214  loss =  12.1183\n",
      "testing  :  1738  accuracy =   0.9223  loss =  12.0929\n",
      "testing  :  1739  accuracy =   0.9229  loss =  12.1393\n",
      "testing  :  1740  accuracy =   0.9213  loss =  12.1934\n",
      "testing  :  1741  accuracy =   0.9217  loss =  12.1879\n",
      "testing  :  1742  accuracy =   0.9212  loss =  12.1881\n",
      "testing  :  1743  accuracy =   0.9224  loss =  12.0846\n",
      "testing  :  1744  accuracy =   0.9225  loss =  12.0237\n",
      "testing  :  1745  accuracy =   0.9224  loss =  12.0413\n",
      "testing  :  1746  accuracy =   0.9223  loss =  12.0354\n",
      "testing  :  1747  accuracy =   0.9235  loss =  11.9502\n",
      "testing  :  1748  accuracy =   0.9227  loss =  11.9946\n",
      "testing  :  1749  accuracy =   0.9226  loss =  12.0254\n",
      "testing  :  1750  accuracy =   0.9202  loss =  12.3437\n",
      "testing  :  1751  accuracy =   0.9210  loss =  12.3391\n",
      "testing  :  1752  accuracy =   0.9215  loss =  12.1922\n",
      "testing  :  1753  accuracy =   0.9213  loss =  12.156\n",
      "testing  :  1754  accuracy =   0.9229  loss =  12.003\n",
      "testing  :  1755  accuracy =   0.9224  loss =  12.0473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1756  accuracy =   0.9229  loss =  12.0056\n",
      "testing  :  1757  accuracy =   0.9233  loss =  12.0086\n",
      "testing  :  1758  accuracy =   0.9217  loss =  12.1109\n",
      "testing  :  1759  accuracy =   0.9227  loss =  12.0502\n",
      "testing  :  1760  accuracy =   0.9224  loss =  12.0692\n",
      "testing  :  1761  accuracy =   0.9232  loss =  12.1068\n",
      "testing  :  1762  accuracy =   0.9229  loss =  12.0252\n",
      "testing  :  1763  accuracy =   0.9217  loss =  12.1106\n",
      "testing  :  1764  accuracy =   0.9226  loss =  12.0904\n",
      "testing  :  1765  accuracy =   0.9206  loss =  12.2854\n",
      "testing  :  1766  accuracy =   0.9211  loss =  12.2337\n",
      "testing  :  1767  accuracy =   0.9210  loss =  12.1541\n",
      "testing  :  1768  accuracy =   0.9201  loss =  12.233\n",
      "testing  :  1769  accuracy =   0.9216  loss =  12.1032\n",
      "testing  :  1770  accuracy =   0.9213  loss =  12.2316\n",
      "testing  :  1771  accuracy =   0.9209  loss =  12.2546\n",
      "testing  :  1772  accuracy =   0.9211  loss =  12.2182\n",
      "testing  :  1773  accuracy =   0.9200  loss =  12.3654\n",
      "testing  :  1774  accuracy =   0.9216  loss =  12.2092\n",
      "testing  :  1775  accuracy =   0.9214  loss =  12.2038\n",
      "testing  :  1776  accuracy =   0.9226  loss =  12.0464\n",
      "testing  :  1777  accuracy =   0.9236  loss =  12.0454\n",
      "testing  :  1778  accuracy =   0.9232  loss =  12.0173\n",
      "testing  :  1779  accuracy =   0.9228  loss =  12.1067\n",
      "testing  :  1780  accuracy =   0.9217  loss =  12.0936\n",
      "testing  :  1781  accuracy =   0.9201  loss =  12.2553\n",
      "testing  :  1782  accuracy =   0.9195  loss =  12.3059\n",
      "testing  :  1783  accuracy =   0.9199  loss =  12.319\n",
      "testing  :  1784  accuracy =   0.9200  loss =  12.4554\n",
      "testing  :  1785  accuracy =   0.9219  loss =  12.2174\n",
      "testing  :  1786  accuracy =   0.9223  loss =  12.1396\n",
      "testing  :  1787  accuracy =   0.9206  loss =  12.367\n",
      "testing  :  1788  accuracy =   0.9205  loss =  12.4177\n",
      "testing  :  1789  accuracy =   0.9192  loss =  12.5623\n",
      "testing  :  1790  accuracy =   0.9209  loss =  12.4121\n",
      "testing  :  1791  accuracy =   0.9196  loss =  12.6029\n",
      "testing  :  1792  accuracy =   0.9204  loss =  12.3087\n",
      "testing  :  1793  accuracy =   0.9211  loss =  12.3081\n",
      "testing  :  1794  accuracy =   0.9194  loss =  12.5336\n",
      "testing  :  1795  accuracy =   0.9202  loss =  12.3299\n",
      "testing  :  1796  accuracy =   0.9204  loss =  12.2095\n",
      "testing  :  1797  accuracy =   0.9197  loss =  12.2452\n",
      "testing  :  1798  accuracy =   0.9216  loss =  12.1162\n",
      "testing  :  1799  accuracy =   0.9219  loss =  12.0933\n",
      "testing  :  1800  accuracy =   0.9207  loss =  12.1521\n",
      "testing  :  1801  accuracy =   0.9215  loss =  12.0948\n",
      "testing  :  1802  accuracy =   0.9192  loss =  12.5546\n",
      "testing  :  1803  accuracy =   0.9207  loss =  12.2589\n",
      "testing  :  1804  accuracy =   0.9214  loss =  12.1814\n",
      "testing  :  1805  accuracy =   0.9230  loss =  12.071\n",
      "testing  :  1806  accuracy =   0.9236  loss =  12.0078\n",
      "testing  :  1807  accuracy =   0.9232  loss =  12.1226\n",
      "testing  :  1808  accuracy =   0.9229  loss =  12.1401\n",
      "testing  :  1809  accuracy =   0.9235  loss =  12.077\n",
      "testing  :  1810  accuracy =   0.9240  loss =  12.0772\n",
      "testing  :  1811  accuracy =   0.9239  loss =  11.9768\n",
      "testing  :  1812  accuracy =   0.9237  loss =  11.9989\n",
      "testing  :  1813  accuracy =   0.9235  loss =  12.0043\n",
      "testing  :  1814  accuracy =   0.9229  loss =  12.0711\n",
      "testing  :  1815  accuracy =   0.9238  loss =  12.0241\n",
      "testing  :  1816  accuracy =   0.9221  loss =  12.1237\n",
      "testing  :  1817  accuracy =   0.9217  loss =  12.2303\n",
      "testing  :  1818  accuracy =   0.9227  loss =  12.1122\n",
      "testing  :  1819  accuracy =   0.9227  loss =  12.0204\n",
      "testing  :  1820  accuracy =   0.9221  loss =  12.0583\n",
      "testing  :  1821  accuracy =   0.9239  loss =  11.9735\n",
      "testing  :  1822  accuracy =   0.9225  loss =  12.0168\n",
      "testing  :  1823  accuracy =   0.9223  loss =  12.056\n",
      "testing  :  1824  accuracy =   0.9224  loss =  12.0388\n",
      "testing  :  1825  accuracy =   0.9220  loss =  12.0879\n",
      "testing  :  1826  accuracy =   0.9195  loss =  12.2226\n",
      "testing  :  1827  accuracy =   0.9220  loss =  12.0319\n",
      "testing  :  1828  accuracy =   0.9223  loss =  12.0686\n",
      "testing  :  1829  accuracy =   0.9231  loss =  12.0706\n",
      "testing  :  1830  accuracy =   0.9219  loss =  12.0005\n",
      "testing  :  1831  accuracy =   0.9223  loss =  12.0232\n",
      "testing  :  1832  accuracy =   0.9220  loss =  12.0079\n",
      "testing  :  1833  accuracy =   0.9227  loss =  11.9905\n",
      "testing  :  1834  accuracy =   0.9232  loss =  12.0188\n",
      "testing  :  1835  accuracy =   0.9219  loss =  12.0742\n",
      "testing  :  1836  accuracy =   0.9211  loss =  12.1265\n",
      "testing  :  1837  accuracy =   0.9230  loss =  12.0379\n",
      "testing  :  1838  accuracy =   0.9226  loss =  12.1273\n",
      "testing  :  1839  accuracy =   0.9214  loss =  12.3076\n",
      "testing  :  1840  accuracy =   0.9219  loss =  12.215\n",
      "testing  :  1841  accuracy =   0.9220  loss =  12.142\n",
      "testing  :  1842  accuracy =   0.9222  loss =  12.097\n",
      "testing  :  1843  accuracy =   0.9211  loss =  12.2448\n",
      "testing  :  1844  accuracy =   0.9222  loss =  12.1549\n",
      "testing  :  1845  accuracy =   0.9221  loss =  12.0445\n",
      "testing  :  1846  accuracy =   0.9207  loss =  12.1383\n",
      "testing  :  1847  accuracy =   0.9228  loss =  12.0987\n",
      "testing  :  1848  accuracy =   0.9217  loss =  12.1054\n",
      "testing  :  1849  accuracy =   0.9213  loss =  12.1124\n",
      "testing  :  1850  accuracy =   0.9221  loss =  12.0615\n",
      "testing  :  1851  accuracy =   0.9198  loss =  12.2586\n",
      "testing  :  1852  accuracy =   0.9201  loss =  12.2358\n",
      "testing  :  1853  accuracy =   0.9220  loss =  12.2056\n",
      "testing  :  1854  accuracy =   0.9199  loss =  12.4558\n",
      "testing  :  1855  accuracy =   0.9210  loss =  12.3093\n",
      "testing  :  1856  accuracy =   0.9204  loss =  12.3271\n",
      "testing  :  1857  accuracy =   0.9173  loss =  12.8381\n",
      "testing  :  1858  accuracy =   0.9210  loss =  12.2358\n",
      "testing  :  1859  accuracy =   0.9194  loss =  12.5579\n",
      "testing  :  1860  accuracy =   0.9224  loss =  12.2044\n",
      "testing  :  1861  accuracy =   0.9213  loss =  12.2712\n",
      "testing  :  1862  accuracy =   0.9224  loss =  12.1508\n",
      "testing  :  1863  accuracy =   0.9229  loss =  12.0048\n",
      "testing  :  1864  accuracy =   0.9226  loss =  12.0912\n",
      "testing  :  1865  accuracy =   0.9230  loss =  12.0233\n",
      "testing  :  1866  accuracy =   0.9220  loss =  12.0335\n",
      "testing  :  1867  accuracy =   0.9232  loss =  11.9619\n",
      "testing  :  1868  accuracy =   0.9229  loss =  12.1191\n",
      "testing  :  1869  accuracy =   0.9241  loss =  11.9951\n",
      "testing  :  1870  accuracy =   0.9240  loss =  11.95\n",
      "testing  :  1871  accuracy =   0.9236  loss =  11.9537\n",
      "testing  :  1872  accuracy =   0.9213  loss =  12.181\n",
      "testing  :  1873  accuracy =   0.9229  loss =  12.0201\n",
      "testing  :  1874  accuracy =   0.9224  loss =  12.0507\n",
      "testing  :  1875  accuracy =   0.9209  loss =  12.1476\n",
      "testing  :  1876  accuracy =   0.9223  loss =  11.9726\n",
      "testing  :  1877  accuracy =   0.9219  loss =  12.0649\n",
      "testing  :  1878  accuracy =   0.9218  loss =  12.1133\n",
      "testing  :  1879  accuracy =   0.9214  loss =  12.1087\n",
      "testing  :  1880  accuracy =   0.9225  loss =  12.1116\n",
      "testing  :  1881  accuracy =   0.9228  loss =  12.0537\n",
      "testing  :  1882  accuracy =   0.9214  loss =  12.3518\n",
      "testing  :  1883  accuracy =   0.9210  loss =  12.22\n",
      "testing  :  1884  accuracy =   0.9207  loss =  12.2649\n",
      "testing  :  1885  accuracy =   0.9218  loss =  12.1225\n",
      "testing  :  1886  accuracy =   0.9224  loss =  11.9067\n",
      "testing  :  1887  accuracy =   0.9227  loss =  11.902\n",
      "testing  :  1888  accuracy =   0.9221  loss =  11.9448\n",
      "testing  :  1889  accuracy =   0.9211  loss =  12.0757\n",
      "testing  :  1890  accuracy =   0.9220  loss =  11.9904\n",
      "testing  :  1891  accuracy =   0.9221  loss =  11.9573\n",
      "testing  :  1892  accuracy =   0.9227  loss =  11.9405\n",
      "testing  :  1893  accuracy =   0.9217  loss =  11.9635\n",
      "testing  :  1894  accuracy =   0.9225  loss =  11.9573\n",
      "testing  :  1895  accuracy =   0.9230  loss =  11.9978\n",
      "testing  :  1896  accuracy =   0.9212  loss =  12.0392\n",
      "testing  :  1897  accuracy =   0.9203  loss =  12.1102\n",
      "testing  :  1898  accuracy =   0.9194  loss =  12.2804\n",
      "testing  :  1899  accuracy =   0.9215  loss =  12.0296\n",
      "testing  :  1900  accuracy =   0.9198  loss =  12.0633\n",
      "testing  :  1901  accuracy =   0.9204  loss =  12.0474\n",
      "testing  :  1902  accuracy =   0.9209  loss =  12.0454\n",
      "testing  :  1903  accuracy =   0.9223  loss =  11.9843\n",
      "testing  :  1904  accuracy =   0.9220  loss =  11.9757\n",
      "testing  :  1905  accuracy =   0.9225  loss =  12.0343\n",
      "testing  :  1906  accuracy =   0.9208  loss =  12.055\n",
      "testing  :  1907  accuracy =   0.9219  loss =  12.0832\n",
      "testing  :  1908  accuracy =   0.9218  loss =  12.0793\n",
      "testing  :  1909  accuracy =   0.9230  loss =  12.0396\n",
      "testing  :  1910  accuracy =   0.9237  loss =  11.9227\n",
      "testing  :  1911  accuracy =   0.9228  loss =  12.0182\n",
      "testing  :  1912  accuracy =   0.9226  loss =  12.0196\n",
      "testing  :  1913  accuracy =   0.9231  loss =  11.9673\n",
      "testing  :  1914  accuracy =   0.9230  loss =  11.9028\n",
      "testing  :  1915  accuracy =   0.9227  loss =  12.0938\n",
      "testing  :  1916  accuracy =   0.9220  loss =  12.2108\n",
      "testing  :  1917  accuracy =   0.9227  loss =  12.1411\n",
      "testing  :  1918  accuracy =   0.9215  loss =  12.0387\n",
      "testing  :  1919  accuracy =   0.9214  loss =  12.0971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing  :  1920  accuracy =   0.9218  loss =  12.2115\n",
      "testing  :  1921  accuracy =   0.9212  loss =  12.0309\n",
      "testing  :  1922  accuracy =   0.9232  loss =  12.0456\n",
      "testing  :  1923  accuracy =   0.9232  loss =  11.953\n",
      "testing  :  1924  accuracy =   0.9227  loss =  12.0059\n",
      "testing  :  1925  accuracy =   0.9215  loss =  12.0087\n",
      "testing  :  1926  accuracy =   0.9217  loss =  12.1619\n",
      "testing  :  1927  accuracy =   0.9226  loss =  12.0724\n",
      "testing  :  1928  accuracy =   0.9226  loss =  11.9997\n",
      "testing  :  1929  accuracy =   0.9235  loss =  11.9152\n",
      "testing  :  1930  accuracy =   0.9225  loss =  11.9004\n",
      "testing  :  1931  accuracy =   0.9208  loss =  12.0531\n",
      "testing  :  1932  accuracy =   0.9220  loss =  12.0908\n",
      "testing  :  1933  accuracy =   0.9219  loss =  12.0977\n",
      "testing  :  1934  accuracy =   0.9217  loss =  12.0759\n",
      "testing  :  1935  accuracy =   0.9209  loss =  12.0472\n",
      "testing  :  1936  accuracy =   0.9222  loss =  11.9612\n",
      "testing  :  1937  accuracy =   0.9209  loss =  12.0574\n",
      "testing  :  1938  accuracy =   0.9222  loss =  11.9837\n",
      "testing  :  1939  accuracy =   0.9224  loss =  12.1138\n",
      "testing  :  1940  accuracy =   0.9225  loss =  12.0242\n",
      "testing  :  1941  accuracy =   0.9229  loss =  11.9778\n",
      "testing  :  1942  accuracy =   0.9233  loss =  11.9291\n",
      "testing  :  1943  accuracy =   0.9229  loss =  11.9487\n",
      "testing  :  1944  accuracy =   0.9214  loss =  11.9931\n",
      "testing  :  1945  accuracy =   0.9217  loss =  12.0402\n",
      "testing  :  1946  accuracy =   0.9214  loss =  12.136\n",
      "testing  :  1947  accuracy =   0.9199  loss =  12.3659\n",
      "testing  :  1948  accuracy =   0.9221  loss =  12.0867\n",
      "testing  :  1949  accuracy =   0.9234  loss =  11.939\n",
      "testing  :  1950  accuracy =   0.9227  loss =  12.0408\n",
      "testing  :  1951  accuracy =   0.9245  loss =  11.9438\n",
      "testing  :  1952  accuracy =   0.9237  loss =  11.9728\n",
      "testing  :  1953  accuracy =   0.9235  loss =  11.8847\n",
      "testing  :  1954  accuracy =   0.9241  loss =  11.933\n",
      "testing  :  1955  accuracy =   0.9230  loss =  12.0838\n",
      "testing  :  1956  accuracy =   0.9204  loss =  12.2496\n",
      "testing  :  1957  accuracy =   0.9226  loss =  12.0234\n",
      "testing  :  1958  accuracy =   0.9187  loss =  12.3935\n",
      "testing  :  1959  accuracy =   0.9211  loss =  12.0163\n",
      "testing  :  1960  accuracy =   0.9194  loss =  12.1864\n",
      "testing  :  1961  accuracy =   0.9203  loss =  12.1422\n",
      "testing  :  1962  accuracy =   0.9222  loss =  12.0151\n",
      "testing  :  1963  accuracy =   0.9224  loss =  12.0081\n",
      "testing  :  1964  accuracy =   0.9228  loss =  11.9365\n",
      "testing  :  1965  accuracy =   0.9222  loss =  11.9926\n",
      "testing  :  1966  accuracy =   0.9222  loss =  11.9443\n",
      "testing  :  1967  accuracy =   0.9225  loss =  11.9882\n",
      "testing  :  1968  accuracy =   0.9229  loss =  11.9173\n",
      "testing  :  1969  accuracy =   0.9230  loss =  11.8809\n",
      "testing  :  1970  accuracy =   0.9220  loss =  11.9206\n",
      "testing  :  1971  accuracy =   0.9227  loss =  11.8997\n",
      "testing  :  1972  accuracy =   0.9221  loss =  11.9053\n",
      "testing  :  1973  accuracy =   0.9222  loss =  11.9175\n",
      "testing  :  1974  accuracy =   0.9222  loss =  12.0558\n",
      "testing  :  1975  accuracy =   0.9245  loss =  11.8514\n",
      "testing  :  1976  accuracy =   0.9251  loss =  11.7779\n",
      "testing  :  1977  accuracy =   0.9240  loss =  11.8755\n",
      "testing  :  1978  accuracy =   0.9257  loss =  11.7799\n",
      "testing  :  1979  accuracy =   0.9229  loss =  12.0477\n",
      "testing  :  1980  accuracy =   0.9249  loss =  11.7991\n",
      "testing  :  1981  accuracy =   0.9258  loss =  11.772\n",
      "testing  :  1982  accuracy =   0.9240  loss =  11.8598\n",
      "testing  :  1983  accuracy =   0.9243  loss =  11.8182\n",
      "testing  :  1984  accuracy =   0.9249  loss =  11.8041\n",
      "testing  :  1985  accuracy =   0.9242  loss =  11.8488\n",
      "testing  :  1986  accuracy =   0.9233  loss =  11.8685\n",
      "testing  :  1987  accuracy =   0.9250  loss =  11.8052\n",
      "testing  :  1988  accuracy =   0.9252  loss =  11.8084\n",
      "testing  :  1989  accuracy =   0.9252  loss =  11.8001\n",
      "testing  :  1990  accuracy =   0.9235  loss =  11.8819\n",
      "testing  :  1991  accuracy =   0.9237  loss =  11.9482\n",
      "testing  :  1992  accuracy =   0.9240  loss =  11.8884\n",
      "testing  :  1993  accuracy =   0.9236  loss =  11.844\n",
      "testing  :  1994  accuracy =   0.9244  loss =  11.8095\n",
      "testing  :  1995  accuracy =   0.9236  loss =  11.827\n",
      "testing  :  1996  accuracy =   0.9234  loss =  11.888\n",
      "testing  :  1997  accuracy =   0.9238  loss =  11.8574\n",
      "testing  :  1998  accuracy =   0.9234  loss =  11.8719\n",
      "testing  :  1999  accuracy =   0.9226  loss =  12.0216\n",
      "testing  :  2000  accuracy =   0.9220  loss =  12.0551\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19f0bc77f28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19f0bd2ecf8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# encoding: UTF-8\n",
    "# original source : https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd/tree/master/tensorflow-mnist-tutorial\n",
    "# 2018.12 : modified by Seungkwon Lee(kahnlee@naver.com)\n",
    "\n",
    "import tensorflow as tf\n",
    "import mnistdata\n",
    "import math\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "# neural network with 1 layer of 10 softmax neurons\n",
    "#\n",
    "#                 (input data, flattened pixels)       X [batch, 784]        # 784 = 28 * 28\n",
    "# \\x/x\\x/x\\x/x\\x/x\\x/    -- fully connected layer (softmax)      W [784, 10]     b[10]\n",
    "#                                                        Y [batch, 10]\n",
    "\n",
    "# The model is:\n",
    "#\n",
    "# Y = softmax( X * W + b)\n",
    "#              X: matrix for 100 grayscale images of 28x28 pixels, flattened (there are 100 images in a mini-batch)\n",
    "#              W: weight matrix with 784 lines and 10 columns\n",
    "#              b: bias vector with 10 dimensions\n",
    "#              +: add with broadcasting: adds the vector to each line of the matrix (numpy)\n",
    "#              softmax(matrix) applies softmax on each line\n",
    "#              softmax(line) applies an exp to each value then divides by the norm of the resulting line\n",
    "#              Y: output matrix with 100 lines and 10 columns\n",
    "\n",
    "# Download images and labels into mnist.test (10K images+labels) and mnist.train (60K images+labels)\n",
    "mnist = mnistdata.read_data_sets(\"data\", one_hot=True, reshape=False)\n",
    "\n",
    "# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "# correct answers will go here\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "# weights W[784, 10]   784=28*28\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "# biases b[10]\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# flatten the images into a single line of pixels\n",
    "# -1 in the shape definition means \"the only possible dimension that will preserve the number of elements\"\n",
    "XX = tf.reshape(X, [-1, 784])\n",
    "\n",
    "# The model\n",
    "Y = tf.nn.softmax(tf.matmul(XX, W) + b)\n",
    "\n",
    "# loss function: MSE\n",
    "loss = tf.reduce_mean(tf.squared_difference(Y, Y_)) * 1000\n",
    "\n",
    "\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# training, learning rate = 0.005\n",
    "train_step = tf.train.GradientDescentOptimizer(0.005).minimize(loss)\n",
    "\n",
    "# save model\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver(max_to_keep=4)\n",
    "    \n",
    "    # init\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "#     saver.save(sess, './model/mnist_model')\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "# run\n",
    "for i in range(2000 + 1) : #2000\n",
    "\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
    "    a, c = sess.run([accuracy, loss], feed_dict={X : batch_X, Y_ : batch_Y})\n",
    "    # print(\"training : \", i, a,c)\n",
    "#     print(\"training : \", i, ' accuracy = ', '{:7.4f}'.format(a), ' loss = ', c)\n",
    "    train_acc_list.append(a)\n",
    "    train_loss_list.append(c)\n",
    "\n",
    "    # test_batch_X, test_batch_Y = mnist.test.next_batch(100)  ==> never use mini batch!!\n",
    "    # sess.run(train_step, feed_dict={X: test_batch_X, Y_: test_batch_Y})  ==> never run train_step on test data!!\n",
    "    a, c = sess.run([accuracy, loss], feed_dict={X: mnist.test.images, Y_: mnist.test.labels})\n",
    "    # print(\"testing  : \",i, a, c)\n",
    "    print(\"testing  : \",i, ' accuracy = ', '{:7.4f}'.format(a), ' loss = ', c)\n",
    "    test_acc_list.append(a)\n",
    "    test_loss_list.append(c)\n",
    "\n",
    "    sess.run(train_step, feed_dict={X : batch_X, Y_ : batch_Y} )\n",
    "    if(i % 500 == 0 and i != 0 ):\n",
    "        saver.save(sess, './model/mnist_model', global_step=i)\n",
    "\n",
    "\n",
    "# draw graph : accuracy\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.figure(1) \n",
    "plt.plot(x, train_acc_list,  label='train', markevery=1)\n",
    "plt.plot(x, test_acc_list, label='test', markevery=1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "# plt.show()\n",
    "\n",
    "# draw graph : loss\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.figure(2) \n",
    "plt.plot(x, train_loss_list,  label='train', markevery=1)\n",
    "plt.plot(x, test_loss_list, label='test', markevery=1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(0, 100)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
